







.version 5.0
.target sm_61
.address_size 64


.func (.param .b64 func_retval0) __internal_accurate_pow
(
.param .b64 __internal_accurate_pow_param_0,
.param .b64 __internal_accurate_pow_param_1
)
;
.global .align 1 .b8 __T20[38] = {84, 32, 112, 111, 119, 105, 40, 84, 44, 32, 84, 41, 32, 91, 119, 105, 116, 104, 32, 84, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 93, 0};
.global .align 1 .b8 __T21[36] = {84, 32, 112, 111, 119, 105, 40, 84, 44, 32, 84, 41, 32, 91, 119, 105, 116, 104, 32, 84, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 93, 0};
.global .align 1 .b8 __T22[30] = {84, 32, 112, 111, 119, 105, 40, 84, 44, 32, 84, 41, 32, 91, 119, 105, 116, 104, 32, 84, 32, 61, 32, 115, 104, 111, 114, 116, 93, 0};
.global .align 1 .b8 __T23[28] = {84, 32, 112, 111, 119, 105, 40, 84, 44, 32, 84, 41, 32, 91, 119, 105, 116, 104, 32, 84, 32, 61, 32, 105, 110, 116, 93, 0};
.global .align 1 .b8 __T24[29] = {84, 32, 112, 111, 119, 105, 40, 84, 44, 32, 84, 41, 32, 91, 119, 105, 116, 104, 32, 84, 32, 61, 32, 108, 111, 110, 103, 93, 0};

.visible .entry _Z12LRNFillScaleIN3c104HalfEfEviPKT_iiiiiS2_S2_PS2_(
.param .u32 _Z12LRNFillScaleIN3c104HalfEfEviPKT_iiiiiS2_S2_PS2__param_0,
.param .u64 _Z12LRNFillScaleIN3c104HalfEfEviPKT_iiiiiS2_S2_PS2__param_1,
.param .u32 _Z12LRNFillScaleIN3c104HalfEfEviPKT_iiiiiS2_S2_PS2__param_2,
.param .u32 _Z12LRNFillScaleIN3c104HalfEfEviPKT_iiiiiS2_S2_PS2__param_3,
.param .u32 _Z12LRNFillScaleIN3c104HalfEfEviPKT_iiiiiS2_S2_PS2__param_4,
.param .u32 _Z12LRNFillScaleIN3c104HalfEfEviPKT_iiiiiS2_S2_PS2__param_5,
.param .u32 _Z12LRNFillScaleIN3c104HalfEfEviPKT_iiiiiS2_S2_PS2__param_6,
.param .align 2 .b8 _Z12LRNFillScaleIN3c104HalfEfEviPKT_iiiiiS2_S2_PS2__param_7[2],
.param .align 2 .b8 _Z12LRNFillScaleIN3c104HalfEfEviPKT_iiiiiS2_S2_PS2__param_8[2],
.param .u64 _Z12LRNFillScaleIN3c104HalfEfEviPKT_iiiiiS2_S2_PS2__param_9
)
.maxntid 1024, 1, 1
{
.reg .pred %p<15>;
.reg .b16 %rs<27>;
.reg .f32 %f<51>;
.reg .b32 %r<66>;
.reg .b64 %rd<34>;


ld.param.u32 %r15, [_Z12LRNFillScaleIN3c104HalfEfEviPKT_iiiiiS2_S2_PS2__param_0];
ld.param.u64 %rd2, [_Z12LRNFillScaleIN3c104HalfEfEviPKT_iiiiiS2_S2_PS2__param_1];
ld.param.u32 %r16, [_Z12LRNFillScaleIN3c104HalfEfEviPKT_iiiiiS2_S2_PS2__param_3];
ld.param.u32 %r17, [_Z12LRNFillScaleIN3c104HalfEfEviPKT_iiiiiS2_S2_PS2__param_4];
ld.param.u32 %r18, [_Z12LRNFillScaleIN3c104HalfEfEviPKT_iiiiiS2_S2_PS2__param_5];
ld.param.u32 %r19, [_Z12LRNFillScaleIN3c104HalfEfEviPKT_iiiiiS2_S2_PS2__param_6];
ld.param.u16 %rs3, [_Z12LRNFillScaleIN3c104HalfEfEviPKT_iiiiiS2_S2_PS2__param_7];
ld.param.u16 %rs4, [_Z12LRNFillScaleIN3c104HalfEfEviPKT_iiiiiS2_S2_PS2__param_8];
ld.param.u64 %rd3, [_Z12LRNFillScaleIN3c104HalfEfEviPKT_iiiiiS2_S2_PS2__param_9];
mov.u32 %r20, %ctaid.x;
mov.u32 %r21, %ntid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r55, %r21, %r20, %r22;
setp.ge.s32	%p1, %r55, %r15;
@%p1 bra BB0_13;

add.s32 %r23, %r19, -1;
shr.u32 %r24, %r23, 31;
add.s32 %r25, %r23, %r24;
shr.s32 %r26, %r25, 1;
sub.s32 %r27, %r19, %r26;
add.s32 %r2, %r27, -1;

BB0_2:
div.s32 %r30, %r55, %r18;
rem.s32 %r31, %r30, %r17;
div.s32 %r32, %r30, %r17;
mul.lo.s32 %r33, %r17, %r16;
mad.lo.s32 %r34, %r33, %r32, %r31;
rem.s32 %r35, %r55, %r18;
mad.lo.s32 %r36, %r34, %r18, %r35;
cvt.s64.s32	%rd1, %r36;
setp.gt.s32	%p2, %r16, 0;
setp.gt.s32	%p3, %r2, 0;
and.pred %p4, %p3, %p2;
mov.f32 %f49, 0f00000000;
mov.u32 %r64, 0;
mov.f32 %f50, %f49;
mov.u32 %r65, %r64;
@!%p4 bra BB0_4;
bra.uni BB0_3;

BB0_3:
mul.lo.s32 %r37, %r18, %r17;
mul.lo.s32 %r38, %r65, %r37;
cvt.s64.s32	%rd4, %r38;
add.s64 %rd5, %rd4, %rd1;
cvta.to.global.u64 %rd6, %rd2;
shl.b64 %rd7, %rd5, 1;
add.s64 %rd8, %rd6, %rd7;
ld.global.u16 %rs5, [%rd8];

	{ cvt.f32.f16 %f14, %rs5;}


	ld.global.u16 %rs6, [%rd8];

	{ cvt.f32.f16 %f15, %rs6;}


	mul.f32 %f16, %f14, %f15;

	{ cvt.rn.f16.f32 %rs7, %f16;}


	
	{ cvt.f32.f16 %f17, %rs7;}


	add.f32 %f50, %f50, %f17;
add.s32 %r65, %r65, 1;
setp.lt.s32	%p5, %r65, %r2;
setp.lt.s32	%p6, %r65, %r16;
and.pred %p7, %p5, %p6;
mov.u32 %r64, %r65;
mov.f32 %f49, %f50;
@%p7 bra BB0_3;

BB0_4:
mov.f32 %f47, %f49;
mov.u32 %r63, %r64;
setp.ge.s32	%p8, %r63, %r16;
mov.u32 %r62, %r63;
mov.f32 %f46, %f47;
@%p8 bra BB0_8;

BB0_5:
mov.f32 %f4, %f47;
mul.lo.s32 %r39, %r18, %r17;
mul.lo.s32 %r40, %r63, %r39;
cvt.s64.s32	%rd9, %r40;
add.s64 %rd10, %rd9, %rd1;
cvta.to.global.u64 %rd11, %rd2;
shl.b64 %rd12, %rd10, 1;
add.s64 %rd13, %rd11, %rd12;
ld.global.u16 %rs9, [%rd13];

	{ cvt.f32.f16 %f18, %rs9;}


	ld.global.u16 %rs10, [%rd13];

	{ cvt.f32.f16 %f19, %rs10;}


	mul.f32 %f20, %f18, %f19;

	{ cvt.rn.f16.f32 %rs11, %f20;}


	
	{ cvt.f32.f16 %f21, %rs11;}


	add.f32 %f48, %f4, %f21;
sub.s32 %r8, %r63, %r19;
setp.lt.s32	%p9, %r8, 0;
@%p9 bra BB0_7;

mul.lo.s32 %r42, %r8, %r39;
cvt.s64.s32	%rd14, %r42;
add.s64 %rd15, %rd14, %rd1;
shl.b64 %rd17, %rd15, 1;
add.s64 %rd18, %rd11, %rd17;
ld.global.u16 %rs13, [%rd18];

	{ cvt.f32.f16 %f22, %rs13;}


	ld.global.u16 %rs14, [%rd18];

	{ cvt.f32.f16 %f23, %rs14;}


	mul.f32 %f24, %f22, %f23;

	{ cvt.rn.f16.f32 %rs15, %f24;}


	
	{ cvt.f32.f16 %f25, %rs15;}


	sub.f32 %f48, %f48, %f25;

BB0_7:
mov.f32 %f47, %f48;
sub.s32 %r44, %r63, %r2;
mul.lo.s32 %r45, %r44, %r39;
cvt.s64.s32	%rd19, %r45;
add.s64 %rd20, %rd19, %rd1;

	{ cvt.f32.f16 %f26, %rs3;}


	
	{ cvt.f32.f16 %f27, %rs4;}


	fma.rn.f32 %f28, %f47, %f26, %f27;

	{ cvt.rn.f16.f32 %rs19, %f28;}


	cvta.to.global.u64 %rd21, %rd3;
shl.b64 %rd22, %rd20, 1;
add.s64 %rd23, %rd21, %rd22;
st.global.u16 [%rd23], %rs19;
add.s32 %r63, %r63, 1;
setp.lt.s32	%p10, %r63, %r16;
mov.u32 %r62, %r63;
mov.f32 %f46, %f47;
@%p10 bra BB0_5;

BB0_8:
mov.f32 %f44, %f46;
mov.u32 %r61, %r62;
add.s32 %r46, %r2, %r16;
setp.ge.s32	%p11, %r61, %r46;
@%p11 bra BB0_12;

BB0_9:
mov.f32 %f42, %f44;
mov.f32 %f45, %f42;
sub.s32 %r12, %r61, %r19;
setp.lt.s32	%p12, %r12, 0;
@%p12 bra BB0_11;

mul.lo.s32 %r47, %r18, %r17;
mul.lo.s32 %r48, %r12, %r47;
cvt.s64.s32	%rd24, %r48;
add.s64 %rd25, %rd24, %rd1;
cvta.to.global.u64 %rd26, %rd2;
shl.b64 %rd27, %rd25, 1;
add.s64 %rd28, %rd26, %rd27;
ld.global.u16 %rs20, [%rd28];

	{ cvt.f32.f16 %f29, %rs20;}


	ld.global.u16 %rs21, [%rd28];

	{ cvt.f32.f16 %f30, %rs21;}


	mul.f32 %f31, %f29, %f30;

	{ cvt.rn.f16.f32 %rs22, %f31;}


	
	{ cvt.f32.f16 %f32, %rs22;}


	sub.f32 %f45, %f45, %f32;

BB0_11:
mov.f32 %f44, %f45;
mul.lo.s32 %r49, %r18, %r17;
sub.s32 %r50, %r61, %r2;
mul.lo.s32 %r51, %r50, %r49;
cvt.s64.s32	%rd29, %r51;
add.s64 %rd30, %rd29, %rd1;

	{ cvt.f32.f16 %f33, %rs3;}


	
	{ cvt.f32.f16 %f34, %rs4;}


	fma.rn.f32 %f35, %f44, %f33, %f34;

	{ cvt.rn.f16.f32 %rs26, %f35;}


	cvta.to.global.u64 %rd31, %rd3;
shl.b64 %rd32, %rd30, 1;
add.s64 %rd33, %rd31, %rd32;
st.global.u16 [%rd33], %rs26;
add.s32 %r61, %r61, 1;
setp.lt.s32	%p13, %r61, %r46;
@%p13 bra BB0_9;

BB0_12:
mov.u32 %r53, %nctaid.x;
mad.lo.s32 %r55, %r53, %r21, %r55;
setp.lt.s32	%p14, %r55, %r15;
@%p14 bra BB0_2;

BB0_13:
ret;
}


.visible .entry _Z16LRNComputeOutputIN3c104HalfEEviPKT_S4_S2_PS2_(
.param .u32 _Z16LRNComputeOutputIN3c104HalfEEviPKT_S4_S2_PS2__param_0,
.param .u64 _Z16LRNComputeOutputIN3c104HalfEEviPKT_S4_S2_PS2__param_1,
.param .u64 _Z16LRNComputeOutputIN3c104HalfEEviPKT_S4_S2_PS2__param_2,
.param .align 2 .b8 _Z16LRNComputeOutputIN3c104HalfEEviPKT_S4_S2_PS2__param_3[2],
.param .u64 _Z16LRNComputeOutputIN3c104HalfEEviPKT_S4_S2_PS2__param_4
)
{
.reg .pred %p<31>;
.reg .b16 %rs<10>;
.reg .f32 %f<111>;
.reg .b32 %r<33>;
.reg .b64 %rd<13>;


ld.param.u32 %r4, [_Z16LRNComputeOutputIN3c104HalfEEviPKT_S4_S2_PS2__param_0];
ld.param.u64 %rd2, [_Z16LRNComputeOutputIN3c104HalfEEviPKT_S4_S2_PS2__param_1];
ld.param.u64 %rd3, [_Z16LRNComputeOutputIN3c104HalfEEviPKT_S4_S2_PS2__param_2];
ld.param.u64 %rd4, [_Z16LRNComputeOutputIN3c104HalfEEviPKT_S4_S2_PS2__param_4];
mov.u32 %r5, %ctaid.x;
mov.u32 %r6, %ntid.x;
mov.u32 %r7, %tid.x;
mad.lo.s32 %r32, %r6, %r5, %r7;
setp.ge.s32	%p2, %r32, %r4;
@%p2 bra BB1_16;

cvta.to.global.u64 %rd5, %rd3;
cvta.to.global.u64 %rd8, %rd2;
cvta.to.global.u64 %rd11, %rd4;

BB1_2:
mov.u32 %r2, %r32;
ld.param.u16 %rs9, [_Z16LRNComputeOutputIN3c104HalfEEviPKT_S4_S2_PS2__param_3];
cvt.s64.s32	%rd1, %r2;
mul.wide.s32 %rd6, %r2, 2;
add.s64 %rd7, %rd5, %rd6;
ld.global.u16 %rs3, [%rd7];

	{ cvt.f32.f16 %f18, %rs3;}


	
	{ cvt.f32.f16 %f19, %rs9;}


	mul.f32 %f24, %f19, 0f3F000000;
cvt.rzi.f32.f32	%f25, %f24;
fma.rn.f32 %f26, %f25, 0fC0000000, %f19;
abs.f32 %f3, %f26;
abs.f32 %f4, %f18;
setp.lt.f32	%p3, %f4, 0f00800000;
mul.f32 %f27, %f4, 0f4B800000;
selp.f32	%f28, 0fC3170000, 0fC2FE0000, %p3;
selp.f32	%f29, %f27, %f4, %p3;
mov.b32 %r8, %f29;
and.b32 %r9, %r8, 8388607;
or.b32 %r10, %r9, 1065353216;
mov.b32 %f30, %r10;
shr.u32 %r11, %r8, 23;
cvt.rn.f32.u32	%f31, %r11;
add.f32 %f32, %f28, %f31;
setp.gt.f32	%p4, %f30, 0f3FB504F3;
mul.f32 %f33, %f30, 0f3F000000;
add.f32 %f34, %f32, 0f3F800000;
selp.f32	%f35, %f33, %f30, %p4;
selp.f32	%f36, %f34, %f32, %p4;
add.f32 %f37, %f35, 0fBF800000;
add.f32 %f21, %f35, 0f3F800000;

	rcp.approx.ftz.f32 %f20,%f21;

	add.f32 %f38, %f37, %f37;
mul.f32 %f39, %f20, %f38;
mul.f32 %f40, %f39, %f39;
mov.f32 %f41, 0f3C4CAF63;
mov.f32 %f42, 0f3B18F0FE;
fma.rn.f32 %f43, %f42, %f40, %f41;
mov.f32 %f44, 0f3DAAAABD;
fma.rn.f32 %f45, %f43, %f40, %f44;
mul.rn.f32 %f46, %f45, %f40;
mul.rn.f32 %f47, %f46, %f39;
sub.f32 %f48, %f37, %f39;
neg.f32 %f49, %f39;
add.f32 %f50, %f48, %f48;
fma.rn.f32 %f51, %f49, %f37, %f50;
mul.rn.f32 %f52, %f20, %f51;
add.f32 %f53, %f47, %f39;
sub.f32 %f54, %f39, %f53;
add.f32 %f55, %f47, %f54;
add.f32 %f56, %f52, %f55;
add.f32 %f57, %f53, %f56;
sub.f32 %f58, %f53, %f57;
add.f32 %f59, %f56, %f58;
mov.f32 %f60, 0f3F317200;
mul.rn.f32 %f61, %f36, %f60;
mov.f32 %f62, 0f35BFBE8E;
mul.rn.f32 %f63, %f36, %f62;
add.f32 %f64, %f61, %f57;
sub.f32 %f65, %f61, %f64;
add.f32 %f66, %f57, %f65;
add.f32 %f67, %f59, %f66;
add.f32 %f68, %f63, %f67;
add.f32 %f69, %f64, %f68;
sub.f32 %f70, %f64, %f69;
add.f32 %f71, %f68, %f70;
abs.f32 %f5, %f19;
setp.gt.f32	%p5, %f5, 0f77F684DF;
mul.f32 %f72, %f19, 0f39000000;
selp.f32	%f73, %f72, %f19, %p5;
mul.rn.f32 %f74, %f73, %f69;
neg.f32 %f75, %f74;
fma.rn.f32 %f76, %f73, %f69, %f75;
fma.rn.f32 %f77, %f73, %f71, %f76;
mov.f32 %f78, 0f00000000;
fma.rn.f32 %f79, %f78, %f69, %f77;
add.rn.f32 %f80, %f74, %f79;
neg.f32 %f81, %f80;
add.rn.f32 %f82, %f74, %f81;
add.rn.f32 %f83, %f82, %f79;
mov.b32 %r12, %f80;
setp.eq.s32	%p6, %r12, 1118925336;
add.s32 %r13, %r12, -1;
mov.b32 %f84, %r13;
add.f32 %f85, %f83, 0f37000000;
selp.f32	%f86, %f84, %f80, %p6;
selp.f32	%f6, %f85, %f83, %p6;
mul.f32 %f87, %f86, 0f3FB8AA3B;
cvt.rzi.f32.f32	%f88, %f87;
mov.f32 %f89, 0fBF317200;
fma.rn.f32 %f90, %f88, %f89, %f86;
mov.f32 %f91, 0fB5BFBE8E;
fma.rn.f32 %f92, %f88, %f91, %f90;
mul.f32 %f23, %f92, 0f3FB8AA3B;

	ex2.approx.ftz.f32 %f22,%f23;

	add.f32 %f93, %f88, 0f00000000;
ex2.approx.f32 %f94, %f93;
mul.f32 %f95, %f22, %f94;
setp.lt.f32	%p7, %f86, 0fC2D20000;
selp.f32	%f96, 0f00000000, %f95, %p7;
setp.gt.f32	%p8, %f86, 0f42D20000;
selp.f32	%f109, 0f7F800000, %f96, %p8;
setp.eq.f32	%p9, %f109, 0f7F800000;
@%p9 bra BB1_4;

fma.rn.f32 %f109, %f109, %f6, %f109;

BB1_4:
setp.lt.f32	%p10, %f18, 0f00000000;
setp.eq.f32	%p11, %f3, 0f3F800000;
and.pred %p1, %p10, %p11;
mov.b32 %r14, %f109;
xor.b32 %r15, %r14, -2147483648;
mov.b32 %f97, %r15;
selp.f32	%f110, %f97, %f109, %p1;
setp.eq.f32	%p12, %f18, 0f00000000;
@%p12 bra BB1_7;
bra.uni BB1_5;

BB1_7:
add.f32 %f99, %f18, %f18;
mov.b32 %r16, %f99;
selp.b32	%r17, %r16, 0, %p11;
or.b32 %r18, %r17, 2139095040;
setp.lt.f32	%p16, %f19, 0f00000000;
selp.b32	%r19, %r18, %r17, %p16;
mov.b32 %f110, %r19;
bra.uni BB1_8;

BB1_5:
setp.geu.f32	%p13, %f18, 0f00000000;
@%p13 bra BB1_8;

cvt.rzi.f32.f32	%f98, %f19;
setp.neu.f32	%p14, %f98, %f19;
selp.f32	%f110, 0f7FFFFFFF, %f110, %p14;

BB1_8:
abs.f32 %f106, %f19;
add.f32 %f100, %f4, %f106;
mov.b32 %r20, %f100;
setp.lt.s32	%p17, %r20, 2139095040;
@%p17 bra BB1_15;

abs.f32 %f107, %f19;
setp.gtu.f32	%p18, %f4, 0f7F800000;
setp.gtu.f32	%p19, %f107, 0f7F800000;
or.pred %p20, %p18, %p19;
@%p20 bra BB1_14;
bra.uni BB1_10;

BB1_14:
add.f32 %f110, %f18, %f19;
bra.uni BB1_15;

BB1_10:
abs.f32 %f108, %f19;
setp.eq.f32	%p21, %f108, 0f7F800000;
@%p21 bra BB1_13;
bra.uni BB1_11;

BB1_13:
setp.gt.f32	%p24, %f4, 0f3F800000;
selp.b32	%r24, 2139095040, 0, %p24;
xor.b32 %r25, %r24, 2139095040;
setp.lt.f32	%p25, %f19, 0f00000000;
selp.b32	%r26, %r25, %r24, %p25;
mov.b32 %f101, %r26;
setp.eq.f32	%p26, %f18, 0fBF800000;
selp.f32	%f110, 0f3F800000, %f101, %p26;
bra.uni BB1_15;

BB1_11:
setp.neu.f32	%p22, %f4, 0f7F800000;
@%p22 bra BB1_15;

setp.ltu.f32	%p23, %f19, 0f00000000;
selp.b32	%r21, 0, 2139095040, %p23;
or.b32 %r22, %r21, -2147483648;
selp.b32	%r23, %r22, %r21, %p1;
mov.b32 %f110, %r23;

BB1_15:
ld.param.u32 %r31, [_Z16LRNComputeOutputIN3c104HalfEEviPKT_S4_S2_PS2__param_0];
mov.u32 %r30, %ntid.x;
setp.eq.f32	%p27, %f19, 0f00000000;
setp.eq.f32	%p28, %f18, 0f3F800000;
or.pred %p29, %p28, %p27;
selp.f32	%f102, 0f3F800000, %f110, %p29;

	{ cvt.rn.f16.f32 %rs5, %f102;}


	shl.b64 %rd9, %rd1, 1;
add.s64 %rd10, %rd8, %rd9;
ld.global.u16 %rs6, [%rd10];

	{ cvt.f32.f16 %f103, %rs6;}


	
	{ cvt.f32.f16 %f104, %rs5;}


	mul.f32 %f105, %f103, %f104;

	{ cvt.rn.f16.f32 %rs8, %f105;}


	add.s64 %rd12, %rd11, %rd9;
st.global.u16 [%rd12], %rs8;
mov.u32 %r28, %nctaid.x;
cvt.u32.u64	%r29, %rd1;
mad.lo.s32 %r32, %r28, %r30, %r29;
setp.lt.s32	%p30, %r32, %r31;
@%p30 bra BB1_2;

BB1_16:
ret;
}


.visible .entry _Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2_(
.param .u32 _Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_0,
.param .u64 _Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_1,
.param .u64 _Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_2,
.param .u64 _Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_3,
.param .u64 _Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_4,
.param .u32 _Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_5,
.param .u32 _Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_6,
.param .u32 _Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_7,
.param .u32 _Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_8,
.param .u32 _Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_9,
.param .align 2 .b8 _Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_10[2],
.param .align 2 .b8 _Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_11[2],
.param .u64 _Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_12
)
{
.reg .pred %p<71>;
.reg .b16 %rs<57>;
.reg .f32 %f<291>;
.reg .b32 %r<106>;
.reg .b64 %rd<69>;


ld.param.u32 %r15, [_Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_0];
ld.param.u64 %rd4, [_Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_1];
ld.param.u64 %rd5, [_Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_2];
ld.param.u64 %rd6, [_Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_3];
ld.param.u64 %rd7, [_Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_4];
ld.param.u32 %r16, [_Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_6];
ld.param.u32 %r17, [_Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_7];
ld.param.u32 %r18, [_Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_8];
ld.param.u32 %r19, [_Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_9];
ld.param.u16 %rs3, [_Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_10];
ld.param.u16 %rs4, [_Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_11];
ld.param.u64 %rd8, [_Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_12];
mov.u32 %r20, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r95, %r20, %r21, %r22;
setp.ge.s32	%p3, %r95, %r15;
@%p3 bra BB2_39;

add.s32 %r23, %r19, 1;
shr.u32 %r24, %r23, 31;
add.s32 %r25, %r23, %r24;
shr.s32 %r26, %r25, 1;
add.s32 %r2, %r26, -1;

BB2_2:
div.s32 %r29, %r95, %r18;
rem.s32 %r30, %r29, %r17;
div.s32 %r31, %r29, %r17;
mul.lo.s32 %r32, %r17, %r16;
mad.lo.s32 %r33, %r32, %r31, %r30;
rem.s32 %r34, %r95, %r18;
mad.lo.s32 %r35, %r33, %r18, %r34;
cvt.s64.s32	%rd1, %r35;
setp.gt.s32	%p4, %r16, 0;
setp.gt.s32	%p5, %r2, 0;
and.pred %p6, %p5, %p4;
mov.f32 %f287, 0f00000000;
mov.u32 %r104, 0;
mov.f32 %f288, %f287;
mov.u32 %r105, %r104;
@!%p6 bra BB2_4;
bra.uni BB2_3;

BB2_3:
mul.lo.s32 %r36, %r18, %r17;
mul.lo.s32 %r37, %r105, %r36;
cvt.s64.s32	%rd9, %r37;
add.s64 %rd10, %rd9, %rd1;
cvta.to.global.u64 %rd11, %rd7;
shl.b64 %rd12, %rd10, 1;
add.s64 %rd13, %rd11, %rd12;
ld.global.u16 %rs5, [%rd13];

	{ cvt.f32.f16 %f48, %rs5;}


	cvta.to.global.u64 %rd14, %rd5;
add.s64 %rd15, %rd14, %rd12;
ld.global.u16 %rs6, [%rd15];

	{ cvt.f32.f16 %f49, %rs6;}


	mul.f32 %f50, %f48, %f49;

	{ cvt.rn.f16.f32 %rs7, %f50;}


	
	{ cvt.f32.f16 %f51, %rs7;}


	cvta.to.global.u64 %rd16, %rd6;
add.s64 %rd17, %rd16, %rd12;
ld.global.u16 %rs9, [%rd17];

	{ cvt.f32.f16 %f52, %rs9;}


	div.rn.f32 %f53, %f51, %f52;

	{ cvt.rn.f16.f32 %rs10, %f53;}


	
	{ cvt.f32.f16 %f54, %rs10;}


	add.f32 %f288, %f288, %f54;
add.s32 %r105, %r105, 1;
setp.lt.s32	%p7, %r105, %r2;
setp.lt.s32	%p8, %r105, %r16;
and.pred %p9, %p7, %p8;
mov.u32 %r104, %r105;
mov.f32 %f287, %f288;
@%p9 bra BB2_3;

BB2_4:
mov.f32 %f285, %f287;
mov.u32 %r103, %r104;
setp.ge.s32	%p10, %r103, %r16;
mov.u32 %r102, %r103;
mov.f32 %f284, %f285;
@%p10 bra BB2_21;

BB2_5:
mul.lo.s32 %r38, %r18, %r17;
mul.lo.s32 %r39, %r103, %r38;
cvt.s64.s32	%rd18, %r39;
add.s64 %rd19, %rd18, %rd1;
cvta.to.global.u64 %rd20, %rd7;
shl.b64 %rd21, %rd19, 1;
add.s64 %rd22, %rd20, %rd21;
ld.global.u16 %rs12, [%rd22];

	{ cvt.f32.f16 %f55, %rs12;}


	cvta.to.global.u64 %rd23, %rd5;
add.s64 %rd24, %rd23, %rd21;
ld.global.u16 %rs13, [%rd24];

	{ cvt.f32.f16 %f56, %rs13;}


	mul.f32 %f57, %f55, %f56;

	{ cvt.rn.f16.f32 %rs14, %f57;}


	
	{ cvt.f32.f16 %f58, %rs14;}


	cvta.to.global.u64 %rd25, %rd6;
add.s64 %rd26, %rd25, %rd21;
ld.global.u16 %rs16, [%rd26];

	{ cvt.f32.f16 %f59, %rs16;}


	div.rn.f32 %f60, %f58, %f59;

	{ cvt.rn.f16.f32 %rs17, %f60;}


	
	{ cvt.f32.f16 %f61, %rs17;}


	add.f32 %f286, %f285, %f61;
sub.s32 %r8, %r103, %r19;
setp.lt.s32	%p11, %r8, 0;
@%p11 bra BB2_7;

cvta.to.global.u64 %rd68, %rd7;
mul.lo.s32 %r41, %r8, %r38;
cvt.s64.s32	%rd27, %r41;
add.s64 %rd28, %rd27, %rd1;
shl.b64 %rd30, %rd28, 1;
add.s64 %rd31, %rd68, %rd30;
ld.global.u16 %rs19, [%rd31];

	{ cvt.f32.f16 %f62, %rs19;}


	add.s64 %rd33, %rd23, %rd30;
ld.global.u16 %rs20, [%rd33];

	{ cvt.f32.f16 %f63, %rs20;}


	mul.f32 %f64, %f62, %f63;

	{ cvt.rn.f16.f32 %rs21, %f64;}


	
	{ cvt.f32.f16 %f65, %rs21;}


	add.s64 %rd35, %rd25, %rd30;
ld.global.u16 %rs23, [%rd35];

	{ cvt.f32.f16 %f66, %rs23;}


	div.rn.f32 %f67, %f65, %f66;

	{ cvt.rn.f16.f32 %rs24, %f67;}


	
	{ cvt.f32.f16 %f68, %rs24;}


	sub.f32 %f286, %f286, %f68;

BB2_7:
mov.f32 %f285, %f286;
sub.s32 %r43, %r103, %r2;
mul.lo.s32 %r44, %r43, %r38;
cvt.s64.s32	%rd36, %r44;
add.s64 %rd2, %rd36, %rd1;
shl.b64 %rd38, %rd2, 1;
add.s64 %rd39, %rd25, %rd38;
ld.global.u16 %rs26, [%rd39];

	{ cvt.f32.f16 %f69, %rs26;}


	
	{ cvt.f32.f16 %f70, %rs3;}


	mul.f32 %f75, %f70, 0f3F000000;
cvt.rzi.f32.f32	%f76, %f75;
fma.rn.f32 %f77, %f76, 0fC0000000, %f70;
abs.f32 %f10, %f77;
abs.f32 %f11, %f69;
setp.lt.f32	%p12, %f11, 0f00800000;
mul.f32 %f78, %f11, 0f4B800000;
selp.f32	%f79, 0fC3170000, 0fC2FE0000, %p12;
selp.f32	%f80, %f78, %f11, %p12;
mov.b32 %r45, %f80;
and.b32 %r46, %r45, 8388607;
or.b32 %r47, %r46, 1065353216;
mov.b32 %f81, %r47;
shr.u32 %r48, %r45, 23;
cvt.rn.f32.u32	%f82, %r48;
add.f32 %f83, %f79, %f82;
setp.gt.f32	%p13, %f81, 0f3FB504F3;
mul.f32 %f84, %f81, 0f3F000000;
add.f32 %f85, %f83, 0f3F800000;
selp.f32	%f86, %f84, %f81, %p13;
selp.f32	%f87, %f85, %f83, %p13;
add.f32 %f88, %f86, 0fBF800000;
add.f32 %f72, %f86, 0f3F800000;

	rcp.approx.ftz.f32 %f71,%f72;

	add.f32 %f89, %f88, %f88;
mul.f32 %f90, %f71, %f89;
mul.f32 %f91, %f90, %f90;
mov.f32 %f92, 0f3C4CAF63;
mov.f32 %f93, 0f3B18F0FE;
fma.rn.f32 %f94, %f93, %f91, %f92;
mov.f32 %f95, 0f3DAAAABD;
fma.rn.f32 %f96, %f94, %f91, %f95;
mul.rn.f32 %f97, %f96, %f91;
mul.rn.f32 %f98, %f97, %f90;
sub.f32 %f99, %f88, %f90;
neg.f32 %f100, %f90;
add.f32 %f101, %f99, %f99;
fma.rn.f32 %f102, %f100, %f88, %f101;
mul.rn.f32 %f103, %f71, %f102;
add.f32 %f104, %f98, %f90;
sub.f32 %f105, %f90, %f104;
add.f32 %f106, %f98, %f105;
add.f32 %f107, %f103, %f106;
add.f32 %f108, %f104, %f107;
sub.f32 %f109, %f104, %f108;
add.f32 %f110, %f107, %f109;
mov.f32 %f111, 0f3F317200;
mul.rn.f32 %f112, %f87, %f111;
mov.f32 %f113, 0f35BFBE8E;
mul.rn.f32 %f114, %f87, %f113;
add.f32 %f115, %f112, %f108;
sub.f32 %f116, %f112, %f115;
add.f32 %f117, %f108, %f116;
add.f32 %f118, %f110, %f117;
add.f32 %f119, %f114, %f118;
add.f32 %f120, %f115, %f119;
sub.f32 %f121, %f115, %f120;
add.f32 %f122, %f119, %f121;
abs.f32 %f12, %f70;
setp.gt.f32	%p14, %f12, 0f77F684DF;
mul.f32 %f123, %f70, 0f39000000;
selp.f32	%f124, %f123, %f70, %p14;
mul.rn.f32 %f125, %f124, %f120;
neg.f32 %f126, %f125;
fma.rn.f32 %f127, %f124, %f120, %f126;
fma.rn.f32 %f128, %f124, %f122, %f127;
mov.f32 %f129, 0f00000000;
fma.rn.f32 %f130, %f129, %f120, %f128;
add.rn.f32 %f131, %f125, %f130;
neg.f32 %f132, %f131;
add.rn.f32 %f133, %f125, %f132;
add.rn.f32 %f134, %f133, %f130;
mov.b32 %r49, %f131;
setp.eq.s32	%p15, %r49, 1118925336;
add.s32 %r50, %r49, -1;
mov.b32 %f135, %r50;
add.f32 %f136, %f134, 0f37000000;
selp.f32	%f137, %f135, %f131, %p15;
selp.f32	%f13, %f136, %f134, %p15;
mul.f32 %f138, %f137, 0f3FB8AA3B;
cvt.rzi.f32.f32	%f139, %f138;
mov.f32 %f140, 0fBF317200;
fma.rn.f32 %f141, %f139, %f140, %f137;
mov.f32 %f142, 0fB5BFBE8E;
fma.rn.f32 %f143, %f139, %f142, %f141;
mul.f32 %f74, %f143, 0f3FB8AA3B;

	ex2.approx.ftz.f32 %f73,%f74;

	add.f32 %f144, %f139, 0f00000000;
ex2.approx.f32 %f145, %f144;
mul.f32 %f146, %f73, %f145;
setp.lt.f32	%p16, %f137, 0fC2D20000;
selp.f32	%f147, 0f00000000, %f146, %p16;
setp.gt.f32	%p17, %f137, 0f42D20000;
selp.f32	%f272, 0f7F800000, %f147, %p17;
setp.eq.f32	%p18, %f272, 0f7F800000;
@%p18 bra BB2_9;

fma.rn.f32 %f272, %f272, %f13, %f272;

BB2_9:
setp.lt.f32	%p19, %f69, 0f00000000;
setp.eq.f32	%p20, %f10, 0f3F800000;
and.pred %p1, %p19, %p20;
mov.b32 %r51, %f272;
xor.b32 %r52, %r51, -2147483648;
mov.b32 %f148, %r52;
selp.f32	%f273, %f148, %f272, %p1;
setp.eq.f32	%p21, %f69, 0f00000000;
@%p21 bra BB2_12;
bra.uni BB2_10;

BB2_12:
add.f32 %f150, %f69, %f69;
mov.b32 %r53, %f150;
selp.b32	%r54, %r53, 0, %p20;
or.b32 %r55, %r54, 2139095040;
setp.lt.f32	%p25, %f70, 0f00000000;
selp.b32	%r56, %r55, %r54, %p25;
mov.b32 %f273, %r56;
bra.uni BB2_13;

BB2_10:
setp.geu.f32	%p22, %f69, 0f00000000;
@%p22 bra BB2_13;

cvt.rzi.f32.f32	%f149, %f70;
setp.neu.f32	%p23, %f149, %f70;
selp.f32	%f273, 0f7FFFFFFF, %f273, %p23;

BB2_13:
abs.f32 %f269, %f70;
add.f32 %f151, %f11, %f269;
mov.b32 %r57, %f151;
setp.lt.s32	%p26, %r57, 2139095040;
@%p26 bra BB2_20;

abs.f32 %f270, %f70;
setp.gtu.f32	%p27, %f11, 0f7F800000;
setp.gtu.f32	%p28, %f270, 0f7F800000;
or.pred %p29, %p27, %p28;
@%p29 bra BB2_19;
bra.uni BB2_15;

BB2_19:
add.f32 %f273, %f69, %f70;
bra.uni BB2_20;

BB2_15:
abs.f32 %f271, %f70;
setp.eq.f32	%p30, %f271, 0f7F800000;
@%p30 bra BB2_18;
bra.uni BB2_16;

BB2_18:
setp.gt.f32	%p33, %f11, 0f3F800000;
selp.b32	%r61, 2139095040, 0, %p33;
xor.b32 %r62, %r61, 2139095040;
setp.lt.f32	%p34, %f70, 0f00000000;
selp.b32	%r63, %r62, %r61, %p34;
mov.b32 %f152, %r63;
setp.eq.f32	%p35, %f69, 0fBF800000;
selp.f32	%f273, 0f3F800000, %f152, %p35;
bra.uni BB2_20;

BB2_16:
setp.neu.f32	%p31, %f11, 0f7F800000;
@%p31 bra BB2_20;

setp.ltu.f32	%p32, %f70, 0f00000000;
selp.b32	%r58, 0, 2139095040, %p32;
or.b32 %r59, %r58, -2147483648;
selp.b32	%r60, %r59, %r58, %p1;
mov.b32 %f273, %r60;

BB2_20:
cvta.to.global.u64 %rd67, %rd7;
setp.eq.f32	%p36, %f70, 0f00000000;
setp.eq.f32	%p37, %f69, 0f3F800000;
or.pred %p38, %p37, %p36;
selp.f32	%f153, 0f3F800000, %f273, %p38;

	{ cvt.rn.f16.f32 %rs28, %f153;}


	add.s64 %rd42, %rd67, %rd38;
ld.global.u16 %rs29, [%rd42];

	{ cvt.f32.f16 %f154, %rs29;}


	
	{ cvt.f32.f16 %f155, %rs28;}


	mul.f32 %f156, %f154, %f155;

	{ cvt.rn.f16.f32 %rs31, %f156;}


	
	{ cvt.f32.f16 %f157, %rs4;}


	cvta.to.global.u64 %rd43, %rd4;
add.s64 %rd44, %rd43, %rd38;
ld.global.u16 %rs33, [%rd44];

	{ cvt.f32.f16 %f158, %rs33;}


	mul.f32 %f159, %f157, %f158;

	{ cvt.rn.f16.f32 %rs34, %f159;}


	
	{ cvt.f32.f16 %f160, %rs34;}


	mul.f32 %f163, %f285, %f160;

	{ cvt.f32.f16 %f161, %rs31;}


	sub.f32 %f162, %f161, %f163;

	{ cvt.rn.f16.f32 %rs37, %f162;}


	cvta.to.global.u64 %rd45, %rd8;
add.s64 %rd46, %rd45, %rd38;
st.global.u16 [%rd46], %rs37;
add.s32 %r103, %r103, 1;
setp.lt.s32	%p39, %r103, %r16;
mov.u32 %r102, %r103;
mov.f32 %f284, %f285;
@%p39 bra BB2_5;

BB2_21:
mov.f32 %f282, %f284;
mov.u32 %r101, %r102;
add.s32 %r64, %r2, %r16;
setp.ge.s32	%p40, %r101, %r64;
@%p40 bra BB2_38;

BB2_22:
mov.f32 %f283, %f282;
sub.s32 %r12, %r101, %r19;
setp.lt.s32	%p41, %r12, 0;
@%p41 bra BB2_24;

mul.lo.s32 %r65, %r18, %r17;
mul.lo.s32 %r66, %r12, %r65;
cvt.s64.s32	%rd47, %r66;
add.s64 %rd48, %rd47, %rd1;
cvta.to.global.u64 %rd49, %rd7;
shl.b64 %rd50, %rd48, 1;
add.s64 %rd51, %rd49, %rd50;
ld.global.u16 %rs38, [%rd51];

	{ cvt.f32.f16 %f164, %rs38;}


	cvta.to.global.u64 %rd52, %rd5;
add.s64 %rd53, %rd52, %rd50;
ld.global.u16 %rs39, [%rd53];

	{ cvt.f32.f16 %f165, %rs39;}


	mul.f32 %f166, %f164, %f165;

	{ cvt.rn.f16.f32 %rs40, %f166;}


	
	{ cvt.f32.f16 %f167, %rs40;}


	cvta.to.global.u64 %rd54, %rd6;
add.s64 %rd55, %rd54, %rd50;
ld.global.u16 %rs42, [%rd55];

	{ cvt.f32.f16 %f168, %rs42;}


	div.rn.f32 %f169, %f167, %f168;

	{ cvt.rn.f16.f32 %rs43, %f169;}


	
	{ cvt.f32.f16 %f170, %rs43;}


	sub.f32 %f283, %f283, %f170;

BB2_24:
mov.f32 %f282, %f283;
mul.lo.s32 %r67, %r18, %r17;
sub.s32 %r68, %r101, %r2;
mul.lo.s32 %r69, %r68, %r67;
cvt.s64.s32	%rd56, %r69;
add.s64 %rd3, %rd56, %rd1;
cvta.to.global.u64 %rd57, %rd6;
shl.b64 %rd58, %rd3, 1;
add.s64 %rd59, %rd57, %rd58;
ld.global.u16 %rs45, [%rd59];

	{ cvt.f32.f16 %f171, %rs45;}


	
	{ cvt.f32.f16 %f172, %rs3;}


	mul.f32 %f177, %f172, 0f3F000000;
cvt.rzi.f32.f32	%f178, %f177;
fma.rn.f32 %f179, %f178, 0fC0000000, %f172;
abs.f32 %f31, %f179;
abs.f32 %f32, %f171;
setp.lt.f32	%p42, %f32, 0f00800000;
mul.f32 %f180, %f32, 0f4B800000;
selp.f32	%f181, 0fC3170000, 0fC2FE0000, %p42;
selp.f32	%f182, %f180, %f32, %p42;
mov.b32 %r70, %f182;
and.b32 %r71, %r70, 8388607;
or.b32 %r72, %r71, 1065353216;
mov.b32 %f183, %r72;
shr.u32 %r73, %r70, 23;
cvt.rn.f32.u32	%f184, %r73;
add.f32 %f185, %f181, %f184;
setp.gt.f32	%p43, %f183, 0f3FB504F3;
mul.f32 %f186, %f183, 0f3F000000;
add.f32 %f187, %f185, 0f3F800000;
selp.f32	%f188, %f186, %f183, %p43;
selp.f32	%f189, %f187, %f185, %p43;
add.f32 %f190, %f188, 0fBF800000;
add.f32 %f174, %f188, 0f3F800000;

	rcp.approx.ftz.f32 %f173,%f174;

	add.f32 %f191, %f190, %f190;
mul.f32 %f192, %f173, %f191;
mul.f32 %f193, %f192, %f192;
mov.f32 %f194, 0f3C4CAF63;
mov.f32 %f195, 0f3B18F0FE;
fma.rn.f32 %f196, %f195, %f193, %f194;
mov.f32 %f197, 0f3DAAAABD;
fma.rn.f32 %f198, %f196, %f193, %f197;
mul.rn.f32 %f199, %f198, %f193;
mul.rn.f32 %f200, %f199, %f192;
sub.f32 %f201, %f190, %f192;
neg.f32 %f202, %f192;
add.f32 %f203, %f201, %f201;
fma.rn.f32 %f204, %f202, %f190, %f203;
mul.rn.f32 %f205, %f173, %f204;
add.f32 %f206, %f200, %f192;
sub.f32 %f207, %f192, %f206;
add.f32 %f208, %f200, %f207;
add.f32 %f209, %f205, %f208;
add.f32 %f210, %f206, %f209;
sub.f32 %f211, %f206, %f210;
add.f32 %f212, %f209, %f211;
mov.f32 %f213, 0f3F317200;
mul.rn.f32 %f214, %f189, %f213;
mov.f32 %f215, 0f35BFBE8E;
mul.rn.f32 %f216, %f189, %f215;
add.f32 %f217, %f214, %f210;
sub.f32 %f218, %f214, %f217;
add.f32 %f219, %f210, %f218;
add.f32 %f220, %f212, %f219;
add.f32 %f221, %f216, %f220;
add.f32 %f222, %f217, %f221;
sub.f32 %f223, %f217, %f222;
add.f32 %f224, %f221, %f223;
abs.f32 %f33, %f172;
setp.gt.f32	%p44, %f33, 0f77F684DF;
mul.f32 %f225, %f172, 0f39000000;
selp.f32	%f226, %f225, %f172, %p44;
mul.rn.f32 %f227, %f226, %f222;
neg.f32 %f228, %f227;
fma.rn.f32 %f229, %f226, %f222, %f228;
fma.rn.f32 %f230, %f226, %f224, %f229;
mov.f32 %f231, 0f00000000;
fma.rn.f32 %f232, %f231, %f222, %f230;
add.rn.f32 %f233, %f227, %f232;
neg.f32 %f234, %f233;
add.rn.f32 %f235, %f227, %f234;
add.rn.f32 %f236, %f235, %f232;
mov.b32 %r74, %f233;
setp.eq.s32	%p45, %r74, 1118925336;
add.s32 %r75, %r74, -1;
mov.b32 %f237, %r75;
add.f32 %f238, %f236, 0f37000000;
selp.f32	%f239, %f237, %f233, %p45;
selp.f32	%f34, %f238, %f236, %p45;
mul.f32 %f240, %f239, 0f3FB8AA3B;
cvt.rzi.f32.f32	%f241, %f240;
mov.f32 %f242, 0fBF317200;
fma.rn.f32 %f243, %f241, %f242, %f239;
mov.f32 %f244, 0fB5BFBE8E;
fma.rn.f32 %f245, %f241, %f244, %f243;
mul.f32 %f176, %f245, 0f3FB8AA3B;

	ex2.approx.ftz.f32 %f175,%f176;

	add.f32 %f246, %f241, 0f00000000;
ex2.approx.f32 %f247, %f246;
mul.f32 %f248, %f175, %f247;
setp.lt.f32	%p46, %f239, 0fC2D20000;
selp.f32	%f249, 0f00000000, %f248, %p46;
setp.gt.f32	%p47, %f239, 0f42D20000;
selp.f32	%f289, 0f7F800000, %f249, %p47;
setp.eq.f32	%p48, %f289, 0f7F800000;
@%p48 bra BB2_26;

fma.rn.f32 %f289, %f289, %f34, %f289;

BB2_26:
setp.lt.f32	%p49, %f171, 0f00000000;
setp.eq.f32	%p50, %f31, 0f3F800000;
and.pred %p2, %p49, %p50;
mov.b32 %r76, %f289;
xor.b32 %r77, %r76, -2147483648;
mov.b32 %f250, %r77;
selp.f32	%f290, %f250, %f289, %p2;
setp.eq.f32	%p51, %f171, 0f00000000;
@%p51 bra BB2_29;
bra.uni BB2_27;

BB2_29:
add.f32 %f252, %f171, %f171;
mov.b32 %r78, %f252;
selp.b32	%r79, %r78, 0, %p50;
or.b32 %r80, %r79, 2139095040;
setp.lt.f32	%p55, %f172, 0f00000000;
selp.b32	%r81, %r80, %r79, %p55;
mov.b32 %f290, %r81;
bra.uni BB2_30;

BB2_27:
setp.geu.f32	%p52, %f171, 0f00000000;
@%p52 bra BB2_30;

cvt.rzi.f32.f32	%f251, %f172;
setp.neu.f32	%p53, %f251, %f172;
selp.f32	%f290, 0f7FFFFFFF, %f290, %p53;

BB2_30:
abs.f32 %f266, %f172;
add.f32 %f253, %f32, %f266;
mov.b32 %r82, %f253;
setp.lt.s32	%p56, %r82, 2139095040;
@%p56 bra BB2_37;

abs.f32 %f267, %f172;
setp.gtu.f32	%p57, %f32, 0f7F800000;
setp.gtu.f32	%p58, %f267, 0f7F800000;
or.pred %p59, %p57, %p58;
@%p59 bra BB2_36;
bra.uni BB2_32;

BB2_36:
add.f32 %f290, %f171, %f172;
bra.uni BB2_37;

BB2_32:
abs.f32 %f268, %f172;
setp.eq.f32	%p60, %f268, 0f7F800000;
@%p60 bra BB2_35;
bra.uni BB2_33;

BB2_35:
setp.gt.f32	%p63, %f32, 0f3F800000;
selp.b32	%r86, 2139095040, 0, %p63;
xor.b32 %r87, %r86, 2139095040;
setp.lt.f32	%p64, %f172, 0f00000000;
selp.b32	%r88, %r87, %r86, %p64;
mov.b32 %f254, %r88;
setp.eq.f32	%p65, %f171, 0fBF800000;
selp.f32	%f290, 0f3F800000, %f254, %p65;
bra.uni BB2_37;

BB2_33:
setp.neu.f32	%p61, %f32, 0f7F800000;
@%p61 bra BB2_37;

setp.ltu.f32	%p62, %f172, 0f00000000;
selp.b32	%r83, 0, 2139095040, %p62;
or.b32 %r84, %r83, -2147483648;
selp.b32	%r85, %r84, %r83, %p2;
mov.b32 %f290, %r85;

BB2_37:
add.s32 %r94, %r2, %r16;
setp.eq.f32	%p66, %f172, 0f00000000;
setp.eq.f32	%p67, %f171, 0f3F800000;
or.pred %p68, %p67, %p66;
selp.f32	%f255, 0f3F800000, %f290, %p68;

	{ cvt.rn.f16.f32 %rs47, %f255;}


	cvta.to.global.u64 %rd60, %rd7;
add.s64 %rd62, %rd60, %rd58;
ld.global.u16 %rs48, [%rd62];

	{ cvt.f32.f16 %f256, %rs48;}


	
	{ cvt.f32.f16 %f257, %rs47;}


	mul.f32 %f258, %f256, %f257;

	{ cvt.rn.f16.f32 %rs50, %f258;}


	
	{ cvt.f32.f16 %f259, %rs4;}


	cvta.to.global.u64 %rd63, %rd4;
add.s64 %rd64, %rd63, %rd58;
ld.global.u16 %rs52, [%rd64];

	{ cvt.f32.f16 %f260, %rs52;}


	mul.f32 %f261, %f259, %f260;

	{ cvt.rn.f16.f32 %rs53, %f261;}


	
	{ cvt.f32.f16 %f262, %rs53;}


	mul.f32 %f265, %f282, %f262;

	{ cvt.f32.f16 %f263, %rs50;}


	sub.f32 %f264, %f263, %f265;

	{ cvt.rn.f16.f32 %rs56, %f264;}


	cvta.to.global.u64 %rd65, %rd8;
add.s64 %rd66, %rd65, %rd58;
st.global.u16 [%rd66], %rs56;
add.s32 %r101, %r101, 1;
setp.lt.s32	%p69, %r101, %r94;
@%p69 bra BB2_22;

BB2_38:
ld.param.u32 %r93, [_Z14LRNComputeDiffIN3c104HalfEfEviPKT_S4_S4_S4_iiiiiS2_S2_PS2__param_0];
mov.u32 %r92, %ntid.x;
mov.u32 %r90, %nctaid.x;
mad.lo.s32 %r95, %r90, %r92, %r95;
setp.lt.s32	%p70, %r95, %r93;
@%p70 bra BB2_2;

BB2_39:
ret;
}


.visible .entry _Z12LRNFillScaleIffEviPKT_iiiiiS0_S0_PS0_(
.param .u32 _Z12LRNFillScaleIffEviPKT_iiiiiS0_S0_PS0__param_0,
.param .u64 _Z12LRNFillScaleIffEviPKT_iiiiiS0_S0_PS0__param_1,
.param .u32 _Z12LRNFillScaleIffEviPKT_iiiiiS0_S0_PS0__param_2,
.param .u32 _Z12LRNFillScaleIffEviPKT_iiiiiS0_S0_PS0__param_3,
.param .u32 _Z12LRNFillScaleIffEviPKT_iiiiiS0_S0_PS0__param_4,
.param .u32 _Z12LRNFillScaleIffEviPKT_iiiiiS0_S0_PS0__param_5,
.param .u32 _Z12LRNFillScaleIffEviPKT_iiiiiS0_S0_PS0__param_6,
.param .f32 _Z12LRNFillScaleIffEviPKT_iiiiiS0_S0_PS0__param_7,
.param .f32 _Z12LRNFillScaleIffEviPKT_iiiiiS0_S0_PS0__param_8,
.param .u64 _Z12LRNFillScaleIffEviPKT_iiiiiS0_S0_PS0__param_9
)
.maxntid 1024, 1, 1
{
.reg .pred %p<15>;
.reg .f32 %f<39>;
.reg .b32 %r<66>;
.reg .b64 %rd<34>;


ld.param.u32 %r15, [_Z12LRNFillScaleIffEviPKT_iiiiiS0_S0_PS0__param_0];
ld.param.u64 %rd2, [_Z12LRNFillScaleIffEviPKT_iiiiiS0_S0_PS0__param_1];
ld.param.u32 %r16, [_Z12LRNFillScaleIffEviPKT_iiiiiS0_S0_PS0__param_3];
ld.param.u32 %r17, [_Z12LRNFillScaleIffEviPKT_iiiiiS0_S0_PS0__param_4];
ld.param.u32 %r18, [_Z12LRNFillScaleIffEviPKT_iiiiiS0_S0_PS0__param_5];
ld.param.u32 %r19, [_Z12LRNFillScaleIffEviPKT_iiiiiS0_S0_PS0__param_6];
ld.param.f32 %f12, [_Z12LRNFillScaleIffEviPKT_iiiiiS0_S0_PS0__param_7];
ld.param.f32 %f13, [_Z12LRNFillScaleIffEviPKT_iiiiiS0_S0_PS0__param_8];
ld.param.u64 %rd3, [_Z12LRNFillScaleIffEviPKT_iiiiiS0_S0_PS0__param_9];
mov.u32 %r20, %ctaid.x;
mov.u32 %r21, %ntid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r55, %r21, %r20, %r22;
setp.ge.s32	%p1, %r55, %r15;
@%p1 bra BB3_13;

add.s32 %r23, %r19, -1;
shr.u32 %r24, %r23, 31;
add.s32 %r25, %r23, %r24;
shr.s32 %r26, %r25, 1;
sub.s32 %r27, %r19, %r26;
add.s32 %r2, %r27, -1;

BB3_2:
div.s32 %r30, %r55, %r18;
rem.s32 %r31, %r30, %r17;
div.s32 %r32, %r30, %r17;
mul.lo.s32 %r33, %r17, %r16;
mad.lo.s32 %r34, %r33, %r32, %r31;
rem.s32 %r35, %r55, %r18;
mad.lo.s32 %r36, %r34, %r18, %r35;
cvt.s64.s32	%rd1, %r36;
setp.gt.s32	%p2, %r16, 0;
setp.gt.s32	%p3, %r2, 0;
and.pred %p4, %p3, %p2;
mov.u32 %r64, 0;
mov.f32 %f37, 0f00000000;
mov.u32 %r65, %r64;
mov.f32 %f38, %f37;
@!%p4 bra BB3_4;
bra.uni BB3_3;

BB3_3:
mul.lo.s32 %r37, %r18, %r17;
mul.lo.s32 %r38, %r65, %r37;
cvt.s64.s32	%rd4, %r38;
add.s64 %rd5, %rd4, %rd1;
cvta.to.global.u64 %rd6, %rd2;
shl.b64 %rd7, %rd5, 2;
add.s64 %rd8, %rd6, %rd7;
ld.global.f32 %f16, [%rd8];
fma.rn.f32 %f38, %f16, %f16, %f38;
add.s32 %r65, %r65, 1;
setp.lt.s32	%p5, %r65, %r2;
setp.lt.s32	%p6, %r65, %r16;
and.pred %p7, %p5, %p6;
mov.f32 %f37, %f38;
mov.u32 %r64, %r65;
@%p7 bra BB3_3;

BB3_4:
mov.u32 %r63, %r64;
mov.f32 %f35, %f37;
setp.ge.s32	%p8, %r63, %r16;
mov.f32 %f34, %f35;
mov.u32 %r62, %r63;
@%p8 bra BB3_8;

BB3_5:
mov.f32 %f4, %f35;
mul.lo.s32 %r39, %r18, %r17;
mul.lo.s32 %r40, %r63, %r39;
cvt.s64.s32	%rd9, %r40;
add.s64 %rd10, %rd9, %rd1;
cvta.to.global.u64 %rd11, %rd2;
shl.b64 %rd12, %rd10, 2;
add.s64 %rd13, %rd11, %rd12;
ld.global.f32 %f17, [%rd13];
fma.rn.f32 %f36, %f17, %f17, %f4;
sub.s32 %r8, %r63, %r19;
setp.lt.s32	%p9, %r8, 0;
@%p9 bra BB3_7;

mul.lo.s32 %r42, %r8, %r39;
cvt.s64.s32	%rd14, %r42;
add.s64 %rd15, %rd14, %rd1;
shl.b64 %rd17, %rd15, 2;
add.s64 %rd18, %rd11, %rd17;
ld.global.f32 %f18, [%rd18];
mul.f32 %f19, %f18, %f18;
sub.f32 %f36, %f36, %f19;

BB3_7:
mov.f32 %f35, %f36;
fma.rn.f32 %f20, %f35, %f12, %f13;
sub.s32 %r44, %r63, %r2;
mul.lo.s32 %r45, %r44, %r39;
cvt.s64.s32	%rd19, %r45;
add.s64 %rd20, %rd19, %rd1;
cvta.to.global.u64 %rd21, %rd3;
shl.b64 %rd22, %rd20, 2;
add.s64 %rd23, %rd21, %rd22;
st.global.f32 [%rd23], %f20;
add.s32 %r63, %r63, 1;
setp.lt.s32	%p10, %r63, %r16;
mov.f32 %f34, %f35;
mov.u32 %r62, %r63;
@%p10 bra BB3_5;

BB3_8:
mov.u32 %r61, %r62;
mov.f32 %f32, %f34;
add.s32 %r46, %r2, %r16;
setp.ge.s32	%p11, %r61, %r46;
@%p11 bra BB3_12;

BB3_9:
mov.f32 %f30, %f32;
mov.f32 %f33, %f30;
sub.s32 %r12, %r61, %r19;
setp.lt.s32	%p12, %r12, 0;
@%p12 bra BB3_11;

mul.lo.s32 %r47, %r18, %r17;
mul.lo.s32 %r48, %r12, %r47;
cvt.s64.s32	%rd24, %r48;
add.s64 %rd25, %rd24, %rd1;
cvta.to.global.u64 %rd26, %rd2;
shl.b64 %rd27, %rd25, 2;
add.s64 %rd28, %rd26, %rd27;
ld.global.f32 %f21, [%rd28];
mul.f32 %f22, %f21, %f21;
sub.f32 %f33, %f33, %f22;

BB3_11:
mov.f32 %f32, %f33;
fma.rn.f32 %f23, %f32, %f12, %f13;
mul.lo.s32 %r49, %r18, %r17;
sub.s32 %r50, %r61, %r2;
mul.lo.s32 %r51, %r50, %r49;
cvt.s64.s32	%rd29, %r51;
add.s64 %rd30, %rd29, %rd1;
cvta.to.global.u64 %rd31, %rd3;
shl.b64 %rd32, %rd30, 2;
add.s64 %rd33, %rd31, %rd32;
st.global.f32 [%rd33], %f23;
add.s32 %r61, %r61, 1;
setp.lt.s32	%p13, %r61, %r46;
@%p13 bra BB3_9;

BB3_12:
mov.u32 %r53, %nctaid.x;
mad.lo.s32 %r55, %r53, %r21, %r55;
setp.lt.s32	%p14, %r55, %r15;
@%p14 bra BB3_2;

BB3_13:
ret;
}


.visible .entry _Z16LRNComputeOutputIfEviPKT_S2_S0_PS0_(
.param .u32 _Z16LRNComputeOutputIfEviPKT_S2_S0_PS0__param_0,
.param .u64 _Z16LRNComputeOutputIfEviPKT_S2_S0_PS0__param_1,
.param .u64 _Z16LRNComputeOutputIfEviPKT_S2_S0_PS0__param_2,
.param .f32 _Z16LRNComputeOutputIfEviPKT_S2_S0_PS0__param_3,
.param .u64 _Z16LRNComputeOutputIfEviPKT_S2_S0_PS0__param_4
)
{
.reg .pred %p<31>;
.reg .f32 %f<105>;
.reg .b32 %r<33>;
.reg .b64 %rd<13>;


ld.param.u32 %r4, [_Z16LRNComputeOutputIfEviPKT_S2_S0_PS0__param_0];
ld.param.u64 %rd2, [_Z16LRNComputeOutputIfEviPKT_S2_S0_PS0__param_1];
ld.param.u64 %rd3, [_Z16LRNComputeOutputIfEviPKT_S2_S0_PS0__param_2];
ld.param.f32 %f19, [_Z16LRNComputeOutputIfEviPKT_S2_S0_PS0__param_3];
ld.param.u64 %rd4, [_Z16LRNComputeOutputIfEviPKT_S2_S0_PS0__param_4];
mov.u32 %r5, %ctaid.x;
mov.u32 %r6, %ntid.x;
mov.u32 %r7, %tid.x;
mad.lo.s32 %r32, %r6, %r5, %r7;
setp.ge.s32	%p2, %r32, %r4;
@%p2 bra BB4_16;

mul.f32 %f20, %f19, 0f3F000000;
cvt.rzi.f32.f32	%f21, %f20;
fma.rn.f32 %f22, %f21, 0fC0000000, %f19;
abs.f32 %f1, %f22;
abs.f32 %f2, %f19;
setp.gt.f32	%p3, %f2, 0f77F684DF;
mul.f32 %f23, %f19, 0f39000000;
selp.f32	%f3, %f23, %f19, %p3;
cvta.to.global.u64 %rd5, %rd2;
cvta.to.global.u64 %rd8, %rd3;
cvta.to.global.u64 %rd10, %rd4;

BB4_2:
mov.u32 %r2, %r32;
cvt.s64.s32	%rd1, %r2;
mul.wide.s32 %rd6, %r2, 4;
add.s64 %rd7, %rd5, %rd6;
ld.global.f32 %f4, [%rd7];
add.s64 %rd9, %rd8, %rd6;
ld.global.f32 %f5, [%rd9];
abs.f32 %f6, %f5;
setp.lt.f32	%p4, %f6, 0f00800000;
mul.f32 %f28, %f6, 0f4B800000;
selp.f32	%f29, 0fC3170000, 0fC2FE0000, %p4;
selp.f32	%f30, %f28, %f6, %p4;
mov.b32 %r8, %f30;
and.b32 %r9, %r8, 8388607;
or.b32 %r10, %r9, 1065353216;
mov.b32 %f31, %r10;
shr.u32 %r11, %r8, 23;
cvt.rn.f32.u32	%f32, %r11;
add.f32 %f33, %f29, %f32;
setp.gt.f32	%p5, %f31, 0f3FB504F3;
mul.f32 %f34, %f31, 0f3F000000;
add.f32 %f35, %f33, 0f3F800000;
selp.f32	%f36, %f34, %f31, %p5;
selp.f32	%f37, %f35, %f33, %p5;
add.f32 %f38, %f36, 0fBF800000;
add.f32 %f25, %f36, 0f3F800000;

	rcp.approx.ftz.f32 %f24,%f25;

	add.f32 %f39, %f38, %f38;
mul.f32 %f40, %f24, %f39;
mul.f32 %f41, %f40, %f40;
mov.f32 %f42, 0f3C4CAF63;
mov.f32 %f43, 0f3B18F0FE;
fma.rn.f32 %f44, %f43, %f41, %f42;
mov.f32 %f45, 0f3DAAAABD;
fma.rn.f32 %f46, %f44, %f41, %f45;
mul.rn.f32 %f47, %f46, %f41;
mul.rn.f32 %f48, %f47, %f40;
sub.f32 %f49, %f38, %f40;
neg.f32 %f50, %f40;
add.f32 %f51, %f49, %f49;
fma.rn.f32 %f52, %f50, %f38, %f51;
mul.rn.f32 %f53, %f24, %f52;
add.f32 %f54, %f48, %f40;
sub.f32 %f55, %f40, %f54;
add.f32 %f56, %f48, %f55;
add.f32 %f57, %f53, %f56;
add.f32 %f58, %f54, %f57;
sub.f32 %f59, %f54, %f58;
add.f32 %f60, %f57, %f59;
mov.f32 %f61, 0f3F317200;
mul.rn.f32 %f62, %f37, %f61;
mov.f32 %f63, 0f35BFBE8E;
mul.rn.f32 %f64, %f37, %f63;
add.f32 %f65, %f62, %f58;
sub.f32 %f66, %f62, %f65;
add.f32 %f67, %f58, %f66;
add.f32 %f68, %f60, %f67;
add.f32 %f69, %f64, %f68;
add.f32 %f70, %f65, %f69;
sub.f32 %f71, %f65, %f70;
add.f32 %f72, %f69, %f71;
mul.rn.f32 %f73, %f3, %f70;
neg.f32 %f74, %f73;
fma.rn.f32 %f75, %f3, %f70, %f74;
fma.rn.f32 %f76, %f3, %f72, %f75;
mov.f32 %f77, 0f00000000;
fma.rn.f32 %f78, %f77, %f70, %f76;
add.rn.f32 %f79, %f73, %f78;
neg.f32 %f80, %f79;
add.rn.f32 %f81, %f73, %f80;
add.rn.f32 %f82, %f81, %f78;
mov.b32 %r12, %f79;
setp.eq.s32	%p6, %r12, 1118925336;
add.s32 %r13, %r12, -1;
mov.b32 %f83, %r13;
add.f32 %f84, %f82, 0f37000000;
selp.f32	%f85, %f83, %f79, %p6;
selp.f32	%f7, %f84, %f82, %p6;
mul.f32 %f86, %f85, 0f3FB8AA3B;
cvt.rzi.f32.f32	%f87, %f86;
mov.f32 %f88, 0fBF317200;
fma.rn.f32 %f89, %f87, %f88, %f85;
mov.f32 %f90, 0fB5BFBE8E;
fma.rn.f32 %f91, %f87, %f90, %f89;
mul.f32 %f27, %f91, 0f3FB8AA3B;

	ex2.approx.ftz.f32 %f26,%f27;

	add.f32 %f92, %f87, 0f00000000;
ex2.approx.f32 %f93, %f92;
mul.f32 %f94, %f26, %f93;
setp.lt.f32	%p7, %f85, 0fC2D20000;
selp.f32	%f95, 0f00000000, %f94, %p7;
setp.gt.f32	%p8, %f85, 0f42D20000;
selp.f32	%f103, 0f7F800000, %f95, %p8;
setp.eq.f32	%p9, %f103, 0f7F800000;
@%p9 bra BB4_4;

fma.rn.f32 %f103, %f103, %f7, %f103;

BB4_4:
setp.lt.f32	%p10, %f5, 0f00000000;
setp.eq.f32	%p11, %f1, 0f3F800000;
and.pred %p1, %p10, %p11;
mov.b32 %r14, %f103;
xor.b32 %r15, %r14, -2147483648;
mov.b32 %f96, %r15;
selp.f32	%f104, %f96, %f103, %p1;
setp.eq.f32	%p12, %f5, 0f00000000;
@%p12 bra BB4_7;
bra.uni BB4_5;

BB4_7:
setp.lt.f32	%p15, %f19, 0f00000000;
add.f32 %f98, %f5, %f5;
mov.b32 %r16, %f98;
selp.b32	%r17, %r16, 0, %p11;
or.b32 %r18, %r17, 2139095040;
selp.b32	%r19, %r18, %r17, %p15;
mov.b32 %f104, %r19;
bra.uni BB4_8;

BB4_5:
setp.geu.f32	%p13, %f5, 0f00000000;
@%p13 bra BB4_8;

cvt.rzi.f32.f32	%f97, %f19;
setp.neu.f32	%p14, %f97, %f19;
selp.f32	%f104, 0f7FFFFFFF, %f104, %p14;

BB4_8:
add.f32 %f99, %f6, %f2;
mov.b32 %r20, %f99;
setp.lt.s32	%p17, %r20, 2139095040;
@%p17 bra BB4_15;

setp.gtu.f32	%p18, %f2, 0f7F800000;
setp.gtu.f32	%p19, %f6, 0f7F800000;
or.pred %p20, %p19, %p18;
@%p20 bra BB4_14;
bra.uni BB4_10;

BB4_14:
add.f32 %f104, %f5, %f19;
bra.uni BB4_15;

BB4_10:
setp.eq.f32	%p21, %f2, 0f7F800000;
@%p21 bra BB4_13;
bra.uni BB4_11;

BB4_13:
setp.lt.f32	%p24, %f19, 0f00000000;
setp.gt.f32	%p25, %f6, 0f3F800000;
selp.b32	%r24, 2139095040, 0, %p25;
xor.b32 %r25, %r24, 2139095040;
selp.b32	%r26, %r25, %r24, %p24;
mov.b32 %f100, %r26;
setp.eq.f32	%p26, %f5, 0fBF800000;
selp.f32	%f104, 0f3F800000, %f100, %p26;
bra.uni BB4_15;

BB4_11:
setp.neu.f32	%p22, %f6, 0f7F800000;
@%p22 bra BB4_15;

setp.ltu.f32	%p23, %f19, 0f00000000;
selp.b32	%r21, 0, 2139095040, %p23;
or.b32 %r22, %r21, -2147483648;
selp.b32	%r23, %r22, %r21, %p1;
mov.b32 %f104, %r23;

BB4_15:
ld.param.u32 %r31, [_Z16LRNComputeOutputIfEviPKT_S2_S0_PS0__param_0];
mov.u32 %r30, %ntid.x;
setp.eq.f32	%p27, %f5, 0f3F800000;
setp.eq.f32	%p28, %f19, 0f00000000;
or.pred %p29, %p27, %p28;
selp.f32	%f101, 0f3F800000, %f104, %p29;
mul.f32 %f102, %f4, %f101;
shl.b64 %rd11, %rd1, 2;
add.s64 %rd12, %rd10, %rd11;
st.global.f32 [%rd12], %f102;
mov.u32 %r28, %nctaid.x;
cvt.u32.u64	%r29, %rd1;
mad.lo.s32 %r32, %r28, %r30, %r29;
setp.lt.s32	%p30, %r32, %r31;
@%p30 bra BB4_2;

BB4_16:
ret;
}


.visible .entry _Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0_(
.param .u32 _Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_0,
.param .u64 _Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_1,
.param .u64 _Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_2,
.param .u64 _Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_3,
.param .u64 _Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_4,
.param .u32 _Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_5,
.param .u32 _Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_6,
.param .u32 _Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_7,
.param .u32 _Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_8,
.param .u32 _Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_9,
.param .f32 _Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_10,
.param .f32 _Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_11,
.param .u64 _Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_12
)
{
.reg .pred %p<71>;
.reg .f32 %f<269>;
.reg .b32 %r<106>;
.reg .b64 %rd<67>;


ld.param.u32 %r15, [_Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_0];
ld.param.u64 %rd4, [_Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_1];
ld.param.u64 %rd5, [_Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_2];
ld.param.u64 %rd6, [_Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_3];
ld.param.u64 %rd7, [_Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_4];
ld.param.u32 %r16, [_Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_6];
ld.param.u32 %r17, [_Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_7];
ld.param.u32 %r18, [_Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_8];
ld.param.u32 %r19, [_Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_9];
ld.param.f32 %f50, [_Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_10];
ld.param.f32 %f51, [_Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_11];
ld.param.u64 %rd8, [_Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_12];
mov.u32 %r20, %ctaid.x;
mov.u32 %r21, %ntid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r95, %r21, %r20, %r22;
setp.ge.s32	%p3, %r95, %r15;
@%p3 bra BB5_41;

add.s32 %r23, %r19, 1;
shr.u32 %r24, %r23, 31;
add.s32 %r25, %r23, %r24;
shr.s32 %r26, %r25, 1;
add.s32 %r2, %r26, -1;
mul.f32 %f1, %f50, 0f3F000000;
mul.f32 %f2, %f50, 0f39000000;

BB5_2:
div.s32 %r29, %r95, %r18;
rem.s32 %r30, %r29, %r17;
div.s32 %r31, %r29, %r17;
mul.lo.s32 %r32, %r17, %r16;
mad.lo.s32 %r33, %r32, %r31, %r30;
rem.s32 %r34, %r95, %r18;
mad.lo.s32 %r35, %r33, %r18, %r34;
cvt.s64.s32	%rd1, %r35;
setp.gt.s32	%p4, %r16, 0;
setp.gt.s32	%p5, %r2, 0;
and.pred %p6, %p5, %p4;
mov.u32 %r104, 0;
mov.f32 %f265, 0f00000000;
mov.u32 %r105, %r104;
mov.f32 %f266, %f265;
@!%p6 bra BB5_4;
bra.uni BB5_3;

BB5_3:
mul.lo.s32 %r36, %r18, %r17;
mul.lo.s32 %r37, %r105, %r36;
cvt.s64.s32	%rd9, %r37;
add.s64 %rd10, %rd9, %rd1;
cvta.to.global.u64 %rd11, %rd7;
shl.b64 %rd12, %rd10, 2;
add.s64 %rd13, %rd11, %rd12;
cvta.to.global.u64 %rd14, %rd5;
add.s64 %rd15, %rd14, %rd12;
ld.global.f32 %f54, [%rd15];
ld.global.f32 %f55, [%rd13];
mul.f32 %f56, %f55, %f54;
cvta.to.global.u64 %rd16, %rd6;
add.s64 %rd17, %rd16, %rd12;
ld.global.f32 %f57, [%rd17];
div.rn.f32 %f58, %f56, %f57;
add.f32 %f266, %f266, %f58;
add.s32 %r105, %r105, 1;
setp.lt.s32	%p7, %r105, %r2;
setp.lt.s32	%p8, %r105, %r16;
and.pred %p9, %p7, %p8;
mov.f32 %f265, %f266;
mov.u32 %r104, %r105;
@%p9 bra BB5_3;

BB5_4:
mov.u32 %r102, %r104;
mov.f32 %f262, %f265;
setp.ge.s32	%p10, %r102, %r16;
@%p10 bra BB5_22;

cvt.rzi.f32.f32	%f59, %f1;
fma.rn.f32 %f60, %f59, 0fC0000000, %f50;
abs.f32 %f6, %f60;
abs.f32 %f7, %f50;
setp.gt.f32	%p11, %f7, 0f77F684DF;
selp.f32	%f8, %f2, %f50, %p11;
mov.f32 %f263, %f262;
mov.u32 %r103, %r102;

BB5_6:
mul.lo.s32 %r38, %r18, %r17;
mul.lo.s32 %r39, %r103, %r38;
cvt.s64.s32	%rd18, %r39;
add.s64 %rd19, %rd18, %rd1;
cvta.to.global.u64 %rd20, %rd7;
shl.b64 %rd21, %rd19, 2;
add.s64 %rd22, %rd20, %rd21;
cvta.to.global.u64 %rd23, %rd5;
add.s64 %rd24, %rd23, %rd21;
ld.global.f32 %f61, [%rd24];
ld.global.f32 %f62, [%rd22];
mul.f32 %f63, %f62, %f61;
cvta.to.global.u64 %rd25, %rd6;
add.s64 %rd26, %rd25, %rd21;
ld.global.f32 %f64, [%rd26];
div.rn.f32 %f65, %f63, %f64;
add.f32 %f264, %f263, %f65;
sub.s32 %r8, %r103, %r19;
setp.lt.s32	%p12, %r8, 0;
@%p12 bra BB5_8;

mul.lo.s32 %r41, %r8, %r38;
cvt.s64.s32	%rd27, %r41;
add.s64 %rd28, %rd27, %rd1;
shl.b64 %rd30, %rd28, 2;
add.s64 %rd31, %rd20, %rd30;
add.s64 %rd33, %rd23, %rd30;
ld.global.f32 %f66, [%rd33];
ld.global.f32 %f67, [%rd31];
mul.f32 %f68, %f67, %f66;
add.s64 %rd35, %rd25, %rd30;
ld.global.f32 %f69, [%rd35];
div.rn.f32 %f70, %f68, %f69;
sub.f32 %f264, %f264, %f70;

BB5_8:
mov.f32 %f263, %f264;
sub.s32 %r43, %r103, %r2;
mul.lo.s32 %r44, %r43, %r38;
cvt.s64.s32	%rd36, %r44;
add.s64 %rd2, %rd36, %rd1;
shl.b64 %rd38, %rd2, 2;
add.s64 %rd39, %rd20, %rd38;
ld.global.f32 %f13, [%rd39];
add.s64 %rd41, %rd25, %rd38;
ld.global.f32 %f14, [%rd41];
abs.f32 %f15, %f14;
setp.lt.f32	%p13, %f15, 0f00800000;
mul.f32 %f75, %f15, 0f4B800000;
selp.f32	%f76, 0fC3170000, 0fC2FE0000, %p13;
selp.f32	%f77, %f75, %f15, %p13;
mov.b32 %r45, %f77;
and.b32 %r46, %r45, 8388607;
or.b32 %r47, %r46, 1065353216;
mov.b32 %f78, %r47;
shr.u32 %r48, %r45, 23;
cvt.rn.f32.u32	%f79, %r48;
add.f32 %f80, %f76, %f79;
setp.gt.f32	%p14, %f78, 0f3FB504F3;
mul.f32 %f81, %f78, 0f3F000000;
add.f32 %f82, %f80, 0f3F800000;
selp.f32	%f83, %f81, %f78, %p14;
selp.f32	%f84, %f82, %f80, %p14;
add.f32 %f85, %f83, 0fBF800000;
add.f32 %f72, %f83, 0f3F800000;

	rcp.approx.ftz.f32 %f71,%f72;

	add.f32 %f86, %f85, %f85;
mul.f32 %f87, %f71, %f86;
mul.f32 %f88, %f87, %f87;
mov.f32 %f89, 0f3C4CAF63;
mov.f32 %f90, 0f3B18F0FE;
fma.rn.f32 %f91, %f90, %f88, %f89;
mov.f32 %f92, 0f3DAAAABD;
fma.rn.f32 %f93, %f91, %f88, %f92;
mul.rn.f32 %f94, %f93, %f88;
mul.rn.f32 %f95, %f94, %f87;
sub.f32 %f96, %f85, %f87;
neg.f32 %f97, %f87;
add.f32 %f98, %f96, %f96;
fma.rn.f32 %f99, %f97, %f85, %f98;
mul.rn.f32 %f100, %f71, %f99;
add.f32 %f101, %f95, %f87;
sub.f32 %f102, %f87, %f101;
add.f32 %f103, %f95, %f102;
add.f32 %f104, %f100, %f103;
add.f32 %f105, %f101, %f104;
sub.f32 %f106, %f101, %f105;
add.f32 %f107, %f104, %f106;
mov.f32 %f108, 0f3F317200;
mul.rn.f32 %f109, %f84, %f108;
mov.f32 %f110, 0f35BFBE8E;
mul.rn.f32 %f111, %f84, %f110;
add.f32 %f112, %f109, %f105;
sub.f32 %f113, %f109, %f112;
add.f32 %f114, %f105, %f113;
add.f32 %f115, %f107, %f114;
add.f32 %f116, %f111, %f115;
add.f32 %f117, %f112, %f116;
sub.f32 %f118, %f112, %f117;
add.f32 %f119, %f116, %f118;
mul.rn.f32 %f120, %f8, %f117;
neg.f32 %f121, %f120;
fma.rn.f32 %f122, %f8, %f117, %f121;
fma.rn.f32 %f123, %f8, %f119, %f122;
mov.f32 %f124, 0f00000000;
fma.rn.f32 %f125, %f124, %f117, %f123;
add.rn.f32 %f126, %f120, %f125;
neg.f32 %f127, %f126;
add.rn.f32 %f128, %f120, %f127;
add.rn.f32 %f129, %f128, %f125;
mov.b32 %r49, %f126;
setp.eq.s32	%p15, %r49, 1118925336;
add.s32 %r50, %r49, -1;
mov.b32 %f130, %r50;
add.f32 %f131, %f129, 0f37000000;
selp.f32	%f132, %f130, %f126, %p15;
selp.f32	%f16, %f131, %f129, %p15;
mul.f32 %f133, %f132, 0f3FB8AA3B;
cvt.rzi.f32.f32	%f134, %f133;
mov.f32 %f135, 0fBF317200;
fma.rn.f32 %f136, %f134, %f135, %f132;
mov.f32 %f137, 0fB5BFBE8E;
fma.rn.f32 %f138, %f134, %f137, %f136;
mul.f32 %f74, %f138, 0f3FB8AA3B;

	ex2.approx.ftz.f32 %f73,%f74;

	add.f32 %f139, %f134, 0f00000000;
ex2.approx.f32 %f140, %f139;
mul.f32 %f141, %f73, %f140;
setp.lt.f32	%p16, %f132, 0fC2D20000;
selp.f32	%f142, 0f00000000, %f141, %p16;
setp.gt.f32	%p17, %f132, 0f42D20000;
selp.f32	%f250, 0f7F800000, %f142, %p17;
setp.eq.f32	%p18, %f250, 0f7F800000;
@%p18 bra BB5_10;

fma.rn.f32 %f250, %f250, %f16, %f250;

BB5_10:
setp.lt.f32	%p19, %f14, 0f00000000;
setp.eq.f32	%p20, %f6, 0f3F800000;
and.pred %p1, %p19, %p20;
mov.b32 %r51, %f250;
xor.b32 %r52, %r51, -2147483648;
mov.b32 %f143, %r52;
selp.f32	%f251, %f143, %f250, %p1;
setp.eq.f32	%p21, %f14, 0f00000000;
@%p21 bra BB5_13;
bra.uni BB5_11;

BB5_13:
add.f32 %f145, %f14, %f14;
mov.b32 %r53, %f145;
selp.b32	%r54, %r53, 0, %p20;
or.b32 %r55, %r54, 2139095040;
setp.lt.f32	%p25, %f50, 0f00000000;
selp.b32	%r56, %r55, %r54, %p25;
mov.b32 %f251, %r56;
bra.uni BB5_14;

BB5_11:
setp.geu.f32	%p22, %f14, 0f00000000;
@%p22 bra BB5_14;

cvt.rzi.f32.f32	%f144, %f50;
setp.neu.f32	%p23, %f144, %f50;
selp.f32	%f251, 0f7FFFFFFF, %f251, %p23;

BB5_14:
abs.f32 %f244, %f50;
add.f32 %f146, %f15, %f244;
mov.b32 %r57, %f146;
setp.lt.s32	%p26, %r57, 2139095040;
@%p26 bra BB5_21;

abs.f32 %f245, %f50;
setp.gtu.f32	%p27, %f245, 0f7F800000;
setp.gtu.f32	%p28, %f15, 0f7F800000;
or.pred %p29, %p28, %p27;
@%p29 bra BB5_20;
bra.uni BB5_16;

BB5_20:
add.f32 %f251, %f14, %f50;
bra.uni BB5_21;

BB5_16:
abs.f32 %f246, %f50;
setp.eq.f32	%p30, %f246, 0f7F800000;
@%p30 bra BB5_19;
bra.uni BB5_17;

BB5_19:
setp.lt.f32	%p33, %f50, 0f00000000;
setp.gt.f32	%p34, %f15, 0f3F800000;
selp.b32	%r61, 2139095040, 0, %p34;
xor.b32 %r62, %r61, 2139095040;
selp.b32	%r63, %r62, %r61, %p33;
mov.b32 %f147, %r63;
setp.eq.f32	%p35, %f14, 0fBF800000;
selp.f32	%f251, 0f3F800000, %f147, %p35;
bra.uni BB5_21;

BB5_17:
setp.neu.f32	%p31, %f15, 0f7F800000;
@%p31 bra BB5_21;

setp.ltu.f32	%p32, %f50, 0f00000000;
selp.b32	%r58, 0, 2139095040, %p32;
or.b32 %r59, %r58, -2147483648;
selp.b32	%r60, %r59, %r58, %p1;
mov.b32 %f251, %r60;

BB5_21:
setp.eq.f32	%p36, %f14, 0f3F800000;
setp.eq.f32	%p37, %f50, 0f00000000;
or.pred %p38, %p36, %p37;
selp.f32	%f148, 0f3F800000, %f251, %p38;
mul.f32 %f149, %f13, %f148;
cvta.to.global.u64 %rd42, %rd4;
add.s64 %rd44, %rd42, %rd38;
ld.global.f32 %f150, [%rd44];
mul.f32 %f151, %f150, %f51;
mul.f32 %f152, %f263, %f151;
sub.f32 %f153, %f149, %f152;
cvta.to.global.u64 %rd45, %rd8;
add.s64 %rd46, %rd45, %rd38;
st.global.f32 [%rd46], %f153;
add.s32 %r103, %r103, 1;
setp.lt.s32	%p39, %r103, %r16;
mov.f32 %f262, %f263;
mov.u32 %r102, %r103;
@%p39 bra BB5_6;

BB5_22:
mov.u32 %r101, %r102;
mov.f32 %f260, %f262;
add.s32 %r64, %r2, %r16;
setp.ge.s32	%p40, %r101, %r64;
@%p40 bra BB5_40;

cvt.rzi.f32.f32	%f154, %f1;
fma.rn.f32 %f155, %f154, 0fC0000000, %f50;
abs.f32 %f29, %f155;
abs.f32 %f30, %f50;
setp.gt.f32	%p41, %f30, 0f77F684DF;
selp.f32	%f31, %f2, %f50, %p41;

BB5_24:
mov.f32 %f261, %f260;
sub.s32 %r12, %r101, %r19;
setp.lt.s32	%p42, %r12, 0;
@%p42 bra BB5_26;

mul.lo.s32 %r65, %r18, %r17;
mul.lo.s32 %r66, %r12, %r65;
cvt.s64.s32	%rd47, %r66;
add.s64 %rd48, %rd47, %rd1;
cvta.to.global.u64 %rd49, %rd7;
shl.b64 %rd50, %rd48, 2;
add.s64 %rd51, %rd49, %rd50;
cvta.to.global.u64 %rd52, %rd5;
add.s64 %rd53, %rd52, %rd50;
ld.global.f32 %f156, [%rd53];
ld.global.f32 %f157, [%rd51];
mul.f32 %f158, %f157, %f156;
cvta.to.global.u64 %rd54, %rd6;
add.s64 %rd55, %rd54, %rd50;
ld.global.f32 %f159, [%rd55];
div.rn.f32 %f160, %f158, %f159;
sub.f32 %f261, %f261, %f160;

BB5_26:
mov.f32 %f260, %f261;
mul.lo.s32 %r67, %r18, %r17;
sub.s32 %r68, %r101, %r2;
mul.lo.s32 %r69, %r68, %r67;
cvt.s64.s32	%rd56, %r69;
add.s64 %rd3, %rd56, %rd1;
cvta.to.global.u64 %rd57, %rd7;
shl.b64 %rd58, %rd3, 2;
add.s64 %rd59, %rd57, %rd58;
ld.global.f32 %f35, [%rd59];
cvta.to.global.u64 %rd60, %rd6;
add.s64 %rd61, %rd60, %rd58;
ld.global.f32 %f36, [%rd61];
abs.f32 %f37, %f36;
setp.lt.f32	%p43, %f37, 0f00800000;
mul.f32 %f165, %f37, 0f4B800000;
selp.f32	%f166, 0fC3170000, 0fC2FE0000, %p43;
selp.f32	%f167, %f165, %f37, %p43;
mov.b32 %r70, %f167;
and.b32 %r71, %r70, 8388607;
or.b32 %r72, %r71, 1065353216;
mov.b32 %f168, %r72;
shr.u32 %r73, %r70, 23;
cvt.rn.f32.u32	%f169, %r73;
add.f32 %f170, %f166, %f169;
setp.gt.f32	%p44, %f168, 0f3FB504F3;
mul.f32 %f171, %f168, 0f3F000000;
add.f32 %f172, %f170, 0f3F800000;
selp.f32	%f173, %f171, %f168, %p44;
selp.f32	%f174, %f172, %f170, %p44;
add.f32 %f175, %f173, 0fBF800000;
add.f32 %f162, %f173, 0f3F800000;

	rcp.approx.ftz.f32 %f161,%f162;

	add.f32 %f176, %f175, %f175;
mul.f32 %f177, %f161, %f176;
mul.f32 %f178, %f177, %f177;
mov.f32 %f179, 0f3C4CAF63;
mov.f32 %f180, 0f3B18F0FE;
fma.rn.f32 %f181, %f180, %f178, %f179;
mov.f32 %f182, 0f3DAAAABD;
fma.rn.f32 %f183, %f181, %f178, %f182;
mul.rn.f32 %f184, %f183, %f178;
mul.rn.f32 %f185, %f184, %f177;
sub.f32 %f186, %f175, %f177;
neg.f32 %f187, %f177;
add.f32 %f188, %f186, %f186;
fma.rn.f32 %f189, %f187, %f175, %f188;
mul.rn.f32 %f190, %f161, %f189;
add.f32 %f191, %f185, %f177;
sub.f32 %f192, %f177, %f191;
add.f32 %f193, %f185, %f192;
add.f32 %f194, %f190, %f193;
add.f32 %f195, %f191, %f194;
sub.f32 %f196, %f191, %f195;
add.f32 %f197, %f194, %f196;
mov.f32 %f198, 0f3F317200;
mul.rn.f32 %f199, %f174, %f198;
mov.f32 %f200, 0f35BFBE8E;
mul.rn.f32 %f201, %f174, %f200;
add.f32 %f202, %f199, %f195;
sub.f32 %f203, %f199, %f202;
add.f32 %f204, %f195, %f203;
add.f32 %f205, %f197, %f204;
add.f32 %f206, %f201, %f205;
add.f32 %f207, %f202, %f206;
sub.f32 %f208, %f202, %f207;
add.f32 %f209, %f206, %f208;
mul.rn.f32 %f210, %f31, %f207;
neg.f32 %f211, %f210;
fma.rn.f32 %f212, %f31, %f207, %f211;
fma.rn.f32 %f213, %f31, %f209, %f212;
mov.f32 %f214, 0f00000000;
fma.rn.f32 %f215, %f214, %f207, %f213;
add.rn.f32 %f216, %f210, %f215;
neg.f32 %f217, %f216;
add.rn.f32 %f218, %f210, %f217;
add.rn.f32 %f219, %f218, %f215;
mov.b32 %r74, %f216;
setp.eq.s32	%p45, %r74, 1118925336;
add.s32 %r75, %r74, -1;
mov.b32 %f220, %r75;
add.f32 %f221, %f219, 0f37000000;
selp.f32	%f222, %f220, %f216, %p45;
selp.f32	%f38, %f221, %f219, %p45;
mul.f32 %f223, %f222, 0f3FB8AA3B;
cvt.rzi.f32.f32	%f224, %f223;
mov.f32 %f225, 0fBF317200;
fma.rn.f32 %f226, %f224, %f225, %f222;
mov.f32 %f227, 0fB5BFBE8E;
fma.rn.f32 %f228, %f224, %f227, %f226;
mul.f32 %f164, %f228, 0f3FB8AA3B;

	ex2.approx.ftz.f32 %f163,%f164;

	add.f32 %f229, %f224, 0f00000000;
ex2.approx.f32 %f230, %f229;
mul.f32 %f231, %f163, %f230;
setp.lt.f32	%p46, %f222, 0fC2D20000;
selp.f32	%f232, 0f00000000, %f231, %p46;
setp.gt.f32	%p47, %f222, 0f42D20000;
selp.f32	%f267, 0f7F800000, %f232, %p47;
setp.eq.f32	%p48, %f267, 0f7F800000;
@%p48 bra BB5_28;

fma.rn.f32 %f267, %f267, %f38, %f267;

BB5_28:
setp.lt.f32	%p49, %f36, 0f00000000;
setp.eq.f32	%p50, %f29, 0f3F800000;
and.pred %p2, %p49, %p50;
mov.b32 %r76, %f267;
xor.b32 %r77, %r76, -2147483648;
mov.b32 %f233, %r77;
selp.f32	%f268, %f233, %f267, %p2;
setp.eq.f32	%p51, %f36, 0f00000000;
@%p51 bra BB5_31;
bra.uni BB5_29;

BB5_31:
add.f32 %f235, %f36, %f36;
mov.b32 %r78, %f235;
selp.b32	%r79, %r78, 0, %p50;
or.b32 %r80, %r79, 2139095040;
setp.lt.f32	%p55, %f50, 0f00000000;
selp.b32	%r81, %r80, %r79, %p55;
mov.b32 %f268, %r81;
bra.uni BB5_32;

BB5_29:
setp.geu.f32	%p52, %f36, 0f00000000;
@%p52 bra BB5_32;

cvt.rzi.f32.f32	%f234, %f50;
setp.neu.f32	%p53, %f234, %f50;
selp.f32	%f268, 0f7FFFFFFF, %f268, %p53;

BB5_32:
abs.f32 %f247, %f50;
add.f32 %f236, %f37, %f247;
mov.b32 %r82, %f236;
setp.lt.s32	%p56, %r82, 2139095040;
@%p56 bra BB5_39;

abs.f32 %f248, %f50;
setp.gtu.f32	%p57, %f248, 0f7F800000;
setp.gtu.f32	%p58, %f37, 0f7F800000;
or.pred %p59, %p58, %p57;
@%p59 bra BB5_38;
bra.uni BB5_34;

BB5_38:
add.f32 %f268, %f36, %f50;
bra.uni BB5_39;

BB5_34:
abs.f32 %f249, %f50;
setp.eq.f32	%p60, %f249, 0f7F800000;
@%p60 bra BB5_37;
bra.uni BB5_35;

BB5_37:
setp.lt.f32	%p63, %f50, 0f00000000;
setp.gt.f32	%p64, %f37, 0f3F800000;
selp.b32	%r86, 2139095040, 0, %p64;
xor.b32 %r87, %r86, 2139095040;
selp.b32	%r88, %r87, %r86, %p63;
mov.b32 %f237, %r88;
setp.eq.f32	%p65, %f36, 0fBF800000;
selp.f32	%f268, 0f3F800000, %f237, %p65;
bra.uni BB5_39;

BB5_35:
setp.neu.f32	%p61, %f37, 0f7F800000;
@%p61 bra BB5_39;

setp.ltu.f32	%p62, %f50, 0f00000000;
selp.b32	%r83, 0, 2139095040, %p62;
or.b32 %r84, %r83, -2147483648;
selp.b32	%r85, %r84, %r83, %p2;
mov.b32 %f268, %r85;

BB5_39:
add.s32 %r94, %r2, %r16;
setp.eq.f32	%p66, %f36, 0f3F800000;
setp.eq.f32	%p67, %f50, 0f00000000;
or.pred %p68, %p66, %p67;
selp.f32	%f238, 0f3F800000, %f268, %p68;
mul.f32 %f239, %f35, %f238;
cvta.to.global.u64 %rd62, %rd4;
add.s64 %rd64, %rd62, %rd58;
ld.global.f32 %f240, [%rd64];
mul.f32 %f241, %f240, %f51;
mul.f32 %f242, %f260, %f241;
sub.f32 %f243, %f239, %f242;
cvta.to.global.u64 %rd65, %rd8;
add.s64 %rd66, %rd65, %rd58;
st.global.f32 [%rd66], %f243;
add.s32 %r101, %r101, 1;
setp.lt.s32	%p69, %r101, %r94;
@%p69 bra BB5_24;

BB5_40:
ld.param.u32 %r93, [_Z14LRNComputeDiffIffEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_0];
mov.u32 %r92, %ntid.x;
mov.u32 %r90, %nctaid.x;
mad.lo.s32 %r95, %r90, %r92, %r95;
setp.lt.s32	%p70, %r95, %r93;
@%p70 bra BB5_2;

BB5_41:
ret;
}


.visible .entry _Z12LRNFillScaleIddEviPKT_iiiiiS0_S0_PS0_(
.param .u32 _Z12LRNFillScaleIddEviPKT_iiiiiS0_S0_PS0__param_0,
.param .u64 _Z12LRNFillScaleIddEviPKT_iiiiiS0_S0_PS0__param_1,
.param .u32 _Z12LRNFillScaleIddEviPKT_iiiiiS0_S0_PS0__param_2,
.param .u32 _Z12LRNFillScaleIddEviPKT_iiiiiS0_S0_PS0__param_3,
.param .u32 _Z12LRNFillScaleIddEviPKT_iiiiiS0_S0_PS0__param_4,
.param .u32 _Z12LRNFillScaleIddEviPKT_iiiiiS0_S0_PS0__param_5,
.param .u32 _Z12LRNFillScaleIddEviPKT_iiiiiS0_S0_PS0__param_6,
.param .f64 _Z12LRNFillScaleIddEviPKT_iiiiiS0_S0_PS0__param_7,
.param .f64 _Z12LRNFillScaleIddEviPKT_iiiiiS0_S0_PS0__param_8,
.param .u64 _Z12LRNFillScaleIddEviPKT_iiiiiS0_S0_PS0__param_9
)
.maxntid 1024, 1, 1
{
.reg .pred %p<15>;
.reg .b32 %r<66>;
.reg .f64 %fd<39>;
.reg .b64 %rd<34>;


ld.param.u32 %r15, [_Z12LRNFillScaleIddEviPKT_iiiiiS0_S0_PS0__param_0];
ld.param.u64 %rd2, [_Z12LRNFillScaleIddEviPKT_iiiiiS0_S0_PS0__param_1];
ld.param.u32 %r16, [_Z12LRNFillScaleIddEviPKT_iiiiiS0_S0_PS0__param_3];
ld.param.u32 %r17, [_Z12LRNFillScaleIddEviPKT_iiiiiS0_S0_PS0__param_4];
ld.param.u32 %r18, [_Z12LRNFillScaleIddEviPKT_iiiiiS0_S0_PS0__param_5];
ld.param.u32 %r19, [_Z12LRNFillScaleIddEviPKT_iiiiiS0_S0_PS0__param_6];
ld.param.f64 %fd12, [_Z12LRNFillScaleIddEviPKT_iiiiiS0_S0_PS0__param_7];
ld.param.f64 %fd13, [_Z12LRNFillScaleIddEviPKT_iiiiiS0_S0_PS0__param_8];
ld.param.u64 %rd3, [_Z12LRNFillScaleIddEviPKT_iiiiiS0_S0_PS0__param_9];
mov.u32 %r20, %ctaid.x;
mov.u32 %r21, %ntid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r55, %r21, %r20, %r22;
setp.ge.s32	%p1, %r55, %r15;
@%p1 bra BB6_13;

add.s32 %r23, %r19, -1;
shr.u32 %r24, %r23, 31;
add.s32 %r25, %r23, %r24;
shr.s32 %r26, %r25, 1;
sub.s32 %r27, %r19, %r26;
add.s32 %r2, %r27, -1;

BB6_2:
div.s32 %r30, %r55, %r18;
rem.s32 %r31, %r30, %r17;
div.s32 %r32, %r30, %r17;
mul.lo.s32 %r33, %r17, %r16;
mad.lo.s32 %r34, %r33, %r32, %r31;
rem.s32 %r35, %r55, %r18;
mad.lo.s32 %r36, %r34, %r18, %r35;
cvt.s64.s32	%rd1, %r36;
setp.gt.s32	%p2, %r16, 0;
setp.gt.s32	%p3, %r2, 0;
and.pred %p4, %p3, %p2;
mov.u32 %r64, 0;
mov.f64 %fd37, 0d0000000000000000;
mov.u32 %r65, %r64;
mov.f64 %fd38, %fd37;
@!%p4 bra BB6_4;
bra.uni BB6_3;

BB6_3:
mul.lo.s32 %r37, %r18, %r17;
mul.lo.s32 %r38, %r65, %r37;
cvt.s64.s32	%rd4, %r38;
add.s64 %rd5, %rd4, %rd1;
cvta.to.global.u64 %rd6, %rd2;
shl.b64 %rd7, %rd5, 3;
add.s64 %rd8, %rd6, %rd7;
ld.global.f64 %fd16, [%rd8];
fma.rn.f64 %fd38, %fd16, %fd16, %fd38;
add.s32 %r65, %r65, 1;
setp.lt.s32	%p5, %r65, %r2;
setp.lt.s32	%p6, %r65, %r16;
and.pred %p7, %p5, %p6;
mov.f64 %fd37, %fd38;
mov.u32 %r64, %r65;
@%p7 bra BB6_3;

BB6_4:
mov.u32 %r63, %r64;
mov.f64 %fd35, %fd37;
setp.ge.s32	%p8, %r63, %r16;
mov.f64 %fd34, %fd35;
mov.u32 %r62, %r63;
@%p8 bra BB6_8;

BB6_5:
mov.f64 %fd4, %fd35;
mul.lo.s32 %r39, %r18, %r17;
mul.lo.s32 %r40, %r63, %r39;
cvt.s64.s32	%rd9, %r40;
add.s64 %rd10, %rd9, %rd1;
cvta.to.global.u64 %rd11, %rd2;
shl.b64 %rd12, %rd10, 3;
add.s64 %rd13, %rd11, %rd12;
ld.global.f64 %fd17, [%rd13];
fma.rn.f64 %fd36, %fd17, %fd17, %fd4;
sub.s32 %r8, %r63, %r19;
setp.lt.s32	%p9, %r8, 0;
@%p9 bra BB6_7;

mul.lo.s32 %r42, %r8, %r39;
cvt.s64.s32	%rd14, %r42;
add.s64 %rd15, %rd14, %rd1;
shl.b64 %rd17, %rd15, 3;
add.s64 %rd18, %rd11, %rd17;
ld.global.f64 %fd18, [%rd18];
mul.f64 %fd19, %fd18, %fd18;
sub.f64 %fd36, %fd36, %fd19;

BB6_7:
mov.f64 %fd35, %fd36;
fma.rn.f64 %fd20, %fd35, %fd12, %fd13;
sub.s32 %r44, %r63, %r2;
mul.lo.s32 %r45, %r44, %r39;
cvt.s64.s32	%rd19, %r45;
add.s64 %rd20, %rd19, %rd1;
cvta.to.global.u64 %rd21, %rd3;
shl.b64 %rd22, %rd20, 3;
add.s64 %rd23, %rd21, %rd22;
st.global.f64 [%rd23], %fd20;
add.s32 %r63, %r63, 1;
setp.lt.s32	%p10, %r63, %r16;
mov.f64 %fd34, %fd35;
mov.u32 %r62, %r63;
@%p10 bra BB6_5;

BB6_8:
mov.u32 %r61, %r62;
mov.f64 %fd32, %fd34;
add.s32 %r46, %r2, %r16;
setp.ge.s32	%p11, %r61, %r46;
@%p11 bra BB6_12;

BB6_9:
mov.f64 %fd30, %fd32;
mov.f64 %fd33, %fd30;
sub.s32 %r12, %r61, %r19;
setp.lt.s32	%p12, %r12, 0;
@%p12 bra BB6_11;

mul.lo.s32 %r47, %r18, %r17;
mul.lo.s32 %r48, %r12, %r47;
cvt.s64.s32	%rd24, %r48;
add.s64 %rd25, %rd24, %rd1;
cvta.to.global.u64 %rd26, %rd2;
shl.b64 %rd27, %rd25, 3;
add.s64 %rd28, %rd26, %rd27;
ld.global.f64 %fd21, [%rd28];
mul.f64 %fd22, %fd21, %fd21;
sub.f64 %fd33, %fd33, %fd22;

BB6_11:
mov.f64 %fd32, %fd33;
fma.rn.f64 %fd23, %fd32, %fd12, %fd13;
mul.lo.s32 %r49, %r18, %r17;
sub.s32 %r50, %r61, %r2;
mul.lo.s32 %r51, %r50, %r49;
cvt.s64.s32	%rd29, %r51;
add.s64 %rd30, %rd29, %rd1;
cvta.to.global.u64 %rd31, %rd3;
shl.b64 %rd32, %rd30, 3;
add.s64 %rd33, %rd31, %rd32;
st.global.f64 [%rd33], %fd23;
add.s32 %r61, %r61, 1;
setp.lt.s32	%p13, %r61, %r46;
@%p13 bra BB6_9;

BB6_12:
mov.u32 %r53, %nctaid.x;
mad.lo.s32 %r55, %r53, %r21, %r55;
setp.lt.s32	%p14, %r55, %r15;
@%p14 bra BB6_2;

BB6_13:
ret;
}


.visible .entry _Z16LRNComputeOutputIdEviPKT_S2_S0_PS0_(
.param .u32 _Z16LRNComputeOutputIdEviPKT_S2_S0_PS0__param_0,
.param .u64 _Z16LRNComputeOutputIdEviPKT_S2_S0_PS0__param_1,
.param .u64 _Z16LRNComputeOutputIdEviPKT_S2_S0_PS0__param_2,
.param .f64 _Z16LRNComputeOutputIdEviPKT_S2_S0_PS0__param_3,
.param .u64 _Z16LRNComputeOutputIdEviPKT_S2_S0_PS0__param_4
)
{
.reg .pred %p<24>;
.reg .b32 %r<40>;
.reg .f64 %fd<27>;
.reg .b64 %rd<15>;


ld.param.u32 %r6, [_Z16LRNComputeOutputIdEviPKT_S2_S0_PS0__param_0];
ld.param.u64 %rd3, [_Z16LRNComputeOutputIdEviPKT_S2_S0_PS0__param_1];
ld.param.u64 %rd4, [_Z16LRNComputeOutputIdEviPKT_S2_S0_PS0__param_2];
ld.param.f64 %fd14, [_Z16LRNComputeOutputIdEviPKT_S2_S0_PS0__param_3];
ld.param.u64 %rd5, [_Z16LRNComputeOutputIdEviPKT_S2_S0_PS0__param_4];
mov.u32 %r7, %ctaid.x;
mov.u32 %r8, %ntid.x;
mov.u32 %r9, %tid.x;
mad.lo.s32 %r39, %r8, %r7, %r9;
setp.ge.s32	%p2, %r39, %r6;
@%p2 bra BB7_18;

{
.reg .b32 %temp; 
mov.b64 {%temp, %r2}, %fd14;
}
bfe.u32 %r10, %r2, 20, 11;
add.s32 %r11, %r10, -1012;
mov.b64 %rd6, %fd14;
shl.b64 %rd1, %rd6, %r11;
cvta.to.global.u64 %rd7, %rd3;
cvta.to.global.u64 %rd10, %rd4;
cvta.to.global.u64 %rd12, %rd5;

BB7_2:
mov.u32 %r3, %r39;
cvt.s64.s32	%rd2, %r3;
mul.wide.s32 %rd8, %r3, 8;
add.s64 %rd9, %rd7, %rd8;
ld.global.f64 %fd1, [%rd9];
add.s64 %rd11, %rd10, %rd8;
ld.global.f64 %fd2, [%rd11];
{
.reg .b32 %temp; 
mov.b64 {%temp, %r4}, %fd2;
}
abs.f64 %fd3, %fd2;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.f64	[param0+0], %fd3;
.param .b64 param1;
st.param.f64	[param1+0], %fd14;
.param .b64 retval0;
call.uni (retval0), 
__internal_accurate_pow, 
(
param0, 
param1
);
ld.param.f64	%fd26, [retval0+0];


	}
	setp.lt.s32	%p3, %r4, 0;
setp.eq.s64	%p4, %rd1, -9223372036854775808;
and.pred %p1, %p3, %p4;
@!%p1 bra BB7_4;
bra.uni BB7_3;

BB7_3:
{
.reg .b32 %temp; 
mov.b64 {%temp, %r12}, %fd26;
}
xor.b32 %r13, %r12, -2147483648;
{
.reg .b32 %temp; 
mov.b64 {%r14, %temp}, %fd26;
}
mov.b64 %fd26, {%r14, %r13};

BB7_4:
mov.f64 %fd25, %fd26;
setp.eq.f64	%p5, %fd2, 0d0000000000000000;
@%p5 bra BB7_7;
bra.uni BB7_5;

BB7_7:
setp.lt.s32	%p8, %r2, 0;
selp.b32	%r15, %r4, 0, %p4;
or.b32 %r16, %r15, 2146435072;
selp.b32	%r17, %r16, %r15, %p8;
mov.u32 %r18, 0;
mov.b64 %fd25, {%r18, %r17};
bra.uni BB7_8;

BB7_5:
setp.gt.s32	%p6, %r4, -1;
@%p6 bra BB7_8;

cvt.rzi.f64.f64	%fd15, %fd14;
setp.neu.f64	%p7, %fd15, %fd14;
selp.f64	%fd25, 0dFFF8000000000000, %fd25, %p7;

BB7_8:
mov.f64 %fd9, %fd25;
add.f64 %fd10, %fd2, %fd14;
{
.reg .b32 %temp; 
mov.b64 {%temp, %r19}, %fd10;
}
and.b32 %r20, %r19, 2146435072;
setp.ne.s32	%p10, %r20, 2146435072;
mov.f64 %fd24, %fd9;
@%p10 bra BB7_17;

setp.gtu.f64	%p11, %fd3, 0d7FF0000000000000;
mov.f64 %fd24, %fd10;
@%p11 bra BB7_17;

abs.f64 %fd16, %fd14;
setp.gtu.f64	%p12, %fd16, 0d7FF0000000000000;
mov.f64 %fd23, %fd10;
mov.f64 %fd24, %fd23;
@%p12 bra BB7_17;

and.b32 %r21, %r2, 2147483647;
setp.ne.s32	%p13, %r21, 2146435072;
@%p13 bra BB7_13;

{
.reg .b32 %temp; 
mov.b64 {%r22, %temp}, %fd14;
}
setp.eq.s32	%p14, %r22, 0;
@%p14 bra BB7_16;
bra.uni BB7_13;

BB7_16:
setp.lt.s32	%p17, %r2, 0;
setp.gt.f64	%p18, %fd3, 0d3FF0000000000000;
selp.b32	%r31, 2146435072, 0, %p18;
xor.b32 %r32, %r31, 2146435072;
selp.b32	%r33, %r32, %r31, %p17;
setp.eq.f64	%p19, %fd2, 0dBFF0000000000000;
selp.b32	%r34, 1072693248, %r33, %p19;
mov.u32 %r35, 0;
mov.b64 %fd24, {%r35, %r34};
bra.uni BB7_17;

BB7_13:
and.b32 %r23, %r4, 2147483647;
setp.ne.s32	%p15, %r23, 2146435072;
mov.f64 %fd21, %fd9;
mov.f64 %fd24, %fd21;
@%p15 bra BB7_17;

{
.reg .b32 %temp; 
mov.b64 {%r24, %temp}, %fd2;
}
setp.ne.s32	%p16, %r24, 0;
mov.f64 %fd24, %fd9;
@%p16 bra BB7_17;

shr.s32 %r25, %r2, 31;
and.b32 %r26, %r25, -2146435072;
add.s32 %r27, %r26, 2146435072;
or.b32 %r28, %r27, -2147483648;
selp.b32	%r29, %r28, %r27, %p1;
mov.u32 %r30, 0;
mov.b64 %fd24, {%r30, %r29};

BB7_17:
setp.eq.f64	%p20, %fd2, 0d3FF0000000000000;
setp.eq.f64	%p21, %fd14, 0d0000000000000000;
or.pred %p22, %p20, %p21;
selp.f64	%fd17, 0d3FF0000000000000, %fd24, %p22;
mul.f64 %fd18, %fd1, %fd17;
shl.b64 %rd13, %rd2, 3;
add.s64 %rd14, %rd12, %rd13;
st.global.f64 [%rd14], %fd18;
mov.u32 %r37, %nctaid.x;
cvt.u32.u64	%r38, %rd2;
mad.lo.s32 %r39, %r37, %r8, %r38;
setp.lt.s32	%p23, %r39, %r6;
@%p23 bra BB7_2;

BB7_18:
ret;
}


.visible .entry _Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0_(
.param .u32 _Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_0,
.param .u64 _Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_1,
.param .u64 _Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_2,
.param .u64 _Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_3,
.param .u64 _Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_4,
.param .u32 _Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_5,
.param .u32 _Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_6,
.param .u32 _Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_7,
.param .u32 _Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_8,
.param .u32 _Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_9,
.param .f64 _Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_10,
.param .f64 _Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_11,
.param .u64 _Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_12
)
{
.reg .pred %p<57>;
.reg .b32 %r<123>;
.reg .f64 %fd<109>;
.reg .b64 %rd<71>;


ld.param.u32 %r25, [_Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_0];
ld.param.u64 %rd6, [_Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_1];
ld.param.u64 %rd7, [_Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_2];
ld.param.u64 %rd8, [_Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_3];
ld.param.u64 %rd9, [_Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_4];
ld.param.u32 %r26, [_Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_6];
ld.param.u32 %r27, [_Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_7];
ld.param.u32 %r28, [_Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_8];
ld.param.u32 %r29, [_Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_9];
ld.param.f64 %fd38, [_Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_10];
ld.param.f64 %fd39, [_Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_11];
ld.param.u64 %rd10, [_Z14LRNComputeDiffIddEviPKT_S2_S2_S2_iiiiiS0_S0_PS0__param_12];
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %ntid.x;
mov.u32 %r32, %tid.x;
mad.lo.s32 %r112, %r31, %r30, %r32;
setp.ge.s32	%p3, %r112, %r25;
@%p3 bra BB8_45;

add.s32 %r33, %r29, 1;
shr.u32 %r34, %r33, 31;
add.s32 %r35, %r33, %r34;
shr.s32 %r36, %r35, 1;
add.s32 %r2, %r36, -1;

BB8_2:
div.s32 %r39, %r112, %r28;
rem.s32 %r40, %r39, %r27;
div.s32 %r41, %r39, %r27;
mul.lo.s32 %r42, %r27, %r26;
mad.lo.s32 %r43, %r42, %r41, %r40;
rem.s32 %r44, %r112, %r28;
mad.lo.s32 %r45, %r43, %r28, %r44;
cvt.s64.s32	%rd1, %r45;
setp.gt.s32	%p4, %r26, 0;
setp.gt.s32	%p5, %r2, 0;
and.pred %p6, %p5, %p4;
mov.u32 %r121, 0;
mov.f64 %fd99, 0d0000000000000000;
mov.u32 %r122, %r121;
mov.f64 %fd100, %fd99;
@!%p6 bra BB8_4;
bra.uni BB8_3;

BB8_3:
mul.lo.s32 %r46, %r28, %r27;
mul.lo.s32 %r47, %r122, %r46;
cvt.s64.s32	%rd11, %r47;
add.s64 %rd12, %rd11, %rd1;
cvta.to.global.u64 %rd13, %rd9;
shl.b64 %rd14, %rd12, 3;
add.s64 %rd15, %rd13, %rd14;
cvta.to.global.u64 %rd16, %rd7;
add.s64 %rd17, %rd16, %rd14;
ld.global.f64 %fd42, [%rd17];
ld.global.f64 %fd43, [%rd15];
mul.f64 %fd44, %fd43, %fd42;
cvta.to.global.u64 %rd18, %rd8;
add.s64 %rd19, %rd18, %rd14;
ld.global.f64 %fd45, [%rd19];
div.rn.f64 %fd46, %fd44, %fd45;
add.f64 %fd100, %fd100, %fd46;
add.s32 %r122, %r122, 1;
setp.lt.s32	%p7, %r122, %r2;
setp.lt.s32	%p8, %r122, %r26;
and.pred %p9, %p7, %p8;
mov.f64 %fd99, %fd100;
mov.u32 %r121, %r122;
@%p9 bra BB8_3;

BB8_4:
mov.u32 %r119, %r121;
mov.f64 %fd96, %fd99;
setp.ge.s32	%p10, %r119, %r26;
@%p10 bra BB8_24;

{
.reg .b32 %temp; 
mov.b64 {%temp, %r7}, %fd38;
}
bfe.u32 %r48, %r7, 20, 11;
add.s32 %r49, %r48, -1012;
mov.b64 %rd20, %fd38;
shl.b64 %rd2, %rd20, %r49;
and.b32 %r8, %r7, 2147483647;
shr.s32 %r50, %r7, 31;
and.b32 %r51, %r50, -2146435072;
add.s32 %r9, %r51, 2146435072;
or.b32 %r10, %r9, -2147483648;
mov.f64 %fd97, %fd96;
mov.u32 %r120, %r119;

BB8_6:
mul.lo.s32 %r52, %r28, %r27;
mul.lo.s32 %r53, %r120, %r52;
cvt.s64.s32	%rd21, %r53;
add.s64 %rd22, %rd21, %rd1;
cvta.to.global.u64 %rd23, %rd9;
shl.b64 %rd24, %rd22, 3;
add.s64 %rd25, %rd23, %rd24;
cvta.to.global.u64 %rd26, %rd7;
add.s64 %rd27, %rd26, %rd24;
ld.global.f64 %fd47, [%rd27];
ld.global.f64 %fd48, [%rd25];
mul.f64 %fd49, %fd48, %fd47;
cvta.to.global.u64 %rd28, %rd8;
add.s64 %rd29, %rd28, %rd24;
ld.global.f64 %fd50, [%rd29];
div.rn.f64 %fd51, %fd49, %fd50;
add.f64 %fd98, %fd97, %fd51;
sub.s32 %r12, %r120, %r29;
setp.lt.s32	%p11, %r12, 0;
@%p11 bra BB8_8;

mul.lo.s32 %r55, %r12, %r52;
cvt.s64.s32	%rd30, %r55;
add.s64 %rd31, %rd30, %rd1;
shl.b64 %rd33, %rd31, 3;
add.s64 %rd34, %rd23, %rd33;
add.s64 %rd36, %rd26, %rd33;
ld.global.f64 %fd52, [%rd36];
ld.global.f64 %fd53, [%rd34];
mul.f64 %fd54, %fd53, %fd52;
add.s64 %rd38, %rd28, %rd33;
ld.global.f64 %fd55, [%rd38];
div.rn.f64 %fd56, %fd54, %fd55;
sub.f64 %fd98, %fd98, %fd56;

BB8_8:
mov.f64 %fd97, %fd98;
sub.s32 %r57, %r120, %r2;
mul.lo.s32 %r58, %r57, %r52;
cvt.s64.s32	%rd39, %r58;
add.s64 %rd3, %rd39, %rd1;
shl.b64 %rd41, %rd3, 3;
add.s64 %rd42, %rd23, %rd41;
ld.global.f64 %fd8, [%rd42];
add.s64 %rd44, %rd28, %rd41;
ld.global.f64 %fd9, [%rd44];
{
.reg .b32 %temp; 
mov.b64 {%temp, %r13}, %fd9;
}
abs.f64 %fd10, %fd9;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.f64	[param0+0], %fd10;
.param .b64 param1;
st.param.f64	[param1+0], %fd38;
.param .b64 retval0;
call.uni (retval0), 
__internal_accurate_pow, 
(
param0, 
param1
);
ld.param.f64	%fd85, [retval0+0];


	}
	setp.lt.s32	%p12, %r13, 0;
setp.eq.s64	%p13, %rd2, -9223372036854775808;
and.pred %p1, %p12, %p13;
@!%p1 bra BB8_10;
bra.uni BB8_9;

BB8_9:
{
.reg .b32 %temp; 
mov.b64 {%temp, %r59}, %fd85;
}
xor.b32 %r60, %r59, -2147483648;
{
.reg .b32 %temp; 
mov.b64 {%r61, %temp}, %fd85;
}
mov.b64 %fd85, {%r61, %r60};

BB8_10:
mov.f64 %fd84, %fd85;
setp.eq.f64	%p14, %fd9, 0d0000000000000000;
@%p14 bra BB8_13;
bra.uni BB8_11;

BB8_13:
{
.reg .b32 %temp; 
mov.b64 {%temp, %r111}, %fd38;
}
setp.lt.s32	%p17, %r111, 0;
selp.b32	%r62, %r13, 0, %p13;
or.b32 %r63, %r62, 2146435072;
selp.b32	%r64, %r63, %r62, %p17;
mov.u32 %r65, 0;
mov.b64 %fd84, {%r65, %r64};
bra.uni BB8_14;

BB8_11:
setp.gt.s32	%p15, %r13, -1;
@%p15 bra BB8_14;

cvt.rzi.f64.f64	%fd57, %fd38;
setp.neu.f64	%p16, %fd57, %fd38;
selp.f64	%fd84, 0dFFF8000000000000, %fd84, %p16;

BB8_14:
mov.f64 %fd16, %fd84;
add.f64 %fd17, %fd9, %fd38;
{
.reg .b32 %temp; 
mov.b64 {%temp, %r66}, %fd17;
}
and.b32 %r67, %r66, 2146435072;
setp.ne.s32	%p19, %r67, 2146435072;
mov.f64 %fd83, %fd16;
@%p19 bra BB8_23;

setp.gtu.f64	%p20, %fd10, 0d7FF0000000000000;
mov.f64 %fd83, %fd17;
@%p20 bra BB8_23;

abs.f64 %fd58, %fd38;
setp.gtu.f64	%p21, %fd58, 0d7FF0000000000000;
mov.f64 %fd82, %fd17;
mov.f64 %fd83, %fd82;
@%p21 bra BB8_23;

setp.ne.s32	%p22, %r8, 2146435072;
@%p22 bra BB8_19;

{
.reg .b32 %temp; 
mov.b64 {%r68, %temp}, %fd38;
}
setp.eq.s32	%p23, %r68, 0;
@%p23 bra BB8_22;
bra.uni BB8_19;

BB8_22:
{
.reg .b32 %temp; 
mov.b64 {%temp, %r110}, %fd38;
}
setp.lt.s32	%p26, %r110, 0;
setp.gt.f64	%p27, %fd10, 0d3FF0000000000000;
selp.b32	%r73, 2146435072, 0, %p27;
xor.b32 %r74, %r73, 2146435072;
selp.b32	%r75, %r74, %r73, %p26;
setp.eq.f64	%p28, %fd9, 0dBFF0000000000000;
selp.b32	%r76, 1072693248, %r75, %p28;
mov.u32 %r77, 0;
mov.b64 %fd83, {%r77, %r76};
bra.uni BB8_23;

BB8_19:
and.b32 %r69, %r13, 2147483647;
setp.ne.s32	%p24, %r69, 2146435072;
mov.f64 %fd80, %fd16;
mov.f64 %fd83, %fd80;
@%p24 bra BB8_23;

{
.reg .b32 %temp; 
mov.b64 {%r70, %temp}, %fd9;
}
setp.ne.s32	%p25, %r70, 0;
mov.f64 %fd83, %fd16;
@%p25 bra BB8_23;

selp.b32	%r71, %r10, %r9, %p1;
mov.u32 %r72, 0;
mov.b64 %fd83, {%r72, %r71};

BB8_23:
setp.eq.f64	%p29, %fd9, 0d3FF0000000000000;
setp.eq.f64	%p30, %fd38, 0d0000000000000000;
or.pred %p31, %p29, %p30;
selp.f64	%fd59, 0d3FF0000000000000, %fd83, %p31;
mul.f64 %fd60, %fd8, %fd59;
cvta.to.global.u64 %rd45, %rd6;
add.s64 %rd47, %rd45, %rd41;
ld.global.f64 %fd61, [%rd47];
mul.f64 %fd62, %fd61, %fd39;
mul.f64 %fd63, %fd97, %fd62;
sub.f64 %fd64, %fd60, %fd63;
cvta.to.global.u64 %rd48, %rd10;
add.s64 %rd49, %rd48, %rd41;
st.global.f64 [%rd49], %fd64;
add.s32 %r120, %r120, 1;
setp.lt.s32	%p32, %r120, %r26;
mov.f64 %fd96, %fd97;
mov.u32 %r119, %r120;
@%p32 bra BB8_6;

BB8_24:
mov.u32 %r118, %r119;
mov.f64 %fd94, %fd96;
add.s32 %r78, %r2, %r26;
setp.ge.s32	%p33, %r118, %r78;
@%p33 bra BB8_44;

{
.reg .b32 %temp; 
mov.b64 {%temp, %r16}, %fd38;
}
bfe.u32 %r79, %r16, 20, 11;
add.s32 %r80, %r79, -1012;
mov.b64 %rd50, %fd38;
shl.b64 %rd4, %rd50, %r80;
and.b32 %r17, %r16, 2147483647;
shr.s32 %r81, %r16, 31;
and.b32 %r82, %r81, -2146435072;
add.s32 %r18, %r82, 2146435072;
or.b32 %r19, %r18, -2147483648;

BB8_26:
mov.f64 %fd95, %fd94;
sub.s32 %r21, %r118, %r29;
setp.lt.s32	%p34, %r21, 0;
@%p34 bra BB8_28;

mul.lo.s32 %r83, %r28, %r27;
mul.lo.s32 %r84, %r21, %r83;
cvt.s64.s32	%rd51, %r84;
add.s64 %rd52, %rd51, %rd1;
cvta.to.global.u64 %rd53, %rd9;
shl.b64 %rd54, %rd52, 3;
add.s64 %rd55, %rd53, %rd54;
cvta.to.global.u64 %rd56, %rd7;
add.s64 %rd57, %rd56, %rd54;
ld.global.f64 %fd65, [%rd57];
ld.global.f64 %fd66, [%rd55];
mul.f64 %fd67, %fd66, %fd65;
cvta.to.global.u64 %rd58, %rd8;
add.s64 %rd59, %rd58, %rd54;
ld.global.f64 %fd68, [%rd59];
div.rn.f64 %fd69, %fd67, %fd68;
sub.f64 %fd95, %fd95, %fd69;

BB8_28:
mov.f64 %fd94, %fd95;
mul.lo.s32 %r85, %r28, %r27;
sub.s32 %r86, %r118, %r2;
mul.lo.s32 %r87, %r86, %r85;
cvt.s64.s32	%rd60, %r87;
add.s64 %rd5, %rd60, %rd1;
cvta.to.global.u64 %rd61, %rd9;
shl.b64 %rd62, %rd5, 3;
add.s64 %rd63, %rd61, %rd62;
ld.global.f64 %fd25, [%rd63];
cvta.to.global.u64 %rd64, %rd8;
add.s64 %rd65, %rd64, %rd62;
ld.global.f64 %fd26, [%rd65];
{
.reg .b32 %temp; 
mov.b64 {%temp, %r22}, %fd26;
}
abs.f64 %fd27, %fd26;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.f64	[param0+0], %fd27;
.param .b64 param1;
st.param.f64	[param1+0], %fd38;
.param .b64 retval0;
call.uni (retval0), 
__internal_accurate_pow, 
(
param0, 
param1
);
ld.param.f64	%fd108, [retval0+0];


	}
	setp.lt.s32	%p35, %r22, 0;
setp.eq.s64	%p36, %rd4, -9223372036854775808;
and.pred %p2, %p35, %p36;
@!%p2 bra BB8_30;
bra.uni BB8_29;

BB8_29:
{
.reg .b32 %temp; 
mov.b64 {%temp, %r88}, %fd108;
}
xor.b32 %r89, %r88, -2147483648;
{
.reg .b32 %temp; 
mov.b64 {%r90, %temp}, %fd108;
}
mov.b64 %fd108, {%r90, %r89};

BB8_30:
mov.f64 %fd107, %fd108;
setp.eq.f64	%p37, %fd26, 0d0000000000000000;
@%p37 bra BB8_33;
bra.uni BB8_31;

BB8_33:
setp.lt.s32	%p40, %r16, 0;
selp.b32	%r91, %r22, 0, %p36;
or.b32 %r92, %r91, 2146435072;
selp.b32	%r93, %r92, %r91, %p40;
mov.u32 %r94, 0;
mov.b64 %fd107, {%r94, %r93};
bra.uni BB8_34;

BB8_31:
setp.gt.s32	%p38, %r22, -1;
@%p38 bra BB8_34;

cvt.rzi.f64.f64	%fd70, %fd38;
setp.neu.f64	%p39, %fd70, %fd38;
selp.f64	%fd107, 0dFFF8000000000000, %fd107, %p39;

BB8_34:
mov.f64 %fd33, %fd107;
add.f64 %fd34, %fd26, %fd38;
{
.reg .b32 %temp; 
mov.b64 {%temp, %r95}, %fd34;
}
and.b32 %r96, %r95, 2146435072;
setp.ne.s32	%p42, %r96, 2146435072;
mov.f64 %fd106, %fd33;
@%p42 bra BB8_43;

setp.gtu.f64	%p43, %fd27, 0d7FF0000000000000;
mov.f64 %fd106, %fd34;
@%p43 bra BB8_43;

abs.f64 %fd71, %fd38;
setp.gtu.f64	%p44, %fd71, 0d7FF0000000000000;
mov.f64 %fd105, %fd34;
mov.f64 %fd106, %fd105;
@%p44 bra BB8_43;

setp.ne.s32	%p45, %r17, 2146435072;
@%p45 bra BB8_39;

{
.reg .b32 %temp; 
mov.b64 {%r97, %temp}, %fd38;
}
setp.eq.s32	%p46, %r97, 0;
@%p46 bra BB8_42;
bra.uni BB8_39;

BB8_42:
setp.lt.s32	%p49, %r16, 0;
setp.gt.f64	%p50, %fd27, 0d3FF0000000000000;
selp.b32	%r102, 2146435072, 0, %p50;
xor.b32 %r103, %r102, 2146435072;
selp.b32	%r104, %r103, %r102, %p49;
setp.eq.f64	%p51, %fd26, 0dBFF0000000000000;
selp.b32	%r105, 1072693248, %r104, %p51;
mov.u32 %r106, 0;
mov.b64 %fd106, {%r106, %r105};
bra.uni BB8_43;

BB8_39:
and.b32 %r98, %r22, 2147483647;
setp.ne.s32	%p47, %r98, 2146435072;
mov.f64 %fd103, %fd33;
mov.f64 %fd106, %fd103;
@%p47 bra BB8_43;

{
.reg .b32 %temp; 
mov.b64 {%r99, %temp}, %fd26;
}
setp.ne.s32	%p48, %r99, 0;
mov.f64 %fd106, %fd33;
@%p48 bra BB8_43;

selp.b32	%r100, %r19, %r18, %p2;
mov.u32 %r101, 0;
mov.b64 %fd106, {%r101, %r100};

BB8_43:
setp.eq.f64	%p52, %fd26, 0d3FF0000000000000;
setp.eq.f64	%p53, %fd38, 0d0000000000000000;
or.pred %p54, %p52, %p53;
selp.f64	%fd72, 0d3FF0000000000000, %fd106, %p54;
mul.f64 %fd73, %fd25, %fd72;
cvta.to.global.u64 %rd66, %rd6;
add.s64 %rd68, %rd66, %rd62;
ld.global.f64 %fd74, [%rd68];
mul.f64 %fd75, %fd74, %fd39;
mul.f64 %fd76, %fd94, %fd75;
sub.f64 %fd77, %fd73, %fd76;
cvta.to.global.u64 %rd69, %rd10;
add.s64 %rd70, %rd69, %rd62;
st.global.f64 [%rd70], %fd77;
add.s32 %r118, %r118, 1;
setp.lt.s32	%p55, %r118, %r78;
@%p55 bra BB8_26;

BB8_44:
mov.u32 %r108, %nctaid.x;
mad.lo.s32 %r112, %r108, %r31, %r112;
setp.lt.s32	%p56, %r112, %r25;
@%p56 bra BB8_2;

BB8_45:
ret;
}

.func (.param .b64 func_retval0) __internal_accurate_pow(
.param .b64 __internal_accurate_pow_param_0,
.param .b64 __internal_accurate_pow_param_1
)
{
.reg .pred %p<9>;
.reg .f32 %f<3>;
.reg .b32 %r<52>;
.reg .f64 %fd<134>;


ld.param.f64 %fd12, [__internal_accurate_pow_param_0];
ld.param.f64 %fd13, [__internal_accurate_pow_param_1];
{
.reg .b32 %temp; 
mov.b64 {%temp, %r49}, %fd12;
}
{
.reg .b32 %temp; 
mov.b64 {%r48, %temp}, %fd12;
}
shr.u32 %r50, %r49, 20;
setp.ne.s32	%p1, %r50, 0;
@%p1 bra BB9_2;

mul.f64 %fd14, %fd12, 0d4350000000000000;
{
.reg .b32 %temp; 
mov.b64 {%temp, %r49}, %fd14;
}
{
.reg .b32 %temp; 
mov.b64 {%r48, %temp}, %fd14;
}
shr.u32 %r16, %r49, 20;
add.s32 %r50, %r16, -54;

BB9_2:
add.s32 %r51, %r50, -1023;
and.b32 %r17, %r49, -2146435073;
or.b32 %r18, %r17, 1072693248;
mov.b64 %fd132, {%r48, %r18};
setp.lt.u32	%p2, %r18, 1073127583;
@%p2 bra BB9_4;

{
.reg .b32 %temp; 
mov.b64 {%r19, %temp}, %fd132;
}
{
.reg .b32 %temp; 
mov.b64 {%temp, %r20}, %fd132;
}
add.s32 %r21, %r20, -1048576;
mov.b64 %fd132, {%r19, %r21};
add.s32 %r51, %r50, -1022;

BB9_4:
add.f64 %fd16, %fd132, 0d3FF0000000000000;

	rcp.approx.ftz.f64 %fd15,%fd16;

	neg.f64 %fd17, %fd16;
mov.f64 %fd18, 0d3FF0000000000000;
fma.rn.f64 %fd19, %fd17, %fd15, %fd18;
fma.rn.f64 %fd20, %fd19, %fd19, %fd19;
fma.rn.f64 %fd21, %fd20, %fd15, %fd15;
add.f64 %fd22, %fd132, 0dBFF0000000000000;
mul.f64 %fd23, %fd22, %fd21;
fma.rn.f64 %fd24, %fd22, %fd21, %fd23;
mul.f64 %fd25, %fd24, %fd24;
mov.f64 %fd26, 0d3ED0F5D241AD3B5A;
mov.f64 %fd27, 0d3EB0F5FF7D2CAFE2;
fma.rn.f64 %fd28, %fd27, %fd25, %fd26;
mov.f64 %fd29, 0d3EF3B20A75488A3F;
fma.rn.f64 %fd30, %fd28, %fd25, %fd29;
mov.f64 %fd31, 0d3F1745CDE4FAECD5;
fma.rn.f64 %fd32, %fd30, %fd25, %fd31;
mov.f64 %fd33, 0d3F3C71C7258A578B;
fma.rn.f64 %fd34, %fd32, %fd25, %fd33;
mov.f64 %fd35, 0d3F6249249242B910;
fma.rn.f64 %fd36, %fd34, %fd25, %fd35;
mov.f64 %fd37, 0d3F89999999999DFB;
fma.rn.f64 %fd38, %fd36, %fd25, %fd37;
sub.f64 %fd39, %fd22, %fd24;
add.f64 %fd40, %fd39, %fd39;
neg.f64 %fd41, %fd24;
fma.rn.f64 %fd42, %fd41, %fd22, %fd40;
mul.f64 %fd43, %fd21, %fd42;
fma.rn.f64 %fd44, %fd25, %fd38, 0d3FB5555555555555;
mov.f64 %fd45, 0d3FB5555555555555;
sub.f64 %fd46, %fd45, %fd44;
fma.rn.f64 %fd47, %fd25, %fd38, %fd46;
add.f64 %fd48, %fd47, 0d0000000000000000;
add.f64 %fd49, %fd48, 0dBC46A4CB00B9E7B0;
add.f64 %fd50, %fd44, %fd49;
sub.f64 %fd51, %fd44, %fd50;
add.f64 %fd52, %fd49, %fd51;
mul.rn.f64 %fd53, %fd24, %fd24;
neg.f64 %fd54, %fd53;
fma.rn.f64 %fd55, %fd24, %fd24, %fd54;
{
.reg .b32 %temp; 
mov.b64 {%r22, %temp}, %fd43;
}
{
.reg .b32 %temp; 
mov.b64 {%temp, %r23}, %fd43;
}
add.s32 %r24, %r23, 1048576;
mov.b64 %fd56, {%r22, %r24};
fma.rn.f64 %fd57, %fd24, %fd56, %fd55;
mul.rn.f64 %fd58, %fd53, %fd24;
neg.f64 %fd59, %fd58;
fma.rn.f64 %fd60, %fd53, %fd24, %fd59;
fma.rn.f64 %fd61, %fd53, %fd43, %fd60;
fma.rn.f64 %fd62, %fd57, %fd24, %fd61;
mul.rn.f64 %fd63, %fd50, %fd58;
neg.f64 %fd64, %fd63;
fma.rn.f64 %fd65, %fd50, %fd58, %fd64;
fma.rn.f64 %fd66, %fd50, %fd62, %fd65;
fma.rn.f64 %fd67, %fd52, %fd58, %fd66;
add.f64 %fd68, %fd63, %fd67;
sub.f64 %fd69, %fd63, %fd68;
add.f64 %fd70, %fd67, %fd69;
add.f64 %fd71, %fd24, %fd68;
sub.f64 %fd72, %fd24, %fd71;
add.f64 %fd73, %fd68, %fd72;
add.f64 %fd74, %fd70, %fd73;
add.f64 %fd75, %fd43, %fd74;
add.f64 %fd76, %fd71, %fd75;
sub.f64 %fd77, %fd71, %fd76;
add.f64 %fd78, %fd75, %fd77;
xor.b32 %r25, %r51, -2147483648;
mov.u32 %r26, 1127219200;
mov.b64 %fd79, {%r25, %r26};
mov.u32 %r27, -2147483648;
mov.b64 %fd80, {%r27, %r26};
sub.f64 %fd81, %fd79, %fd80;
mov.f64 %fd82, 0d3FE62E42FEFA39EF;
fma.rn.f64 %fd83, %fd81, %fd82, %fd76;
neg.f64 %fd84, %fd81;
fma.rn.f64 %fd85, %fd84, %fd82, %fd83;
sub.f64 %fd86, %fd85, %fd76;
sub.f64 %fd87, %fd78, %fd86;
mov.f64 %fd88, 0d3C7ABC9E3B39803F;
fma.rn.f64 %fd89, %fd81, %fd88, %fd87;
add.f64 %fd90, %fd83, %fd89;
sub.f64 %fd91, %fd83, %fd90;
add.f64 %fd92, %fd89, %fd91;
{
.reg .b32 %temp; 
mov.b64 {%temp, %r28}, %fd13;
}
add.s32 %r29, %r28, %r28;
setp.gt.u32	%p3, %r29, -33554433;
and.b32 %r30, %r28, -15728641;
selp.b32	%r31, %r30, %r28, %p3;
{
.reg .b32 %temp; 
mov.b64 {%r32, %temp}, %fd13;
}
mov.b64 %fd93, {%r32, %r31};
mul.rn.f64 %fd94, %fd90, %fd93;
neg.f64 %fd95, %fd94;
fma.rn.f64 %fd96, %fd90, %fd93, %fd95;
fma.rn.f64 %fd97, %fd92, %fd93, %fd96;
add.f64 %fd4, %fd94, %fd97;
sub.f64 %fd98, %fd94, %fd4;
add.f64 %fd5, %fd97, %fd98;
mov.f64 %fd99, 0d4338000000000000;
mov.f64 %fd100, 0d3FF71547652B82FE;
fma.rn.f64 %fd101, %fd4, %fd100, %fd99;
{
.reg .b32 %temp; 
mov.b64 {%r13, %temp}, %fd101;
}
mov.f64 %fd102, 0dC338000000000000;
add.rn.f64 %fd103, %fd101, %fd102;
mov.f64 %fd104, 0dBFE62E42FEFA39EF;
fma.rn.f64 %fd105, %fd103, %fd104, %fd4;
mov.f64 %fd106, 0dBC7ABC9E3B39803F;
fma.rn.f64 %fd107, %fd103, %fd106, %fd105;
mov.f64 %fd108, 0d3E928AF3FCA213EA;
mov.f64 %fd109, 0d3E5ADE1569CE2BDF;
fma.rn.f64 %fd110, %fd109, %fd107, %fd108;
mov.f64 %fd111, 0d3EC71DEE62401315;
fma.rn.f64 %fd112, %fd110, %fd107, %fd111;
mov.f64 %fd113, 0d3EFA01997C89EB71;
fma.rn.f64 %fd114, %fd112, %fd107, %fd113;
mov.f64 %fd115, 0d3F2A01A014761F65;
fma.rn.f64 %fd116, %fd114, %fd107, %fd115;
mov.f64 %fd117, 0d3F56C16C1852B7AF;
fma.rn.f64 %fd118, %fd116, %fd107, %fd117;
mov.f64 %fd119, 0d3F81111111122322;
fma.rn.f64 %fd120, %fd118, %fd107, %fd119;
mov.f64 %fd121, 0d3FA55555555502A1;
fma.rn.f64 %fd122, %fd120, %fd107, %fd121;
mov.f64 %fd123, 0d3FC5555555555511;
fma.rn.f64 %fd124, %fd122, %fd107, %fd123;
mov.f64 %fd125, 0d3FE000000000000B;
fma.rn.f64 %fd126, %fd124, %fd107, %fd125;
fma.rn.f64 %fd127, %fd126, %fd107, %fd18;
fma.rn.f64 %fd128, %fd127, %fd107, %fd18;
{
.reg .b32 %temp; 
mov.b64 {%r14, %temp}, %fd128;
}
{
.reg .b32 %temp; 
mov.b64 {%temp, %r15}, %fd128;
}
shl.b32 %r33, %r13, 20;
add.s32 %r34, %r15, %r33;
mov.b64 %fd133, {%r14, %r34};
{
.reg .b32 %temp; 
mov.b64 {%temp, %r35}, %fd4;
}
mov.b32 %f2, %r35;
abs.f32 %f1, %f2;
setp.lt.f32	%p4, %f1, 0f4086232B;
@%p4 bra BB9_7;

setp.lt.f64	%p5, %fd4, 0d0000000000000000;
add.f64 %fd129, %fd4, 0d7FF0000000000000;
selp.f64	%fd133, 0d0000000000000000, %fd129, %p5;
setp.geu.f32	%p6, %f1, 0f40874800;
@%p6 bra BB9_7;

shr.u32 %r36, %r13, 31;
add.s32 %r37, %r13, %r36;
shr.s32 %r38, %r37, 1;
shl.b32 %r39, %r38, 20;
add.s32 %r40, %r39, %r15;
mov.b64 %fd130, {%r14, %r40};
sub.s32 %r41, %r13, %r38;
shl.b32 %r42, %r41, 20;
add.s32 %r43, %r42, 1072693248;
mov.u32 %r44, 0;
mov.b64 %fd131, {%r44, %r43};
mul.f64 %fd133, %fd130, %fd131;

BB9_7:
{
.reg .b32 %temp; 
mov.b64 {%temp, %r45}, %fd133;
}
and.b32 %r46, %r45, 2147483647;
setp.ne.s32	%p7, %r46, 2146435072;
@%p7 bra BB9_9;

{
.reg .b32 %temp; 
mov.b64 {%r47, %temp}, %fd133;
}
setp.eq.s32	%p8, %r47, 0;
@%p8 bra BB9_10;

BB9_9:
fma.rn.f64 %fd133, %fd133, %fd5, %fd133;

BB9_10:
st.param.f64	[func_retval0+0], %fd133;
ret;
}


