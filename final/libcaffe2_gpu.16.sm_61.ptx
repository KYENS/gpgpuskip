







.version 5.0
.target sm_61
.address_size 64


.extern .func __assertfail
(
.param .b64 __assertfail_param_0,
.param .b64 __assertfail_param_1,
.param .b32 __assertfail_param_2,
.param .b64 __assertfail_param_3,
.param .b64 __assertfail_param_4
)
;
.global .align 8 .b8 _ZTVSt9basic_iosIcSt11char_traitsIcEE[32];
.global .align 8 .b8 _ZTTSo[8];
.global .align 8 .b8 _ZTVSt15basic_streambufIcSt11char_traitsIcEE[128];
.global .align 8 .b8 _ZTVNSt7__cxx1115basic_stringbufIcSt11char_traitsIcESaIcEEE[128];
.global .align 8 .b8 _ZTTNSt7__cxx1119basic_ostringstreamIcSt11char_traitsIcESaIcEEE[8];
.global .align 8 .b8 _ZTVN10__cxxabiv117__class_type_infoE[8];
.global .align 8 .b8 _ZTVN10__cxxabiv120__si_class_type_infoE[8];
.global .align 8 .b8 _ZTVN3c105ErrorE[40];
.global .align 1 .b8 __T20[38] = {84, 32, 112, 111, 119, 105, 40, 84, 44, 32, 84, 41, 32, 91, 119, 105, 116, 104, 32, 84, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 93, 0};
.global .align 1 .b8 __T21[36] = {84, 32, 112, 111, 119, 105, 40, 84, 44, 32, 84, 41, 32, 91, 119, 105, 116, 104, 32, 84, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 93, 0};
.global .align 1 .b8 __T22[30] = {84, 32, 112, 111, 119, 105, 40, 84, 44, 32, 84, 41, 32, 91, 119, 105, 116, 104, 32, 84, 32, 61, 32, 115, 104, 111, 114, 116, 93, 0};
.global .align 1 .b8 __T23[28] = {84, 32, 112, 111, 119, 105, 40, 84, 44, 32, 84, 41, 32, 91, 119, 105, 116, 104, 32, 84, 32, 61, 32, 105, 110, 116, 93, 0};
.global .align 1 .b8 __T24[29] = {84, 32, 112, 111, 119, 105, 40, 84, 44, 32, 84, 41, 32, 91, 119, 105, 116, 104, 32, 84, 32, 61, 32, 108, 111, 110, 103, 93, 0};
.global .align 1 .b8 __T29[198] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T210[198] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T211[198] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T212[199] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T215[200] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T216[199] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T217[199] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T218[199] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T219[200] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T220[201] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T221[202] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T222[202] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T223[202] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T224[203] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T225[204] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T226[180] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T227[180] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T228[180] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T229[181] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T230[182] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T233[196] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T234[196] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T235[196] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T236[197] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T238[198] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T239[197] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T240[197] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T241[197] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T242[198] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T243[199] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T244[200] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T245[200] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T246[200] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T247[201] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T248[202] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T249[178] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T250[178] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T251[178] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T252[179] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T253[180] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T256[190] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 104, 111, 114, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T257[190] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 104, 111, 114, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T258[190] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 104, 111, 114, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T259[191] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 104, 111, 114, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T261[192] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 104, 111, 114, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T262[191] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 104, 111, 114, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T263[191] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 104, 111, 114, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T264[191] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 104, 111, 114, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T265[192] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 104, 111, 114, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T266[193] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 104, 111, 114, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T267[194] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 104, 111, 114, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T268[194] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 104, 111, 114, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T269[194] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 104, 111, 114, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T270[195] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 104, 111, 114, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T271[196] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 104, 111, 114, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T272[172] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 104, 111, 114, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T273[172] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 104, 111, 114, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T274[172] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 104, 111, 114, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T275[173] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 104, 111, 114, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T276[174] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 115, 104, 111, 114, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T279[188] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 105, 110, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T280[188] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 105, 110, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T281[188] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 105, 110, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T282[189] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 105, 110, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T284[190] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 105, 110, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T285[189] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 105, 110, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T286[189] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 105, 110, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T287[189] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 105, 110, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T288[190] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 105, 110, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T289[191] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 105, 110, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T290[192] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 105, 110, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T291[192] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 105, 110, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T292[192] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 105, 110, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T293[193] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 105, 110, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T294[194] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 105, 110, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T295[170] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 105, 110, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T296[170] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 105, 110, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T297[170] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 105, 110, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T298[171] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 105, 110, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T299[172] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 105, 110, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2100[189] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 108, 111, 110, 103, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T2101[189] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 108, 111, 110, 103, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T2102[189] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 108, 111, 110, 103, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T2103[190] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 108, 111, 110, 103, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2104[191] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 108, 111, 110, 103, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2105[190] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 108, 111, 110, 103, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T2106[190] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 108, 111, 110, 103, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T2107[190] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 108, 111, 110, 103, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T2108[191] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 108, 111, 110, 103, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2109[192] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 108, 111, 110, 103, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2110[193] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 108, 111, 110, 103, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T2111[193] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 108, 111, 110, 103, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T2112[193] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 108, 111, 110, 103, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T2113[194] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 108, 111, 110, 103, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2114[195] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 108, 111, 110, 103, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2115[171] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 108, 111, 110, 103, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T2116[171] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 108, 111, 110, 103, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T2117[171] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 108, 111, 110, 103, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T2118[172] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 108, 111, 110, 103, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2119[173] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 108, 111, 110, 103, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2122[194] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 99, 49, 48, 58, 58, 72, 97, 108, 102, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T2123[194] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 99, 49, 48, 58, 58, 72, 97, 108, 102, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T2124[194] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 99, 49, 48, 58, 58, 72, 97, 108, 102, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T2125[195] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 99, 49, 48, 58, 58, 72, 97, 108, 102, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2127[196] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 99, 49, 48, 58, 58, 72, 97, 108, 102, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2128[195] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 99, 49, 48, 58, 58, 72, 97, 108, 102, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T2129[195] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 99, 49, 48, 58, 58, 72, 97, 108, 102, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T2130[195] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 99, 49, 48, 58, 58, 72, 97, 108, 102, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T2131[196] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 99, 49, 48, 58, 58, 72, 97, 108, 102, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2132[197] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 99, 49, 48, 58, 58, 72, 97, 108, 102, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2133[198] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 99, 49, 48, 58, 58, 72, 97, 108, 102, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T2134[198] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 99, 49, 48, 58, 58, 72, 97, 108, 102, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T2135[198] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 99, 49, 48, 58, 58, 72, 97, 108, 102, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T2136[199] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 99, 49, 48, 58, 58, 72, 97, 108, 102, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2137[200] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 99, 49, 48, 58, 58, 72, 97, 108, 102, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2138[176] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 99, 49, 48, 58, 58, 72, 97, 108, 102, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T2139[176] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 99, 49, 48, 58, 58, 72, 97, 108, 102, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T2140[176] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 99, 49, 48, 58, 58, 72, 97, 108, 102, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T2141[177] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 99, 49, 48, 58, 58, 72, 97, 108, 102, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2142[178] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 99, 49, 48, 58, 58, 72, 97, 108, 102, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2145[190] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 102, 108, 111, 97, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T2146[190] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 102, 108, 111, 97, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T2147[190] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 102, 108, 111, 97, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T2148[191] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 102, 108, 111, 97, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2150[192] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 102, 108, 111, 97, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2151[191] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 102, 108, 111, 97, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T2152[191] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 102, 108, 111, 97, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T2153[191] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 102, 108, 111, 97, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T2154[192] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 102, 108, 111, 97, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2155[193] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 102, 108, 111, 97, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2156[194] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 102, 108, 111, 97, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T2157[194] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 102, 108, 111, 97, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T2158[194] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 102, 108, 111, 97, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T2159[195] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 102, 108, 111, 97, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2160[196] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 102, 108, 111, 97, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2161[172] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 102, 108, 111, 97, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T2162[172] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 102, 108, 111, 97, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T2163[172] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 102, 108, 111, 97, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T2164[173] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 102, 108, 111, 97, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2165[174] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 102, 108, 111, 97, 116, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2168[191] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 100, 111, 117, 98, 108, 101, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T2169[191] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 100, 111, 117, 98, 108, 101, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T2170[191] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 100, 111, 117, 98, 108, 101, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T2171[192] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 100, 111, 117, 98, 108, 101, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2173[193] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 103, 97, 116, 104, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 100, 111, 117, 98, 108, 101, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2174[192] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 100, 111, 117, 98, 108, 101, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T2175[192] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 100, 111, 117, 98, 108, 101, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T2176[192] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 100, 111, 117, 98, 108, 101, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T2177[193] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 100, 111, 117, 98, 108, 101, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2178[194] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 100, 111, 117, 98, 108, 101, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2179[195] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 100, 111, 117, 98, 108, 101, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T2180[195] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 100, 111, 117, 98, 108, 101, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T2181[195] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 100, 111, 117, 98, 108, 101, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T2182[196] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 100, 111, 117, 98, 108, 101, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2183[197] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 65, 100, 100, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 100, 111, 117, 98, 108, 101, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2184[173] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 100, 111, 117, 98, 108, 101, 44, 32, 68, 105, 109, 115, 32, 61, 32, 49, 93, 0};
.global .align 1 .b8 __T2185[173] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 100, 111, 117, 98, 108, 101, 44, 32, 68, 105, 109, 115, 32, 61, 32, 50, 93, 0};
.global .align 1 .b8 __T2186[173] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 100, 111, 117, 98, 108, 101, 44, 32, 68, 105, 109, 115, 32, 61, 32, 51, 93, 0};
.global .align 1 .b8 __T2187[174] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 82, 101, 97, 108, 32, 61, 32, 100, 111, 117, 98, 108, 101, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 __T2188[175] = {118, 111, 105, 100, 32, 84, 72, 67, 117, 100, 97, 84, 101, 110, 115, 111, 114, 95, 115, 99, 97, 116, 116, 101, 114, 70, 105, 108, 108, 75, 101, 114, 110, 101, 108, 40, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 82, 101, 97, 108, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 84, 101, 110, 115, 111, 114, 73, 110, 102, 111, 60, 108, 111, 110, 103, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 62, 44, 32, 82, 101, 97, 108, 44, 32, 105, 110, 116, 44, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 41, 32, 91, 119, 105, 116, 104, 32, 73, 110, 100, 101, 120, 84, 121, 112, 101, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 108, 111, 110, 103, 44, 32, 82, 101, 97, 108, 32, 61, 32, 100, 111, 117, 98, 108, 101, 44, 32, 68, 105, 109, 115, 32, 61, 32, 45, 49, 93, 0};
.global .align 1 .b8 $str[47] = {105, 110, 100, 101, 120, 86, 97, 108, 117, 101, 32, 62, 61, 32, 48, 32, 38, 38, 32, 105, 110, 100, 101, 120, 86, 97, 108, 117, 101, 32, 60, 32, 115, 114, 99, 46, 115, 105, 122, 101, 115, 91, 100, 105, 109, 93, 0};
.global .align 1 .b8 $str1[53] = {47, 114, 111, 111, 116, 47, 112, 121, 116, 111, 114, 99, 104, 47, 97, 116, 101, 110, 47, 115, 114, 99, 47, 84, 72, 67, 47, 84, 72, 67, 84, 101, 110, 115, 111, 114, 83, 99, 97, 116, 116, 101, 114, 71, 97, 116, 104, 101, 114, 46, 99, 117, 0};
.global .align 1 .b8 $str2[50] = {105, 110, 100, 101, 120, 86, 97, 108, 117, 101, 32, 62, 61, 32, 48, 32, 38, 38, 32, 105, 110, 100, 101, 120, 86, 97, 108, 117, 101, 32, 60, 32, 116, 101, 110, 115, 111, 114, 46, 115, 105, 122, 101, 115, 91, 100, 105, 109, 93, 0};

.visible .entry _Z25THCudaTensor_gatherKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot0[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .b32 %r<25>;
.reg .b64 %rd<43>;


mov.u64 %rd42, __local_depot0;
cvta.local.u64 %SP, %rd42;
ld.param.u32 %r10, [_Z25THCudaTensor_gatherKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r11, [_Z25THCudaTensor_gatherKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd3, %rd11;
mov.u32 %r23, 0;
mov.pred %p1, 0;
@%p1 bra BB0_2;

BB0_1:
mul.wide.s32 %rd12, %r23, 8;
add.s64 %rd13, %rd4, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd3, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r23, %r23, 1;
setp.lt.u32	%p2, %r23, 27;
@%p2 bra BB0_1;

BB0_2:
mov.u32 %r13, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r24, %r13, %r14, %r15;
setp.ge.u32	%p3, %r24, %r11;
@%p3 bra BB0_10;

ld.param.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd6, %rd16;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd17, [%rd2];
cvta.to.global.u64 %rd7, %rd17;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB0_4:
rem.u32 %r8, %r24, %r5;
setp.eq.s32	%p4, %r10, 0;
mov.u64 %rd41, 0;
@%p4 bra BB0_6;

ld.local.u32 %r16, [%rd3+108];
mul.lo.s32 %r17, %r16, %r8;
cvt.u64.u32	%rd41, %r17;

BB0_6:
mul.lo.s32 %r18, %r6, %r8;
mul.wide.u32 %rd19, %r18, 8;
add.s64 %rd20, %rd7, %rd19;
ld.global.u64 %rd10, [%rd20];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB0_8;

mul.wide.s32 %rd21, %r10, 4;
add.s64 %rd22, %rd3, %rd21;
ld.local.u32 %rd23, [%rd22+8];
setp.lt.s64	%p6, %rd10, %rd23;
@%p6 bra BB0_9;

BB0_8:
mov.u64 %rd24, $str;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, $str1;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, __T29;
cvta.global.u64 %rd29, %rd28;
mov.u32 %r19, 97;
mov.u64 %rd30, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd25;
.param .b64 param1;
st.param.b64	[param1+0], %rd27;
.param .b32 param2;
st.param.b32	[param2+0], %r19;
.param .b64 param3;
st.param.b64	[param3+0], %rd29;
.param .b64 param4;
st.param.b64	[param4+0], %rd30;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB0_9:
mul.lo.s32 %r20, %r4, %r8;
mul.wide.s32 %rd31, %r10, 4;
add.s64 %rd32, %rd3, %rd31;
ld.local.u32 %rd33, [%rd32+108];
mul.lo.s64 %rd34, %rd33, %rd10;
add.s64 %rd35, %rd34, %rd41;
and.b64 %rd36, %rd35, 4294967295;
ld.local.u64 %rd37, [%rd3];
add.s64 %rd38, %rd37, %rd36;
ld.u8 %rs1, [%rd38];
cvt.u64.u32	%rd39, %r20;
add.s64 %rd40, %rd6, %rd39;
st.global.u8 [%rd40], %rs1;
mov.u32 %r22, %nctaid.x;
mad.lo.s32 %r24, %r22, %r13, %r24;
setp.lt.u32	%p7, %r24, %r11;
@%p7 bra BB0_4;

BB0_10:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot1[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b16 %rs<2>;
.reg .b32 %r<40>;
.reg .b64 %rd<40>;


mov.u64 %rd39, __local_depot1;
cvta.local.u64 %SP, %rd39;
ld.param.u32 %r19, [_Z25THCudaTensor_gatherKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r20, [_Z25THCudaTensor_gatherKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r37, 0;
mov.pred %p1, 0;
@%p1 bra BB1_2;

BB1_1:
mul.wide.s32 %rd10, %r37, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r37, %r37, 1;
setp.lt.u32	%p2, %r37, 27;
@%p2 bra BB1_1;

BB1_2:
mov.u32 %r22, %ntid.x;
mov.u32 %r23, %ctaid.x;
mov.u32 %r24, %tid.x;
mad.lo.s32 %r38, %r22, %r23, %r24;
setp.ge.u32	%p3, %r38, %r20;
@%p3 bra BB1_12;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r25, %r26}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB1_4:
rem.u32 %r11, %r38, %r26;
setp.eq.s32	%p4, %r19, 1;
mov.u32 %r39, 0;
@%p4 bra BB1_6;

ld.local.u32 %r28, [%rd3+112];
mul.lo.s32 %r39, %r28, %r11;

BB1_6:
div.u32 %r29, %r38, %r26;
rem.u32 %r14, %r29, %r25;
setp.eq.s32	%p5, %r19, 0;
@%p5 bra BB1_8;

ld.local.u32 %r30, [%rd3+108];
mad.lo.s32 %r39, %r30, %r14, %r39;

BB1_8:
mul.lo.s32 %r31, %r9, %r11;
mul.lo.s32 %r32, %r5, %r11;
mad.lo.s32 %r33, %r8, %r14, %r31;
mad.lo.s32 %r17, %r4, %r14, %r32;
mul.wide.u32 %rd16, %r33, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB1_10;

mul.wide.s32 %rd18, %r19, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p7, %rd8, %rd20;
@%p7 bra BB1_11;

BB1_10:
mov.u64 %rd21, $str;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T210;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r34, 97;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r34;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB1_11:
mul.wide.s32 %rd28, %r19, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r39;
add.s64 %rd33, %rd31, %rd32;
and.b64 %rd34, %rd33, 4294967295;
ld.local.u64 %rd35, [%rd3];
add.s64 %rd36, %rd35, %rd34;
ld.u8 %rs1, [%rd36];
cvt.u64.u32	%rd37, %r17;
add.s64 %rd38, %rd6, %rd37;
st.global.u8 [%rd38], %rs1;
mov.u32 %r36, %nctaid.x;
mad.lo.s32 %r38, %r36, %r22, %r38;
setp.lt.u32	%p8, %r38, %r20;
@%p8 bra BB1_4;

BB1_12:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot2[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b16 %rs<2>;
.reg .b32 %r<54>;
.reg .b64 %rd<40>;


mov.u64 %rd39, __local_depot2;
cvta.local.u64 %SP, %rd39;
ld.param.u32 %r26, [_Z25THCudaTensor_gatherKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r27, [_Z25THCudaTensor_gatherKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r51, 0;
mov.pred %p1, 0;
@%p1 bra BB2_2;

BB2_1:
mul.wide.s32 %rd10, %r51, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p2, %r51, 27;
@%p2 bra BB2_1;

BB2_2:
mov.u32 %r29, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r52, %r29, %r30, %r31;
setp.ge.u32	%p3, %r52, %r27;
@%p3 bra BB2_14;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r32, %r33}, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r34, %r35}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r36, %r37}, [%rd2+112];

BB2_4:
rem.u32 %r14, %r52, %r9;
setp.eq.s32	%p4, %r26, 2;
mov.u32 %r53, 0;
@%p4 bra BB2_6;

ld.local.u32 %r39, [%rd3+116];
mul.lo.s32 %r53, %r39, %r14;

BB2_6:
div.u32 %r17, %r52, %r9;
rem.u32 %r18, %r17, %r35;
setp.eq.s32	%p5, %r26, 1;
@%p5 bra BB2_8;

ld.local.u32 %r40, [%rd3+112];
mad.lo.s32 %r53, %r40, %r18, %r53;

BB2_8:
div.u32 %r41, %r17, %r35;
rem.u32 %r21, %r41, %r34;
setp.eq.s32	%p6, %r26, 0;
@%p6 bra BB2_10;

ld.local.u32 %r42, [%rd3+108];
mad.lo.s32 %r53, %r42, %r21, %r53;

BB2_10:
mul.lo.s32 %r43, %r37, %r14;
mul.lo.s32 %r44, %r33, %r14;
mad.lo.s32 %r45, %r36, %r18, %r43;
mad.lo.s32 %r46, %r32, %r18, %r44;
mad.lo.s32 %r47, %r10, %r21, %r45;
mad.lo.s32 %r24, %r4, %r21, %r46;
mul.wide.u32 %rd16, %r47, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB2_12;

mul.wide.s32 %rd18, %r26, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p8, %rd8, %rd20;
@%p8 bra BB2_13;

BB2_12:
mov.u64 %rd21, $str;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T211;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r48, 97;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r48;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB2_13:
mul.wide.s32 %rd28, %r26, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r53;
add.s64 %rd33, %rd31, %rd32;
and.b64 %rd34, %rd33, 4294967295;
ld.local.u64 %rd35, [%rd3];
add.s64 %rd36, %rd35, %rd34;
ld.u8 %rs1, [%rd36];
cvt.u64.u32	%rd37, %r24;
add.s64 %rd38, %rd6, %rd37;
st.global.u8 [%rd38], %rs1;
mov.u32 %r50, %nctaid.x;
mad.lo.s32 %r52, %r50, %r29, %r52;
setp.lt.u32	%p9, %r52, %r27;
@%p9 bra BB2_4;

BB2_14:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot3[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .b32 %r<63>;
.reg .b64 %rd<68>;


mov.u64 %rd67, __local_depot3;
cvta.local.u64 %SP, %rd67;
ld.param.u32 %r28, [_Z25THCudaTensor_gatherKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r29, [_Z25THCudaTensor_gatherKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z25THCudaTensor_gatherKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd20, %SP, 216;
cvta.to.local.u64 %rd3, %rd20;
add.u64 %rd21, %SP, 432;
cvta.to.local.u64 %rd4, %rd21;
add.u64 %rd22, %SP, 0;
cvta.to.local.u64 %rd5, %rd22;
mov.u32 %r47, 0;
mov.pred %p1, 0;
@%p1 bra BB3_2;

BB3_1:
mul.wide.s32 %rd23, %r47, 8;
add.s64 %rd24, %rd6, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r47, %r47, 1;
setp.lt.u32	%p2, %r47, 27;
@%p2 bra BB3_1;

BB3_2:
mov.u32 %r48, 0;
@%p1 bra BB3_4;

BB3_3:
mul.wide.s32 %rd27, %r48, 8;
add.s64 %rd28, %rd1, %rd27;
ld.param.u64 %rd29, [%rd28];
add.s64 %rd30, %rd4, %rd27;
st.local.u64 [%rd30], %rd29;
add.s32 %r48, %r48, 1;
setp.lt.u32	%p4, %r48, 27;
@%p4 bra BB3_3;

BB3_4:
mov.u32 %r49, 0;
@%p1 bra BB3_6;

BB3_5:
mul.wide.s32 %rd31, %r49, 8;
add.s64 %rd32, %rd2, %rd31;
ld.param.u64 %rd33, [%rd32];
add.s64 %rd34, %rd5, %rd31;
st.local.u64 [%rd34], %rd33;
add.s32 %r49, %r49, 1;
setp.lt.u32	%p6, %r49, 27;
@%p6 bra BB3_5;

BB3_6:
mov.u32 %r33, %ntid.x;
mov.u32 %r34, %ctaid.x;
mov.u32 %r35, %tid.x;
mad.lo.s32 %r54, %r33, %r34, %r35;
setp.ge.u32	%p7, %r54, %r29;
@%p7 bra BB3_17;

ld.local.u32 %r8, [%rd5+208];

BB3_8:
mov.u32 %r52, %r54;
mov.u32 %r9, %r52;
mul.wide.s32 %rd64, %r8, 4;
add.s32 %r40, %r8, -1;
sub.s32 %r50, %r40, %r28;
mov.u64 %rd66, 0;
mov.u32 %r60, 0;
mov.u64 %rd65, %rd66;
mov.u32 %r56, %r60;
mov.u32 %r61, %r60;
mov.u32 %r55, %r60;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r51, %r8;
mov.u32 %r53, %r9;
@%p8 bra BB3_13;

BB3_9:
mov.u32 %r57, %r61;
mov.u32 %r62, %r57;
mov.u32 %r13, %r53;
mov.u32 %r12, %r51;
add.s64 %rd37, %rd3, %rd64;
add.s32 %r17, %r12, -1;
add.s64 %rd38, %rd5, %rd64;
ld.local.u32 %r18, [%rd38+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r41, [%rd38+104];
mad.lo.s32 %r55, %r41, %r19, %r55;
ld.local.u32 %r42, [%rd37+104];
mad.lo.s32 %r56, %r42, %r19, %r56;
setp.eq.s32	%p9, %r50, 0;
@%p9 bra BB3_11;

add.s64 %rd39, %rd4, %rd64;
ld.local.u32 %r43, [%rd39+104];
mad.lo.s32 %r62, %r43, %r19, %r62;

BB3_11:
mov.u32 %r61, %r62;
div.u32 %r24, %r13, %r18;
add.s32 %r50, %r50, -1;
add.s64 %rd64, %rd64, -4;
setp.gt.s32	%p10, %r17, 0;
mov.u32 %r51, %r17;
mov.u32 %r53, %r24;
@%p10 bra BB3_9;

cvt.u64.u32	%rd65, %r55;
cvt.u64.u32	%rd66, %r56;
mov.u32 %r60, %r61;

BB3_13:
ld.local.u64 %rd40, [%rd5];
shl.b64 %rd41, %rd65, 3;
add.s64 %rd42, %rd40, %rd41;
ld.u64 %rd19, [%rd42];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB3_15;

mul.wide.s32 %rd43, %r28, 4;
add.s64 %rd44, %rd4, %rd43;
ld.local.u32 %rd45, [%rd44+8];
setp.lt.s64	%p12, %rd19, %rd45;
@%p12 bra BB3_16;

BB3_15:
mov.u64 %rd46, $str;
cvta.global.u64 %rd47, %rd46;
mov.u64 %rd48, $str1;
cvta.global.u64 %rd49, %rd48;
mov.u64 %rd50, __T212;
cvta.global.u64 %rd51, %rd50;
mov.u32 %r44, 97;
mov.u64 %rd52, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd47;
.param .b64 param1;
st.param.b64	[param1+0], %rd49;
.param .b32 param2;
st.param.b32	[param2+0], %r44;
.param .b64 param3;
st.param.b64	[param3+0], %rd51;
.param .b64 param4;
st.param.b64	[param4+0], %rd52;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB3_16:
mul.wide.s32 %rd53, %r28, 4;
add.s64 %rd54, %rd4, %rd53;
ld.local.u32 %rd55, [%rd54+108];
mul.lo.s64 %rd56, %rd55, %rd19;
cvt.u64.u32	%rd57, %r60;
add.s64 %rd58, %rd56, %rd57;
and.b64 %rd59, %rd58, 4294967295;
ld.local.u64 %rd60, [%rd4];
add.s64 %rd61, %rd60, %rd59;
ld.u8 %rs1, [%rd61];
ld.local.u64 %rd62, [%rd3];
add.s64 %rd63, %rd62, %rd66;
st.u8 [%rd63], %rs1;
mov.u32 %r46, %nctaid.x;
mad.lo.s32 %r54, %r46, %r33, %r9;
setp.lt.u32	%p13, %r54, %r29;
@%p13 bra BB3_8;

BB3_17:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[416],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[416],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[416],
.param .u32 _Z25THCudaTensor_gatherKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u64 _Z25THCudaTensor_gatherKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot4[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<16>;
.reg .b16 %rs<2>;
.reg .b32 %r<37>;
.reg .b64 %rd<115>;


mov.u64 %rd114, __local_depot4;
cvta.local.u64 %SP, %rd114;
ld.param.u32 %r13, [_Z25THCudaTensor_gatherKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u64 %rd38, [_Z25THCudaTensor_gatherKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z25THCudaTensor_gatherKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd39, %SP, 416;
cvta.to.local.u64 %rd3, %rd39;
add.u64 %rd40, %SP, 832;
cvta.to.local.u64 %rd4, %rd40;
add.u64 %rd41, %SP, 0;
cvta.to.local.u64 %rd5, %rd41;
mov.u32 %r32, 0;
mov.pred %p1, 0;
@%p1 bra BB4_2;

BB4_1:
mul.wide.s32 %rd42, %r32, 8;
add.s64 %rd43, %rd6, %rd42;
ld.param.u64 %rd44, [%rd43];
add.s64 %rd45, %rd3, %rd42;
st.local.u64 [%rd45], %rd44;
add.s32 %r32, %r32, 1;
setp.lt.u32	%p2, %r32, 52;
@%p2 bra BB4_1;

BB4_2:
mov.u32 %r33, 0;
@%p1 bra BB4_4;

BB4_3:
mul.wide.s32 %rd46, %r33, 8;
add.s64 %rd47, %rd1, %rd46;
ld.param.u64 %rd48, [%rd47];
add.s64 %rd49, %rd4, %rd46;
st.local.u64 [%rd49], %rd48;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p4, %r33, 52;
@%p4 bra BB4_3;

BB4_4:
mov.u32 %r34, 0;
@%p1 bra BB4_6;

BB4_5:
mul.wide.s32 %rd50, %r34, 8;
add.s64 %rd51, %rd2, %rd50;
ld.param.u64 %rd52, [%rd51];
add.s64 %rd53, %rd5, %rd50;
st.local.u64 [%rd53], %rd52;
add.s32 %r34, %r34, 1;
setp.lt.u32	%p6, %r34, 52;
@%p6 bra BB4_5;

BB4_6:
mov.u32 %r17, %ntid.x;
mov.u32 %r18, %ctaid.x;
mov.u32 %r19, %tid.x;
mad.lo.s32 %r20, %r17, %r18, %r19;
cvt.u64.u32	%rd100, %r20;
setp.ge.u64	%p7, %rd100, %rd38;
@%p7 bra BB4_22;

ld.local.u32 %r7, [%rd5+408];

BB4_8:
mov.u64 %rd96, %rd100;
mov.u64 %rd13, %rd96;
mul.wide.s32 %rd95, %r7, 8;
add.s32 %r21, %r7, -1;
sub.s32 %r35, %r21, %r13;
mov.u64 %rd112, 0;
mov.u64 %rd108, %rd112;
mov.u64 %rd103, %rd112;
mov.u64 %rd113, %rd112;
mov.u64 %rd109, %rd112;
mov.u64 %rd104, %rd112;
setp.lt.s32	%p8, %r7, 1;
mov.u32 %r36, %r7;
mov.u64 %rd98, %rd13;
@%p8 bra BB4_18;

BB4_9:
mov.u64 %rd110, %rd109;
mov.u64 %rd16, %rd98;
mov.u32 %r10, %r36;
add.s32 %r11, %r10, -1;
add.s64 %rd20, %rd5, %rd95;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd60, %rd16, %rd21;
and.b64 %rd61, %rd60, -4294967296;
setp.eq.s64	%p9, %rd61, 0;
@%p9 bra BB4_11;
bra.uni BB4_10;

BB4_11:
cvt.u32.u64	%r22, %rd21;
cvt.u32.u64	%r23, %rd16;
rem.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd101, %r24;
bra.uni BB4_12;

BB4_10:
rem.u64 %rd101, %rd16, %rd21;

BB4_12:
add.s64 %rd62, %rd3, %rd95;
ld.local.u64 %rd63, [%rd20+200];
mul.lo.s64 %rd64, %rd63, %rd101;
add.s64 %rd104, %rd64, %rd104;
ld.local.u64 %rd65, [%rd62+200];
mul.lo.s64 %rd66, %rd65, %rd101;
add.s64 %rd113, %rd66, %rd113;
setp.eq.s32	%p10, %r35, 0;
@%p10 bra BB4_14;

add.s64 %rd67, %rd4, %rd95;
ld.local.u64 %rd68, [%rd67+200];
mul.lo.s64 %rd69, %rd68, %rd101;
add.s64 %rd110, %rd69, %rd110;

BB4_14:
mov.u64 %rd109, %rd110;
@%p9 bra BB4_16;
bra.uni BB4_15;

BB4_16:
cvt.u32.u64	%r25, %rd21;
cvt.u32.u64	%r26, %rd16;
div.u32 %r27, %r26, %r25;
cvt.u64.u32	%rd99, %r27;
bra.uni BB4_17;

BB4_15:
div.u64 %rd99, %rd16, %rd21;

BB4_17:
mov.u64 %rd31, %rd99;
add.s32 %r35, %r35, -1;
add.s64 %rd95, %rd95, -8;
setp.gt.s32	%p12, %r11, 0;
mov.u32 %r36, %r11;
mov.u64 %rd98, %rd31;
mov.u64 %rd103, %rd104;
mov.u64 %rd108, %rd109;
mov.u64 %rd112, %rd113;
@%p12 bra BB4_9;

BB4_18:
ld.local.u64 %rd72, [%rd5];
shl.b64 %rd73, %rd103, 3;
add.s64 %rd74, %rd72, %rd73;
ld.u64 %rd36, [%rd74];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB4_20;

mul.wide.s32 %rd75, %r13, 8;
add.s64 %rd76, %rd4, %rd75;
ld.local.u64 %rd77, [%rd76+8];
setp.lt.u64	%p14, %rd36, %rd77;
@%p14 bra BB4_21;

BB4_20:
mov.u64 %rd78, $str;
cvta.global.u64 %rd79, %rd78;
mov.u64 %rd80, $str1;
cvta.global.u64 %rd81, %rd80;
mov.u64 %rd82, __T215;
cvta.global.u64 %rd83, %rd82;
mov.u32 %r28, 97;
mov.u64 %rd84, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd79;
.param .b64 param1;
st.param.b64	[param1+0], %rd81;
.param .b32 param2;
st.param.b32	[param2+0], %r28;
.param .b64 param3;
st.param.b64	[param3+0], %rd83;
.param .b64 param4;
st.param.b64	[param4+0], %rd84;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB4_21:
mul.wide.s32 %rd85, %r13, 8;
add.s64 %rd86, %rd4, %rd85;
ld.local.u64 %rd87, [%rd86+208];
mul.lo.s64 %rd88, %rd87, %rd36;
add.s64 %rd89, %rd88, %rd108;
ld.local.u64 %rd90, [%rd4];
add.s64 %rd91, %rd90, %rd89;
ld.u8 %rs1, [%rd91];
ld.local.u64 %rd92, [%rd3];
add.s64 %rd93, %rd92, %rd112;
st.u8 [%rd93], %rs1;
mov.u32 %r30, %nctaid.x;
mul.lo.s32 %r31, %r30, %r17;
cvt.u64.u32	%rd94, %r31;
add.s64 %rd100, %rd94, %rd13;
setp.lt.u64	%p15, %rd100, %rd38;
@%p15 bra BB4_8;

BB4_22:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot5[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .b32 %r<25>;
.reg .b64 %rd<43>;


mov.u64 %rd42, __local_depot5;
cvta.local.u64 %SP, %rd42;
ld.param.u32 %r10, [_Z26THCudaTensor_scatterKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r11, [_Z26THCudaTensor_scatterKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd3, %rd11;
mov.u32 %r23, 0;
mov.pred %p1, 0;
@%p1 bra BB5_2;

BB5_1:
mul.wide.s32 %rd12, %r23, 8;
add.s64 %rd13, %rd4, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd3, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r23, %r23, 1;
setp.lt.u32	%p2, %r23, 27;
@%p2 bra BB5_1;

BB5_2:
mov.u32 %r13, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r24, %r13, %r14, %r15;
setp.ge.u32	%p3, %r24, %r11;
@%p3 bra BB5_10;

ld.param.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd6, %rd16;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd17, [%rd2];
cvta.to.global.u64 %rd7, %rd17;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB5_4:
rem.u32 %r8, %r24, %r5;
setp.eq.s32	%p4, %r10, 0;
mov.u64 %rd41, 0;
@%p4 bra BB5_6;

ld.local.u32 %r16, [%rd3+108];
mul.lo.s32 %r17, %r16, %r8;
cvt.u64.u32	%rd41, %r17;

BB5_6:
mul.lo.s32 %r18, %r6, %r8;
mul.wide.u32 %rd19, %r18, 8;
add.s64 %rd20, %rd7, %rd19;
ld.global.u64 %rd10, [%rd20];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB5_8;

mul.wide.s32 %rd21, %r10, 4;
add.s64 %rd22, %rd3, %rd21;
ld.local.u32 %rd23, [%rd22+8];
setp.lt.s64	%p6, %rd10, %rd23;
@%p6 bra BB5_9;

BB5_8:
mov.u64 %rd24, $str2;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, $str1;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, __T216;
cvta.global.u64 %rd29, %rd28;
mov.u32 %r19, 124;
mov.u64 %rd30, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd25;
.param .b64 param1;
st.param.b64	[param1+0], %rd27;
.param .b32 param2;
st.param.b32	[param2+0], %r19;
.param .b64 param3;
st.param.b64	[param3+0], %rd29;
.param .b64 param4;
st.param.b64	[param4+0], %rd30;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB5_9:
mul.lo.s32 %r20, %r4, %r8;
mul.wide.s32 %rd31, %r10, 4;
add.s64 %rd32, %rd3, %rd31;
ld.local.u32 %rd33, [%rd32+108];
mul.lo.s64 %rd34, %rd33, %rd10;
add.s64 %rd35, %rd34, %rd41;
cvt.u64.u32	%rd36, %r20;
add.s64 %rd37, %rd6, %rd36;
ld.global.u8 %rs1, [%rd37];
and.b64 %rd38, %rd35, 4294967295;
ld.local.u64 %rd39, [%rd3];
add.s64 %rd40, %rd39, %rd38;
st.u8 [%rd40], %rs1;
mov.u32 %r22, %nctaid.x;
mad.lo.s32 %r24, %r22, %r13, %r24;
setp.lt.u32	%p7, %r24, %r11;
@%p7 bra BB5_4;

BB5_10:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot6[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b16 %rs<2>;
.reg .b32 %r<40>;
.reg .b64 %rd<40>;


mov.u64 %rd39, __local_depot6;
cvta.local.u64 %SP, %rd39;
ld.param.u32 %r19, [_Z26THCudaTensor_scatterKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r20, [_Z26THCudaTensor_scatterKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r37, 0;
mov.pred %p1, 0;
@%p1 bra BB6_2;

BB6_1:
mul.wide.s32 %rd10, %r37, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r37, %r37, 1;
setp.lt.u32	%p2, %r37, 27;
@%p2 bra BB6_1;

BB6_2:
mov.u32 %r22, %ntid.x;
mov.u32 %r23, %ctaid.x;
mov.u32 %r24, %tid.x;
mad.lo.s32 %r38, %r22, %r23, %r24;
setp.ge.u32	%p3, %r38, %r20;
@%p3 bra BB6_12;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r25, %r26}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB6_4:
rem.u32 %r11, %r38, %r26;
setp.eq.s32	%p4, %r19, 1;
mov.u32 %r39, 0;
@%p4 bra BB6_6;

ld.local.u32 %r28, [%rd3+112];
mul.lo.s32 %r39, %r28, %r11;

BB6_6:
div.u32 %r29, %r38, %r26;
rem.u32 %r14, %r29, %r25;
setp.eq.s32	%p5, %r19, 0;
@%p5 bra BB6_8;

ld.local.u32 %r30, [%rd3+108];
mad.lo.s32 %r39, %r30, %r14, %r39;

BB6_8:
mul.lo.s32 %r31, %r9, %r11;
mul.lo.s32 %r32, %r5, %r11;
mad.lo.s32 %r33, %r8, %r14, %r31;
mad.lo.s32 %r17, %r4, %r14, %r32;
mul.wide.u32 %rd16, %r33, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB6_10;

mul.wide.s32 %rd18, %r19, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p7, %rd8, %rd20;
@%p7 bra BB6_11;

BB6_10:
mov.u64 %rd21, $str2;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T217;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r34, 124;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r34;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB6_11:
mul.wide.s32 %rd28, %r19, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r39;
add.s64 %rd33, %rd31, %rd32;
cvt.u64.u32	%rd34, %r17;
add.s64 %rd35, %rd6, %rd34;
ld.global.u8 %rs1, [%rd35];
and.b64 %rd36, %rd33, 4294967295;
ld.local.u64 %rd37, [%rd3];
add.s64 %rd38, %rd37, %rd36;
st.u8 [%rd38], %rs1;
mov.u32 %r36, %nctaid.x;
mad.lo.s32 %r38, %r36, %r22, %r38;
setp.lt.u32	%p8, %r38, %r20;
@%p8 bra BB6_4;

BB6_12:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot7[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b16 %rs<2>;
.reg .b32 %r<54>;
.reg .b64 %rd<40>;


mov.u64 %rd39, __local_depot7;
cvta.local.u64 %SP, %rd39;
ld.param.u32 %r26, [_Z26THCudaTensor_scatterKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r27, [_Z26THCudaTensor_scatterKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r51, 0;
mov.pred %p1, 0;
@%p1 bra BB7_2;

BB7_1:
mul.wide.s32 %rd10, %r51, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p2, %r51, 27;
@%p2 bra BB7_1;

BB7_2:
mov.u32 %r29, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r52, %r29, %r30, %r31;
setp.ge.u32	%p3, %r52, %r27;
@%p3 bra BB7_14;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r32, %r33}, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r34, %r35}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r36, %r37}, [%rd2+112];

BB7_4:
rem.u32 %r14, %r52, %r9;
setp.eq.s32	%p4, %r26, 2;
mov.u32 %r53, 0;
@%p4 bra BB7_6;

ld.local.u32 %r39, [%rd3+116];
mul.lo.s32 %r53, %r39, %r14;

BB7_6:
div.u32 %r17, %r52, %r9;
rem.u32 %r18, %r17, %r35;
setp.eq.s32	%p5, %r26, 1;
@%p5 bra BB7_8;

ld.local.u32 %r40, [%rd3+112];
mad.lo.s32 %r53, %r40, %r18, %r53;

BB7_8:
div.u32 %r41, %r17, %r35;
rem.u32 %r21, %r41, %r34;
setp.eq.s32	%p6, %r26, 0;
@%p6 bra BB7_10;

ld.local.u32 %r42, [%rd3+108];
mad.lo.s32 %r53, %r42, %r21, %r53;

BB7_10:
mul.lo.s32 %r43, %r37, %r14;
mul.lo.s32 %r44, %r33, %r14;
mad.lo.s32 %r45, %r36, %r18, %r43;
mad.lo.s32 %r46, %r32, %r18, %r44;
mad.lo.s32 %r47, %r10, %r21, %r45;
mad.lo.s32 %r24, %r4, %r21, %r46;
mul.wide.u32 %rd16, %r47, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB7_12;

mul.wide.s32 %rd18, %r26, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p8, %rd8, %rd20;
@%p8 bra BB7_13;

BB7_12:
mov.u64 %rd21, $str2;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T218;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r48, 124;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r48;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB7_13:
mul.wide.s32 %rd28, %r26, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r53;
add.s64 %rd33, %rd31, %rd32;
cvt.u64.u32	%rd34, %r24;
add.s64 %rd35, %rd6, %rd34;
ld.global.u8 %rs1, [%rd35];
and.b64 %rd36, %rd33, 4294967295;
ld.local.u64 %rd37, [%rd3];
add.s64 %rd38, %rd37, %rd36;
st.u8 [%rd38], %rs1;
mov.u32 %r50, %nctaid.x;
mad.lo.s32 %r52, %r50, %r29, %r52;
setp.lt.u32	%p9, %r52, %r27;
@%p9 bra BB7_4;

BB7_14:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot8[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .b32 %r<63>;
.reg .b64 %rd<68>;


mov.u64 %rd67, __local_depot8;
cvta.local.u64 %SP, %rd67;
ld.param.u32 %r28, [_Z26THCudaTensor_scatterKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r29, [_Z26THCudaTensor_scatterKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z26THCudaTensor_scatterKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd20, %SP, 216;
cvta.to.local.u64 %rd3, %rd20;
add.u64 %rd21, %SP, 432;
cvta.to.local.u64 %rd4, %rd21;
add.u64 %rd22, %SP, 0;
cvta.to.local.u64 %rd5, %rd22;
mov.u32 %r47, 0;
mov.pred %p1, 0;
@%p1 bra BB8_2;

BB8_1:
mul.wide.s32 %rd23, %r47, 8;
add.s64 %rd24, %rd6, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r47, %r47, 1;
setp.lt.u32	%p2, %r47, 27;
@%p2 bra BB8_1;

BB8_2:
mov.u32 %r48, 0;
@%p1 bra BB8_4;

BB8_3:
mul.wide.s32 %rd27, %r48, 8;
add.s64 %rd28, %rd1, %rd27;
ld.param.u64 %rd29, [%rd28];
add.s64 %rd30, %rd4, %rd27;
st.local.u64 [%rd30], %rd29;
add.s32 %r48, %r48, 1;
setp.lt.u32	%p4, %r48, 27;
@%p4 bra BB8_3;

BB8_4:
mov.u32 %r49, 0;
@%p1 bra BB8_6;

BB8_5:
mul.wide.s32 %rd31, %r49, 8;
add.s64 %rd32, %rd2, %rd31;
ld.param.u64 %rd33, [%rd32];
add.s64 %rd34, %rd5, %rd31;
st.local.u64 [%rd34], %rd33;
add.s32 %r49, %r49, 1;
setp.lt.u32	%p6, %r49, 27;
@%p6 bra BB8_5;

BB8_6:
mov.u32 %r33, %ntid.x;
mov.u32 %r34, %ctaid.x;
mov.u32 %r35, %tid.x;
mad.lo.s32 %r54, %r33, %r34, %r35;
setp.ge.u32	%p7, %r54, %r29;
@%p7 bra BB8_17;

ld.local.u32 %r8, [%rd5+208];

BB8_8:
mov.u32 %r52, %r54;
mov.u32 %r9, %r52;
mul.wide.s32 %rd64, %r8, 4;
add.s32 %r40, %r8, -1;
sub.s32 %r50, %r40, %r28;
mov.u32 %r60, 0;
mov.u64 %rd66, 0;
mov.u64 %rd65, %rd66;
mov.u32 %r61, %r60;
mov.u32 %r56, %r60;
mov.u32 %r55, %r60;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r51, %r8;
mov.u32 %r53, %r9;
@%p8 bra BB8_13;

BB8_9:
mov.u32 %r57, %r61;
mov.u32 %r62, %r57;
mov.u32 %r13, %r53;
mov.u32 %r12, %r51;
add.s64 %rd37, %rd4, %rd64;
add.s32 %r17, %r12, -1;
add.s64 %rd38, %rd5, %rd64;
ld.local.u32 %r18, [%rd38+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r41, [%rd38+104];
mad.lo.s32 %r55, %r41, %r19, %r55;
ld.local.u32 %r42, [%rd37+104];
mad.lo.s32 %r56, %r42, %r19, %r56;
setp.eq.s32	%p9, %r50, 0;
@%p9 bra BB8_11;

add.s64 %rd39, %rd3, %rd64;
ld.local.u32 %r43, [%rd39+104];
mad.lo.s32 %r62, %r43, %r19, %r62;

BB8_11:
mov.u32 %r61, %r62;
div.u32 %r24, %r13, %r18;
add.s32 %r50, %r50, -1;
add.s64 %rd64, %rd64, -4;
setp.gt.s32	%p10, %r17, 0;
mov.u32 %r51, %r17;
mov.u32 %r53, %r24;
@%p10 bra BB8_9;

cvt.u64.u32	%rd65, %r55;
cvt.u64.u32	%rd66, %r56;
mov.u32 %r60, %r61;

BB8_13:
ld.local.u64 %rd40, [%rd5];
shl.b64 %rd41, %rd65, 3;
add.s64 %rd42, %rd40, %rd41;
ld.u64 %rd19, [%rd42];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB8_15;

mul.wide.s32 %rd43, %r28, 4;
add.s64 %rd44, %rd3, %rd43;
ld.local.u32 %rd45, [%rd44+8];
setp.lt.s64	%p12, %rd19, %rd45;
@%p12 bra BB8_16;

BB8_15:
mov.u64 %rd46, $str2;
cvta.global.u64 %rd47, %rd46;
mov.u64 %rd48, $str1;
cvta.global.u64 %rd49, %rd48;
mov.u64 %rd50, __T219;
cvta.global.u64 %rd51, %rd50;
mov.u32 %r44, 124;
mov.u64 %rd52, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd47;
.param .b64 param1;
st.param.b64	[param1+0], %rd49;
.param .b32 param2;
st.param.b32	[param2+0], %r44;
.param .b64 param3;
st.param.b64	[param3+0], %rd51;
.param .b64 param4;
st.param.b64	[param4+0], %rd52;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB8_16:
mul.wide.s32 %rd53, %r28, 4;
add.s64 %rd54, %rd3, %rd53;
ld.local.u32 %rd55, [%rd54+108];
mul.lo.s64 %rd56, %rd55, %rd19;
cvt.u64.u32	%rd57, %r60;
add.s64 %rd58, %rd56, %rd57;
ld.local.u64 %rd59, [%rd4];
add.s64 %rd60, %rd59, %rd66;
ld.u8 %rs1, [%rd60];
and.b64 %rd61, %rd58, 4294967295;
ld.local.u64 %rd62, [%rd3];
add.s64 %rd63, %rd62, %rd61;
st.u8 [%rd63], %rs1;
mov.u32 %r46, %nctaid.x;
mad.lo.s32 %r54, %r46, %r33, %r9;
setp.lt.u32	%p13, %r54, %r29;
@%p13 bra BB8_8;

BB8_17:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[416],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[416],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[416],
.param .u32 _Z26THCudaTensor_scatterKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u64 _Z26THCudaTensor_scatterKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot9[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<16>;
.reg .b16 %rs<2>;
.reg .b32 %r<37>;
.reg .b64 %rd<115>;


mov.u64 %rd114, __local_depot9;
cvta.local.u64 %SP, %rd114;
ld.param.u32 %r13, [_Z26THCudaTensor_scatterKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u64 %rd38, [_Z26THCudaTensor_scatterKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z26THCudaTensor_scatterKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd39, %SP, 416;
cvta.to.local.u64 %rd3, %rd39;
add.u64 %rd40, %SP, 832;
cvta.to.local.u64 %rd4, %rd40;
add.u64 %rd41, %SP, 0;
cvta.to.local.u64 %rd5, %rd41;
mov.u32 %r32, 0;
mov.pred %p1, 0;
@%p1 bra BB9_2;

BB9_1:
mul.wide.s32 %rd42, %r32, 8;
add.s64 %rd43, %rd6, %rd42;
ld.param.u64 %rd44, [%rd43];
add.s64 %rd45, %rd3, %rd42;
st.local.u64 [%rd45], %rd44;
add.s32 %r32, %r32, 1;
setp.lt.u32	%p2, %r32, 52;
@%p2 bra BB9_1;

BB9_2:
mov.u32 %r33, 0;
@%p1 bra BB9_4;

BB9_3:
mul.wide.s32 %rd46, %r33, 8;
add.s64 %rd47, %rd1, %rd46;
ld.param.u64 %rd48, [%rd47];
add.s64 %rd49, %rd4, %rd46;
st.local.u64 [%rd49], %rd48;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p4, %r33, 52;
@%p4 bra BB9_3;

BB9_4:
mov.u32 %r34, 0;
@%p1 bra BB9_6;

BB9_5:
mul.wide.s32 %rd50, %r34, 8;
add.s64 %rd51, %rd2, %rd50;
ld.param.u64 %rd52, [%rd51];
add.s64 %rd53, %rd5, %rd50;
st.local.u64 [%rd53], %rd52;
add.s32 %r34, %r34, 1;
setp.lt.u32	%p6, %r34, 52;
@%p6 bra BB9_5;

BB9_6:
mov.u32 %r17, %ntid.x;
mov.u32 %r18, %ctaid.x;
mov.u32 %r19, %tid.x;
mad.lo.s32 %r20, %r17, %r18, %r19;
cvt.u64.u32	%rd100, %r20;
setp.ge.u64	%p7, %rd100, %rd38;
@%p7 bra BB9_22;

ld.local.u32 %r7, [%rd5+408];

BB9_8:
mov.u64 %rd96, %rd100;
mov.u64 %rd13, %rd96;
mul.wide.s32 %rd95, %r7, 8;
add.s32 %r21, %r7, -1;
sub.s32 %r35, %r21, %r13;
mov.u64 %rd111, 0;
mov.u64 %rd106, %rd111;
mov.u64 %rd103, %rd111;
mov.u64 %rd112, %rd111;
mov.u64 %rd107, %rd111;
mov.u64 %rd104, %rd111;
setp.lt.s32	%p8, %r7, 1;
mov.u32 %r36, %r7;
mov.u64 %rd98, %rd13;
@%p8 bra BB9_18;

BB9_9:
mov.u64 %rd113, %rd112;
mov.u64 %rd16, %rd98;
mov.u32 %r10, %r36;
add.s32 %r11, %r10, -1;
add.s64 %rd20, %rd5, %rd95;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd60, %rd16, %rd21;
and.b64 %rd61, %rd60, -4294967296;
setp.eq.s64	%p9, %rd61, 0;
@%p9 bra BB9_11;
bra.uni BB9_10;

BB9_11:
cvt.u32.u64	%r22, %rd21;
cvt.u32.u64	%r23, %rd16;
rem.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd101, %r24;
bra.uni BB9_12;

BB9_10:
rem.u64 %rd101, %rd16, %rd21;

BB9_12:
add.s64 %rd62, %rd4, %rd95;
ld.local.u64 %rd63, [%rd20+200];
mul.lo.s64 %rd64, %rd63, %rd101;
add.s64 %rd104, %rd64, %rd104;
ld.local.u64 %rd65, [%rd62+200];
mul.lo.s64 %rd66, %rd65, %rd101;
add.s64 %rd107, %rd66, %rd107;
setp.eq.s32	%p10, %r35, 0;
@%p10 bra BB9_14;

add.s64 %rd67, %rd3, %rd95;
ld.local.u64 %rd68, [%rd67+200];
mul.lo.s64 %rd69, %rd68, %rd101;
add.s64 %rd113, %rd69, %rd113;

BB9_14:
mov.u64 %rd112, %rd113;
@%p9 bra BB9_16;
bra.uni BB9_15;

BB9_16:
cvt.u32.u64	%r25, %rd21;
cvt.u32.u64	%r26, %rd16;
div.u32 %r27, %r26, %r25;
cvt.u64.u32	%rd99, %r27;
bra.uni BB9_17;

BB9_15:
div.u64 %rd99, %rd16, %rd21;

BB9_17:
mov.u64 %rd31, %rd99;
add.s32 %r35, %r35, -1;
add.s64 %rd95, %rd95, -8;
setp.gt.s32	%p12, %r11, 0;
mov.u32 %r36, %r11;
mov.u64 %rd98, %rd31;
mov.u64 %rd103, %rd104;
mov.u64 %rd106, %rd107;
mov.u64 %rd111, %rd112;
@%p12 bra BB9_9;

BB9_18:
ld.local.u64 %rd72, [%rd5];
shl.b64 %rd73, %rd103, 3;
add.s64 %rd74, %rd72, %rd73;
ld.u64 %rd36, [%rd74];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB9_20;

mul.wide.s32 %rd75, %r13, 8;
add.s64 %rd76, %rd3, %rd75;
ld.local.u64 %rd77, [%rd76+8];
setp.lt.u64	%p14, %rd36, %rd77;
@%p14 bra BB9_21;

BB9_20:
mov.u64 %rd78, $str2;
cvta.global.u64 %rd79, %rd78;
mov.u64 %rd80, $str1;
cvta.global.u64 %rd81, %rd80;
mov.u64 %rd82, __T220;
cvta.global.u64 %rd83, %rd82;
mov.u32 %r28, 124;
mov.u64 %rd84, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd79;
.param .b64 param1;
st.param.b64	[param1+0], %rd81;
.param .b32 param2;
st.param.b32	[param2+0], %r28;
.param .b64 param3;
st.param.b64	[param3+0], %rd83;
.param .b64 param4;
st.param.b64	[param4+0], %rd84;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB9_21:
mul.wide.s32 %rd85, %r13, 8;
add.s64 %rd86, %rd3, %rd85;
ld.local.u64 %rd87, [%rd86+208];
mul.lo.s64 %rd88, %rd87, %rd36;
add.s64 %rd89, %rd88, %rd111;
ld.local.u64 %rd90, [%rd4];
add.s64 %rd91, %rd90, %rd106;
ld.u8 %rs1, [%rd91];
ld.local.u64 %rd92, [%rd3];
add.s64 %rd93, %rd92, %rd89;
st.u8 [%rd93], %rs1;
mov.u32 %r30, %nctaid.x;
mul.lo.s32 %r31, %r30, %r17;
cvt.u64.u32	%rd94, %r31;
add.s64 %rd100, %rd94, %rd13;
setp.lt.u64	%p15, %rd100, %rd38;
@%p15 bra BB9_8;

BB9_22:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot10[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b32 %r<40>;
.reg .b64 %rd<47>;


mov.u64 %rd46, __local_depot10;
cvta.local.u64 %SP, %rd46;
ld.param.u32 %r15, [_Z29THCudaTensor_scatterAddKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r16, [_Z29THCudaTensor_scatterAddKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjhLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd12, %SP, 0;
cvta.to.local.u64 %rd3, %rd12;
mov.u32 %r37, 0;
mov.pred %p1, 0;
@%p1 bra BB10_2;

BB10_1:
mul.wide.s32 %rd13, %r37, 8;
add.s64 %rd14, %rd4, %rd13;
ld.param.u64 %rd15, [%rd14];
add.s64 %rd16, %rd3, %rd13;
st.local.u64 [%rd16], %rd15;
add.s32 %r37, %r37, 1;
setp.lt.u32	%p2, %r37, 27;
@%p2 bra BB10_1;

BB10_2:
mov.u32 %r18, %ntid.x;
mov.u32 %r19, %ctaid.x;
mov.u32 %r20, %tid.x;
mad.lo.s32 %r38, %r18, %r19, %r20;
setp.ge.u32	%p3, %r38, %r16;
@%p3 bra BB10_12;

ld.param.u64 %rd17, [%rd1];
cvta.to.global.u64 %rd6, %rd17;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd18, [%rd2];
cvta.to.global.u64 %rd7, %rd18;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB10_4:
rem.u32 %r8, %r38, %r5;
setp.eq.s32	%p4, %r15, 0;
mov.u64 %rd45, 0;
@%p4 bra BB10_6;

ld.local.u32 %r21, [%rd3+108];
mul.lo.s32 %r22, %r21, %r8;
cvt.u64.u32	%rd45, %r22;

BB10_6:
mul.lo.s32 %r23, %r6, %r8;
mul.wide.u32 %rd20, %r23, 8;
add.s64 %rd21, %rd7, %rd20;
ld.global.u64 %rd10, [%rd21];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB10_8;

mul.wide.s32 %rd22, %r15, 4;
add.s64 %rd23, %rd3, %rd22;
ld.local.u32 %rd24, [%rd23+8];
setp.lt.s64	%p6, %rd10, %rd24;
@%p6 bra BB10_9;

BB10_8:
mov.u64 %rd25, $str2;
cvta.global.u64 %rd26, %rd25;
mov.u64 %rd27, $str1;
cvta.global.u64 %rd28, %rd27;
mov.u64 %rd29, __T221;
cvta.global.u64 %rd30, %rd29;
mov.u32 %r24, 151;
mov.u64 %rd31, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd26;
.param .b64 param1;
st.param.b64	[param1+0], %rd28;
.param .b32 param2;
st.param.b32	[param2+0], %r24;
.param .b64 param3;
st.param.b64	[param3+0], %rd30;
.param .b64 param4;
st.param.b64	[param4+0], %rd31;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB10_9:
mul.lo.s32 %r25, %r4, %r8;
mul.wide.s32 %rd32, %r15, 4;
add.s64 %rd33, %rd3, %rd32;
ld.local.u32 %rd34, [%rd33+108];
mul.lo.s64 %rd35, %rd34, %rd10;
add.s64 %rd36, %rd35, %rd45;
and.b64 %rd37, %rd36, 4294967295;
ld.local.u64 %rd38, [%rd3];
add.s64 %rd39, %rd38, %rd37;
cvt.u64.u32	%rd40, %r25;
add.s64 %rd41, %rd6, %rd40;
and.b64 %rd42, %rd39, 3;
sub.s64 %rd43, %rd37, %rd42;
add.s64 %rd11, %rd38, %rd43;
ld.u32 %r39, [%rd11];
shl.b64 %rd44, %rd42, 3;
cvt.u32.u64	%r10, %rd44;
ld.global.u8 %r11, [%rd41];

BB10_10:
mov.u32 %r12, %r39;
shr.u32 %r26, %r12, %r10;
and.b32 %r27, %r26, 255;
add.s32 %r28, %r27, %r11;
mov.u32 %r29, 255;
shl.b32 %r30, %r29, %r10;
not.b32 %r31, %r30;
and.b32 %r32, %r12, %r31;
shl.b32 %r33, %r28, %r10;
or.b32 %r34, %r33, %r32;
atom.cas.b32 %r39, [%rd11], %r12, %r34;
setp.ne.s32	%p7, %r12, %r39;
@%p7 bra BB10_10;

mov.u32 %r36, %nctaid.x;
mad.lo.s32 %r38, %r36, %r18, %r38;
setp.lt.u32	%p8, %r38, %r16;
@%p8 bra BB10_4;

BB10_12:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot11[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b32 %r<55>;
.reg .b64 %rd<44>;


mov.u64 %rd43, __local_depot11;
cvta.local.u64 %SP, %rd43;
ld.param.u32 %r24, [_Z29THCudaTensor_scatterAddKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r25, [_Z29THCudaTensor_scatterAddKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjhLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd3, %rd10;
mov.u32 %r51, 0;
mov.pred %p1, 0;
@%p1 bra BB11_2;

BB11_1:
mul.wide.s32 %rd11, %r51, 8;
add.s64 %rd12, %rd4, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd3, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p2, %r51, 27;
@%p2 bra BB11_1;

BB11_2:
mov.u32 %r27, %ntid.x;
mov.u32 %r28, %ctaid.x;
mov.u32 %r29, %tid.x;
mad.lo.s32 %r52, %r27, %r28, %r29;
setp.ge.u32	%p3, %r52, %r25;
@%p3 bra BB11_14;

ld.param.u64 %rd15, [%rd1];
cvta.to.global.u64 %rd6, %rd15;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd16, [%rd2];
cvta.to.global.u64 %rd7, %rd16;
ld.param.v2.u32 {%r30, %r31}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB11_4:
rem.u32 %r11, %r52, %r31;
setp.eq.s32	%p4, %r24, 1;
mov.u32 %r53, 0;
@%p4 bra BB11_6;

ld.local.u32 %r33, [%rd3+112];
mul.lo.s32 %r53, %r33, %r11;

BB11_6:
div.u32 %r34, %r52, %r31;
rem.u32 %r14, %r34, %r30;
setp.eq.s32	%p5, %r24, 0;
@%p5 bra BB11_8;

ld.local.u32 %r35, [%rd3+108];
mad.lo.s32 %r53, %r35, %r14, %r53;

BB11_8:
mul.lo.s32 %r36, %r9, %r11;
mul.lo.s32 %r37, %r5, %r11;
mad.lo.s32 %r38, %r8, %r14, %r36;
mad.lo.s32 %r17, %r4, %r14, %r37;
mul.wide.u32 %rd17, %r38, 8;
add.s64 %rd18, %rd7, %rd17;
ld.global.u64 %rd8, [%rd18];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB11_10;

mul.wide.s32 %rd19, %r24, 4;
add.s64 %rd20, %rd3, %rd19;
ld.local.u32 %rd21, [%rd20+8];
setp.lt.s64	%p7, %rd8, %rd21;
@%p7 bra BB11_11;

BB11_10:
mov.u64 %rd22, $str2;
cvta.global.u64 %rd23, %rd22;
mov.u64 %rd24, $str1;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, __T222;
cvta.global.u64 %rd27, %rd26;
mov.u32 %r39, 151;
mov.u64 %rd28, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd23;
.param .b64 param1;
st.param.b64	[param1+0], %rd25;
.param .b32 param2;
st.param.b32	[param2+0], %r39;
.param .b64 param3;
st.param.b64	[param3+0], %rd27;
.param .b64 param4;
st.param.b64	[param4+0], %rd28;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB11_11:
mul.wide.s32 %rd29, %r24, 4;
add.s64 %rd30, %rd3, %rd29;
ld.local.u32 %rd31, [%rd30+108];
mul.lo.s64 %rd32, %rd31, %rd8;
cvt.u64.u32	%rd33, %r53;
add.s64 %rd34, %rd32, %rd33;
and.b64 %rd35, %rd34, 4294967295;
ld.local.u64 %rd36, [%rd3];
add.s64 %rd37, %rd36, %rd35;
cvt.u64.u32	%rd38, %r17;
add.s64 %rd39, %rd6, %rd38;
and.b64 %rd40, %rd37, 3;
sub.s64 %rd41, %rd35, %rd40;
add.s64 %rd9, %rd36, %rd41;
ld.u32 %r54, [%rd9];
shl.b64 %rd42, %rd40, 3;
cvt.u32.u64	%r19, %rd42;
ld.global.u8 %r20, [%rd39];

BB11_12:
mov.u32 %r21, %r54;
shr.u32 %r40, %r21, %r19;
and.b32 %r41, %r40, 255;
add.s32 %r42, %r41, %r20;
mov.u32 %r43, 255;
shl.b32 %r44, %r43, %r19;
not.b32 %r45, %r44;
and.b32 %r46, %r21, %r45;
shl.b32 %r47, %r42, %r19;
or.b32 %r48, %r47, %r46;
atom.cas.b32 %r54, [%rd9], %r21, %r48;
setp.ne.s32	%p8, %r21, %r54;
@%p8 bra BB11_12;

mov.u32 %r50, %nctaid.x;
mad.lo.s32 %r52, %r50, %r27, %r52;
setp.lt.u32	%p9, %r52, %r25;
@%p9 bra BB11_4;

BB11_14:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot12[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<11>;
.reg .b32 %r<69>;
.reg .b64 %rd<44>;


mov.u64 %rd43, __local_depot12;
cvta.local.u64 %SP, %rd43;
ld.param.u32 %r32, [_Z29THCudaTensor_scatterAddKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r33, [_Z29THCudaTensor_scatterAddKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjhLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd3, %rd10;
mov.u32 %r65, 0;
mov.pred %p1, 0;
@%p1 bra BB12_2;

BB12_1:
mul.wide.s32 %rd11, %r65, 8;
add.s64 %rd12, %rd4, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd3, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r65, %r65, 1;
setp.lt.u32	%p2, %r65, 27;
@%p2 bra BB12_1;

BB12_2:
mov.u32 %r35, %ntid.x;
mov.u32 %r36, %ctaid.x;
mov.u32 %r37, %tid.x;
mad.lo.s32 %r66, %r35, %r36, %r37;
setp.ge.u32	%p3, %r66, %r33;
@%p3 bra BB12_16;

ld.param.u64 %rd15, [%rd1];
cvta.to.global.u64 %rd6, %rd15;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r38, %r39}, [%rd1+112];
ld.param.u64 %rd16, [%rd2];
cvta.to.global.u64 %rd7, %rd16;
ld.param.v2.u32 {%r40, %r41}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r42, %r43}, [%rd2+112];

BB12_4:
rem.u32 %r14, %r66, %r9;
setp.eq.s32	%p4, %r32, 2;
mov.u32 %r67, 0;
@%p4 bra BB12_6;

ld.local.u32 %r45, [%rd3+116];
mul.lo.s32 %r67, %r45, %r14;

BB12_6:
div.u32 %r17, %r66, %r9;
rem.u32 %r18, %r17, %r41;
setp.eq.s32	%p5, %r32, 1;
@%p5 bra BB12_8;

ld.local.u32 %r46, [%rd3+112];
mad.lo.s32 %r67, %r46, %r18, %r67;

BB12_8:
div.u32 %r47, %r17, %r41;
rem.u32 %r21, %r47, %r40;
setp.eq.s32	%p6, %r32, 0;
@%p6 bra BB12_10;

ld.local.u32 %r48, [%rd3+108];
mad.lo.s32 %r67, %r48, %r21, %r67;

BB12_10:
mul.lo.s32 %r49, %r43, %r14;
mul.lo.s32 %r50, %r39, %r14;
mad.lo.s32 %r51, %r42, %r18, %r49;
mad.lo.s32 %r52, %r38, %r18, %r50;
mad.lo.s32 %r53, %r10, %r21, %r51;
mad.lo.s32 %r24, %r4, %r21, %r52;
mul.wide.u32 %rd17, %r53, 8;
add.s64 %rd18, %rd7, %rd17;
ld.global.u64 %rd8, [%rd18];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB12_12;

mul.wide.s32 %rd19, %r32, 4;
add.s64 %rd20, %rd3, %rd19;
ld.local.u32 %rd21, [%rd20+8];
setp.lt.s64	%p8, %rd8, %rd21;
@%p8 bra BB12_13;

BB12_12:
mov.u64 %rd22, $str2;
cvta.global.u64 %rd23, %rd22;
mov.u64 %rd24, $str1;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, __T223;
cvta.global.u64 %rd27, %rd26;
mov.u32 %r54, 151;
mov.u64 %rd28, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd23;
.param .b64 param1;
st.param.b64	[param1+0], %rd25;
.param .b32 param2;
st.param.b32	[param2+0], %r54;
.param .b64 param3;
st.param.b64	[param3+0], %rd27;
.param .b64 param4;
st.param.b64	[param4+0], %rd28;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB12_13:
mul.wide.s32 %rd29, %r32, 4;
add.s64 %rd30, %rd3, %rd29;
ld.local.u32 %rd31, [%rd30+108];
mul.lo.s64 %rd32, %rd31, %rd8;
cvt.u64.u32	%rd33, %r67;
add.s64 %rd34, %rd32, %rd33;
and.b64 %rd35, %rd34, 4294967295;
ld.local.u64 %rd36, [%rd3];
add.s64 %rd37, %rd36, %rd35;
cvt.u64.u32	%rd38, %r24;
add.s64 %rd39, %rd6, %rd38;
and.b64 %rd40, %rd37, 3;
sub.s64 %rd41, %rd35, %rd40;
add.s64 %rd9, %rd36, %rd41;
ld.u32 %r68, [%rd9];
shl.b64 %rd42, %rd40, 3;
cvt.u32.u64	%r26, %rd42;
ld.global.u8 %r27, [%rd39];
mov.u32 %r55, 255;
shl.b32 %r56, %r55, %r26;
not.b32 %r28, %r56;

BB12_14:
mov.u32 %r29, %r68;
shr.u32 %r57, %r29, %r26;
and.b32 %r58, %r57, 255;
add.s32 %r59, %r58, %r27;
shl.b32 %r60, %r59, %r26;
and.b32 %r61, %r29, %r28;
or.b32 %r62, %r60, %r61;
atom.cas.b32 %r68, [%rd9], %r29, %r62;
setp.ne.s32	%p9, %r29, %r68;
@%p9 bra BB12_14;

mov.u32 %r64, %nctaid.x;
mad.lo.s32 %r66, %r64, %r35, %r66;
setp.lt.u32	%p10, %r66, %r33;
@%p10 bra BB12_4;

BB12_16:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot13[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<15>;
.reg .b32 %r<73>;
.reg .b64 %rd<72>;


mov.u64 %rd71, __local_depot13;
cvta.local.u64 %SP, %rd71;
ld.param.u32 %r36, [_Z29THCudaTensor_scatterAddKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r37, [_Z29THCudaTensor_scatterAddKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z29THCudaTensor_scatterAddKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd21, %SP, 216;
cvta.to.local.u64 %rd3, %rd21;
add.u64 %rd22, %SP, 432;
cvta.to.local.u64 %rd4, %rd22;
add.u64 %rd23, %SP, 0;
cvta.to.local.u64 %rd5, %rd23;
mov.u32 %r61, 0;
mov.pred %p1, 0;
@%p1 bra BB13_2;

BB13_1:
mul.wide.s32 %rd24, %r61, 8;
add.s64 %rd25, %rd6, %rd24;
ld.param.u64 %rd26, [%rd25];
add.s64 %rd27, %rd3, %rd24;
st.local.u64 [%rd27], %rd26;
add.s32 %r61, %r61, 1;
setp.lt.u32	%p2, %r61, 27;
@%p2 bra BB13_1;

BB13_2:
mov.u32 %r62, 0;
@%p1 bra BB13_4;

BB13_3:
mul.wide.s32 %rd28, %r62, 8;
add.s64 %rd29, %rd1, %rd28;
ld.param.u64 %rd30, [%rd29];
add.s64 %rd31, %rd4, %rd28;
st.local.u64 [%rd31], %rd30;
add.s32 %r62, %r62, 1;
setp.lt.u32	%p4, %r62, 27;
@%p4 bra BB13_3;

BB13_4:
mov.u32 %r63, 0;
@%p1 bra BB13_6;

BB13_5:
mul.wide.s32 %rd32, %r63, 8;
add.s64 %rd33, %rd2, %rd32;
ld.param.u64 %rd34, [%rd33];
add.s64 %rd35, %rd5, %rd32;
st.local.u64 [%rd35], %rd34;
add.s32 %r63, %r63, 1;
setp.lt.u32	%p6, %r63, 27;
@%p6 bra BB13_5;

BB13_6:
mov.u32 %r41, %ntid.x;
mov.u32 %r42, %ctaid.x;
mov.u32 %r43, %tid.x;
mad.lo.s32 %r68, %r41, %r42, %r43;
setp.ge.u32	%p7, %r68, %r37;
@%p7 bra BB13_19;

BB13_7:
mov.u32 %r66, %r68;
mov.u32 %r8, %r66;
ld.local.u32 %r65, [%rd5+208];
mov.u32 %r71, 0;
mov.u64 %rd70, 0;
mov.u64 %rd69, %rd70;
setp.lt.s32	%p8, %r65, 1;
@%p8 bra BB13_13;

not.b32 %r48, %r36;
add.s32 %r64, %r48, %r65;
mul.wide.s32 %rd68, %r65, 4;
mov.u32 %r71, 0;
mov.u32 %r70, %r71;
mov.u32 %r69, %r71;
mov.u32 %r67, %r8;

BB13_9:
mov.u32 %r13, %r67;
add.s64 %rd38, %rd4, %rd68;
add.s32 %r65, %r65, -1;
add.s64 %rd39, %rd5, %rd68;
ld.local.u32 %r18, [%rd39+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r49, [%rd39+104];
mad.lo.s32 %r69, %r49, %r19, %r69;
ld.local.u32 %r50, [%rd38+104];
mad.lo.s32 %r70, %r50, %r19, %r70;
setp.eq.s32	%p9, %r64, 0;
@%p9 bra BB13_11;

add.s64 %rd40, %rd3, %rd68;
ld.local.u32 %r51, [%rd40+104];
mad.lo.s32 %r71, %r51, %r19, %r71;

BB13_11:
div.u32 %r24, %r13, %r18;
add.s32 %r64, %r64, -1;
add.s64 %rd68, %rd68, -4;
setp.gt.s32	%p10, %r65, 0;
mov.u32 %r67, %r24;
@%p10 bra BB13_9;

cvt.u64.u32	%rd69, %r69;
cvt.u64.u32	%rd70, %r70;

BB13_13:
ld.local.u64 %rd41, [%rd5];
shl.b64 %rd42, %rd69, 3;
add.s64 %rd43, %rd41, %rd42;
ld.u64 %rd19, [%rd43];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB13_15;

mul.wide.s32 %rd44, %r36, 4;
add.s64 %rd45, %rd3, %rd44;
ld.local.u32 %rd46, [%rd45+8];
setp.lt.s64	%p12, %rd19, %rd46;
@%p12 bra BB13_16;

BB13_15:
mov.u64 %rd47, $str2;
cvta.global.u64 %rd48, %rd47;
mov.u64 %rd49, $str1;
cvta.global.u64 %rd50, %rd49;
mov.u64 %rd51, __T224;
cvta.global.u64 %rd52, %rd51;
mov.u32 %r52, 151;
mov.u64 %rd53, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd48;
.param .b64 param1;
st.param.b64	[param1+0], %rd50;
.param .b32 param2;
st.param.b32	[param2+0], %r52;
.param .b64 param3;
st.param.b64	[param3+0], %rd52;
.param .b64 param4;
st.param.b64	[param4+0], %rd53;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB13_16:
mul.wide.s32 %rd54, %r36, 4;
add.s64 %rd55, %rd3, %rd54;
ld.local.u32 %rd56, [%rd55+108];
mul.lo.s64 %rd57, %rd56, %rd19;
cvt.u64.u32	%rd58, %r71;
add.s64 %rd59, %rd57, %rd58;
and.b64 %rd60, %rd59, 4294967295;
ld.local.u64 %rd61, [%rd3];
add.s64 %rd62, %rd61, %rd60;
ld.local.u64 %rd63, [%rd4];
add.s64 %rd64, %rd63, %rd70;
and.b64 %rd65, %rd62, 3;
sub.s64 %rd66, %rd60, %rd65;
add.s64 %rd20, %rd61, %rd66;
ld.u32 %r72, [%rd20];
shl.b64 %rd67, %rd65, 3;
cvt.u32.u64	%r28, %rd67;
ld.u8 %r29, [%rd64];
mov.u32 %r53, 255;
shl.b32 %r54, %r53, %r28;
not.b32 %r30, %r54;
mov.u32 %r31, %nctaid.x;

BB13_17:
mov.u32 %r33, %r72;
shr.u32 %r55, %r33, %r28;
and.b32 %r56, %r55, 255;
add.s32 %r57, %r56, %r29;
shl.b32 %r58, %r57, %r28;
and.b32 %r59, %r33, %r30;
or.b32 %r60, %r58, %r59;
atom.cas.b32 %r72, [%rd20], %r33, %r60;
setp.ne.s32	%p13, %r33, %r72;
@%p13 bra BB13_17;

mad.lo.s32 %r68, %r31, %r41, %r8;
setp.lt.u32	%p14, %r68, %r37;
@%p14 bra BB13_7;

BB13_19:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[416],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[416],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[416],
.param .u32 _Z29THCudaTensor_scatterAddKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u64 _Z29THCudaTensor_scatterAddKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot14[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<17>;
.reg .b32 %r<52>;
.reg .b64 %rd<110>;


mov.u64 %rd109, __local_depot14;
cvta.local.u64 %SP, %rd109;
ld.param.u32 %r20, [_Z29THCudaTensor_scatterAddKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u64 %rd39, [_Z29THCudaTensor_scatterAddKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z29THCudaTensor_scatterAddKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelImhLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd40, %SP, 416;
cvta.to.local.u64 %rd3, %rd40;
add.u64 %rd41, %SP, 832;
cvta.to.local.u64 %rd4, %rd41;
add.u64 %rd42, %SP, 0;
cvta.to.local.u64 %rd5, %rd42;
mov.u32 %r46, 0;
mov.pred %p1, 0;
@%p1 bra BB14_2;

BB14_1:
mul.wide.s32 %rd43, %r46, 8;
add.s64 %rd44, %rd6, %rd43;
ld.param.u64 %rd45, [%rd44];
add.s64 %rd46, %rd3, %rd43;
st.local.u64 [%rd46], %rd45;
add.s32 %r46, %r46, 1;
setp.lt.u32	%p2, %r46, 52;
@%p2 bra BB14_1;

BB14_2:
mov.u32 %r47, 0;
@%p1 bra BB14_4;

BB14_3:
mul.wide.s32 %rd47, %r47, 8;
add.s64 %rd48, %rd1, %rd47;
ld.param.u64 %rd49, [%rd48];
add.s64 %rd50, %rd4, %rd47;
st.local.u64 [%rd50], %rd49;
add.s32 %r47, %r47, 1;
setp.lt.u32	%p4, %r47, 52;
@%p4 bra BB14_3;

BB14_4:
mov.u32 %r48, 0;
@%p1 bra BB14_6;

BB14_5:
mul.wide.s32 %rd51, %r48, 8;
add.s64 %rd52, %rd2, %rd51;
ld.param.u64 %rd53, [%rd52];
add.s64 %rd54, %rd5, %rd51;
st.local.u64 [%rd54], %rd53;
add.s32 %r48, %r48, 1;
setp.lt.u32	%p6, %r48, 52;
@%p6 bra BB14_5;

BB14_6:
mov.u32 %r24, %ntid.x;
mov.u32 %r25, %ctaid.x;
mov.u32 %r26, %tid.x;
mad.lo.s32 %r27, %r24, %r25, %r26;
cvt.u64.u32	%rd104, %r27;
setp.ge.u64	%p7, %rd104, %rd39;
@%p7 bra BB14_24;

BB14_7:
mov.u64 %rd100, %rd104;
mov.u64 %rd13, %rd100;
ld.local.u32 %r50, [%rd5+408];
mov.u64 %rd108, 0;
mov.u64 %rd107, %rd108;
mov.u64 %rd106, %rd108;
setp.lt.s32	%p8, %r50, 1;
@%p8 bra BB14_18;

not.b32 %r28, %r20;
add.s32 %r49, %r28, %r50;
mul.wide.s32 %rd99, %r50, 8;
mov.u64 %rd108, 0;
mov.u64 %rd107, %rd108;
mov.u64 %rd106, %rd108;
mov.u64 %rd102, %rd13;

BB14_9:
mov.u64 %rd16, %rd102;
add.s32 %r50, %r50, -1;
add.s64 %rd20, %rd5, %rd99;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd61, %rd16, %rd21;
and.b64 %rd62, %rd61, -4294967296;
setp.eq.s64	%p9, %rd62, 0;
@%p9 bra BB14_11;
bra.uni BB14_10;

BB14_11:
cvt.u32.u64	%r29, %rd21;
cvt.u32.u64	%r30, %rd16;
rem.u32 %r31, %r30, %r29;
cvt.u64.u32	%rd105, %r31;
bra.uni BB14_12;

BB14_10:
rem.u64 %rd105, %rd16, %rd21;

BB14_12:
add.s64 %rd63, %rd4, %rd99;
ld.local.u64 %rd64, [%rd20+200];
mul.lo.s64 %rd65, %rd64, %rd105;
add.s64 %rd106, %rd65, %rd106;
ld.local.u64 %rd66, [%rd63+200];
mul.lo.s64 %rd67, %rd66, %rd105;
add.s64 %rd107, %rd67, %rd107;
setp.eq.s32	%p10, %r49, 0;
@%p10 bra BB14_14;

add.s64 %rd68, %rd3, %rd99;
ld.local.u64 %rd69, [%rd68+200];
mul.lo.s64 %rd70, %rd69, %rd105;
add.s64 %rd108, %rd70, %rd108;

BB14_14:
@%p9 bra BB14_16;
bra.uni BB14_15;

BB14_16:
cvt.u32.u64	%r32, %rd21;
cvt.u32.u64	%r33, %rd16;
div.u32 %r34, %r33, %r32;
cvt.u64.u32	%rd103, %r34;
bra.uni BB14_17;

BB14_15:
div.u64 %rd103, %rd16, %rd21;

BB14_17:
mov.u64 %rd31, %rd103;
add.s32 %r49, %r49, -1;
add.s64 %rd99, %rd99, -8;
setp.gt.s32	%p12, %r50, 0;
mov.u64 %rd102, %rd31;
@%p12 bra BB14_9;

BB14_18:
ld.local.u64 %rd73, [%rd5];
shl.b64 %rd74, %rd106, 3;
add.s64 %rd75, %rd73, %rd74;
ld.u64 %rd36, [%rd75];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB14_20;

mul.wide.s32 %rd76, %r20, 8;
add.s64 %rd77, %rd3, %rd76;
ld.local.u64 %rd78, [%rd77+8];
setp.lt.u64	%p14, %rd36, %rd78;
@%p14 bra BB14_21;

BB14_20:
mov.u64 %rd79, $str2;
cvta.global.u64 %rd80, %rd79;
mov.u64 %rd81, $str1;
cvta.global.u64 %rd82, %rd81;
mov.u64 %rd83, __T225;
cvta.global.u64 %rd84, %rd83;
mov.u32 %r35, 151;
mov.u64 %rd85, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd80;
.param .b64 param1;
st.param.b64	[param1+0], %rd82;
.param .b32 param2;
st.param.b32	[param2+0], %r35;
.param .b64 param3;
st.param.b64	[param3+0], %rd84;
.param .b64 param4;
st.param.b64	[param4+0], %rd85;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB14_21:
mul.wide.s32 %rd86, %r20, 8;
add.s64 %rd87, %rd3, %rd86;
ld.local.u64 %rd88, [%rd87+208];
mul.lo.s64 %rd89, %rd88, %rd36;
add.s64 %rd90, %rd89, %rd108;
ld.local.u64 %rd91, [%rd3];
add.s64 %rd92, %rd91, %rd90;
ld.local.u64 %rd93, [%rd4];
add.s64 %rd94, %rd93, %rd107;
and.b64 %rd95, %rd92, 3;
sub.s64 %rd96, %rd90, %rd95;
add.s64 %rd37, %rd91, %rd96;
ld.u32 %r51, [%rd37];
shl.b64 %rd97, %rd95, 3;
cvt.u32.u64	%r14, %rd97;
ld.u8 %r15, [%rd94];
mov.u32 %r36, 255;
shl.b32 %r37, %r36, %r14;
not.b32 %r16, %r37;
mov.u32 %r39, %nctaid.x;
mul.lo.s32 %r17, %r39, %r24;

BB14_22:
mov.u32 %r18, %r51;
shr.u32 %r40, %r18, %r14;
and.b32 %r41, %r40, 255;
add.s32 %r42, %r41, %r15;
shl.b32 %r43, %r42, %r14;
and.b32 %r44, %r18, %r16;
or.b32 %r45, %r43, %r44;
atom.cas.b32 %r51, [%rd37], %r18, %r45;
setp.ne.s32	%p15, %r18, %r51;
@%p15 bra BB14_22;

cvt.u64.u32	%rd98, %r17;
add.s64 %rd104, %rd98, %rd13;
setp.lt.u64	%p16, %rd104, %rd39;
@%p16 bra BB14_7;

BB14_24:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjhLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjhLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjhLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .u8 _Z30THCudaTensor_scatterFillKernelIjhLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjhLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjhLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot15[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .b32 %r<23>;
.reg .b64 %rd<37>;


mov.u64 %rd36, __local_depot15;
cvta.local.u64 %SP, %rd36;
ld.param.u32 %r11, [_Z30THCudaTensor_scatterFillKernelIjhLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r12, [_Z30THCudaTensor_scatterFillKernelIjhLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
ld.param.u8 %rs1, [_Z30THCudaTensor_scatterFillKernelIjhLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjhLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjhLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd2, %rd10;
mov.u32 %r21, 0;
mov.pred %p1, 0;
@%p1 bra BB15_2;

BB15_1:
mul.wide.s32 %rd11, %r21, 8;
add.s64 %rd12, %rd3, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd2, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r21, %r21, 1;
setp.lt.u32	%p2, %r21, 27;
@%p2 bra BB15_1;

BB15_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r22, %r3, %r14, %r15;
setp.ge.u32	%p3, %r22, %r12;
@%p3 bra BB15_10;

ld.param.u64 %rd15, [%rd1];
cvta.to.global.u64 %rd5, %rd15;
ld.param.u32 %r5, [%rd1+8];
ld.param.u32 %r6, [%rd1+108];
mul.wide.s32 %rd16, %r11, 4;
add.s64 %rd17, %rd2, %rd16;
add.s64 %rd6, %rd17, 8;
mov.u32 %r16, %nctaid.x;
mul.lo.s32 %r7, %r16, %r3;

BB15_4:
rem.u32 %r9, %r22, %r5;
setp.eq.s32	%p4, %r11, 0;
mov.u64 %rd35, 0;
@%p4 bra BB15_6;

ld.local.u32 %r17, [%rd2+108];
mul.lo.s32 %r18, %r17, %r9;
cvt.u64.u32	%rd35, %r18;

BB15_6:
mul.lo.s32 %r19, %r6, %r9;
mul.wide.u32 %rd19, %r19, 8;
add.s64 %rd20, %rd5, %rd19;
ld.global.u64 %rd9, [%rd20];
setp.lt.s64	%p5, %rd9, 0;
@%p5 bra BB15_8;

ld.local.u32 %rd21, [%rd6];
setp.lt.s64	%p6, %rd9, %rd21;
@%p6 bra BB15_9;

BB15_8:
mov.u64 %rd22, $str2;
cvta.global.u64 %rd23, %rd22;
mov.u64 %rd24, $str1;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, __T226;
cvta.global.u64 %rd27, %rd26;
mov.u32 %r20, 176;
mov.u64 %rd28, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd23;
.param .b64 param1;
st.param.b64	[param1+0], %rd25;
.param .b32 param2;
st.param.b32	[param2+0], %r20;
.param .b64 param3;
st.param.b64	[param3+0], %rd27;
.param .b64 param4;
st.param.b64	[param4+0], %rd28;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB15_9:
ld.local.u32 %rd29, [%rd6+100];
mul.lo.s64 %rd30, %rd29, %rd9;
add.s64 %rd31, %rd30, %rd35;
and.b64 %rd32, %rd31, 4294967295;
ld.local.u64 %rd33, [%rd2];
add.s64 %rd34, %rd33, %rd32;
st.u8 [%rd34], %rs1;
add.s32 %r22, %r7, %r22;
setp.lt.u32	%p7, %r22, %r12;
@%p7 bra BB15_4;

BB15_10:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjhLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjhLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjhLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .u8 _Z30THCudaTensor_scatterFillKernelIjhLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjhLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjhLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot16[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b16 %rs<2>;
.reg .b32 %r<36>;
.reg .b64 %rd<35>;


mov.u64 %rd34, __local_depot16;
cvta.local.u64 %SP, %rd34;
ld.param.u32 %r16, [_Z30THCudaTensor_scatterFillKernelIjhLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r17, [_Z30THCudaTensor_scatterFillKernelIjhLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
ld.param.u8 %rs1, [_Z30THCudaTensor_scatterFillKernelIjhLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjhLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjhLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd7, %SP, 0;
cvta.to.local.u64 %rd2, %rd7;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB16_2;

BB16_1:
mul.wide.s32 %rd8, %r33, 8;
add.s64 %rd9, %rd3, %rd8;
ld.param.u64 %rd10, [%rd9];
add.s64 %rd11, %rd2, %rd8;
st.local.u64 [%rd11], %rd10;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB16_1;

BB16_2:
mov.u32 %r19, %ntid.x;
mov.u32 %r20, %ctaid.x;
mov.u32 %r21, %tid.x;
mad.lo.s32 %r34, %r19, %r20, %r21;
setp.ge.u32	%p3, %r34, %r17;
@%p3 bra BB16_12;

ld.param.u64 %rd12, [%rd1];
cvta.to.global.u64 %rd5, %rd12;
ld.param.v2.u32 {%r22, %r23}, [%rd1+8];
ld.param.u32 %r6, [%rd1+108];
ld.param.u32 %r7, [%rd1+112];

BB16_4:
rem.u32 %r9, %r34, %r23;
setp.eq.s32	%p4, %r16, 1;
mov.u32 %r35, 0;
@%p4 bra BB16_6;

ld.local.u32 %r25, [%rd2+112];
mul.lo.s32 %r35, %r25, %r9;

BB16_6:
div.u32 %r26, %r34, %r23;
rem.u32 %r12, %r26, %r22;
setp.eq.s32	%p5, %r16, 0;
@%p5 bra BB16_8;

ld.local.u32 %r27, [%rd2+108];
mad.lo.s32 %r35, %r27, %r12, %r35;

BB16_8:
mul.lo.s32 %r28, %r7, %r9;
mad.lo.s32 %r29, %r6, %r12, %r28;
mul.wide.u32 %rd13, %r29, 8;
add.s64 %rd14, %rd5, %rd13;
ld.global.u64 %rd6, [%rd14];
setp.lt.s64	%p6, %rd6, 0;
@%p6 bra BB16_10;

mul.wide.s32 %rd15, %r16, 4;
add.s64 %rd16, %rd2, %rd15;
ld.local.u32 %rd17, [%rd16+8];
setp.lt.s64	%p7, %rd6, %rd17;
@%p7 bra BB16_11;

BB16_10:
mov.u64 %rd18, $str2;
cvta.global.u64 %rd19, %rd18;
mov.u64 %rd20, $str1;
cvta.global.u64 %rd21, %rd20;
mov.u64 %rd22, __T227;
cvta.global.u64 %rd23, %rd22;
mov.u32 %r30, 176;
mov.u64 %rd24, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd19;
.param .b64 param1;
st.param.b64	[param1+0], %rd21;
.param .b32 param2;
st.param.b32	[param2+0], %r30;
.param .b64 param3;
st.param.b64	[param3+0], %rd23;
.param .b64 param4;
st.param.b64	[param4+0], %rd24;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB16_11:
mul.wide.s32 %rd25, %r16, 4;
add.s64 %rd26, %rd2, %rd25;
ld.local.u32 %rd27, [%rd26+108];
mul.lo.s64 %rd28, %rd27, %rd6;
cvt.u64.u32	%rd29, %r35;
add.s64 %rd30, %rd28, %rd29;
and.b64 %rd31, %rd30, 4294967295;
ld.local.u64 %rd32, [%rd2];
add.s64 %rd33, %rd32, %rd31;
st.u8 [%rd33], %rs1;
mov.u32 %r32, %nctaid.x;
mad.lo.s32 %r34, %r32, %r19, %r34;
setp.lt.u32	%p8, %r34, %r17;
@%p8 bra BB16_4;

BB16_12:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjhLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjhLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjhLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .u8 _Z30THCudaTensor_scatterFillKernelIjhLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjhLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjhLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot17[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b16 %rs<2>;
.reg .b32 %r<46>;
.reg .b64 %rd<35>;


mov.u64 %rd34, __local_depot17;
cvta.local.u64 %SP, %rd34;
ld.param.u32 %r23, [_Z30THCudaTensor_scatterFillKernelIjhLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r24, [_Z30THCudaTensor_scatterFillKernelIjhLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
ld.param.u8 %rs1, [_Z30THCudaTensor_scatterFillKernelIjhLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjhLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjhLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd7, %SP, 0;
cvta.to.local.u64 %rd2, %rd7;
mov.u32 %r43, 0;
mov.pred %p1, 0;
@%p1 bra BB17_2;

BB17_1:
mul.wide.s32 %rd8, %r43, 8;
add.s64 %rd9, %rd3, %rd8;
ld.param.u64 %rd10, [%rd9];
add.s64 %rd11, %rd2, %rd8;
st.local.u64 [%rd11], %rd10;
add.s32 %r43, %r43, 1;
setp.lt.u32	%p2, %r43, 27;
@%p2 bra BB17_1;

BB17_2:
mov.u32 %r26, %ntid.x;
mov.u32 %r27, %ctaid.x;
mov.u32 %r28, %tid.x;
mad.lo.s32 %r44, %r26, %r27, %r28;
setp.ge.u32	%p3, %r44, %r24;
@%p3 bra BB17_14;

ld.param.u64 %rd12, [%rd1];
cvta.to.global.u64 %rd5, %rd12;
ld.param.v2.u32 {%r29, %r30}, [%rd1+8];
ld.param.u32 %r6, [%rd1+16];
ld.param.u32 %r7, [%rd1+108];
ld.param.v2.u32 {%r31, %r32}, [%rd1+112];

BB17_4:
rem.u32 %r11, %r44, %r6;
setp.eq.s32	%p4, %r23, 2;
mov.u32 %r45, 0;
@%p4 bra BB17_6;

ld.local.u32 %r34, [%rd2+116];
mul.lo.s32 %r45, %r34, %r11;

BB17_6:
div.u32 %r14, %r44, %r6;
rem.u32 %r15, %r14, %r30;
setp.eq.s32	%p5, %r23, 1;
@%p5 bra BB17_8;

ld.local.u32 %r35, [%rd2+112];
mad.lo.s32 %r45, %r35, %r15, %r45;

BB17_8:
mul.lo.s32 %r36, %r32, %r11;
mad.lo.s32 %r18, %r31, %r15, %r36;
div.u32 %r37, %r14, %r30;
rem.u32 %r19, %r37, %r29;
setp.eq.s32	%p6, %r23, 0;
@%p6 bra BB17_10;

ld.local.u32 %r38, [%rd2+108];
mad.lo.s32 %r45, %r38, %r19, %r45;

BB17_10:
mad.lo.s32 %r39, %r7, %r19, %r18;
mul.wide.u32 %rd13, %r39, 8;
add.s64 %rd14, %rd5, %rd13;
ld.global.u64 %rd6, [%rd14];
setp.lt.s64	%p7, %rd6, 0;
@%p7 bra BB17_12;

mul.wide.s32 %rd15, %r23, 4;
add.s64 %rd16, %rd2, %rd15;
ld.local.u32 %rd17, [%rd16+8];
setp.lt.s64	%p8, %rd6, %rd17;
@%p8 bra BB17_13;

BB17_12:
mov.u64 %rd18, $str2;
cvta.global.u64 %rd19, %rd18;
mov.u64 %rd20, $str1;
cvta.global.u64 %rd21, %rd20;
mov.u64 %rd22, __T228;
cvta.global.u64 %rd23, %rd22;
mov.u32 %r40, 176;
mov.u64 %rd24, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd19;
.param .b64 param1;
st.param.b64	[param1+0], %rd21;
.param .b32 param2;
st.param.b32	[param2+0], %r40;
.param .b64 param3;
st.param.b64	[param3+0], %rd23;
.param .b64 param4;
st.param.b64	[param4+0], %rd24;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB17_13:
mul.wide.s32 %rd25, %r23, 4;
add.s64 %rd26, %rd2, %rd25;
ld.local.u32 %rd27, [%rd26+108];
mul.lo.s64 %rd28, %rd27, %rd6;
cvt.u64.u32	%rd29, %r45;
add.s64 %rd30, %rd28, %rd29;
and.b64 %rd31, %rd30, 4294967295;
ld.local.u64 %rd32, [%rd2];
add.s64 %rd33, %rd32, %rd31;
st.u8 [%rd33], %rs1;
mov.u32 %r42, %nctaid.x;
mad.lo.s32 %r44, %r42, %r26, %r44;
setp.lt.u32	%p9, %r44, %r24;
@%p9 bra BB17_4;

BB17_14:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjhLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjhLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjhLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .u8 _Z30THCudaTensor_scatterFillKernelIjhLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjhLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjhLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot18[432];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<12>;
.reg .b16 %rs<2>;
.reg .b32 %r<54>;
.reg .b64 %rd<62>;


mov.u64 %rd61, __local_depot18;
cvta.local.u64 %SP, %rd61;
ld.param.u32 %r24, [_Z30THCudaTensor_scatterFillKernelIjhLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r25, [_Z30THCudaTensor_scatterFillKernelIjhLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
ld.param.u8 %rs1, [_Z30THCudaTensor_scatterFillKernelIjhLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
mov.u64 %rd4, _Z30THCudaTensor_scatterFillKernelIjhLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjhLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd17, %SP, 216;
cvta.to.local.u64 %rd2, %rd17;
add.u64 %rd18, %SP, 0;
cvta.to.local.u64 %rd3, %rd18;
mov.u32 %r40, 0;
mov.pred %p1, 0;
@%p1 bra BB18_2;

BB18_1:
mul.wide.s32 %rd19, %r40, 8;
add.s64 %rd20, %rd4, %rd19;
ld.param.u64 %rd21, [%rd20];
add.s64 %rd22, %rd2, %rd19;
st.local.u64 [%rd22], %rd21;
add.s32 %r40, %r40, 1;
setp.lt.u32	%p2, %r40, 27;
@%p2 bra BB18_1;

BB18_2:
mov.u32 %r41, 0;
@%p1 bra BB18_4;

BB18_3:
mul.wide.s32 %rd23, %r41, 8;
add.s64 %rd24, %rd1, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r41, %r41, 1;
setp.lt.u32	%p4, %r41, 27;
@%p4 bra BB18_3;

BB18_4:
mov.u32 %r28, %ntid.x;
mov.u32 %r29, %ctaid.x;
mov.u32 %r30, %tid.x;
mad.lo.s32 %r46, %r28, %r29, %r30;
setp.ge.u32	%p5, %r46, %r25;
@%p5 bra BB18_15;

ld.local.u32 %r6, [%rd3+208];

BB18_6:
mov.u32 %r44, %r46;
mov.u32 %r7, %r44;
cvt.s64.s32	%rd28, %r6;
not.b64 %rd29, %rd28;
mov.u64 %rd30, -26;
sub.s64 %rd31, %rd30, %rd28;
add.s32 %r34, %r6, -1;
sub.s32 %r42, %r34, %r24;
neg.s64 %rd58, %rd29;
neg.s64 %rd59, %rd31;
mov.u32 %r51, 0;
mov.u64 %rd60, 0;
mov.u32 %r52, %r51;
mov.u32 %r47, %r51;
setp.lt.s32	%p6, %r6, 1;
mov.u32 %r43, %r6;
mov.u32 %r45, %r7;
@%p6 bra BB18_11;

BB18_7:
mov.u32 %r48, %r52;
mov.u32 %r53, %r48;
mov.u32 %r11, %r45;
mov.u32 %r10, %r43;
add.s32 %r14, %r10, -1;
shl.b64 %rd32, %rd58, 2;
add.s64 %rd33, %rd3, %rd32;
ld.local.u32 %r15, [%rd33];
rem.u32 %r16, %r11, %r15;
ld.local.u32 %r35, [%rd33+100];
mad.lo.s32 %r47, %r35, %r16, %r47;
setp.eq.s32	%p7, %r42, 0;
@%p7 bra BB18_9;

shl.b64 %rd34, %rd59, 2;
add.s64 %rd35, %rd2, %rd34;
ld.local.u32 %r36, [%rd35];
mad.lo.s32 %r53, %r36, %r16, %r53;

BB18_9:
mov.u32 %r52, %r53;
div.u32 %r20, %r11, %r15;
add.s32 %r42, %r42, -1;
add.s64 %rd59, %rd59, -1;
add.s64 %rd58, %rd58, -1;
setp.gt.s32	%p8, %r14, 0;
mov.u32 %r43, %r14;
mov.u32 %r45, %r20;
@%p8 bra BB18_7;

cvt.u64.u32	%rd60, %r47;
mov.u32 %r51, %r52;

BB18_11:
ld.local.u64 %rd36, [%rd3];
shl.b64 %rd37, %rd60, 3;
add.s64 %rd38, %rd36, %rd37;
ld.u64 %rd16, [%rd38];
setp.lt.s64	%p9, %rd16, 0;
@%p9 bra BB18_13;

mul.wide.s32 %rd39, %r24, 4;
add.s64 %rd40, %rd2, %rd39;
ld.local.u32 %rd41, [%rd40+8];
setp.lt.s64	%p10, %rd16, %rd41;
@%p10 bra BB18_14;

BB18_13:
mov.u64 %rd42, $str2;
cvta.global.u64 %rd43, %rd42;
mov.u64 %rd44, $str1;
cvta.global.u64 %rd45, %rd44;
mov.u64 %rd46, __T229;
cvta.global.u64 %rd47, %rd46;
mov.u32 %r37, 176;
mov.u64 %rd48, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd43;
.param .b64 param1;
st.param.b64	[param1+0], %rd45;
.param .b32 param2;
st.param.b32	[param2+0], %r37;
.param .b64 param3;
st.param.b64	[param3+0], %rd47;
.param .b64 param4;
st.param.b64	[param4+0], %rd48;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB18_14:
mul.wide.s32 %rd49, %r24, 4;
add.s64 %rd50, %rd2, %rd49;
ld.local.u32 %rd51, [%rd50+108];
mul.lo.s64 %rd52, %rd51, %rd16;
cvt.u64.u32	%rd53, %r51;
add.s64 %rd54, %rd52, %rd53;
and.b64 %rd55, %rd54, 4294967295;
ld.local.u64 %rd56, [%rd2];
add.s64 %rd57, %rd56, %rd55;
st.u8 [%rd57], %rs1;
mov.u32 %r39, %nctaid.x;
mad.lo.s32 %r46, %r39, %r28, %r7;
setp.lt.u32	%p11, %r46, %r25;
@%p11 bra BB18_6;

BB18_15:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelImhLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelImhLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[416],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelImhLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[416],
.param .u8 _Z30THCudaTensor_scatterFillKernelImhLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelImhLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u64 _Z30THCudaTensor_scatterFillKernelImhLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot19[832];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .b32 %r<33>;
.reg .b64 %rd<98>;


mov.u64 %rd97, __local_depot19;
cvta.local.u64 %SP, %rd97;
ld.param.u32 %r11, [_Z30THCudaTensor_scatterFillKernelImhLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u64 %rd34, [_Z30THCudaTensor_scatterFillKernelImhLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
ld.param.u8 %rs1, [_Z30THCudaTensor_scatterFillKernelImhLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
mov.u64 %rd4, _Z30THCudaTensor_scatterFillKernelImhLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelImhLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd35, %SP, 416;
cvta.to.local.u64 %rd2, %rd35;
add.u64 %rd36, %SP, 0;
cvta.to.local.u64 %rd3, %rd36;
mov.u32 %r29, 0;
mov.pred %p1, 0;
@%p1 bra BB19_2;

BB19_1:
mul.wide.s32 %rd37, %r29, 8;
add.s64 %rd38, %rd4, %rd37;
ld.param.u64 %rd39, [%rd38];
add.s64 %rd40, %rd2, %rd37;
st.local.u64 [%rd40], %rd39;
add.s32 %r29, %r29, 1;
setp.lt.u32	%p2, %r29, 52;
@%p2 bra BB19_1;

BB19_2:
mov.u32 %r30, 0;
@%p1 bra BB19_4;

BB19_3:
mul.wide.s32 %rd41, %r30, 8;
add.s64 %rd42, %rd1, %rd41;
ld.param.u64 %rd43, [%rd42];
add.s64 %rd44, %rd3, %rd41;
st.local.u64 [%rd44], %rd43;
add.s32 %r30, %r30, 1;
setp.lt.u32	%p4, %r30, 52;
@%p4 bra BB19_3;

BB19_4:
mov.u32 %r14, %ntid.x;
mov.u32 %r15, %ctaid.x;
mov.u32 %r16, %tid.x;
mad.lo.s32 %r17, %r14, %r15, %r16;
cvt.u64.u32	%rd86, %r17;
setp.ge.u64	%p5, %rd86, %rd34;
@%p5 bra BB19_20;

ld.local.u32 %r5, [%rd3+408];

BB19_6:
mov.u64 %rd82, %rd86;
mov.u64 %rd9, %rd82;
mul.wide.s32 %rd49, %r5, 8;
add.s64 %rd80, %rd3, %rd49;
add.s64 %rd50, %rd49, %rd2;
add.s64 %rd81, %rd50, 200;
add.s32 %r18, %r5, -1;
sub.s32 %r31, %r18, %r11;
mov.u64 %rd94, 0;
mov.u64 %rd89, %rd94;
mov.u64 %rd95, %rd94;
mov.u64 %rd90, %rd94;
setp.lt.s32	%p6, %r5, 1;
mov.u32 %r32, %r5;
mov.u64 %rd84, %rd9;
@%p6 bra BB19_16;

BB19_7:
mov.u64 %rd96, %rd95;
mov.u64 %rd14, %rd84;
mov.u32 %r8, %r32;
add.s32 %r9, %r8, -1;
ld.local.u64 %rd18, [%rd80];
or.b64 %rd51, %rd14, %rd18;
and.b64 %rd52, %rd51, -4294967296;
setp.eq.s64	%p7, %rd52, 0;
@%p7 bra BB19_9;
bra.uni BB19_8;

BB19_9:
cvt.u32.u64	%r19, %rd18;
cvt.u32.u64	%r20, %rd14;
rem.u32 %r21, %r20, %r19;
cvt.u64.u32	%rd87, %r21;
bra.uni BB19_10;

BB19_8:
rem.u64 %rd87, %rd14, %rd18;

BB19_10:
ld.local.u64 %rd53, [%rd80+200];
mul.lo.s64 %rd54, %rd53, %rd87;
add.s64 %rd90, %rd54, %rd90;
setp.eq.s32	%p8, %r31, 0;
@%p8 bra BB19_12;

ld.local.u64 %rd55, [%rd81];
mul.lo.s64 %rd56, %rd55, %rd87;
add.s64 %rd96, %rd56, %rd96;

BB19_12:
mov.u64 %rd95, %rd96;
@%p7 bra BB19_14;
bra.uni BB19_13;

BB19_14:
cvt.u32.u64	%r22, %rd18;
cvt.u32.u64	%r23, %rd14;
div.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd85, %r24;
bra.uni BB19_15;

BB19_13:
div.u64 %rd85, %rd14, %rd18;

BB19_15:
mov.u64 %rd27, %rd85;
add.s32 %r31, %r31, -1;
add.s64 %rd81, %rd81, -8;
add.s64 %rd80, %rd80, -8;
setp.gt.s32	%p10, %r9, 0;
mov.u32 %r32, %r9;
mov.u64 %rd84, %rd27;
mov.u64 %rd89, %rd90;
mov.u64 %rd94, %rd95;
@%p10 bra BB19_7;

BB19_16:
ld.local.u64 %rd59, [%rd3];
shl.b64 %rd60, %rd89, 3;
add.s64 %rd61, %rd59, %rd60;
ld.u64 %rd32, [%rd61];
setp.lt.s64	%p11, %rd32, 0;
@%p11 bra BB19_18;

mul.wide.s32 %rd62, %r11, 8;
add.s64 %rd63, %rd2, %rd62;
ld.local.u64 %rd64, [%rd63+8];
setp.lt.u64	%p12, %rd32, %rd64;
@%p12 bra BB19_19;

BB19_18:
mov.u64 %rd65, $str2;
cvta.global.u64 %rd66, %rd65;
mov.u64 %rd67, $str1;
cvta.global.u64 %rd68, %rd67;
mov.u64 %rd69, __T230;
cvta.global.u64 %rd70, %rd69;
mov.u32 %r25, 176;
mov.u64 %rd71, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd66;
.param .b64 param1;
st.param.b64	[param1+0], %rd68;
.param .b32 param2;
st.param.b32	[param2+0], %r25;
.param .b64 param3;
st.param.b64	[param3+0], %rd70;
.param .b64 param4;
st.param.b64	[param4+0], %rd71;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB19_19:
mul.wide.s32 %rd72, %r11, 8;
add.s64 %rd73, %rd2, %rd72;
ld.local.u64 %rd74, [%rd73+208];
mul.lo.s64 %rd75, %rd74, %rd32;
add.s64 %rd76, %rd75, %rd94;
ld.local.u64 %rd77, [%rd2];
add.s64 %rd78, %rd77, %rd76;
st.u8 [%rd78], %rs1;
mov.u32 %r27, %nctaid.x;
mul.lo.s32 %r28, %r27, %r14;
cvt.u64.u32	%rd79, %r28;
add.s64 %rd86, %rd79, %rd9;
setp.lt.u64	%p13, %rd86, %rd34;
@%p13 bra BB19_6;

BB19_20:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot20[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .b32 %r<25>;
.reg .b64 %rd<43>;


mov.u64 %rd42, __local_depot20;
cvta.local.u64 %SP, %rd42;
ld.param.u32 %r10, [_Z25THCudaTensor_gatherKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r11, [_Z25THCudaTensor_gatherKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd3, %rd11;
mov.u32 %r23, 0;
mov.pred %p1, 0;
@%p1 bra BB20_2;

BB20_1:
mul.wide.s32 %rd12, %r23, 8;
add.s64 %rd13, %rd4, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd3, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r23, %r23, 1;
setp.lt.u32	%p2, %r23, 27;
@%p2 bra BB20_1;

BB20_2:
mov.u32 %r13, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r24, %r13, %r14, %r15;
setp.ge.u32	%p3, %r24, %r11;
@%p3 bra BB20_10;

ld.param.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd6, %rd16;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd17, [%rd2];
cvta.to.global.u64 %rd7, %rd17;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB20_4:
rem.u32 %r8, %r24, %r5;
setp.eq.s32	%p4, %r10, 0;
mov.u64 %rd41, 0;
@%p4 bra BB20_6;

ld.local.u32 %r16, [%rd3+108];
mul.lo.s32 %r17, %r16, %r8;
cvt.u64.u32	%rd41, %r17;

BB20_6:
mul.lo.s32 %r18, %r6, %r8;
mul.wide.u32 %rd19, %r18, 8;
add.s64 %rd20, %rd7, %rd19;
ld.global.u64 %rd10, [%rd20];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB20_8;

mul.wide.s32 %rd21, %r10, 4;
add.s64 %rd22, %rd3, %rd21;
ld.local.u32 %rd23, [%rd22+8];
setp.lt.s64	%p6, %rd10, %rd23;
@%p6 bra BB20_9;

BB20_8:
mov.u64 %rd24, $str;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, $str1;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, __T233;
cvta.global.u64 %rd29, %rd28;
mov.u32 %r19, 97;
mov.u64 %rd30, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd25;
.param .b64 param1;
st.param.b64	[param1+0], %rd27;
.param .b32 param2;
st.param.b32	[param2+0], %r19;
.param .b64 param3;
st.param.b64	[param3+0], %rd29;
.param .b64 param4;
st.param.b64	[param4+0], %rd30;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB20_9:
mul.lo.s32 %r20, %r4, %r8;
mul.wide.s32 %rd31, %r10, 4;
add.s64 %rd32, %rd3, %rd31;
ld.local.u32 %rd33, [%rd32+108];
mul.lo.s64 %rd34, %rd33, %rd10;
add.s64 %rd35, %rd34, %rd41;
and.b64 %rd36, %rd35, 4294967295;
ld.local.u64 %rd37, [%rd3];
add.s64 %rd38, %rd37, %rd36;
ld.u8 %rs1, [%rd38];
cvt.u64.u32	%rd39, %r20;
add.s64 %rd40, %rd6, %rd39;
st.global.u8 [%rd40], %rs1;
mov.u32 %r22, %nctaid.x;
mad.lo.s32 %r24, %r22, %r13, %r24;
setp.lt.u32	%p7, %r24, %r11;
@%p7 bra BB20_4;

BB20_10:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot21[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b16 %rs<2>;
.reg .b32 %r<40>;
.reg .b64 %rd<40>;


mov.u64 %rd39, __local_depot21;
cvta.local.u64 %SP, %rd39;
ld.param.u32 %r19, [_Z25THCudaTensor_gatherKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r20, [_Z25THCudaTensor_gatherKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r37, 0;
mov.pred %p1, 0;
@%p1 bra BB21_2;

BB21_1:
mul.wide.s32 %rd10, %r37, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r37, %r37, 1;
setp.lt.u32	%p2, %r37, 27;
@%p2 bra BB21_1;

BB21_2:
mov.u32 %r22, %ntid.x;
mov.u32 %r23, %ctaid.x;
mov.u32 %r24, %tid.x;
mad.lo.s32 %r38, %r22, %r23, %r24;
setp.ge.u32	%p3, %r38, %r20;
@%p3 bra BB21_12;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r25, %r26}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB21_4:
rem.u32 %r11, %r38, %r26;
setp.eq.s32	%p4, %r19, 1;
mov.u32 %r39, 0;
@%p4 bra BB21_6;

ld.local.u32 %r28, [%rd3+112];
mul.lo.s32 %r39, %r28, %r11;

BB21_6:
div.u32 %r29, %r38, %r26;
rem.u32 %r14, %r29, %r25;
setp.eq.s32	%p5, %r19, 0;
@%p5 bra BB21_8;

ld.local.u32 %r30, [%rd3+108];
mad.lo.s32 %r39, %r30, %r14, %r39;

BB21_8:
mul.lo.s32 %r31, %r9, %r11;
mul.lo.s32 %r32, %r5, %r11;
mad.lo.s32 %r33, %r8, %r14, %r31;
mad.lo.s32 %r17, %r4, %r14, %r32;
mul.wide.u32 %rd16, %r33, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB21_10;

mul.wide.s32 %rd18, %r19, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p7, %rd8, %rd20;
@%p7 bra BB21_11;

BB21_10:
mov.u64 %rd21, $str;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T234;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r34, 97;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r34;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB21_11:
mul.wide.s32 %rd28, %r19, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r39;
add.s64 %rd33, %rd31, %rd32;
and.b64 %rd34, %rd33, 4294967295;
ld.local.u64 %rd35, [%rd3];
add.s64 %rd36, %rd35, %rd34;
ld.u8 %rs1, [%rd36];
cvt.u64.u32	%rd37, %r17;
add.s64 %rd38, %rd6, %rd37;
st.global.u8 [%rd38], %rs1;
mov.u32 %r36, %nctaid.x;
mad.lo.s32 %r38, %r36, %r22, %r38;
setp.lt.u32	%p8, %r38, %r20;
@%p8 bra BB21_4;

BB21_12:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot22[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b16 %rs<2>;
.reg .b32 %r<54>;
.reg .b64 %rd<40>;


mov.u64 %rd39, __local_depot22;
cvta.local.u64 %SP, %rd39;
ld.param.u32 %r26, [_Z25THCudaTensor_gatherKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r27, [_Z25THCudaTensor_gatherKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r51, 0;
mov.pred %p1, 0;
@%p1 bra BB22_2;

BB22_1:
mul.wide.s32 %rd10, %r51, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p2, %r51, 27;
@%p2 bra BB22_1;

BB22_2:
mov.u32 %r29, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r52, %r29, %r30, %r31;
setp.ge.u32	%p3, %r52, %r27;
@%p3 bra BB22_14;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r32, %r33}, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r34, %r35}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r36, %r37}, [%rd2+112];

BB22_4:
rem.u32 %r14, %r52, %r9;
setp.eq.s32	%p4, %r26, 2;
mov.u32 %r53, 0;
@%p4 bra BB22_6;

ld.local.u32 %r39, [%rd3+116];
mul.lo.s32 %r53, %r39, %r14;

BB22_6:
div.u32 %r17, %r52, %r9;
rem.u32 %r18, %r17, %r35;
setp.eq.s32	%p5, %r26, 1;
@%p5 bra BB22_8;

ld.local.u32 %r40, [%rd3+112];
mad.lo.s32 %r53, %r40, %r18, %r53;

BB22_8:
div.u32 %r41, %r17, %r35;
rem.u32 %r21, %r41, %r34;
setp.eq.s32	%p6, %r26, 0;
@%p6 bra BB22_10;

ld.local.u32 %r42, [%rd3+108];
mad.lo.s32 %r53, %r42, %r21, %r53;

BB22_10:
mul.lo.s32 %r43, %r37, %r14;
mul.lo.s32 %r44, %r33, %r14;
mad.lo.s32 %r45, %r36, %r18, %r43;
mad.lo.s32 %r46, %r32, %r18, %r44;
mad.lo.s32 %r47, %r10, %r21, %r45;
mad.lo.s32 %r24, %r4, %r21, %r46;
mul.wide.u32 %rd16, %r47, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB22_12;

mul.wide.s32 %rd18, %r26, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p8, %rd8, %rd20;
@%p8 bra BB22_13;

BB22_12:
mov.u64 %rd21, $str;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T235;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r48, 97;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r48;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB22_13:
mul.wide.s32 %rd28, %r26, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r53;
add.s64 %rd33, %rd31, %rd32;
and.b64 %rd34, %rd33, 4294967295;
ld.local.u64 %rd35, [%rd3];
add.s64 %rd36, %rd35, %rd34;
ld.u8 %rs1, [%rd36];
cvt.u64.u32	%rd37, %r24;
add.s64 %rd38, %rd6, %rd37;
st.global.u8 [%rd38], %rs1;
mov.u32 %r50, %nctaid.x;
mad.lo.s32 %r52, %r50, %r29, %r52;
setp.lt.u32	%p9, %r52, %r27;
@%p9 bra BB22_4;

BB22_14:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot23[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .b32 %r<63>;
.reg .b64 %rd<68>;


mov.u64 %rd67, __local_depot23;
cvta.local.u64 %SP, %rd67;
ld.param.u32 %r28, [_Z25THCudaTensor_gatherKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r29, [_Z25THCudaTensor_gatherKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z25THCudaTensor_gatherKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd20, %SP, 216;
cvta.to.local.u64 %rd3, %rd20;
add.u64 %rd21, %SP, 432;
cvta.to.local.u64 %rd4, %rd21;
add.u64 %rd22, %SP, 0;
cvta.to.local.u64 %rd5, %rd22;
mov.u32 %r47, 0;
mov.pred %p1, 0;
@%p1 bra BB23_2;

BB23_1:
mul.wide.s32 %rd23, %r47, 8;
add.s64 %rd24, %rd6, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r47, %r47, 1;
setp.lt.u32	%p2, %r47, 27;
@%p2 bra BB23_1;

BB23_2:
mov.u32 %r48, 0;
@%p1 bra BB23_4;

BB23_3:
mul.wide.s32 %rd27, %r48, 8;
add.s64 %rd28, %rd1, %rd27;
ld.param.u64 %rd29, [%rd28];
add.s64 %rd30, %rd4, %rd27;
st.local.u64 [%rd30], %rd29;
add.s32 %r48, %r48, 1;
setp.lt.u32	%p4, %r48, 27;
@%p4 bra BB23_3;

BB23_4:
mov.u32 %r49, 0;
@%p1 bra BB23_6;

BB23_5:
mul.wide.s32 %rd31, %r49, 8;
add.s64 %rd32, %rd2, %rd31;
ld.param.u64 %rd33, [%rd32];
add.s64 %rd34, %rd5, %rd31;
st.local.u64 [%rd34], %rd33;
add.s32 %r49, %r49, 1;
setp.lt.u32	%p6, %r49, 27;
@%p6 bra BB23_5;

BB23_6:
mov.u32 %r33, %ntid.x;
mov.u32 %r34, %ctaid.x;
mov.u32 %r35, %tid.x;
mad.lo.s32 %r54, %r33, %r34, %r35;
setp.ge.u32	%p7, %r54, %r29;
@%p7 bra BB23_17;

ld.local.u32 %r8, [%rd5+208];

BB23_8:
mov.u32 %r52, %r54;
mov.u32 %r9, %r52;
mul.wide.s32 %rd64, %r8, 4;
add.s32 %r40, %r8, -1;
sub.s32 %r50, %r40, %r28;
mov.u64 %rd66, 0;
mov.u32 %r60, 0;
mov.u64 %rd65, %rd66;
mov.u32 %r56, %r60;
mov.u32 %r61, %r60;
mov.u32 %r55, %r60;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r51, %r8;
mov.u32 %r53, %r9;
@%p8 bra BB23_13;

BB23_9:
mov.u32 %r57, %r61;
mov.u32 %r62, %r57;
mov.u32 %r13, %r53;
mov.u32 %r12, %r51;
add.s64 %rd37, %rd3, %rd64;
add.s32 %r17, %r12, -1;
add.s64 %rd38, %rd5, %rd64;
ld.local.u32 %r18, [%rd38+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r41, [%rd38+104];
mad.lo.s32 %r55, %r41, %r19, %r55;
ld.local.u32 %r42, [%rd37+104];
mad.lo.s32 %r56, %r42, %r19, %r56;
setp.eq.s32	%p9, %r50, 0;
@%p9 bra BB23_11;

add.s64 %rd39, %rd4, %rd64;
ld.local.u32 %r43, [%rd39+104];
mad.lo.s32 %r62, %r43, %r19, %r62;

BB23_11:
mov.u32 %r61, %r62;
div.u32 %r24, %r13, %r18;
add.s32 %r50, %r50, -1;
add.s64 %rd64, %rd64, -4;
setp.gt.s32	%p10, %r17, 0;
mov.u32 %r51, %r17;
mov.u32 %r53, %r24;
@%p10 bra BB23_9;

cvt.u64.u32	%rd65, %r55;
cvt.u64.u32	%rd66, %r56;
mov.u32 %r60, %r61;

BB23_13:
ld.local.u64 %rd40, [%rd5];
shl.b64 %rd41, %rd65, 3;
add.s64 %rd42, %rd40, %rd41;
ld.u64 %rd19, [%rd42];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB23_15;

mul.wide.s32 %rd43, %r28, 4;
add.s64 %rd44, %rd4, %rd43;
ld.local.u32 %rd45, [%rd44+8];
setp.lt.s64	%p12, %rd19, %rd45;
@%p12 bra BB23_16;

BB23_15:
mov.u64 %rd46, $str;
cvta.global.u64 %rd47, %rd46;
mov.u64 %rd48, $str1;
cvta.global.u64 %rd49, %rd48;
mov.u64 %rd50, __T236;
cvta.global.u64 %rd51, %rd50;
mov.u32 %r44, 97;
mov.u64 %rd52, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd47;
.param .b64 param1;
st.param.b64	[param1+0], %rd49;
.param .b32 param2;
st.param.b32	[param2+0], %r44;
.param .b64 param3;
st.param.b64	[param3+0], %rd51;
.param .b64 param4;
st.param.b64	[param4+0], %rd52;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB23_16:
mul.wide.s32 %rd53, %r28, 4;
add.s64 %rd54, %rd4, %rd53;
ld.local.u32 %rd55, [%rd54+108];
mul.lo.s64 %rd56, %rd55, %rd19;
cvt.u64.u32	%rd57, %r60;
add.s64 %rd58, %rd56, %rd57;
and.b64 %rd59, %rd58, 4294967295;
ld.local.u64 %rd60, [%rd4];
add.s64 %rd61, %rd60, %rd59;
ld.u8 %rs1, [%rd61];
ld.local.u64 %rd62, [%rd3];
add.s64 %rd63, %rd62, %rd66;
st.u8 [%rd63], %rs1;
mov.u32 %r46, %nctaid.x;
mad.lo.s32 %r54, %r46, %r33, %r9;
setp.lt.u32	%p13, %r54, %r29;
@%p13 bra BB23_8;

BB23_17:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[416],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[416],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[416],
.param .u32 _Z25THCudaTensor_gatherKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u64 _Z25THCudaTensor_gatherKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot24[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<16>;
.reg .b16 %rs<2>;
.reg .b32 %r<37>;
.reg .b64 %rd<115>;


mov.u64 %rd114, __local_depot24;
cvta.local.u64 %SP, %rd114;
ld.param.u32 %r13, [_Z25THCudaTensor_gatherKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u64 %rd38, [_Z25THCudaTensor_gatherKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z25THCudaTensor_gatherKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd39, %SP, 416;
cvta.to.local.u64 %rd3, %rd39;
add.u64 %rd40, %SP, 832;
cvta.to.local.u64 %rd4, %rd40;
add.u64 %rd41, %SP, 0;
cvta.to.local.u64 %rd5, %rd41;
mov.u32 %r32, 0;
mov.pred %p1, 0;
@%p1 bra BB24_2;

BB24_1:
mul.wide.s32 %rd42, %r32, 8;
add.s64 %rd43, %rd6, %rd42;
ld.param.u64 %rd44, [%rd43];
add.s64 %rd45, %rd3, %rd42;
st.local.u64 [%rd45], %rd44;
add.s32 %r32, %r32, 1;
setp.lt.u32	%p2, %r32, 52;
@%p2 bra BB24_1;

BB24_2:
mov.u32 %r33, 0;
@%p1 bra BB24_4;

BB24_3:
mul.wide.s32 %rd46, %r33, 8;
add.s64 %rd47, %rd1, %rd46;
ld.param.u64 %rd48, [%rd47];
add.s64 %rd49, %rd4, %rd46;
st.local.u64 [%rd49], %rd48;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p4, %r33, 52;
@%p4 bra BB24_3;

BB24_4:
mov.u32 %r34, 0;
@%p1 bra BB24_6;

BB24_5:
mul.wide.s32 %rd50, %r34, 8;
add.s64 %rd51, %rd2, %rd50;
ld.param.u64 %rd52, [%rd51];
add.s64 %rd53, %rd5, %rd50;
st.local.u64 [%rd53], %rd52;
add.s32 %r34, %r34, 1;
setp.lt.u32	%p6, %r34, 52;
@%p6 bra BB24_5;

BB24_6:
mov.u32 %r17, %ntid.x;
mov.u32 %r18, %ctaid.x;
mov.u32 %r19, %tid.x;
mad.lo.s32 %r20, %r17, %r18, %r19;
cvt.u64.u32	%rd100, %r20;
setp.ge.u64	%p7, %rd100, %rd38;
@%p7 bra BB24_22;

ld.local.u32 %r7, [%rd5+408];

BB24_8:
mov.u64 %rd96, %rd100;
mov.u64 %rd13, %rd96;
mul.wide.s32 %rd95, %r7, 8;
add.s32 %r21, %r7, -1;
sub.s32 %r35, %r21, %r13;
mov.u64 %rd112, 0;
mov.u64 %rd108, %rd112;
mov.u64 %rd103, %rd112;
mov.u64 %rd113, %rd112;
mov.u64 %rd109, %rd112;
mov.u64 %rd104, %rd112;
setp.lt.s32	%p8, %r7, 1;
mov.u32 %r36, %r7;
mov.u64 %rd98, %rd13;
@%p8 bra BB24_18;

BB24_9:
mov.u64 %rd110, %rd109;
mov.u64 %rd16, %rd98;
mov.u32 %r10, %r36;
add.s32 %r11, %r10, -1;
add.s64 %rd20, %rd5, %rd95;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd60, %rd16, %rd21;
and.b64 %rd61, %rd60, -4294967296;
setp.eq.s64	%p9, %rd61, 0;
@%p9 bra BB24_11;
bra.uni BB24_10;

BB24_11:
cvt.u32.u64	%r22, %rd21;
cvt.u32.u64	%r23, %rd16;
rem.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd101, %r24;
bra.uni BB24_12;

BB24_10:
rem.u64 %rd101, %rd16, %rd21;

BB24_12:
add.s64 %rd62, %rd3, %rd95;
ld.local.u64 %rd63, [%rd20+200];
mul.lo.s64 %rd64, %rd63, %rd101;
add.s64 %rd104, %rd64, %rd104;
ld.local.u64 %rd65, [%rd62+200];
mul.lo.s64 %rd66, %rd65, %rd101;
add.s64 %rd113, %rd66, %rd113;
setp.eq.s32	%p10, %r35, 0;
@%p10 bra BB24_14;

add.s64 %rd67, %rd4, %rd95;
ld.local.u64 %rd68, [%rd67+200];
mul.lo.s64 %rd69, %rd68, %rd101;
add.s64 %rd110, %rd69, %rd110;

BB24_14:
mov.u64 %rd109, %rd110;
@%p9 bra BB24_16;
bra.uni BB24_15;

BB24_16:
cvt.u32.u64	%r25, %rd21;
cvt.u32.u64	%r26, %rd16;
div.u32 %r27, %r26, %r25;
cvt.u64.u32	%rd99, %r27;
bra.uni BB24_17;

BB24_15:
div.u64 %rd99, %rd16, %rd21;

BB24_17:
mov.u64 %rd31, %rd99;
add.s32 %r35, %r35, -1;
add.s64 %rd95, %rd95, -8;
setp.gt.s32	%p12, %r11, 0;
mov.u32 %r36, %r11;
mov.u64 %rd98, %rd31;
mov.u64 %rd103, %rd104;
mov.u64 %rd108, %rd109;
mov.u64 %rd112, %rd113;
@%p12 bra BB24_9;

BB24_18:
ld.local.u64 %rd72, [%rd5];
shl.b64 %rd73, %rd103, 3;
add.s64 %rd74, %rd72, %rd73;
ld.u64 %rd36, [%rd74];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB24_20;

mul.wide.s32 %rd75, %r13, 8;
add.s64 %rd76, %rd4, %rd75;
ld.local.u64 %rd77, [%rd76+8];
setp.lt.u64	%p14, %rd36, %rd77;
@%p14 bra BB24_21;

BB24_20:
mov.u64 %rd78, $str;
cvta.global.u64 %rd79, %rd78;
mov.u64 %rd80, $str1;
cvta.global.u64 %rd81, %rd80;
mov.u64 %rd82, __T238;
cvta.global.u64 %rd83, %rd82;
mov.u32 %r28, 97;
mov.u64 %rd84, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd79;
.param .b64 param1;
st.param.b64	[param1+0], %rd81;
.param .b32 param2;
st.param.b32	[param2+0], %r28;
.param .b64 param3;
st.param.b64	[param3+0], %rd83;
.param .b64 param4;
st.param.b64	[param4+0], %rd84;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB24_21:
mul.wide.s32 %rd85, %r13, 8;
add.s64 %rd86, %rd4, %rd85;
ld.local.u64 %rd87, [%rd86+208];
mul.lo.s64 %rd88, %rd87, %rd36;
add.s64 %rd89, %rd88, %rd108;
ld.local.u64 %rd90, [%rd4];
add.s64 %rd91, %rd90, %rd89;
ld.u8 %rs1, [%rd91];
ld.local.u64 %rd92, [%rd3];
add.s64 %rd93, %rd92, %rd112;
st.u8 [%rd93], %rs1;
mov.u32 %r30, %nctaid.x;
mul.lo.s32 %r31, %r30, %r17;
cvt.u64.u32	%rd94, %r31;
add.s64 %rd100, %rd94, %rd13;
setp.lt.u64	%p15, %rd100, %rd38;
@%p15 bra BB24_8;

BB24_22:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot25[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .b32 %r<25>;
.reg .b64 %rd<43>;


mov.u64 %rd42, __local_depot25;
cvta.local.u64 %SP, %rd42;
ld.param.u32 %r10, [_Z26THCudaTensor_scatterKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r11, [_Z26THCudaTensor_scatterKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd3, %rd11;
mov.u32 %r23, 0;
mov.pred %p1, 0;
@%p1 bra BB25_2;

BB25_1:
mul.wide.s32 %rd12, %r23, 8;
add.s64 %rd13, %rd4, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd3, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r23, %r23, 1;
setp.lt.u32	%p2, %r23, 27;
@%p2 bra BB25_1;

BB25_2:
mov.u32 %r13, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r24, %r13, %r14, %r15;
setp.ge.u32	%p3, %r24, %r11;
@%p3 bra BB25_10;

ld.param.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd6, %rd16;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd17, [%rd2];
cvta.to.global.u64 %rd7, %rd17;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB25_4:
rem.u32 %r8, %r24, %r5;
setp.eq.s32	%p4, %r10, 0;
mov.u64 %rd41, 0;
@%p4 bra BB25_6;

ld.local.u32 %r16, [%rd3+108];
mul.lo.s32 %r17, %r16, %r8;
cvt.u64.u32	%rd41, %r17;

BB25_6:
mul.lo.s32 %r18, %r6, %r8;
mul.wide.u32 %rd19, %r18, 8;
add.s64 %rd20, %rd7, %rd19;
ld.global.u64 %rd10, [%rd20];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB25_8;

mul.wide.s32 %rd21, %r10, 4;
add.s64 %rd22, %rd3, %rd21;
ld.local.u32 %rd23, [%rd22+8];
setp.lt.s64	%p6, %rd10, %rd23;
@%p6 bra BB25_9;

BB25_8:
mov.u64 %rd24, $str2;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, $str1;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, __T239;
cvta.global.u64 %rd29, %rd28;
mov.u32 %r19, 124;
mov.u64 %rd30, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd25;
.param .b64 param1;
st.param.b64	[param1+0], %rd27;
.param .b32 param2;
st.param.b32	[param2+0], %r19;
.param .b64 param3;
st.param.b64	[param3+0], %rd29;
.param .b64 param4;
st.param.b64	[param4+0], %rd30;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB25_9:
mul.lo.s32 %r20, %r4, %r8;
mul.wide.s32 %rd31, %r10, 4;
add.s64 %rd32, %rd3, %rd31;
ld.local.u32 %rd33, [%rd32+108];
mul.lo.s64 %rd34, %rd33, %rd10;
add.s64 %rd35, %rd34, %rd41;
cvt.u64.u32	%rd36, %r20;
add.s64 %rd37, %rd6, %rd36;
ld.global.u8 %rs1, [%rd37];
and.b64 %rd38, %rd35, 4294967295;
ld.local.u64 %rd39, [%rd3];
add.s64 %rd40, %rd39, %rd38;
st.u8 [%rd40], %rs1;
mov.u32 %r22, %nctaid.x;
mad.lo.s32 %r24, %r22, %r13, %r24;
setp.lt.u32	%p7, %r24, %r11;
@%p7 bra BB25_4;

BB25_10:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot26[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b16 %rs<2>;
.reg .b32 %r<40>;
.reg .b64 %rd<40>;


mov.u64 %rd39, __local_depot26;
cvta.local.u64 %SP, %rd39;
ld.param.u32 %r19, [_Z26THCudaTensor_scatterKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r20, [_Z26THCudaTensor_scatterKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r37, 0;
mov.pred %p1, 0;
@%p1 bra BB26_2;

BB26_1:
mul.wide.s32 %rd10, %r37, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r37, %r37, 1;
setp.lt.u32	%p2, %r37, 27;
@%p2 bra BB26_1;

BB26_2:
mov.u32 %r22, %ntid.x;
mov.u32 %r23, %ctaid.x;
mov.u32 %r24, %tid.x;
mad.lo.s32 %r38, %r22, %r23, %r24;
setp.ge.u32	%p3, %r38, %r20;
@%p3 bra BB26_12;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r25, %r26}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB26_4:
rem.u32 %r11, %r38, %r26;
setp.eq.s32	%p4, %r19, 1;
mov.u32 %r39, 0;
@%p4 bra BB26_6;

ld.local.u32 %r28, [%rd3+112];
mul.lo.s32 %r39, %r28, %r11;

BB26_6:
div.u32 %r29, %r38, %r26;
rem.u32 %r14, %r29, %r25;
setp.eq.s32	%p5, %r19, 0;
@%p5 bra BB26_8;

ld.local.u32 %r30, [%rd3+108];
mad.lo.s32 %r39, %r30, %r14, %r39;

BB26_8:
mul.lo.s32 %r31, %r9, %r11;
mul.lo.s32 %r32, %r5, %r11;
mad.lo.s32 %r33, %r8, %r14, %r31;
mad.lo.s32 %r17, %r4, %r14, %r32;
mul.wide.u32 %rd16, %r33, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB26_10;

mul.wide.s32 %rd18, %r19, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p7, %rd8, %rd20;
@%p7 bra BB26_11;

BB26_10:
mov.u64 %rd21, $str2;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T240;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r34, 124;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r34;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB26_11:
mul.wide.s32 %rd28, %r19, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r39;
add.s64 %rd33, %rd31, %rd32;
cvt.u64.u32	%rd34, %r17;
add.s64 %rd35, %rd6, %rd34;
ld.global.u8 %rs1, [%rd35];
and.b64 %rd36, %rd33, 4294967295;
ld.local.u64 %rd37, [%rd3];
add.s64 %rd38, %rd37, %rd36;
st.u8 [%rd38], %rs1;
mov.u32 %r36, %nctaid.x;
mad.lo.s32 %r38, %r36, %r22, %r38;
setp.lt.u32	%p8, %r38, %r20;
@%p8 bra BB26_4;

BB26_12:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot27[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b16 %rs<2>;
.reg .b32 %r<54>;
.reg .b64 %rd<40>;


mov.u64 %rd39, __local_depot27;
cvta.local.u64 %SP, %rd39;
ld.param.u32 %r26, [_Z26THCudaTensor_scatterKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r27, [_Z26THCudaTensor_scatterKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r51, 0;
mov.pred %p1, 0;
@%p1 bra BB27_2;

BB27_1:
mul.wide.s32 %rd10, %r51, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p2, %r51, 27;
@%p2 bra BB27_1;

BB27_2:
mov.u32 %r29, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r52, %r29, %r30, %r31;
setp.ge.u32	%p3, %r52, %r27;
@%p3 bra BB27_14;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r32, %r33}, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r34, %r35}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r36, %r37}, [%rd2+112];

BB27_4:
rem.u32 %r14, %r52, %r9;
setp.eq.s32	%p4, %r26, 2;
mov.u32 %r53, 0;
@%p4 bra BB27_6;

ld.local.u32 %r39, [%rd3+116];
mul.lo.s32 %r53, %r39, %r14;

BB27_6:
div.u32 %r17, %r52, %r9;
rem.u32 %r18, %r17, %r35;
setp.eq.s32	%p5, %r26, 1;
@%p5 bra BB27_8;

ld.local.u32 %r40, [%rd3+112];
mad.lo.s32 %r53, %r40, %r18, %r53;

BB27_8:
div.u32 %r41, %r17, %r35;
rem.u32 %r21, %r41, %r34;
setp.eq.s32	%p6, %r26, 0;
@%p6 bra BB27_10;

ld.local.u32 %r42, [%rd3+108];
mad.lo.s32 %r53, %r42, %r21, %r53;

BB27_10:
mul.lo.s32 %r43, %r37, %r14;
mul.lo.s32 %r44, %r33, %r14;
mad.lo.s32 %r45, %r36, %r18, %r43;
mad.lo.s32 %r46, %r32, %r18, %r44;
mad.lo.s32 %r47, %r10, %r21, %r45;
mad.lo.s32 %r24, %r4, %r21, %r46;
mul.wide.u32 %rd16, %r47, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB27_12;

mul.wide.s32 %rd18, %r26, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p8, %rd8, %rd20;
@%p8 bra BB27_13;

BB27_12:
mov.u64 %rd21, $str2;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T241;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r48, 124;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r48;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB27_13:
mul.wide.s32 %rd28, %r26, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r53;
add.s64 %rd33, %rd31, %rd32;
cvt.u64.u32	%rd34, %r24;
add.s64 %rd35, %rd6, %rd34;
ld.global.u8 %rs1, [%rd35];
and.b64 %rd36, %rd33, 4294967295;
ld.local.u64 %rd37, [%rd3];
add.s64 %rd38, %rd37, %rd36;
st.u8 [%rd38], %rs1;
mov.u32 %r50, %nctaid.x;
mad.lo.s32 %r52, %r50, %r29, %r52;
setp.lt.u32	%p9, %r52, %r27;
@%p9 bra BB27_4;

BB27_14:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot28[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .b32 %r<63>;
.reg .b64 %rd<68>;


mov.u64 %rd67, __local_depot28;
cvta.local.u64 %SP, %rd67;
ld.param.u32 %r28, [_Z26THCudaTensor_scatterKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r29, [_Z26THCudaTensor_scatterKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z26THCudaTensor_scatterKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd20, %SP, 216;
cvta.to.local.u64 %rd3, %rd20;
add.u64 %rd21, %SP, 432;
cvta.to.local.u64 %rd4, %rd21;
add.u64 %rd22, %SP, 0;
cvta.to.local.u64 %rd5, %rd22;
mov.u32 %r47, 0;
mov.pred %p1, 0;
@%p1 bra BB28_2;

BB28_1:
mul.wide.s32 %rd23, %r47, 8;
add.s64 %rd24, %rd6, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r47, %r47, 1;
setp.lt.u32	%p2, %r47, 27;
@%p2 bra BB28_1;

BB28_2:
mov.u32 %r48, 0;
@%p1 bra BB28_4;

BB28_3:
mul.wide.s32 %rd27, %r48, 8;
add.s64 %rd28, %rd1, %rd27;
ld.param.u64 %rd29, [%rd28];
add.s64 %rd30, %rd4, %rd27;
st.local.u64 [%rd30], %rd29;
add.s32 %r48, %r48, 1;
setp.lt.u32	%p4, %r48, 27;
@%p4 bra BB28_3;

BB28_4:
mov.u32 %r49, 0;
@%p1 bra BB28_6;

BB28_5:
mul.wide.s32 %rd31, %r49, 8;
add.s64 %rd32, %rd2, %rd31;
ld.param.u64 %rd33, [%rd32];
add.s64 %rd34, %rd5, %rd31;
st.local.u64 [%rd34], %rd33;
add.s32 %r49, %r49, 1;
setp.lt.u32	%p6, %r49, 27;
@%p6 bra BB28_5;

BB28_6:
mov.u32 %r33, %ntid.x;
mov.u32 %r34, %ctaid.x;
mov.u32 %r35, %tid.x;
mad.lo.s32 %r54, %r33, %r34, %r35;
setp.ge.u32	%p7, %r54, %r29;
@%p7 bra BB28_17;

ld.local.u32 %r8, [%rd5+208];

BB28_8:
mov.u32 %r52, %r54;
mov.u32 %r9, %r52;
mul.wide.s32 %rd64, %r8, 4;
add.s32 %r40, %r8, -1;
sub.s32 %r50, %r40, %r28;
mov.u32 %r60, 0;
mov.u64 %rd66, 0;
mov.u64 %rd65, %rd66;
mov.u32 %r61, %r60;
mov.u32 %r56, %r60;
mov.u32 %r55, %r60;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r51, %r8;
mov.u32 %r53, %r9;
@%p8 bra BB28_13;

BB28_9:
mov.u32 %r57, %r61;
mov.u32 %r62, %r57;
mov.u32 %r13, %r53;
mov.u32 %r12, %r51;
add.s64 %rd37, %rd4, %rd64;
add.s32 %r17, %r12, -1;
add.s64 %rd38, %rd5, %rd64;
ld.local.u32 %r18, [%rd38+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r41, [%rd38+104];
mad.lo.s32 %r55, %r41, %r19, %r55;
ld.local.u32 %r42, [%rd37+104];
mad.lo.s32 %r56, %r42, %r19, %r56;
setp.eq.s32	%p9, %r50, 0;
@%p9 bra BB28_11;

add.s64 %rd39, %rd3, %rd64;
ld.local.u32 %r43, [%rd39+104];
mad.lo.s32 %r62, %r43, %r19, %r62;

BB28_11:
mov.u32 %r61, %r62;
div.u32 %r24, %r13, %r18;
add.s32 %r50, %r50, -1;
add.s64 %rd64, %rd64, -4;
setp.gt.s32	%p10, %r17, 0;
mov.u32 %r51, %r17;
mov.u32 %r53, %r24;
@%p10 bra BB28_9;

cvt.u64.u32	%rd65, %r55;
cvt.u64.u32	%rd66, %r56;
mov.u32 %r60, %r61;

BB28_13:
ld.local.u64 %rd40, [%rd5];
shl.b64 %rd41, %rd65, 3;
add.s64 %rd42, %rd40, %rd41;
ld.u64 %rd19, [%rd42];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB28_15;

mul.wide.s32 %rd43, %r28, 4;
add.s64 %rd44, %rd3, %rd43;
ld.local.u32 %rd45, [%rd44+8];
setp.lt.s64	%p12, %rd19, %rd45;
@%p12 bra BB28_16;

BB28_15:
mov.u64 %rd46, $str2;
cvta.global.u64 %rd47, %rd46;
mov.u64 %rd48, $str1;
cvta.global.u64 %rd49, %rd48;
mov.u64 %rd50, __T242;
cvta.global.u64 %rd51, %rd50;
mov.u32 %r44, 124;
mov.u64 %rd52, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd47;
.param .b64 param1;
st.param.b64	[param1+0], %rd49;
.param .b32 param2;
st.param.b32	[param2+0], %r44;
.param .b64 param3;
st.param.b64	[param3+0], %rd51;
.param .b64 param4;
st.param.b64	[param4+0], %rd52;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB28_16:
mul.wide.s32 %rd53, %r28, 4;
add.s64 %rd54, %rd3, %rd53;
ld.local.u32 %rd55, [%rd54+108];
mul.lo.s64 %rd56, %rd55, %rd19;
cvt.u64.u32	%rd57, %r60;
add.s64 %rd58, %rd56, %rd57;
ld.local.u64 %rd59, [%rd4];
add.s64 %rd60, %rd59, %rd66;
ld.u8 %rs1, [%rd60];
and.b64 %rd61, %rd58, 4294967295;
ld.local.u64 %rd62, [%rd3];
add.s64 %rd63, %rd62, %rd61;
st.u8 [%rd63], %rs1;
mov.u32 %r46, %nctaid.x;
mad.lo.s32 %r54, %r46, %r33, %r9;
setp.lt.u32	%p13, %r54, %r29;
@%p13 bra BB28_8;

BB28_17:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[416],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[416],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[416],
.param .u32 _Z26THCudaTensor_scatterKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u64 _Z26THCudaTensor_scatterKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot29[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<16>;
.reg .b16 %rs<2>;
.reg .b32 %r<37>;
.reg .b64 %rd<115>;


mov.u64 %rd114, __local_depot29;
cvta.local.u64 %SP, %rd114;
ld.param.u32 %r13, [_Z26THCudaTensor_scatterKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u64 %rd38, [_Z26THCudaTensor_scatterKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z26THCudaTensor_scatterKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd39, %SP, 416;
cvta.to.local.u64 %rd3, %rd39;
add.u64 %rd40, %SP, 832;
cvta.to.local.u64 %rd4, %rd40;
add.u64 %rd41, %SP, 0;
cvta.to.local.u64 %rd5, %rd41;
mov.u32 %r32, 0;
mov.pred %p1, 0;
@%p1 bra BB29_2;

BB29_1:
mul.wide.s32 %rd42, %r32, 8;
add.s64 %rd43, %rd6, %rd42;
ld.param.u64 %rd44, [%rd43];
add.s64 %rd45, %rd3, %rd42;
st.local.u64 [%rd45], %rd44;
add.s32 %r32, %r32, 1;
setp.lt.u32	%p2, %r32, 52;
@%p2 bra BB29_1;

BB29_2:
mov.u32 %r33, 0;
@%p1 bra BB29_4;

BB29_3:
mul.wide.s32 %rd46, %r33, 8;
add.s64 %rd47, %rd1, %rd46;
ld.param.u64 %rd48, [%rd47];
add.s64 %rd49, %rd4, %rd46;
st.local.u64 [%rd49], %rd48;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p4, %r33, 52;
@%p4 bra BB29_3;

BB29_4:
mov.u32 %r34, 0;
@%p1 bra BB29_6;

BB29_5:
mul.wide.s32 %rd50, %r34, 8;
add.s64 %rd51, %rd2, %rd50;
ld.param.u64 %rd52, [%rd51];
add.s64 %rd53, %rd5, %rd50;
st.local.u64 [%rd53], %rd52;
add.s32 %r34, %r34, 1;
setp.lt.u32	%p6, %r34, 52;
@%p6 bra BB29_5;

BB29_6:
mov.u32 %r17, %ntid.x;
mov.u32 %r18, %ctaid.x;
mov.u32 %r19, %tid.x;
mad.lo.s32 %r20, %r17, %r18, %r19;
cvt.u64.u32	%rd100, %r20;
setp.ge.u64	%p7, %rd100, %rd38;
@%p7 bra BB29_22;

ld.local.u32 %r7, [%rd5+408];

BB29_8:
mov.u64 %rd96, %rd100;
mov.u64 %rd13, %rd96;
mul.wide.s32 %rd95, %r7, 8;
add.s32 %r21, %r7, -1;
sub.s32 %r35, %r21, %r13;
mov.u64 %rd111, 0;
mov.u64 %rd106, %rd111;
mov.u64 %rd103, %rd111;
mov.u64 %rd112, %rd111;
mov.u64 %rd107, %rd111;
mov.u64 %rd104, %rd111;
setp.lt.s32	%p8, %r7, 1;
mov.u32 %r36, %r7;
mov.u64 %rd98, %rd13;
@%p8 bra BB29_18;

BB29_9:
mov.u64 %rd113, %rd112;
mov.u64 %rd16, %rd98;
mov.u32 %r10, %r36;
add.s32 %r11, %r10, -1;
add.s64 %rd20, %rd5, %rd95;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd60, %rd16, %rd21;
and.b64 %rd61, %rd60, -4294967296;
setp.eq.s64	%p9, %rd61, 0;
@%p9 bra BB29_11;
bra.uni BB29_10;

BB29_11:
cvt.u32.u64	%r22, %rd21;
cvt.u32.u64	%r23, %rd16;
rem.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd101, %r24;
bra.uni BB29_12;

BB29_10:
rem.u64 %rd101, %rd16, %rd21;

BB29_12:
add.s64 %rd62, %rd4, %rd95;
ld.local.u64 %rd63, [%rd20+200];
mul.lo.s64 %rd64, %rd63, %rd101;
add.s64 %rd104, %rd64, %rd104;
ld.local.u64 %rd65, [%rd62+200];
mul.lo.s64 %rd66, %rd65, %rd101;
add.s64 %rd107, %rd66, %rd107;
setp.eq.s32	%p10, %r35, 0;
@%p10 bra BB29_14;

add.s64 %rd67, %rd3, %rd95;
ld.local.u64 %rd68, [%rd67+200];
mul.lo.s64 %rd69, %rd68, %rd101;
add.s64 %rd113, %rd69, %rd113;

BB29_14:
mov.u64 %rd112, %rd113;
@%p9 bra BB29_16;
bra.uni BB29_15;

BB29_16:
cvt.u32.u64	%r25, %rd21;
cvt.u32.u64	%r26, %rd16;
div.u32 %r27, %r26, %r25;
cvt.u64.u32	%rd99, %r27;
bra.uni BB29_17;

BB29_15:
div.u64 %rd99, %rd16, %rd21;

BB29_17:
mov.u64 %rd31, %rd99;
add.s32 %r35, %r35, -1;
add.s64 %rd95, %rd95, -8;
setp.gt.s32	%p12, %r11, 0;
mov.u32 %r36, %r11;
mov.u64 %rd98, %rd31;
mov.u64 %rd103, %rd104;
mov.u64 %rd106, %rd107;
mov.u64 %rd111, %rd112;
@%p12 bra BB29_9;

BB29_18:
ld.local.u64 %rd72, [%rd5];
shl.b64 %rd73, %rd103, 3;
add.s64 %rd74, %rd72, %rd73;
ld.u64 %rd36, [%rd74];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB29_20;

mul.wide.s32 %rd75, %r13, 8;
add.s64 %rd76, %rd3, %rd75;
ld.local.u64 %rd77, [%rd76+8];
setp.lt.u64	%p14, %rd36, %rd77;
@%p14 bra BB29_21;

BB29_20:
mov.u64 %rd78, $str2;
cvta.global.u64 %rd79, %rd78;
mov.u64 %rd80, $str1;
cvta.global.u64 %rd81, %rd80;
mov.u64 %rd82, __T243;
cvta.global.u64 %rd83, %rd82;
mov.u32 %r28, 124;
mov.u64 %rd84, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd79;
.param .b64 param1;
st.param.b64	[param1+0], %rd81;
.param .b32 param2;
st.param.b32	[param2+0], %r28;
.param .b64 param3;
st.param.b64	[param3+0], %rd83;
.param .b64 param4;
st.param.b64	[param4+0], %rd84;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB29_21:
mul.wide.s32 %rd85, %r13, 8;
add.s64 %rd86, %rd3, %rd85;
ld.local.u64 %rd87, [%rd86+208];
mul.lo.s64 %rd88, %rd87, %rd36;
add.s64 %rd89, %rd88, %rd111;
ld.local.u64 %rd90, [%rd4];
add.s64 %rd91, %rd90, %rd106;
ld.u8 %rs1, [%rd91];
ld.local.u64 %rd92, [%rd3];
add.s64 %rd93, %rd92, %rd89;
st.u8 [%rd93], %rs1;
mov.u32 %r30, %nctaid.x;
mul.lo.s32 %r31, %r30, %r17;
cvt.u64.u32	%rd94, %r31;
add.s64 %rd100, %rd94, %rd13;
setp.lt.u64	%p15, %rd100, %rd38;
@%p15 bra BB29_8;

BB29_22:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot30[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b32 %r<40>;
.reg .b64 %rd<47>;


mov.u64 %rd46, __local_depot30;
cvta.local.u64 %SP, %rd46;
ld.param.u32 %r15, [_Z29THCudaTensor_scatterAddKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r16, [_Z29THCudaTensor_scatterAddKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjaLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd12, %SP, 0;
cvta.to.local.u64 %rd3, %rd12;
mov.u32 %r37, 0;
mov.pred %p1, 0;
@%p1 bra BB30_2;

BB30_1:
mul.wide.s32 %rd13, %r37, 8;
add.s64 %rd14, %rd4, %rd13;
ld.param.u64 %rd15, [%rd14];
add.s64 %rd16, %rd3, %rd13;
st.local.u64 [%rd16], %rd15;
add.s32 %r37, %r37, 1;
setp.lt.u32	%p2, %r37, 27;
@%p2 bra BB30_1;

BB30_2:
mov.u32 %r18, %ntid.x;
mov.u32 %r19, %ctaid.x;
mov.u32 %r20, %tid.x;
mad.lo.s32 %r38, %r18, %r19, %r20;
setp.ge.u32	%p3, %r38, %r16;
@%p3 bra BB30_12;

ld.param.u64 %rd17, [%rd1];
cvta.to.global.u64 %rd6, %rd17;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd18, [%rd2];
cvta.to.global.u64 %rd7, %rd18;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB30_4:
rem.u32 %r8, %r38, %r5;
setp.eq.s32	%p4, %r15, 0;
mov.u64 %rd45, 0;
@%p4 bra BB30_6;

ld.local.u32 %r21, [%rd3+108];
mul.lo.s32 %r22, %r21, %r8;
cvt.u64.u32	%rd45, %r22;

BB30_6:
mul.lo.s32 %r23, %r6, %r8;
mul.wide.u32 %rd20, %r23, 8;
add.s64 %rd21, %rd7, %rd20;
ld.global.u64 %rd10, [%rd21];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB30_8;

mul.wide.s32 %rd22, %r15, 4;
add.s64 %rd23, %rd3, %rd22;
ld.local.u32 %rd24, [%rd23+8];
setp.lt.s64	%p6, %rd10, %rd24;
@%p6 bra BB30_9;

BB30_8:
mov.u64 %rd25, $str2;
cvta.global.u64 %rd26, %rd25;
mov.u64 %rd27, $str1;
cvta.global.u64 %rd28, %rd27;
mov.u64 %rd29, __T244;
cvta.global.u64 %rd30, %rd29;
mov.u32 %r24, 151;
mov.u64 %rd31, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd26;
.param .b64 param1;
st.param.b64	[param1+0], %rd28;
.param .b32 param2;
st.param.b32	[param2+0], %r24;
.param .b64 param3;
st.param.b64	[param3+0], %rd30;
.param .b64 param4;
st.param.b64	[param4+0], %rd31;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB30_9:
mul.lo.s32 %r25, %r4, %r8;
mul.wide.s32 %rd32, %r15, 4;
add.s64 %rd33, %rd3, %rd32;
ld.local.u32 %rd34, [%rd33+108];
mul.lo.s64 %rd35, %rd34, %rd10;
add.s64 %rd36, %rd35, %rd45;
and.b64 %rd37, %rd36, 4294967295;
ld.local.u64 %rd38, [%rd3];
add.s64 %rd39, %rd38, %rd37;
cvt.u64.u32	%rd40, %r25;
add.s64 %rd41, %rd6, %rd40;
and.b64 %rd42, %rd39, 3;
sub.s64 %rd43, %rd37, %rd42;
add.s64 %rd11, %rd38, %rd43;
ld.u32 %r39, [%rd11];
shl.b64 %rd44, %rd42, 3;
cvt.u32.u64	%r10, %rd44;
ld.global.s8 %r11, [%rd41];

BB30_10:
mov.u32 %r12, %r39;
shr.u32 %r26, %r12, %r10;
cvt.s32.s8 %r27, %r26;
add.s32 %r28, %r27, %r11;
mov.u32 %r29, 255;
shl.b32 %r30, %r29, %r10;
not.b32 %r31, %r30;
and.b32 %r32, %r12, %r31;
shl.b32 %r33, %r28, %r10;
or.b32 %r34, %r33, %r32;
atom.cas.b32 %r39, [%rd11], %r12, %r34;
setp.ne.s32	%p7, %r12, %r39;
@%p7 bra BB30_10;

mov.u32 %r36, %nctaid.x;
mad.lo.s32 %r38, %r36, %r18, %r38;
setp.lt.u32	%p8, %r38, %r16;
@%p8 bra BB30_4;

BB30_12:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot31[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b32 %r<55>;
.reg .b64 %rd<44>;


mov.u64 %rd43, __local_depot31;
cvta.local.u64 %SP, %rd43;
ld.param.u32 %r24, [_Z29THCudaTensor_scatterAddKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r25, [_Z29THCudaTensor_scatterAddKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjaLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd3, %rd10;
mov.u32 %r51, 0;
mov.pred %p1, 0;
@%p1 bra BB31_2;

BB31_1:
mul.wide.s32 %rd11, %r51, 8;
add.s64 %rd12, %rd4, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd3, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p2, %r51, 27;
@%p2 bra BB31_1;

BB31_2:
mov.u32 %r27, %ntid.x;
mov.u32 %r28, %ctaid.x;
mov.u32 %r29, %tid.x;
mad.lo.s32 %r52, %r27, %r28, %r29;
setp.ge.u32	%p3, %r52, %r25;
@%p3 bra BB31_14;

ld.param.u64 %rd15, [%rd1];
cvta.to.global.u64 %rd6, %rd15;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd16, [%rd2];
cvta.to.global.u64 %rd7, %rd16;
ld.param.v2.u32 {%r30, %r31}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB31_4:
rem.u32 %r11, %r52, %r31;
setp.eq.s32	%p4, %r24, 1;
mov.u32 %r53, 0;
@%p4 bra BB31_6;

ld.local.u32 %r33, [%rd3+112];
mul.lo.s32 %r53, %r33, %r11;

BB31_6:
div.u32 %r34, %r52, %r31;
rem.u32 %r14, %r34, %r30;
setp.eq.s32	%p5, %r24, 0;
@%p5 bra BB31_8;

ld.local.u32 %r35, [%rd3+108];
mad.lo.s32 %r53, %r35, %r14, %r53;

BB31_8:
mul.lo.s32 %r36, %r9, %r11;
mul.lo.s32 %r37, %r5, %r11;
mad.lo.s32 %r38, %r8, %r14, %r36;
mad.lo.s32 %r17, %r4, %r14, %r37;
mul.wide.u32 %rd17, %r38, 8;
add.s64 %rd18, %rd7, %rd17;
ld.global.u64 %rd8, [%rd18];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB31_10;

mul.wide.s32 %rd19, %r24, 4;
add.s64 %rd20, %rd3, %rd19;
ld.local.u32 %rd21, [%rd20+8];
setp.lt.s64	%p7, %rd8, %rd21;
@%p7 bra BB31_11;

BB31_10:
mov.u64 %rd22, $str2;
cvta.global.u64 %rd23, %rd22;
mov.u64 %rd24, $str1;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, __T245;
cvta.global.u64 %rd27, %rd26;
mov.u32 %r39, 151;
mov.u64 %rd28, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd23;
.param .b64 param1;
st.param.b64	[param1+0], %rd25;
.param .b32 param2;
st.param.b32	[param2+0], %r39;
.param .b64 param3;
st.param.b64	[param3+0], %rd27;
.param .b64 param4;
st.param.b64	[param4+0], %rd28;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB31_11:
mul.wide.s32 %rd29, %r24, 4;
add.s64 %rd30, %rd3, %rd29;
ld.local.u32 %rd31, [%rd30+108];
mul.lo.s64 %rd32, %rd31, %rd8;
cvt.u64.u32	%rd33, %r53;
add.s64 %rd34, %rd32, %rd33;
and.b64 %rd35, %rd34, 4294967295;
ld.local.u64 %rd36, [%rd3];
add.s64 %rd37, %rd36, %rd35;
cvt.u64.u32	%rd38, %r17;
add.s64 %rd39, %rd6, %rd38;
and.b64 %rd40, %rd37, 3;
sub.s64 %rd41, %rd35, %rd40;
add.s64 %rd9, %rd36, %rd41;
ld.u32 %r54, [%rd9];
shl.b64 %rd42, %rd40, 3;
cvt.u32.u64	%r19, %rd42;
ld.global.s8 %r20, [%rd39];

BB31_12:
mov.u32 %r21, %r54;
shr.u32 %r40, %r21, %r19;
cvt.s32.s8 %r41, %r40;
add.s32 %r42, %r41, %r20;
mov.u32 %r43, 255;
shl.b32 %r44, %r43, %r19;
not.b32 %r45, %r44;
and.b32 %r46, %r21, %r45;
shl.b32 %r47, %r42, %r19;
or.b32 %r48, %r47, %r46;
atom.cas.b32 %r54, [%rd9], %r21, %r48;
setp.ne.s32	%p8, %r21, %r54;
@%p8 bra BB31_12;

mov.u32 %r50, %nctaid.x;
mad.lo.s32 %r52, %r50, %r27, %r52;
setp.lt.u32	%p9, %r52, %r25;
@%p9 bra BB31_4;

BB31_14:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot32[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<11>;
.reg .b32 %r<69>;
.reg .b64 %rd<44>;


mov.u64 %rd43, __local_depot32;
cvta.local.u64 %SP, %rd43;
ld.param.u32 %r32, [_Z29THCudaTensor_scatterAddKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r33, [_Z29THCudaTensor_scatterAddKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjaLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd3, %rd10;
mov.u32 %r65, 0;
mov.pred %p1, 0;
@%p1 bra BB32_2;

BB32_1:
mul.wide.s32 %rd11, %r65, 8;
add.s64 %rd12, %rd4, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd3, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r65, %r65, 1;
setp.lt.u32	%p2, %r65, 27;
@%p2 bra BB32_1;

BB32_2:
mov.u32 %r35, %ntid.x;
mov.u32 %r36, %ctaid.x;
mov.u32 %r37, %tid.x;
mad.lo.s32 %r66, %r35, %r36, %r37;
setp.ge.u32	%p3, %r66, %r33;
@%p3 bra BB32_16;

ld.param.u64 %rd15, [%rd1];
cvta.to.global.u64 %rd6, %rd15;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r38, %r39}, [%rd1+112];
ld.param.u64 %rd16, [%rd2];
cvta.to.global.u64 %rd7, %rd16;
ld.param.v2.u32 {%r40, %r41}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r42, %r43}, [%rd2+112];

BB32_4:
rem.u32 %r14, %r66, %r9;
setp.eq.s32	%p4, %r32, 2;
mov.u32 %r67, 0;
@%p4 bra BB32_6;

ld.local.u32 %r45, [%rd3+116];
mul.lo.s32 %r67, %r45, %r14;

BB32_6:
div.u32 %r17, %r66, %r9;
rem.u32 %r18, %r17, %r41;
setp.eq.s32	%p5, %r32, 1;
@%p5 bra BB32_8;

ld.local.u32 %r46, [%rd3+112];
mad.lo.s32 %r67, %r46, %r18, %r67;

BB32_8:
div.u32 %r47, %r17, %r41;
rem.u32 %r21, %r47, %r40;
setp.eq.s32	%p6, %r32, 0;
@%p6 bra BB32_10;

ld.local.u32 %r48, [%rd3+108];
mad.lo.s32 %r67, %r48, %r21, %r67;

BB32_10:
mul.lo.s32 %r49, %r43, %r14;
mul.lo.s32 %r50, %r39, %r14;
mad.lo.s32 %r51, %r42, %r18, %r49;
mad.lo.s32 %r52, %r38, %r18, %r50;
mad.lo.s32 %r53, %r10, %r21, %r51;
mad.lo.s32 %r24, %r4, %r21, %r52;
mul.wide.u32 %rd17, %r53, 8;
add.s64 %rd18, %rd7, %rd17;
ld.global.u64 %rd8, [%rd18];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB32_12;

mul.wide.s32 %rd19, %r32, 4;
add.s64 %rd20, %rd3, %rd19;
ld.local.u32 %rd21, [%rd20+8];
setp.lt.s64	%p8, %rd8, %rd21;
@%p8 bra BB32_13;

BB32_12:
mov.u64 %rd22, $str2;
cvta.global.u64 %rd23, %rd22;
mov.u64 %rd24, $str1;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, __T246;
cvta.global.u64 %rd27, %rd26;
mov.u32 %r54, 151;
mov.u64 %rd28, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd23;
.param .b64 param1;
st.param.b64	[param1+0], %rd25;
.param .b32 param2;
st.param.b32	[param2+0], %r54;
.param .b64 param3;
st.param.b64	[param3+0], %rd27;
.param .b64 param4;
st.param.b64	[param4+0], %rd28;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB32_13:
mul.wide.s32 %rd29, %r32, 4;
add.s64 %rd30, %rd3, %rd29;
ld.local.u32 %rd31, [%rd30+108];
mul.lo.s64 %rd32, %rd31, %rd8;
cvt.u64.u32	%rd33, %r67;
add.s64 %rd34, %rd32, %rd33;
and.b64 %rd35, %rd34, 4294967295;
ld.local.u64 %rd36, [%rd3];
add.s64 %rd37, %rd36, %rd35;
cvt.u64.u32	%rd38, %r24;
add.s64 %rd39, %rd6, %rd38;
and.b64 %rd40, %rd37, 3;
sub.s64 %rd41, %rd35, %rd40;
add.s64 %rd9, %rd36, %rd41;
ld.u32 %r68, [%rd9];
shl.b64 %rd42, %rd40, 3;
cvt.u32.u64	%r26, %rd42;
ld.global.s8 %r27, [%rd39];
mov.u32 %r55, 255;
shl.b32 %r56, %r55, %r26;
not.b32 %r28, %r56;

BB32_14:
mov.u32 %r29, %r68;
shr.u32 %r57, %r29, %r26;
cvt.s32.s8 %r58, %r57;
add.s32 %r59, %r58, %r27;
shl.b32 %r60, %r59, %r26;
and.b32 %r61, %r29, %r28;
or.b32 %r62, %r60, %r61;
atom.cas.b32 %r68, [%rd9], %r29, %r62;
setp.ne.s32	%p9, %r29, %r68;
@%p9 bra BB32_14;

mov.u32 %r64, %nctaid.x;
mad.lo.s32 %r66, %r64, %r35, %r66;
setp.lt.u32	%p10, %r66, %r33;
@%p10 bra BB32_4;

BB32_16:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot33[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<15>;
.reg .b32 %r<73>;
.reg .b64 %rd<72>;


mov.u64 %rd71, __local_depot33;
cvta.local.u64 %SP, %rd71;
ld.param.u32 %r36, [_Z29THCudaTensor_scatterAddKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r37, [_Z29THCudaTensor_scatterAddKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z29THCudaTensor_scatterAddKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd21, %SP, 216;
cvta.to.local.u64 %rd3, %rd21;
add.u64 %rd22, %SP, 432;
cvta.to.local.u64 %rd4, %rd22;
add.u64 %rd23, %SP, 0;
cvta.to.local.u64 %rd5, %rd23;
mov.u32 %r61, 0;
mov.pred %p1, 0;
@%p1 bra BB33_2;

BB33_1:
mul.wide.s32 %rd24, %r61, 8;
add.s64 %rd25, %rd6, %rd24;
ld.param.u64 %rd26, [%rd25];
add.s64 %rd27, %rd3, %rd24;
st.local.u64 [%rd27], %rd26;
add.s32 %r61, %r61, 1;
setp.lt.u32	%p2, %r61, 27;
@%p2 bra BB33_1;

BB33_2:
mov.u32 %r62, 0;
@%p1 bra BB33_4;

BB33_3:
mul.wide.s32 %rd28, %r62, 8;
add.s64 %rd29, %rd1, %rd28;
ld.param.u64 %rd30, [%rd29];
add.s64 %rd31, %rd4, %rd28;
st.local.u64 [%rd31], %rd30;
add.s32 %r62, %r62, 1;
setp.lt.u32	%p4, %r62, 27;
@%p4 bra BB33_3;

BB33_4:
mov.u32 %r63, 0;
@%p1 bra BB33_6;

BB33_5:
mul.wide.s32 %rd32, %r63, 8;
add.s64 %rd33, %rd2, %rd32;
ld.param.u64 %rd34, [%rd33];
add.s64 %rd35, %rd5, %rd32;
st.local.u64 [%rd35], %rd34;
add.s32 %r63, %r63, 1;
setp.lt.u32	%p6, %r63, 27;
@%p6 bra BB33_5;

BB33_6:
mov.u32 %r41, %ntid.x;
mov.u32 %r42, %ctaid.x;
mov.u32 %r43, %tid.x;
mad.lo.s32 %r68, %r41, %r42, %r43;
setp.ge.u32	%p7, %r68, %r37;
@%p7 bra BB33_19;

BB33_7:
mov.u32 %r66, %r68;
mov.u32 %r8, %r66;
ld.local.u32 %r65, [%rd5+208];
mov.u32 %r71, 0;
mov.u64 %rd70, 0;
mov.u64 %rd69, %rd70;
setp.lt.s32	%p8, %r65, 1;
@%p8 bra BB33_13;

not.b32 %r48, %r36;
add.s32 %r64, %r48, %r65;
mul.wide.s32 %rd68, %r65, 4;
mov.u32 %r71, 0;
mov.u32 %r70, %r71;
mov.u32 %r69, %r71;
mov.u32 %r67, %r8;

BB33_9:
mov.u32 %r13, %r67;
add.s64 %rd38, %rd4, %rd68;
add.s32 %r65, %r65, -1;
add.s64 %rd39, %rd5, %rd68;
ld.local.u32 %r18, [%rd39+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r49, [%rd39+104];
mad.lo.s32 %r69, %r49, %r19, %r69;
ld.local.u32 %r50, [%rd38+104];
mad.lo.s32 %r70, %r50, %r19, %r70;
setp.eq.s32	%p9, %r64, 0;
@%p9 bra BB33_11;

add.s64 %rd40, %rd3, %rd68;
ld.local.u32 %r51, [%rd40+104];
mad.lo.s32 %r71, %r51, %r19, %r71;

BB33_11:
div.u32 %r24, %r13, %r18;
add.s32 %r64, %r64, -1;
add.s64 %rd68, %rd68, -4;
setp.gt.s32	%p10, %r65, 0;
mov.u32 %r67, %r24;
@%p10 bra BB33_9;

cvt.u64.u32	%rd69, %r69;
cvt.u64.u32	%rd70, %r70;

BB33_13:
ld.local.u64 %rd41, [%rd5];
shl.b64 %rd42, %rd69, 3;
add.s64 %rd43, %rd41, %rd42;
ld.u64 %rd19, [%rd43];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB33_15;

mul.wide.s32 %rd44, %r36, 4;
add.s64 %rd45, %rd3, %rd44;
ld.local.u32 %rd46, [%rd45+8];
setp.lt.s64	%p12, %rd19, %rd46;
@%p12 bra BB33_16;

BB33_15:
mov.u64 %rd47, $str2;
cvta.global.u64 %rd48, %rd47;
mov.u64 %rd49, $str1;
cvta.global.u64 %rd50, %rd49;
mov.u64 %rd51, __T247;
cvta.global.u64 %rd52, %rd51;
mov.u32 %r52, 151;
mov.u64 %rd53, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd48;
.param .b64 param1;
st.param.b64	[param1+0], %rd50;
.param .b32 param2;
st.param.b32	[param2+0], %r52;
.param .b64 param3;
st.param.b64	[param3+0], %rd52;
.param .b64 param4;
st.param.b64	[param4+0], %rd53;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB33_16:
mul.wide.s32 %rd54, %r36, 4;
add.s64 %rd55, %rd3, %rd54;
ld.local.u32 %rd56, [%rd55+108];
mul.lo.s64 %rd57, %rd56, %rd19;
cvt.u64.u32	%rd58, %r71;
add.s64 %rd59, %rd57, %rd58;
and.b64 %rd60, %rd59, 4294967295;
ld.local.u64 %rd61, [%rd3];
add.s64 %rd62, %rd61, %rd60;
ld.local.u64 %rd63, [%rd4];
add.s64 %rd64, %rd63, %rd70;
and.b64 %rd65, %rd62, 3;
sub.s64 %rd66, %rd60, %rd65;
add.s64 %rd20, %rd61, %rd66;
ld.u32 %r72, [%rd20];
shl.b64 %rd67, %rd65, 3;
cvt.u32.u64	%r28, %rd67;
ld.s8 %r29, [%rd64];
mov.u32 %r53, 255;
shl.b32 %r54, %r53, %r28;
not.b32 %r30, %r54;
mov.u32 %r31, %nctaid.x;

BB33_17:
mov.u32 %r33, %r72;
shr.u32 %r55, %r33, %r28;
cvt.s32.s8 %r56, %r55;
add.s32 %r57, %r56, %r29;
shl.b32 %r58, %r57, %r28;
and.b32 %r59, %r33, %r30;
or.b32 %r60, %r58, %r59;
atom.cas.b32 %r72, [%rd20], %r33, %r60;
setp.ne.s32	%p13, %r33, %r72;
@%p13 bra BB33_17;

mad.lo.s32 %r68, %r31, %r41, %r8;
setp.lt.u32	%p14, %r68, %r37;
@%p14 bra BB33_7;

BB33_19:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[416],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[416],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[416],
.param .u32 _Z29THCudaTensor_scatterAddKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u64 _Z29THCudaTensor_scatterAddKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot34[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<17>;
.reg .b32 %r<52>;
.reg .b64 %rd<110>;


mov.u64 %rd109, __local_depot34;
cvta.local.u64 %SP, %rd109;
ld.param.u32 %r20, [_Z29THCudaTensor_scatterAddKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u64 %rd39, [_Z29THCudaTensor_scatterAddKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z29THCudaTensor_scatterAddKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelImaLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd40, %SP, 416;
cvta.to.local.u64 %rd3, %rd40;
add.u64 %rd41, %SP, 832;
cvta.to.local.u64 %rd4, %rd41;
add.u64 %rd42, %SP, 0;
cvta.to.local.u64 %rd5, %rd42;
mov.u32 %r46, 0;
mov.pred %p1, 0;
@%p1 bra BB34_2;

BB34_1:
mul.wide.s32 %rd43, %r46, 8;
add.s64 %rd44, %rd6, %rd43;
ld.param.u64 %rd45, [%rd44];
add.s64 %rd46, %rd3, %rd43;
st.local.u64 [%rd46], %rd45;
add.s32 %r46, %r46, 1;
setp.lt.u32	%p2, %r46, 52;
@%p2 bra BB34_1;

BB34_2:
mov.u32 %r47, 0;
@%p1 bra BB34_4;

BB34_3:
mul.wide.s32 %rd47, %r47, 8;
add.s64 %rd48, %rd1, %rd47;
ld.param.u64 %rd49, [%rd48];
add.s64 %rd50, %rd4, %rd47;
st.local.u64 [%rd50], %rd49;
add.s32 %r47, %r47, 1;
setp.lt.u32	%p4, %r47, 52;
@%p4 bra BB34_3;

BB34_4:
mov.u32 %r48, 0;
@%p1 bra BB34_6;

BB34_5:
mul.wide.s32 %rd51, %r48, 8;
add.s64 %rd52, %rd2, %rd51;
ld.param.u64 %rd53, [%rd52];
add.s64 %rd54, %rd5, %rd51;
st.local.u64 [%rd54], %rd53;
add.s32 %r48, %r48, 1;
setp.lt.u32	%p6, %r48, 52;
@%p6 bra BB34_5;

BB34_6:
mov.u32 %r24, %ntid.x;
mov.u32 %r25, %ctaid.x;
mov.u32 %r26, %tid.x;
mad.lo.s32 %r27, %r24, %r25, %r26;
cvt.u64.u32	%rd104, %r27;
setp.ge.u64	%p7, %rd104, %rd39;
@%p7 bra BB34_24;

BB34_7:
mov.u64 %rd100, %rd104;
mov.u64 %rd13, %rd100;
ld.local.u32 %r50, [%rd5+408];
mov.u64 %rd108, 0;
mov.u64 %rd107, %rd108;
mov.u64 %rd106, %rd108;
setp.lt.s32	%p8, %r50, 1;
@%p8 bra BB34_18;

not.b32 %r28, %r20;
add.s32 %r49, %r28, %r50;
mul.wide.s32 %rd99, %r50, 8;
mov.u64 %rd108, 0;
mov.u64 %rd107, %rd108;
mov.u64 %rd106, %rd108;
mov.u64 %rd102, %rd13;

BB34_9:
mov.u64 %rd16, %rd102;
add.s32 %r50, %r50, -1;
add.s64 %rd20, %rd5, %rd99;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd61, %rd16, %rd21;
and.b64 %rd62, %rd61, -4294967296;
setp.eq.s64	%p9, %rd62, 0;
@%p9 bra BB34_11;
bra.uni BB34_10;

BB34_11:
cvt.u32.u64	%r29, %rd21;
cvt.u32.u64	%r30, %rd16;
rem.u32 %r31, %r30, %r29;
cvt.u64.u32	%rd105, %r31;
bra.uni BB34_12;

BB34_10:
rem.u64 %rd105, %rd16, %rd21;

BB34_12:
add.s64 %rd63, %rd4, %rd99;
ld.local.u64 %rd64, [%rd20+200];
mul.lo.s64 %rd65, %rd64, %rd105;
add.s64 %rd106, %rd65, %rd106;
ld.local.u64 %rd66, [%rd63+200];
mul.lo.s64 %rd67, %rd66, %rd105;
add.s64 %rd107, %rd67, %rd107;
setp.eq.s32	%p10, %r49, 0;
@%p10 bra BB34_14;

add.s64 %rd68, %rd3, %rd99;
ld.local.u64 %rd69, [%rd68+200];
mul.lo.s64 %rd70, %rd69, %rd105;
add.s64 %rd108, %rd70, %rd108;

BB34_14:
@%p9 bra BB34_16;
bra.uni BB34_15;

BB34_16:
cvt.u32.u64	%r32, %rd21;
cvt.u32.u64	%r33, %rd16;
div.u32 %r34, %r33, %r32;
cvt.u64.u32	%rd103, %r34;
bra.uni BB34_17;

BB34_15:
div.u64 %rd103, %rd16, %rd21;

BB34_17:
mov.u64 %rd31, %rd103;
add.s32 %r49, %r49, -1;
add.s64 %rd99, %rd99, -8;
setp.gt.s32	%p12, %r50, 0;
mov.u64 %rd102, %rd31;
@%p12 bra BB34_9;

BB34_18:
ld.local.u64 %rd73, [%rd5];
shl.b64 %rd74, %rd106, 3;
add.s64 %rd75, %rd73, %rd74;
ld.u64 %rd36, [%rd75];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB34_20;

mul.wide.s32 %rd76, %r20, 8;
add.s64 %rd77, %rd3, %rd76;
ld.local.u64 %rd78, [%rd77+8];
setp.lt.u64	%p14, %rd36, %rd78;
@%p14 bra BB34_21;

BB34_20:
mov.u64 %rd79, $str2;
cvta.global.u64 %rd80, %rd79;
mov.u64 %rd81, $str1;
cvta.global.u64 %rd82, %rd81;
mov.u64 %rd83, __T248;
cvta.global.u64 %rd84, %rd83;
mov.u32 %r35, 151;
mov.u64 %rd85, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd80;
.param .b64 param1;
st.param.b64	[param1+0], %rd82;
.param .b32 param2;
st.param.b32	[param2+0], %r35;
.param .b64 param3;
st.param.b64	[param3+0], %rd84;
.param .b64 param4;
st.param.b64	[param4+0], %rd85;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB34_21:
mul.wide.s32 %rd86, %r20, 8;
add.s64 %rd87, %rd3, %rd86;
ld.local.u64 %rd88, [%rd87+208];
mul.lo.s64 %rd89, %rd88, %rd36;
add.s64 %rd90, %rd89, %rd108;
ld.local.u64 %rd91, [%rd3];
add.s64 %rd92, %rd91, %rd90;
ld.local.u64 %rd93, [%rd4];
add.s64 %rd94, %rd93, %rd107;
and.b64 %rd95, %rd92, 3;
sub.s64 %rd96, %rd90, %rd95;
add.s64 %rd37, %rd91, %rd96;
ld.u32 %r51, [%rd37];
shl.b64 %rd97, %rd95, 3;
cvt.u32.u64	%r14, %rd97;
ld.s8 %r15, [%rd94];
mov.u32 %r36, 255;
shl.b32 %r37, %r36, %r14;
not.b32 %r16, %r37;
mov.u32 %r39, %nctaid.x;
mul.lo.s32 %r17, %r39, %r24;

BB34_22:
mov.u32 %r18, %r51;
shr.u32 %r40, %r18, %r14;
cvt.s32.s8 %r41, %r40;
add.s32 %r42, %r41, %r15;
shl.b32 %r43, %r42, %r14;
and.b32 %r44, %r18, %r16;
or.b32 %r45, %r43, %r44;
atom.cas.b32 %r51, [%rd37], %r18, %r45;
setp.ne.s32	%p15, %r18, %r51;
@%p15 bra BB34_22;

cvt.u64.u32	%rd98, %r17;
add.s64 %rd104, %rd98, %rd13;
setp.lt.u64	%p16, %rd104, %rd39;
@%p16 bra BB34_7;

BB34_24:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjaLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjaLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjaLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .u8 _Z30THCudaTensor_scatterFillKernelIjaLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjaLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjaLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot35[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .b32 %r<23>;
.reg .b64 %rd<37>;


mov.u64 %rd36, __local_depot35;
cvta.local.u64 %SP, %rd36;
ld.param.u32 %r11, [_Z30THCudaTensor_scatterFillKernelIjaLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r12, [_Z30THCudaTensor_scatterFillKernelIjaLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
ld.param.s8 %rs1, [_Z30THCudaTensor_scatterFillKernelIjaLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjaLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjaLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd2, %rd10;
mov.u32 %r21, 0;
mov.pred %p1, 0;
@%p1 bra BB35_2;

BB35_1:
mul.wide.s32 %rd11, %r21, 8;
add.s64 %rd12, %rd3, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd2, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r21, %r21, 1;
setp.lt.u32	%p2, %r21, 27;
@%p2 bra BB35_1;

BB35_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r22, %r3, %r14, %r15;
setp.ge.u32	%p3, %r22, %r12;
@%p3 bra BB35_10;

ld.param.u64 %rd15, [%rd1];
cvta.to.global.u64 %rd5, %rd15;
ld.param.u32 %r5, [%rd1+8];
ld.param.u32 %r6, [%rd1+108];
mul.wide.s32 %rd16, %r11, 4;
add.s64 %rd17, %rd2, %rd16;
add.s64 %rd6, %rd17, 8;
mov.u32 %r16, %nctaid.x;
mul.lo.s32 %r7, %r16, %r3;

BB35_4:
rem.u32 %r9, %r22, %r5;
setp.eq.s32	%p4, %r11, 0;
mov.u64 %rd35, 0;
@%p4 bra BB35_6;

ld.local.u32 %r17, [%rd2+108];
mul.lo.s32 %r18, %r17, %r9;
cvt.u64.u32	%rd35, %r18;

BB35_6:
mul.lo.s32 %r19, %r6, %r9;
mul.wide.u32 %rd19, %r19, 8;
add.s64 %rd20, %rd5, %rd19;
ld.global.u64 %rd9, [%rd20];
setp.lt.s64	%p5, %rd9, 0;
@%p5 bra BB35_8;

ld.local.u32 %rd21, [%rd6];
setp.lt.s64	%p6, %rd9, %rd21;
@%p6 bra BB35_9;

BB35_8:
mov.u64 %rd22, $str2;
cvta.global.u64 %rd23, %rd22;
mov.u64 %rd24, $str1;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, __T249;
cvta.global.u64 %rd27, %rd26;
mov.u32 %r20, 176;
mov.u64 %rd28, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd23;
.param .b64 param1;
st.param.b64	[param1+0], %rd25;
.param .b32 param2;
st.param.b32	[param2+0], %r20;
.param .b64 param3;
st.param.b64	[param3+0], %rd27;
.param .b64 param4;
st.param.b64	[param4+0], %rd28;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB35_9:
ld.local.u32 %rd29, [%rd6+100];
mul.lo.s64 %rd30, %rd29, %rd9;
add.s64 %rd31, %rd30, %rd35;
and.b64 %rd32, %rd31, 4294967295;
ld.local.u64 %rd33, [%rd2];
add.s64 %rd34, %rd33, %rd32;
st.u8 [%rd34], %rs1;
add.s32 %r22, %r7, %r22;
setp.lt.u32	%p7, %r22, %r12;
@%p7 bra BB35_4;

BB35_10:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjaLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjaLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjaLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .u8 _Z30THCudaTensor_scatterFillKernelIjaLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjaLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjaLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot36[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b16 %rs<2>;
.reg .b32 %r<36>;
.reg .b64 %rd<35>;


mov.u64 %rd34, __local_depot36;
cvta.local.u64 %SP, %rd34;
ld.param.u32 %r16, [_Z30THCudaTensor_scatterFillKernelIjaLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r17, [_Z30THCudaTensor_scatterFillKernelIjaLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
ld.param.s8 %rs1, [_Z30THCudaTensor_scatterFillKernelIjaLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjaLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjaLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd7, %SP, 0;
cvta.to.local.u64 %rd2, %rd7;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB36_2;

BB36_1:
mul.wide.s32 %rd8, %r33, 8;
add.s64 %rd9, %rd3, %rd8;
ld.param.u64 %rd10, [%rd9];
add.s64 %rd11, %rd2, %rd8;
st.local.u64 [%rd11], %rd10;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB36_1;

BB36_2:
mov.u32 %r19, %ntid.x;
mov.u32 %r20, %ctaid.x;
mov.u32 %r21, %tid.x;
mad.lo.s32 %r34, %r19, %r20, %r21;
setp.ge.u32	%p3, %r34, %r17;
@%p3 bra BB36_12;

ld.param.u64 %rd12, [%rd1];
cvta.to.global.u64 %rd5, %rd12;
ld.param.v2.u32 {%r22, %r23}, [%rd1+8];
ld.param.u32 %r6, [%rd1+108];
ld.param.u32 %r7, [%rd1+112];

BB36_4:
rem.u32 %r9, %r34, %r23;
setp.eq.s32	%p4, %r16, 1;
mov.u32 %r35, 0;
@%p4 bra BB36_6;

ld.local.u32 %r25, [%rd2+112];
mul.lo.s32 %r35, %r25, %r9;

BB36_6:
div.u32 %r26, %r34, %r23;
rem.u32 %r12, %r26, %r22;
setp.eq.s32	%p5, %r16, 0;
@%p5 bra BB36_8;

ld.local.u32 %r27, [%rd2+108];
mad.lo.s32 %r35, %r27, %r12, %r35;

BB36_8:
mul.lo.s32 %r28, %r7, %r9;
mad.lo.s32 %r29, %r6, %r12, %r28;
mul.wide.u32 %rd13, %r29, 8;
add.s64 %rd14, %rd5, %rd13;
ld.global.u64 %rd6, [%rd14];
setp.lt.s64	%p6, %rd6, 0;
@%p6 bra BB36_10;

mul.wide.s32 %rd15, %r16, 4;
add.s64 %rd16, %rd2, %rd15;
ld.local.u32 %rd17, [%rd16+8];
setp.lt.s64	%p7, %rd6, %rd17;
@%p7 bra BB36_11;

BB36_10:
mov.u64 %rd18, $str2;
cvta.global.u64 %rd19, %rd18;
mov.u64 %rd20, $str1;
cvta.global.u64 %rd21, %rd20;
mov.u64 %rd22, __T250;
cvta.global.u64 %rd23, %rd22;
mov.u32 %r30, 176;
mov.u64 %rd24, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd19;
.param .b64 param1;
st.param.b64	[param1+0], %rd21;
.param .b32 param2;
st.param.b32	[param2+0], %r30;
.param .b64 param3;
st.param.b64	[param3+0], %rd23;
.param .b64 param4;
st.param.b64	[param4+0], %rd24;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB36_11:
mul.wide.s32 %rd25, %r16, 4;
add.s64 %rd26, %rd2, %rd25;
ld.local.u32 %rd27, [%rd26+108];
mul.lo.s64 %rd28, %rd27, %rd6;
cvt.u64.u32	%rd29, %r35;
add.s64 %rd30, %rd28, %rd29;
and.b64 %rd31, %rd30, 4294967295;
ld.local.u64 %rd32, [%rd2];
add.s64 %rd33, %rd32, %rd31;
st.u8 [%rd33], %rs1;
mov.u32 %r32, %nctaid.x;
mad.lo.s32 %r34, %r32, %r19, %r34;
setp.lt.u32	%p8, %r34, %r17;
@%p8 bra BB36_4;

BB36_12:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjaLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjaLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjaLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .u8 _Z30THCudaTensor_scatterFillKernelIjaLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjaLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjaLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot37[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b16 %rs<2>;
.reg .b32 %r<46>;
.reg .b64 %rd<35>;


mov.u64 %rd34, __local_depot37;
cvta.local.u64 %SP, %rd34;
ld.param.u32 %r23, [_Z30THCudaTensor_scatterFillKernelIjaLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r24, [_Z30THCudaTensor_scatterFillKernelIjaLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
ld.param.s8 %rs1, [_Z30THCudaTensor_scatterFillKernelIjaLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjaLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjaLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd7, %SP, 0;
cvta.to.local.u64 %rd2, %rd7;
mov.u32 %r43, 0;
mov.pred %p1, 0;
@%p1 bra BB37_2;

BB37_1:
mul.wide.s32 %rd8, %r43, 8;
add.s64 %rd9, %rd3, %rd8;
ld.param.u64 %rd10, [%rd9];
add.s64 %rd11, %rd2, %rd8;
st.local.u64 [%rd11], %rd10;
add.s32 %r43, %r43, 1;
setp.lt.u32	%p2, %r43, 27;
@%p2 bra BB37_1;

BB37_2:
mov.u32 %r26, %ntid.x;
mov.u32 %r27, %ctaid.x;
mov.u32 %r28, %tid.x;
mad.lo.s32 %r44, %r26, %r27, %r28;
setp.ge.u32	%p3, %r44, %r24;
@%p3 bra BB37_14;

ld.param.u64 %rd12, [%rd1];
cvta.to.global.u64 %rd5, %rd12;
ld.param.v2.u32 {%r29, %r30}, [%rd1+8];
ld.param.u32 %r6, [%rd1+16];
ld.param.u32 %r7, [%rd1+108];
ld.param.v2.u32 {%r31, %r32}, [%rd1+112];

BB37_4:
rem.u32 %r11, %r44, %r6;
setp.eq.s32	%p4, %r23, 2;
mov.u32 %r45, 0;
@%p4 bra BB37_6;

ld.local.u32 %r34, [%rd2+116];
mul.lo.s32 %r45, %r34, %r11;

BB37_6:
div.u32 %r14, %r44, %r6;
rem.u32 %r15, %r14, %r30;
setp.eq.s32	%p5, %r23, 1;
@%p5 bra BB37_8;

ld.local.u32 %r35, [%rd2+112];
mad.lo.s32 %r45, %r35, %r15, %r45;

BB37_8:
mul.lo.s32 %r36, %r32, %r11;
mad.lo.s32 %r18, %r31, %r15, %r36;
div.u32 %r37, %r14, %r30;
rem.u32 %r19, %r37, %r29;
setp.eq.s32	%p6, %r23, 0;
@%p6 bra BB37_10;

ld.local.u32 %r38, [%rd2+108];
mad.lo.s32 %r45, %r38, %r19, %r45;

BB37_10:
mad.lo.s32 %r39, %r7, %r19, %r18;
mul.wide.u32 %rd13, %r39, 8;
add.s64 %rd14, %rd5, %rd13;
ld.global.u64 %rd6, [%rd14];
setp.lt.s64	%p7, %rd6, 0;
@%p7 bra BB37_12;

mul.wide.s32 %rd15, %r23, 4;
add.s64 %rd16, %rd2, %rd15;
ld.local.u32 %rd17, [%rd16+8];
setp.lt.s64	%p8, %rd6, %rd17;
@%p8 bra BB37_13;

BB37_12:
mov.u64 %rd18, $str2;
cvta.global.u64 %rd19, %rd18;
mov.u64 %rd20, $str1;
cvta.global.u64 %rd21, %rd20;
mov.u64 %rd22, __T251;
cvta.global.u64 %rd23, %rd22;
mov.u32 %r40, 176;
mov.u64 %rd24, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd19;
.param .b64 param1;
st.param.b64	[param1+0], %rd21;
.param .b32 param2;
st.param.b32	[param2+0], %r40;
.param .b64 param3;
st.param.b64	[param3+0], %rd23;
.param .b64 param4;
st.param.b64	[param4+0], %rd24;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB37_13:
mul.wide.s32 %rd25, %r23, 4;
add.s64 %rd26, %rd2, %rd25;
ld.local.u32 %rd27, [%rd26+108];
mul.lo.s64 %rd28, %rd27, %rd6;
cvt.u64.u32	%rd29, %r45;
add.s64 %rd30, %rd28, %rd29;
and.b64 %rd31, %rd30, 4294967295;
ld.local.u64 %rd32, [%rd2];
add.s64 %rd33, %rd32, %rd31;
st.u8 [%rd33], %rs1;
mov.u32 %r42, %nctaid.x;
mad.lo.s32 %r44, %r42, %r26, %r44;
setp.lt.u32	%p9, %r44, %r24;
@%p9 bra BB37_4;

BB37_14:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjaLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjaLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjaLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .u8 _Z30THCudaTensor_scatterFillKernelIjaLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjaLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjaLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot38[432];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<12>;
.reg .b16 %rs<2>;
.reg .b32 %r<54>;
.reg .b64 %rd<62>;


mov.u64 %rd61, __local_depot38;
cvta.local.u64 %SP, %rd61;
ld.param.u32 %r24, [_Z30THCudaTensor_scatterFillKernelIjaLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r25, [_Z30THCudaTensor_scatterFillKernelIjaLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
ld.param.s8 %rs1, [_Z30THCudaTensor_scatterFillKernelIjaLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
mov.u64 %rd4, _Z30THCudaTensor_scatterFillKernelIjaLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjaLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd17, %SP, 216;
cvta.to.local.u64 %rd2, %rd17;
add.u64 %rd18, %SP, 0;
cvta.to.local.u64 %rd3, %rd18;
mov.u32 %r40, 0;
mov.pred %p1, 0;
@%p1 bra BB38_2;

BB38_1:
mul.wide.s32 %rd19, %r40, 8;
add.s64 %rd20, %rd4, %rd19;
ld.param.u64 %rd21, [%rd20];
add.s64 %rd22, %rd2, %rd19;
st.local.u64 [%rd22], %rd21;
add.s32 %r40, %r40, 1;
setp.lt.u32	%p2, %r40, 27;
@%p2 bra BB38_1;

BB38_2:
mov.u32 %r41, 0;
@%p1 bra BB38_4;

BB38_3:
mul.wide.s32 %rd23, %r41, 8;
add.s64 %rd24, %rd1, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r41, %r41, 1;
setp.lt.u32	%p4, %r41, 27;
@%p4 bra BB38_3;

BB38_4:
mov.u32 %r28, %ntid.x;
mov.u32 %r29, %ctaid.x;
mov.u32 %r30, %tid.x;
mad.lo.s32 %r46, %r28, %r29, %r30;
setp.ge.u32	%p5, %r46, %r25;
@%p5 bra BB38_15;

ld.local.u32 %r6, [%rd3+208];

BB38_6:
mov.u32 %r44, %r46;
mov.u32 %r7, %r44;
cvt.s64.s32	%rd28, %r6;
not.b64 %rd29, %rd28;
mov.u64 %rd30, -26;
sub.s64 %rd31, %rd30, %rd28;
add.s32 %r34, %r6, -1;
sub.s32 %r42, %r34, %r24;
neg.s64 %rd58, %rd29;
neg.s64 %rd59, %rd31;
mov.u32 %r51, 0;
mov.u64 %rd60, 0;
mov.u32 %r52, %r51;
mov.u32 %r47, %r51;
setp.lt.s32	%p6, %r6, 1;
mov.u32 %r43, %r6;
mov.u32 %r45, %r7;
@%p6 bra BB38_11;

BB38_7:
mov.u32 %r48, %r52;
mov.u32 %r53, %r48;
mov.u32 %r11, %r45;
mov.u32 %r10, %r43;
add.s32 %r14, %r10, -1;
shl.b64 %rd32, %rd58, 2;
add.s64 %rd33, %rd3, %rd32;
ld.local.u32 %r15, [%rd33];
rem.u32 %r16, %r11, %r15;
ld.local.u32 %r35, [%rd33+100];
mad.lo.s32 %r47, %r35, %r16, %r47;
setp.eq.s32	%p7, %r42, 0;
@%p7 bra BB38_9;

shl.b64 %rd34, %rd59, 2;
add.s64 %rd35, %rd2, %rd34;
ld.local.u32 %r36, [%rd35];
mad.lo.s32 %r53, %r36, %r16, %r53;

BB38_9:
mov.u32 %r52, %r53;
div.u32 %r20, %r11, %r15;
add.s32 %r42, %r42, -1;
add.s64 %rd59, %rd59, -1;
add.s64 %rd58, %rd58, -1;
setp.gt.s32	%p8, %r14, 0;
mov.u32 %r43, %r14;
mov.u32 %r45, %r20;
@%p8 bra BB38_7;

cvt.u64.u32	%rd60, %r47;
mov.u32 %r51, %r52;

BB38_11:
ld.local.u64 %rd36, [%rd3];
shl.b64 %rd37, %rd60, 3;
add.s64 %rd38, %rd36, %rd37;
ld.u64 %rd16, [%rd38];
setp.lt.s64	%p9, %rd16, 0;
@%p9 bra BB38_13;

mul.wide.s32 %rd39, %r24, 4;
add.s64 %rd40, %rd2, %rd39;
ld.local.u32 %rd41, [%rd40+8];
setp.lt.s64	%p10, %rd16, %rd41;
@%p10 bra BB38_14;

BB38_13:
mov.u64 %rd42, $str2;
cvta.global.u64 %rd43, %rd42;
mov.u64 %rd44, $str1;
cvta.global.u64 %rd45, %rd44;
mov.u64 %rd46, __T252;
cvta.global.u64 %rd47, %rd46;
mov.u32 %r37, 176;
mov.u64 %rd48, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd43;
.param .b64 param1;
st.param.b64	[param1+0], %rd45;
.param .b32 param2;
st.param.b32	[param2+0], %r37;
.param .b64 param3;
st.param.b64	[param3+0], %rd47;
.param .b64 param4;
st.param.b64	[param4+0], %rd48;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB38_14:
mul.wide.s32 %rd49, %r24, 4;
add.s64 %rd50, %rd2, %rd49;
ld.local.u32 %rd51, [%rd50+108];
mul.lo.s64 %rd52, %rd51, %rd16;
cvt.u64.u32	%rd53, %r51;
add.s64 %rd54, %rd52, %rd53;
and.b64 %rd55, %rd54, 4294967295;
ld.local.u64 %rd56, [%rd2];
add.s64 %rd57, %rd56, %rd55;
st.u8 [%rd57], %rs1;
mov.u32 %r39, %nctaid.x;
mad.lo.s32 %r46, %r39, %r28, %r7;
setp.lt.u32	%p11, %r46, %r25;
@%p11 bra BB38_6;

BB38_15:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelImaLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelImaLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[416],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelImaLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[416],
.param .u8 _Z30THCudaTensor_scatterFillKernelImaLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelImaLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u64 _Z30THCudaTensor_scatterFillKernelImaLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot39[832];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .b32 %r<33>;
.reg .b64 %rd<98>;


mov.u64 %rd97, __local_depot39;
cvta.local.u64 %SP, %rd97;
ld.param.u32 %r11, [_Z30THCudaTensor_scatterFillKernelImaLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u64 %rd34, [_Z30THCudaTensor_scatterFillKernelImaLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
ld.param.s8 %rs1, [_Z30THCudaTensor_scatterFillKernelImaLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
mov.u64 %rd4, _Z30THCudaTensor_scatterFillKernelImaLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelImaLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd35, %SP, 416;
cvta.to.local.u64 %rd2, %rd35;
add.u64 %rd36, %SP, 0;
cvta.to.local.u64 %rd3, %rd36;
mov.u32 %r29, 0;
mov.pred %p1, 0;
@%p1 bra BB39_2;

BB39_1:
mul.wide.s32 %rd37, %r29, 8;
add.s64 %rd38, %rd4, %rd37;
ld.param.u64 %rd39, [%rd38];
add.s64 %rd40, %rd2, %rd37;
st.local.u64 [%rd40], %rd39;
add.s32 %r29, %r29, 1;
setp.lt.u32	%p2, %r29, 52;
@%p2 bra BB39_1;

BB39_2:
mov.u32 %r30, 0;
@%p1 bra BB39_4;

BB39_3:
mul.wide.s32 %rd41, %r30, 8;
add.s64 %rd42, %rd1, %rd41;
ld.param.u64 %rd43, [%rd42];
add.s64 %rd44, %rd3, %rd41;
st.local.u64 [%rd44], %rd43;
add.s32 %r30, %r30, 1;
setp.lt.u32	%p4, %r30, 52;
@%p4 bra BB39_3;

BB39_4:
mov.u32 %r14, %ntid.x;
mov.u32 %r15, %ctaid.x;
mov.u32 %r16, %tid.x;
mad.lo.s32 %r17, %r14, %r15, %r16;
cvt.u64.u32	%rd86, %r17;
setp.ge.u64	%p5, %rd86, %rd34;
@%p5 bra BB39_20;

ld.local.u32 %r5, [%rd3+408];

BB39_6:
mov.u64 %rd82, %rd86;
mov.u64 %rd9, %rd82;
mul.wide.s32 %rd49, %r5, 8;
add.s64 %rd80, %rd3, %rd49;
add.s64 %rd50, %rd49, %rd2;
add.s64 %rd81, %rd50, 200;
add.s32 %r18, %r5, -1;
sub.s32 %r31, %r18, %r11;
mov.u64 %rd94, 0;
mov.u64 %rd89, %rd94;
mov.u64 %rd95, %rd94;
mov.u64 %rd90, %rd94;
setp.lt.s32	%p6, %r5, 1;
mov.u32 %r32, %r5;
mov.u64 %rd84, %rd9;
@%p6 bra BB39_16;

BB39_7:
mov.u64 %rd96, %rd95;
mov.u64 %rd14, %rd84;
mov.u32 %r8, %r32;
add.s32 %r9, %r8, -1;
ld.local.u64 %rd18, [%rd80];
or.b64 %rd51, %rd14, %rd18;
and.b64 %rd52, %rd51, -4294967296;
setp.eq.s64	%p7, %rd52, 0;
@%p7 bra BB39_9;
bra.uni BB39_8;

BB39_9:
cvt.u32.u64	%r19, %rd18;
cvt.u32.u64	%r20, %rd14;
rem.u32 %r21, %r20, %r19;
cvt.u64.u32	%rd87, %r21;
bra.uni BB39_10;

BB39_8:
rem.u64 %rd87, %rd14, %rd18;

BB39_10:
ld.local.u64 %rd53, [%rd80+200];
mul.lo.s64 %rd54, %rd53, %rd87;
add.s64 %rd90, %rd54, %rd90;
setp.eq.s32	%p8, %r31, 0;
@%p8 bra BB39_12;

ld.local.u64 %rd55, [%rd81];
mul.lo.s64 %rd56, %rd55, %rd87;
add.s64 %rd96, %rd56, %rd96;

BB39_12:
mov.u64 %rd95, %rd96;
@%p7 bra BB39_14;
bra.uni BB39_13;

BB39_14:
cvt.u32.u64	%r22, %rd18;
cvt.u32.u64	%r23, %rd14;
div.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd85, %r24;
bra.uni BB39_15;

BB39_13:
div.u64 %rd85, %rd14, %rd18;

BB39_15:
mov.u64 %rd27, %rd85;
add.s32 %r31, %r31, -1;
add.s64 %rd81, %rd81, -8;
add.s64 %rd80, %rd80, -8;
setp.gt.s32	%p10, %r9, 0;
mov.u32 %r32, %r9;
mov.u64 %rd84, %rd27;
mov.u64 %rd89, %rd90;
mov.u64 %rd94, %rd95;
@%p10 bra BB39_7;

BB39_16:
ld.local.u64 %rd59, [%rd3];
shl.b64 %rd60, %rd89, 3;
add.s64 %rd61, %rd59, %rd60;
ld.u64 %rd32, [%rd61];
setp.lt.s64	%p11, %rd32, 0;
@%p11 bra BB39_18;

mul.wide.s32 %rd62, %r11, 8;
add.s64 %rd63, %rd2, %rd62;
ld.local.u64 %rd64, [%rd63+8];
setp.lt.u64	%p12, %rd32, %rd64;
@%p12 bra BB39_19;

BB39_18:
mov.u64 %rd65, $str2;
cvta.global.u64 %rd66, %rd65;
mov.u64 %rd67, $str1;
cvta.global.u64 %rd68, %rd67;
mov.u64 %rd69, __T253;
cvta.global.u64 %rd70, %rd69;
mov.u32 %r25, 176;
mov.u64 %rd71, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd66;
.param .b64 param1;
st.param.b64	[param1+0], %rd68;
.param .b32 param2;
st.param.b32	[param2+0], %r25;
.param .b64 param3;
st.param.b64	[param3+0], %rd70;
.param .b64 param4;
st.param.b64	[param4+0], %rd71;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB39_19:
mul.wide.s32 %rd72, %r11, 8;
add.s64 %rd73, %rd2, %rd72;
ld.local.u64 %rd74, [%rd73+208];
mul.lo.s64 %rd75, %rd74, %rd32;
add.s64 %rd76, %rd75, %rd94;
ld.local.u64 %rd77, [%rd2];
add.s64 %rd78, %rd77, %rd76;
st.u8 [%rd78], %rs1;
mov.u32 %r27, %nctaid.x;
mul.lo.s32 %r28, %r27, %r14;
cvt.u64.u32	%rd79, %r28;
add.s64 %rd86, %rd79, %rd9;
setp.lt.u64	%p13, %rd86, %rd34;
@%p13 bra BB39_6;

BB39_20:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot40[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .b32 %r<25>;
.reg .b64 %rd<44>;


mov.u64 %rd43, __local_depot40;
cvta.local.u64 %SP, %rd43;
ld.param.u32 %r10, [_Z25THCudaTensor_gatherKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r11, [_Z25THCudaTensor_gatherKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd3, %rd11;
mov.u32 %r23, 0;
mov.pred %p1, 0;
@%p1 bra BB40_2;

BB40_1:
mul.wide.s32 %rd12, %r23, 8;
add.s64 %rd13, %rd4, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd3, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r23, %r23, 1;
setp.lt.u32	%p2, %r23, 27;
@%p2 bra BB40_1;

BB40_2:
mov.u32 %r13, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r24, %r13, %r14, %r15;
setp.ge.u32	%p3, %r24, %r11;
@%p3 bra BB40_10;

ld.param.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd6, %rd16;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd17, [%rd2];
cvta.to.global.u64 %rd7, %rd17;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB40_4:
rem.u32 %r8, %r24, %r5;
setp.eq.s32	%p4, %r10, 0;
mov.u64 %rd42, 0;
@%p4 bra BB40_6;

ld.local.u32 %r16, [%rd3+108];
mul.lo.s32 %r17, %r16, %r8;
cvt.u64.u32	%rd42, %r17;

BB40_6:
mul.lo.s32 %r18, %r6, %r8;
mul.wide.u32 %rd19, %r18, 8;
add.s64 %rd20, %rd7, %rd19;
ld.global.u64 %rd10, [%rd20];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB40_8;

mul.wide.s32 %rd21, %r10, 4;
add.s64 %rd22, %rd3, %rd21;
ld.local.u32 %rd23, [%rd22+8];
setp.lt.s64	%p6, %rd10, %rd23;
@%p6 bra BB40_9;

BB40_8:
mov.u64 %rd24, $str;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, $str1;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, __T256;
cvta.global.u64 %rd29, %rd28;
mov.u32 %r19, 97;
mov.u64 %rd30, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd25;
.param .b64 param1;
st.param.b64	[param1+0], %rd27;
.param .b32 param2;
st.param.b32	[param2+0], %r19;
.param .b64 param3;
st.param.b64	[param3+0], %rd29;
.param .b64 param4;
st.param.b64	[param4+0], %rd30;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB40_9:
mul.lo.s32 %r20, %r4, %r8;
mul.wide.s32 %rd31, %r10, 4;
add.s64 %rd32, %rd3, %rd31;
ld.local.u32 %rd33, [%rd32+108];
mul.lo.s64 %rd34, %rd33, %rd10;
add.s64 %rd35, %rd34, %rd42;
and.b64 %rd36, %rd35, 4294967295;
ld.local.u64 %rd37, [%rd3];
shl.b64 %rd38, %rd36, 1;
add.s64 %rd39, %rd37, %rd38;
ld.u16 %rs1, [%rd39];
mul.wide.u32 %rd40, %r20, 2;
add.s64 %rd41, %rd6, %rd40;
st.global.u16 [%rd41], %rs1;
mov.u32 %r22, %nctaid.x;
mad.lo.s32 %r24, %r22, %r13, %r24;
setp.lt.u32	%p7, %r24, %r11;
@%p7 bra BB40_4;

BB40_10:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot41[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b16 %rs<2>;
.reg .b32 %r<40>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot41;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r19, [_Z25THCudaTensor_gatherKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r20, [_Z25THCudaTensor_gatherKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r37, 0;
mov.pred %p1, 0;
@%p1 bra BB41_2;

BB41_1:
mul.wide.s32 %rd10, %r37, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r37, %r37, 1;
setp.lt.u32	%p2, %r37, 27;
@%p2 bra BB41_1;

BB41_2:
mov.u32 %r22, %ntid.x;
mov.u32 %r23, %ctaid.x;
mov.u32 %r24, %tid.x;
mad.lo.s32 %r38, %r22, %r23, %r24;
setp.ge.u32	%p3, %r38, %r20;
@%p3 bra BB41_12;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r25, %r26}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB41_4:
rem.u32 %r11, %r38, %r26;
setp.eq.s32	%p4, %r19, 1;
mov.u32 %r39, 0;
@%p4 bra BB41_6;

ld.local.u32 %r28, [%rd3+112];
mul.lo.s32 %r39, %r28, %r11;

BB41_6:
div.u32 %r29, %r38, %r26;
rem.u32 %r14, %r29, %r25;
setp.eq.s32	%p5, %r19, 0;
@%p5 bra BB41_8;

ld.local.u32 %r30, [%rd3+108];
mad.lo.s32 %r39, %r30, %r14, %r39;

BB41_8:
mul.lo.s32 %r31, %r9, %r11;
mul.lo.s32 %r32, %r5, %r11;
mad.lo.s32 %r33, %r8, %r14, %r31;
mad.lo.s32 %r17, %r4, %r14, %r32;
mul.wide.u32 %rd16, %r33, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB41_10;

mul.wide.s32 %rd18, %r19, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p7, %rd8, %rd20;
@%p7 bra BB41_11;

BB41_10:
mov.u64 %rd21, $str;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T257;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r34, 97;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r34;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB41_11:
mul.wide.s32 %rd28, %r19, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r39;
add.s64 %rd33, %rd31, %rd32;
and.b64 %rd34, %rd33, 4294967295;
ld.local.u64 %rd35, [%rd3];
shl.b64 %rd36, %rd34, 1;
add.s64 %rd37, %rd35, %rd36;
ld.u16 %rs1, [%rd37];
mul.wide.u32 %rd38, %r17, 2;
add.s64 %rd39, %rd6, %rd38;
st.global.u16 [%rd39], %rs1;
mov.u32 %r36, %nctaid.x;
mad.lo.s32 %r38, %r36, %r22, %r38;
setp.lt.u32	%p8, %r38, %r20;
@%p8 bra BB41_4;

BB41_12:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot42[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b16 %rs<2>;
.reg .b32 %r<54>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot42;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r26, [_Z25THCudaTensor_gatherKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r27, [_Z25THCudaTensor_gatherKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r51, 0;
mov.pred %p1, 0;
@%p1 bra BB42_2;

BB42_1:
mul.wide.s32 %rd10, %r51, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p2, %r51, 27;
@%p2 bra BB42_1;

BB42_2:
mov.u32 %r29, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r52, %r29, %r30, %r31;
setp.ge.u32	%p3, %r52, %r27;
@%p3 bra BB42_14;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r32, %r33}, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r34, %r35}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r36, %r37}, [%rd2+112];

BB42_4:
rem.u32 %r14, %r52, %r9;
setp.eq.s32	%p4, %r26, 2;
mov.u32 %r53, 0;
@%p4 bra BB42_6;

ld.local.u32 %r39, [%rd3+116];
mul.lo.s32 %r53, %r39, %r14;

BB42_6:
div.u32 %r17, %r52, %r9;
rem.u32 %r18, %r17, %r35;
setp.eq.s32	%p5, %r26, 1;
@%p5 bra BB42_8;

ld.local.u32 %r40, [%rd3+112];
mad.lo.s32 %r53, %r40, %r18, %r53;

BB42_8:
div.u32 %r41, %r17, %r35;
rem.u32 %r21, %r41, %r34;
setp.eq.s32	%p6, %r26, 0;
@%p6 bra BB42_10;

ld.local.u32 %r42, [%rd3+108];
mad.lo.s32 %r53, %r42, %r21, %r53;

BB42_10:
mul.lo.s32 %r43, %r37, %r14;
mul.lo.s32 %r44, %r33, %r14;
mad.lo.s32 %r45, %r36, %r18, %r43;
mad.lo.s32 %r46, %r32, %r18, %r44;
mad.lo.s32 %r47, %r10, %r21, %r45;
mad.lo.s32 %r24, %r4, %r21, %r46;
mul.wide.u32 %rd16, %r47, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB42_12;

mul.wide.s32 %rd18, %r26, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p8, %rd8, %rd20;
@%p8 bra BB42_13;

BB42_12:
mov.u64 %rd21, $str;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T258;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r48, 97;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r48;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB42_13:
mul.wide.s32 %rd28, %r26, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r53;
add.s64 %rd33, %rd31, %rd32;
and.b64 %rd34, %rd33, 4294967295;
ld.local.u64 %rd35, [%rd3];
shl.b64 %rd36, %rd34, 1;
add.s64 %rd37, %rd35, %rd36;
ld.u16 %rs1, [%rd37];
mul.wide.u32 %rd38, %r24, 2;
add.s64 %rd39, %rd6, %rd38;
st.global.u16 [%rd39], %rs1;
mov.u32 %r50, %nctaid.x;
mad.lo.s32 %r52, %r50, %r29, %r52;
setp.lt.u32	%p9, %r52, %r27;
@%p9 bra BB42_4;

BB42_14:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot43[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .b32 %r<63>;
.reg .b64 %rd<70>;


mov.u64 %rd69, __local_depot43;
cvta.local.u64 %SP, %rd69;
ld.param.u32 %r28, [_Z25THCudaTensor_gatherKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r29, [_Z25THCudaTensor_gatherKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z25THCudaTensor_gatherKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd20, %SP, 216;
cvta.to.local.u64 %rd3, %rd20;
add.u64 %rd21, %SP, 432;
cvta.to.local.u64 %rd4, %rd21;
add.u64 %rd22, %SP, 0;
cvta.to.local.u64 %rd5, %rd22;
mov.u32 %r47, 0;
mov.pred %p1, 0;
@%p1 bra BB43_2;

BB43_1:
mul.wide.s32 %rd23, %r47, 8;
add.s64 %rd24, %rd6, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r47, %r47, 1;
setp.lt.u32	%p2, %r47, 27;
@%p2 bra BB43_1;

BB43_2:
mov.u32 %r48, 0;
@%p1 bra BB43_4;

BB43_3:
mul.wide.s32 %rd27, %r48, 8;
add.s64 %rd28, %rd1, %rd27;
ld.param.u64 %rd29, [%rd28];
add.s64 %rd30, %rd4, %rd27;
st.local.u64 [%rd30], %rd29;
add.s32 %r48, %r48, 1;
setp.lt.u32	%p4, %r48, 27;
@%p4 bra BB43_3;

BB43_4:
mov.u32 %r49, 0;
@%p1 bra BB43_6;

BB43_5:
mul.wide.s32 %rd31, %r49, 8;
add.s64 %rd32, %rd2, %rd31;
ld.param.u64 %rd33, [%rd32];
add.s64 %rd34, %rd5, %rd31;
st.local.u64 [%rd34], %rd33;
add.s32 %r49, %r49, 1;
setp.lt.u32	%p6, %r49, 27;
@%p6 bra BB43_5;

BB43_6:
mov.u32 %r33, %ntid.x;
mov.u32 %r34, %ctaid.x;
mov.u32 %r35, %tid.x;
mad.lo.s32 %r54, %r33, %r34, %r35;
setp.ge.u32	%p7, %r54, %r29;
@%p7 bra BB43_17;

ld.local.u32 %r8, [%rd5+208];

BB43_8:
mov.u32 %r52, %r54;
mov.u32 %r9, %r52;
mul.wide.s32 %rd66, %r8, 4;
add.s32 %r40, %r8, -1;
sub.s32 %r50, %r40, %r28;
mov.u64 %rd68, 0;
mov.u32 %r60, 0;
mov.u64 %rd67, %rd68;
mov.u32 %r56, %r60;
mov.u32 %r61, %r60;
mov.u32 %r55, %r60;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r51, %r8;
mov.u32 %r53, %r9;
@%p8 bra BB43_13;

BB43_9:
mov.u32 %r57, %r61;
mov.u32 %r62, %r57;
mov.u32 %r13, %r53;
mov.u32 %r12, %r51;
add.s64 %rd37, %rd3, %rd66;
add.s32 %r17, %r12, -1;
add.s64 %rd38, %rd5, %rd66;
ld.local.u32 %r18, [%rd38+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r41, [%rd38+104];
mad.lo.s32 %r55, %r41, %r19, %r55;
ld.local.u32 %r42, [%rd37+104];
mad.lo.s32 %r56, %r42, %r19, %r56;
setp.eq.s32	%p9, %r50, 0;
@%p9 bra BB43_11;

add.s64 %rd39, %rd4, %rd66;
ld.local.u32 %r43, [%rd39+104];
mad.lo.s32 %r62, %r43, %r19, %r62;

BB43_11:
mov.u32 %r61, %r62;
div.u32 %r24, %r13, %r18;
add.s32 %r50, %r50, -1;
add.s64 %rd66, %rd66, -4;
setp.gt.s32	%p10, %r17, 0;
mov.u32 %r51, %r17;
mov.u32 %r53, %r24;
@%p10 bra BB43_9;

cvt.u64.u32	%rd67, %r55;
cvt.u64.u32	%rd68, %r56;
mov.u32 %r60, %r61;

BB43_13:
ld.local.u64 %rd40, [%rd5];
shl.b64 %rd41, %rd67, 3;
add.s64 %rd42, %rd40, %rd41;
ld.u64 %rd19, [%rd42];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB43_15;

mul.wide.s32 %rd43, %r28, 4;
add.s64 %rd44, %rd4, %rd43;
ld.local.u32 %rd45, [%rd44+8];
setp.lt.s64	%p12, %rd19, %rd45;
@%p12 bra BB43_16;

BB43_15:
mov.u64 %rd46, $str;
cvta.global.u64 %rd47, %rd46;
mov.u64 %rd48, $str1;
cvta.global.u64 %rd49, %rd48;
mov.u64 %rd50, __T259;
cvta.global.u64 %rd51, %rd50;
mov.u32 %r44, 97;
mov.u64 %rd52, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd47;
.param .b64 param1;
st.param.b64	[param1+0], %rd49;
.param .b32 param2;
st.param.b32	[param2+0], %r44;
.param .b64 param3;
st.param.b64	[param3+0], %rd51;
.param .b64 param4;
st.param.b64	[param4+0], %rd52;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB43_16:
mul.wide.s32 %rd53, %r28, 4;
add.s64 %rd54, %rd4, %rd53;
ld.local.u32 %rd55, [%rd54+108];
mul.lo.s64 %rd56, %rd55, %rd19;
cvt.u64.u32	%rd57, %r60;
add.s64 %rd58, %rd56, %rd57;
ld.local.u64 %rd59, [%rd4];
shl.b64 %rd60, %rd58, 1;
and.b64 %rd61, %rd60, 8589934590;
add.s64 %rd62, %rd59, %rd61;
ld.u16 %rs1, [%rd62];
ld.local.u64 %rd63, [%rd3];
shl.b64 %rd64, %rd68, 1;
add.s64 %rd65, %rd63, %rd64;
st.u16 [%rd65], %rs1;
mov.u32 %r46, %nctaid.x;
mad.lo.s32 %r54, %r46, %r33, %r9;
setp.lt.u32	%p13, %r54, %r29;
@%p13 bra BB43_8;

BB43_17:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[416],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[416],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[416],
.param .u32 _Z25THCudaTensor_gatherKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u64 _Z25THCudaTensor_gatherKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot44[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<16>;
.reg .b16 %rs<2>;
.reg .b32 %r<37>;
.reg .b64 %rd<117>;


mov.u64 %rd116, __local_depot44;
cvta.local.u64 %SP, %rd116;
ld.param.u32 %r13, [_Z25THCudaTensor_gatherKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u64 %rd38, [_Z25THCudaTensor_gatherKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z25THCudaTensor_gatherKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd39, %SP, 416;
cvta.to.local.u64 %rd3, %rd39;
add.u64 %rd40, %SP, 832;
cvta.to.local.u64 %rd4, %rd40;
add.u64 %rd41, %SP, 0;
cvta.to.local.u64 %rd5, %rd41;
mov.u32 %r32, 0;
mov.pred %p1, 0;
@%p1 bra BB44_2;

BB44_1:
mul.wide.s32 %rd42, %r32, 8;
add.s64 %rd43, %rd6, %rd42;
ld.param.u64 %rd44, [%rd43];
add.s64 %rd45, %rd3, %rd42;
st.local.u64 [%rd45], %rd44;
add.s32 %r32, %r32, 1;
setp.lt.u32	%p2, %r32, 52;
@%p2 bra BB44_1;

BB44_2:
mov.u32 %r33, 0;
@%p1 bra BB44_4;

BB44_3:
mul.wide.s32 %rd46, %r33, 8;
add.s64 %rd47, %rd1, %rd46;
ld.param.u64 %rd48, [%rd47];
add.s64 %rd49, %rd4, %rd46;
st.local.u64 [%rd49], %rd48;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p4, %r33, 52;
@%p4 bra BB44_3;

BB44_4:
mov.u32 %r34, 0;
@%p1 bra BB44_6;

BB44_5:
mul.wide.s32 %rd50, %r34, 8;
add.s64 %rd51, %rd2, %rd50;
ld.param.u64 %rd52, [%rd51];
add.s64 %rd53, %rd5, %rd50;
st.local.u64 [%rd53], %rd52;
add.s32 %r34, %r34, 1;
setp.lt.u32	%p6, %r34, 52;
@%p6 bra BB44_5;

BB44_6:
mov.u32 %r17, %ntid.x;
mov.u32 %r18, %ctaid.x;
mov.u32 %r19, %tid.x;
mad.lo.s32 %r20, %r17, %r18, %r19;
cvt.u64.u32	%rd102, %r20;
setp.ge.u64	%p7, %rd102, %rd38;
@%p7 bra BB44_22;

ld.local.u32 %r7, [%rd5+408];

BB44_8:
mov.u64 %rd98, %rd102;
mov.u64 %rd13, %rd98;
mul.wide.s32 %rd97, %r7, 8;
add.s32 %r21, %r7, -1;
sub.s32 %r35, %r21, %r13;
mov.u64 %rd114, 0;
mov.u64 %rd110, %rd114;
mov.u64 %rd105, %rd114;
mov.u64 %rd115, %rd114;
mov.u64 %rd111, %rd114;
mov.u64 %rd106, %rd114;
setp.lt.s32	%p8, %r7, 1;
mov.u32 %r36, %r7;
mov.u64 %rd100, %rd13;
@%p8 bra BB44_18;

BB44_9:
mov.u64 %rd112, %rd111;
mov.u64 %rd16, %rd100;
mov.u32 %r10, %r36;
add.s32 %r11, %r10, -1;
add.s64 %rd20, %rd5, %rd97;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd60, %rd16, %rd21;
and.b64 %rd61, %rd60, -4294967296;
setp.eq.s64	%p9, %rd61, 0;
@%p9 bra BB44_11;
bra.uni BB44_10;

BB44_11:
cvt.u32.u64	%r22, %rd21;
cvt.u32.u64	%r23, %rd16;
rem.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd103, %r24;
bra.uni BB44_12;

BB44_10:
rem.u64 %rd103, %rd16, %rd21;

BB44_12:
add.s64 %rd62, %rd3, %rd97;
ld.local.u64 %rd63, [%rd20+200];
mul.lo.s64 %rd64, %rd63, %rd103;
add.s64 %rd106, %rd64, %rd106;
ld.local.u64 %rd65, [%rd62+200];
mul.lo.s64 %rd66, %rd65, %rd103;
add.s64 %rd115, %rd66, %rd115;
setp.eq.s32	%p10, %r35, 0;
@%p10 bra BB44_14;

add.s64 %rd67, %rd4, %rd97;
ld.local.u64 %rd68, [%rd67+200];
mul.lo.s64 %rd69, %rd68, %rd103;
add.s64 %rd112, %rd69, %rd112;

BB44_14:
mov.u64 %rd111, %rd112;
@%p9 bra BB44_16;
bra.uni BB44_15;

BB44_16:
cvt.u32.u64	%r25, %rd21;
cvt.u32.u64	%r26, %rd16;
div.u32 %r27, %r26, %r25;
cvt.u64.u32	%rd101, %r27;
bra.uni BB44_17;

BB44_15:
div.u64 %rd101, %rd16, %rd21;

BB44_17:
mov.u64 %rd31, %rd101;
add.s32 %r35, %r35, -1;
add.s64 %rd97, %rd97, -8;
setp.gt.s32	%p12, %r11, 0;
mov.u32 %r36, %r11;
mov.u64 %rd100, %rd31;
mov.u64 %rd105, %rd106;
mov.u64 %rd110, %rd111;
mov.u64 %rd114, %rd115;
@%p12 bra BB44_9;

BB44_18:
ld.local.u64 %rd72, [%rd5];
shl.b64 %rd73, %rd105, 3;
add.s64 %rd74, %rd72, %rd73;
ld.u64 %rd36, [%rd74];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB44_20;

mul.wide.s32 %rd75, %r13, 8;
add.s64 %rd76, %rd4, %rd75;
ld.local.u64 %rd77, [%rd76+8];
setp.lt.u64	%p14, %rd36, %rd77;
@%p14 bra BB44_21;

BB44_20:
mov.u64 %rd78, $str;
cvta.global.u64 %rd79, %rd78;
mov.u64 %rd80, $str1;
cvta.global.u64 %rd81, %rd80;
mov.u64 %rd82, __T261;
cvta.global.u64 %rd83, %rd82;
mov.u32 %r28, 97;
mov.u64 %rd84, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd79;
.param .b64 param1;
st.param.b64	[param1+0], %rd81;
.param .b32 param2;
st.param.b32	[param2+0], %r28;
.param .b64 param3;
st.param.b64	[param3+0], %rd83;
.param .b64 param4;
st.param.b64	[param4+0], %rd84;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB44_21:
mul.wide.s32 %rd85, %r13, 8;
add.s64 %rd86, %rd4, %rd85;
ld.local.u64 %rd87, [%rd86+208];
mul.lo.s64 %rd88, %rd87, %rd36;
add.s64 %rd89, %rd88, %rd110;
ld.local.u64 %rd90, [%rd4];
shl.b64 %rd91, %rd89, 1;
add.s64 %rd92, %rd90, %rd91;
ld.u16 %rs1, [%rd92];
ld.local.u64 %rd93, [%rd3];
shl.b64 %rd94, %rd114, 1;
add.s64 %rd95, %rd93, %rd94;
st.u16 [%rd95], %rs1;
mov.u32 %r30, %nctaid.x;
mul.lo.s32 %r31, %r30, %r17;
cvt.u64.u32	%rd96, %r31;
add.s64 %rd102, %rd96, %rd13;
setp.lt.u64	%p15, %rd102, %rd38;
@%p15 bra BB44_8;

BB44_22:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot45[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .b32 %r<25>;
.reg .b64 %rd<44>;


mov.u64 %rd43, __local_depot45;
cvta.local.u64 %SP, %rd43;
ld.param.u32 %r10, [_Z26THCudaTensor_scatterKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r11, [_Z26THCudaTensor_scatterKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd3, %rd11;
mov.u32 %r23, 0;
mov.pred %p1, 0;
@%p1 bra BB45_2;

BB45_1:
mul.wide.s32 %rd12, %r23, 8;
add.s64 %rd13, %rd4, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd3, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r23, %r23, 1;
setp.lt.u32	%p2, %r23, 27;
@%p2 bra BB45_1;

BB45_2:
mov.u32 %r13, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r24, %r13, %r14, %r15;
setp.ge.u32	%p3, %r24, %r11;
@%p3 bra BB45_10;

ld.param.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd6, %rd16;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd17, [%rd2];
cvta.to.global.u64 %rd7, %rd17;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB45_4:
rem.u32 %r8, %r24, %r5;
setp.eq.s32	%p4, %r10, 0;
mov.u64 %rd42, 0;
@%p4 bra BB45_6;

ld.local.u32 %r16, [%rd3+108];
mul.lo.s32 %r17, %r16, %r8;
cvt.u64.u32	%rd42, %r17;

BB45_6:
mul.lo.s32 %r18, %r6, %r8;
mul.wide.u32 %rd19, %r18, 8;
add.s64 %rd20, %rd7, %rd19;
ld.global.u64 %rd10, [%rd20];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB45_8;

mul.wide.s32 %rd21, %r10, 4;
add.s64 %rd22, %rd3, %rd21;
ld.local.u32 %rd23, [%rd22+8];
setp.lt.s64	%p6, %rd10, %rd23;
@%p6 bra BB45_9;

BB45_8:
mov.u64 %rd24, $str2;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, $str1;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, __T262;
cvta.global.u64 %rd29, %rd28;
mov.u32 %r19, 124;
mov.u64 %rd30, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd25;
.param .b64 param1;
st.param.b64	[param1+0], %rd27;
.param .b32 param2;
st.param.b32	[param2+0], %r19;
.param .b64 param3;
st.param.b64	[param3+0], %rd29;
.param .b64 param4;
st.param.b64	[param4+0], %rd30;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB45_9:
mul.lo.s32 %r20, %r4, %r8;
mul.wide.s32 %rd31, %r10, 4;
add.s64 %rd32, %rd3, %rd31;
ld.local.u32 %rd33, [%rd32+108];
mul.lo.s64 %rd34, %rd33, %rd10;
add.s64 %rd35, %rd34, %rd42;
mul.wide.u32 %rd36, %r20, 2;
add.s64 %rd37, %rd6, %rd36;
ld.global.u16 %rs1, [%rd37];
ld.local.u64 %rd38, [%rd3];
shl.b64 %rd39, %rd35, 1;
and.b64 %rd40, %rd39, 8589934590;
add.s64 %rd41, %rd38, %rd40;
st.u16 [%rd41], %rs1;
mov.u32 %r22, %nctaid.x;
mad.lo.s32 %r24, %r22, %r13, %r24;
setp.lt.u32	%p7, %r24, %r11;
@%p7 bra BB45_4;

BB45_10:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot46[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b16 %rs<2>;
.reg .b32 %r<40>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot46;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r19, [_Z26THCudaTensor_scatterKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r20, [_Z26THCudaTensor_scatterKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r37, 0;
mov.pred %p1, 0;
@%p1 bra BB46_2;

BB46_1:
mul.wide.s32 %rd10, %r37, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r37, %r37, 1;
setp.lt.u32	%p2, %r37, 27;
@%p2 bra BB46_1;

BB46_2:
mov.u32 %r22, %ntid.x;
mov.u32 %r23, %ctaid.x;
mov.u32 %r24, %tid.x;
mad.lo.s32 %r38, %r22, %r23, %r24;
setp.ge.u32	%p3, %r38, %r20;
@%p3 bra BB46_12;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r25, %r26}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB46_4:
rem.u32 %r11, %r38, %r26;
setp.eq.s32	%p4, %r19, 1;
mov.u32 %r39, 0;
@%p4 bra BB46_6;

ld.local.u32 %r28, [%rd3+112];
mul.lo.s32 %r39, %r28, %r11;

BB46_6:
div.u32 %r29, %r38, %r26;
rem.u32 %r14, %r29, %r25;
setp.eq.s32	%p5, %r19, 0;
@%p5 bra BB46_8;

ld.local.u32 %r30, [%rd3+108];
mad.lo.s32 %r39, %r30, %r14, %r39;

BB46_8:
mul.lo.s32 %r31, %r9, %r11;
mul.lo.s32 %r32, %r5, %r11;
mad.lo.s32 %r33, %r8, %r14, %r31;
mad.lo.s32 %r17, %r4, %r14, %r32;
mul.wide.u32 %rd16, %r33, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB46_10;

mul.wide.s32 %rd18, %r19, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p7, %rd8, %rd20;
@%p7 bra BB46_11;

BB46_10:
mov.u64 %rd21, $str2;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T263;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r34, 124;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r34;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB46_11:
mul.wide.s32 %rd28, %r19, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r39;
add.s64 %rd33, %rd31, %rd32;
mul.wide.u32 %rd34, %r17, 2;
add.s64 %rd35, %rd6, %rd34;
ld.global.u16 %rs1, [%rd35];
ld.local.u64 %rd36, [%rd3];
shl.b64 %rd37, %rd33, 1;
and.b64 %rd38, %rd37, 8589934590;
add.s64 %rd39, %rd36, %rd38;
st.u16 [%rd39], %rs1;
mov.u32 %r36, %nctaid.x;
mad.lo.s32 %r38, %r36, %r22, %r38;
setp.lt.u32	%p8, %r38, %r20;
@%p8 bra BB46_4;

BB46_12:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot47[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b16 %rs<2>;
.reg .b32 %r<54>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot47;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r26, [_Z26THCudaTensor_scatterKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r27, [_Z26THCudaTensor_scatterKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r51, 0;
mov.pred %p1, 0;
@%p1 bra BB47_2;

BB47_1:
mul.wide.s32 %rd10, %r51, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p2, %r51, 27;
@%p2 bra BB47_1;

BB47_2:
mov.u32 %r29, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r52, %r29, %r30, %r31;
setp.ge.u32	%p3, %r52, %r27;
@%p3 bra BB47_14;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r32, %r33}, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r34, %r35}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r36, %r37}, [%rd2+112];

BB47_4:
rem.u32 %r14, %r52, %r9;
setp.eq.s32	%p4, %r26, 2;
mov.u32 %r53, 0;
@%p4 bra BB47_6;

ld.local.u32 %r39, [%rd3+116];
mul.lo.s32 %r53, %r39, %r14;

BB47_6:
div.u32 %r17, %r52, %r9;
rem.u32 %r18, %r17, %r35;
setp.eq.s32	%p5, %r26, 1;
@%p5 bra BB47_8;

ld.local.u32 %r40, [%rd3+112];
mad.lo.s32 %r53, %r40, %r18, %r53;

BB47_8:
div.u32 %r41, %r17, %r35;
rem.u32 %r21, %r41, %r34;
setp.eq.s32	%p6, %r26, 0;
@%p6 bra BB47_10;

ld.local.u32 %r42, [%rd3+108];
mad.lo.s32 %r53, %r42, %r21, %r53;

BB47_10:
mul.lo.s32 %r43, %r37, %r14;
mul.lo.s32 %r44, %r33, %r14;
mad.lo.s32 %r45, %r36, %r18, %r43;
mad.lo.s32 %r46, %r32, %r18, %r44;
mad.lo.s32 %r47, %r10, %r21, %r45;
mad.lo.s32 %r24, %r4, %r21, %r46;
mul.wide.u32 %rd16, %r47, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB47_12;

mul.wide.s32 %rd18, %r26, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p8, %rd8, %rd20;
@%p8 bra BB47_13;

BB47_12:
mov.u64 %rd21, $str2;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T264;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r48, 124;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r48;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB47_13:
mul.wide.s32 %rd28, %r26, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r53;
add.s64 %rd33, %rd31, %rd32;
mul.wide.u32 %rd34, %r24, 2;
add.s64 %rd35, %rd6, %rd34;
ld.global.u16 %rs1, [%rd35];
ld.local.u64 %rd36, [%rd3];
shl.b64 %rd37, %rd33, 1;
and.b64 %rd38, %rd37, 8589934590;
add.s64 %rd39, %rd36, %rd38;
st.u16 [%rd39], %rs1;
mov.u32 %r50, %nctaid.x;
mad.lo.s32 %r52, %r50, %r29, %r52;
setp.lt.u32	%p9, %r52, %r27;
@%p9 bra BB47_4;

BB47_14:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot48[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .b32 %r<63>;
.reg .b64 %rd<70>;


mov.u64 %rd69, __local_depot48;
cvta.local.u64 %SP, %rd69;
ld.param.u32 %r28, [_Z26THCudaTensor_scatterKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r29, [_Z26THCudaTensor_scatterKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z26THCudaTensor_scatterKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd20, %SP, 216;
cvta.to.local.u64 %rd3, %rd20;
add.u64 %rd21, %SP, 432;
cvta.to.local.u64 %rd4, %rd21;
add.u64 %rd22, %SP, 0;
cvta.to.local.u64 %rd5, %rd22;
mov.u32 %r47, 0;
mov.pred %p1, 0;
@%p1 bra BB48_2;

BB48_1:
mul.wide.s32 %rd23, %r47, 8;
add.s64 %rd24, %rd6, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r47, %r47, 1;
setp.lt.u32	%p2, %r47, 27;
@%p2 bra BB48_1;

BB48_2:
mov.u32 %r48, 0;
@%p1 bra BB48_4;

BB48_3:
mul.wide.s32 %rd27, %r48, 8;
add.s64 %rd28, %rd1, %rd27;
ld.param.u64 %rd29, [%rd28];
add.s64 %rd30, %rd4, %rd27;
st.local.u64 [%rd30], %rd29;
add.s32 %r48, %r48, 1;
setp.lt.u32	%p4, %r48, 27;
@%p4 bra BB48_3;

BB48_4:
mov.u32 %r49, 0;
@%p1 bra BB48_6;

BB48_5:
mul.wide.s32 %rd31, %r49, 8;
add.s64 %rd32, %rd2, %rd31;
ld.param.u64 %rd33, [%rd32];
add.s64 %rd34, %rd5, %rd31;
st.local.u64 [%rd34], %rd33;
add.s32 %r49, %r49, 1;
setp.lt.u32	%p6, %r49, 27;
@%p6 bra BB48_5;

BB48_6:
mov.u32 %r33, %ntid.x;
mov.u32 %r34, %ctaid.x;
mov.u32 %r35, %tid.x;
mad.lo.s32 %r54, %r33, %r34, %r35;
setp.ge.u32	%p7, %r54, %r29;
@%p7 bra BB48_17;

ld.local.u32 %r8, [%rd5+208];

BB48_8:
mov.u32 %r52, %r54;
mov.u32 %r9, %r52;
mul.wide.s32 %rd66, %r8, 4;
add.s32 %r40, %r8, -1;
sub.s32 %r50, %r40, %r28;
mov.u32 %r60, 0;
mov.u64 %rd68, 0;
mov.u64 %rd67, %rd68;
mov.u32 %r61, %r60;
mov.u32 %r56, %r60;
mov.u32 %r55, %r60;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r51, %r8;
mov.u32 %r53, %r9;
@%p8 bra BB48_13;

BB48_9:
mov.u32 %r57, %r61;
mov.u32 %r62, %r57;
mov.u32 %r13, %r53;
mov.u32 %r12, %r51;
add.s64 %rd37, %rd4, %rd66;
add.s32 %r17, %r12, -1;
add.s64 %rd38, %rd5, %rd66;
ld.local.u32 %r18, [%rd38+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r41, [%rd38+104];
mad.lo.s32 %r55, %r41, %r19, %r55;
ld.local.u32 %r42, [%rd37+104];
mad.lo.s32 %r56, %r42, %r19, %r56;
setp.eq.s32	%p9, %r50, 0;
@%p9 bra BB48_11;

add.s64 %rd39, %rd3, %rd66;
ld.local.u32 %r43, [%rd39+104];
mad.lo.s32 %r62, %r43, %r19, %r62;

BB48_11:
mov.u32 %r61, %r62;
div.u32 %r24, %r13, %r18;
add.s32 %r50, %r50, -1;
add.s64 %rd66, %rd66, -4;
setp.gt.s32	%p10, %r17, 0;
mov.u32 %r51, %r17;
mov.u32 %r53, %r24;
@%p10 bra BB48_9;

cvt.u64.u32	%rd67, %r55;
cvt.u64.u32	%rd68, %r56;
mov.u32 %r60, %r61;

BB48_13:
ld.local.u64 %rd40, [%rd5];
shl.b64 %rd41, %rd67, 3;
add.s64 %rd42, %rd40, %rd41;
ld.u64 %rd19, [%rd42];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB48_15;

mul.wide.s32 %rd43, %r28, 4;
add.s64 %rd44, %rd3, %rd43;
ld.local.u32 %rd45, [%rd44+8];
setp.lt.s64	%p12, %rd19, %rd45;
@%p12 bra BB48_16;

BB48_15:
mov.u64 %rd46, $str2;
cvta.global.u64 %rd47, %rd46;
mov.u64 %rd48, $str1;
cvta.global.u64 %rd49, %rd48;
mov.u64 %rd50, __T265;
cvta.global.u64 %rd51, %rd50;
mov.u32 %r44, 124;
mov.u64 %rd52, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd47;
.param .b64 param1;
st.param.b64	[param1+0], %rd49;
.param .b32 param2;
st.param.b32	[param2+0], %r44;
.param .b64 param3;
st.param.b64	[param3+0], %rd51;
.param .b64 param4;
st.param.b64	[param4+0], %rd52;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB48_16:
mul.wide.s32 %rd53, %r28, 4;
add.s64 %rd54, %rd3, %rd53;
ld.local.u32 %rd55, [%rd54+108];
mul.lo.s64 %rd56, %rd55, %rd19;
cvt.u64.u32	%rd57, %r60;
add.s64 %rd58, %rd56, %rd57;
ld.local.u64 %rd59, [%rd4];
shl.b64 %rd60, %rd68, 1;
add.s64 %rd61, %rd59, %rd60;
ld.u16 %rs1, [%rd61];
ld.local.u64 %rd62, [%rd3];
shl.b64 %rd63, %rd58, 1;
and.b64 %rd64, %rd63, 8589934590;
add.s64 %rd65, %rd62, %rd64;
st.u16 [%rd65], %rs1;
mov.u32 %r46, %nctaid.x;
mad.lo.s32 %r54, %r46, %r33, %r9;
setp.lt.u32	%p13, %r54, %r29;
@%p13 bra BB48_8;

BB48_17:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[416],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[416],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[416],
.param .u32 _Z26THCudaTensor_scatterKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u64 _Z26THCudaTensor_scatterKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot49[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<16>;
.reg .b16 %rs<2>;
.reg .b32 %r<37>;
.reg .b64 %rd<117>;


mov.u64 %rd116, __local_depot49;
cvta.local.u64 %SP, %rd116;
ld.param.u32 %r13, [_Z26THCudaTensor_scatterKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u64 %rd38, [_Z26THCudaTensor_scatterKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z26THCudaTensor_scatterKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd39, %SP, 416;
cvta.to.local.u64 %rd3, %rd39;
add.u64 %rd40, %SP, 832;
cvta.to.local.u64 %rd4, %rd40;
add.u64 %rd41, %SP, 0;
cvta.to.local.u64 %rd5, %rd41;
mov.u32 %r32, 0;
mov.pred %p1, 0;
@%p1 bra BB49_2;

BB49_1:
mul.wide.s32 %rd42, %r32, 8;
add.s64 %rd43, %rd6, %rd42;
ld.param.u64 %rd44, [%rd43];
add.s64 %rd45, %rd3, %rd42;
st.local.u64 [%rd45], %rd44;
add.s32 %r32, %r32, 1;
setp.lt.u32	%p2, %r32, 52;
@%p2 bra BB49_1;

BB49_2:
mov.u32 %r33, 0;
@%p1 bra BB49_4;

BB49_3:
mul.wide.s32 %rd46, %r33, 8;
add.s64 %rd47, %rd1, %rd46;
ld.param.u64 %rd48, [%rd47];
add.s64 %rd49, %rd4, %rd46;
st.local.u64 [%rd49], %rd48;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p4, %r33, 52;
@%p4 bra BB49_3;

BB49_4:
mov.u32 %r34, 0;
@%p1 bra BB49_6;

BB49_5:
mul.wide.s32 %rd50, %r34, 8;
add.s64 %rd51, %rd2, %rd50;
ld.param.u64 %rd52, [%rd51];
add.s64 %rd53, %rd5, %rd50;
st.local.u64 [%rd53], %rd52;
add.s32 %r34, %r34, 1;
setp.lt.u32	%p6, %r34, 52;
@%p6 bra BB49_5;

BB49_6:
mov.u32 %r17, %ntid.x;
mov.u32 %r18, %ctaid.x;
mov.u32 %r19, %tid.x;
mad.lo.s32 %r20, %r17, %r18, %r19;
cvt.u64.u32	%rd102, %r20;
setp.ge.u64	%p7, %rd102, %rd38;
@%p7 bra BB49_22;

ld.local.u32 %r7, [%rd5+408];

BB49_8:
mov.u64 %rd98, %rd102;
mov.u64 %rd13, %rd98;
mul.wide.s32 %rd97, %r7, 8;
add.s32 %r21, %r7, -1;
sub.s32 %r35, %r21, %r13;
mov.u64 %rd113, 0;
mov.u64 %rd108, %rd113;
mov.u64 %rd105, %rd113;
mov.u64 %rd114, %rd113;
mov.u64 %rd109, %rd113;
mov.u64 %rd106, %rd113;
setp.lt.s32	%p8, %r7, 1;
mov.u32 %r36, %r7;
mov.u64 %rd100, %rd13;
@%p8 bra BB49_18;

BB49_9:
mov.u64 %rd115, %rd114;
mov.u64 %rd16, %rd100;
mov.u32 %r10, %r36;
add.s32 %r11, %r10, -1;
add.s64 %rd20, %rd5, %rd97;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd60, %rd16, %rd21;
and.b64 %rd61, %rd60, -4294967296;
setp.eq.s64	%p9, %rd61, 0;
@%p9 bra BB49_11;
bra.uni BB49_10;

BB49_11:
cvt.u32.u64	%r22, %rd21;
cvt.u32.u64	%r23, %rd16;
rem.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd103, %r24;
bra.uni BB49_12;

BB49_10:
rem.u64 %rd103, %rd16, %rd21;

BB49_12:
add.s64 %rd62, %rd4, %rd97;
ld.local.u64 %rd63, [%rd20+200];
mul.lo.s64 %rd64, %rd63, %rd103;
add.s64 %rd106, %rd64, %rd106;
ld.local.u64 %rd65, [%rd62+200];
mul.lo.s64 %rd66, %rd65, %rd103;
add.s64 %rd109, %rd66, %rd109;
setp.eq.s32	%p10, %r35, 0;
@%p10 bra BB49_14;

add.s64 %rd67, %rd3, %rd97;
ld.local.u64 %rd68, [%rd67+200];
mul.lo.s64 %rd69, %rd68, %rd103;
add.s64 %rd115, %rd69, %rd115;

BB49_14:
mov.u64 %rd114, %rd115;
@%p9 bra BB49_16;
bra.uni BB49_15;

BB49_16:
cvt.u32.u64	%r25, %rd21;
cvt.u32.u64	%r26, %rd16;
div.u32 %r27, %r26, %r25;
cvt.u64.u32	%rd101, %r27;
bra.uni BB49_17;

BB49_15:
div.u64 %rd101, %rd16, %rd21;

BB49_17:
mov.u64 %rd31, %rd101;
add.s32 %r35, %r35, -1;
add.s64 %rd97, %rd97, -8;
setp.gt.s32	%p12, %r11, 0;
mov.u32 %r36, %r11;
mov.u64 %rd100, %rd31;
mov.u64 %rd105, %rd106;
mov.u64 %rd108, %rd109;
mov.u64 %rd113, %rd114;
@%p12 bra BB49_9;

BB49_18:
ld.local.u64 %rd72, [%rd5];
shl.b64 %rd73, %rd105, 3;
add.s64 %rd74, %rd72, %rd73;
ld.u64 %rd36, [%rd74];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB49_20;

mul.wide.s32 %rd75, %r13, 8;
add.s64 %rd76, %rd3, %rd75;
ld.local.u64 %rd77, [%rd76+8];
setp.lt.u64	%p14, %rd36, %rd77;
@%p14 bra BB49_21;

BB49_20:
mov.u64 %rd78, $str2;
cvta.global.u64 %rd79, %rd78;
mov.u64 %rd80, $str1;
cvta.global.u64 %rd81, %rd80;
mov.u64 %rd82, __T266;
cvta.global.u64 %rd83, %rd82;
mov.u32 %r28, 124;
mov.u64 %rd84, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd79;
.param .b64 param1;
st.param.b64	[param1+0], %rd81;
.param .b32 param2;
st.param.b32	[param2+0], %r28;
.param .b64 param3;
st.param.b64	[param3+0], %rd83;
.param .b64 param4;
st.param.b64	[param4+0], %rd84;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB49_21:
mul.wide.s32 %rd85, %r13, 8;
add.s64 %rd86, %rd3, %rd85;
ld.local.u64 %rd87, [%rd86+208];
mul.lo.s64 %rd88, %rd87, %rd36;
add.s64 %rd89, %rd88, %rd113;
ld.local.u64 %rd90, [%rd4];
shl.b64 %rd91, %rd108, 1;
add.s64 %rd92, %rd90, %rd91;
ld.u16 %rs1, [%rd92];
ld.local.u64 %rd93, [%rd3];
shl.b64 %rd94, %rd89, 1;
add.s64 %rd95, %rd93, %rd94;
st.u16 [%rd95], %rs1;
mov.u32 %r30, %nctaid.x;
mul.lo.s32 %r31, %r30, %r17;
cvt.u64.u32	%rd96, %r31;
add.s64 %rd102, %rd96, %rd13;
setp.lt.u64	%p15, %rd102, %rd38;
@%p15 bra BB49_8;

BB49_22:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot50[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<11>;
.reg .b32 %r<37>;
.reg .b64 %rd<49>;


mov.u64 %rd48, __local_depot50;
cvta.local.u64 %SP, %rd48;
ld.param.u32 %r13, [_Z29THCudaTensor_scatterAddKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r14, [_Z29THCudaTensor_scatterAddKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjsLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd14, %SP, 0;
cvta.to.local.u64 %rd3, %rd14;
mov.u32 %r34, 0;
mov.pred %p1, 0;
@%p1 bra BB50_2;

BB50_1:
mul.wide.s32 %rd15, %r34, 8;
add.s64 %rd16, %rd4, %rd15;
ld.param.u64 %rd17, [%rd16];
add.s64 %rd18, %rd3, %rd15;
st.local.u64 [%rd18], %rd17;
add.s32 %r34, %r34, 1;
setp.lt.u32	%p2, %r34, 27;
@%p2 bra BB50_1;

BB50_2:
mov.u32 %r16, %ntid.x;
mov.u32 %r17, %ctaid.x;
mov.u32 %r18, %tid.x;
mad.lo.s32 %r35, %r16, %r17, %r18;
setp.ge.u32	%p3, %r35, %r14;
@%p3 bra BB50_12;

ld.param.u64 %rd19, [%rd1];
cvta.to.global.u64 %rd6, %rd19;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd20, [%rd2];
cvta.to.global.u64 %rd7, %rd20;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB50_4:
rem.u32 %r8, %r35, %r5;
setp.eq.s32	%p4, %r13, 0;
mov.u64 %rd47, 0;
@%p4 bra BB50_6;

ld.local.u32 %r19, [%rd3+108];
mul.lo.s32 %r20, %r19, %r8;
cvt.u64.u32	%rd47, %r20;

BB50_6:
mul.lo.s32 %r21, %r6, %r8;
mul.wide.u32 %rd22, %r21, 8;
add.s64 %rd23, %rd7, %rd22;
ld.global.u64 %rd10, [%rd23];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB50_8;

mul.wide.s32 %rd24, %r13, 4;
add.s64 %rd25, %rd3, %rd24;
ld.local.u32 %rd26, [%rd25+8];
setp.lt.s64	%p6, %rd10, %rd26;
@%p6 bra BB50_9;

BB50_8:
mov.u64 %rd27, $str2;
cvta.global.u64 %rd28, %rd27;
mov.u64 %rd29, $str1;
cvta.global.u64 %rd30, %rd29;
mov.u64 %rd31, __T267;
cvta.global.u64 %rd32, %rd31;
mov.u32 %r22, 151;
mov.u64 %rd33, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd28;
.param .b64 param1;
st.param.b64	[param1+0], %rd30;
.param .b32 param2;
st.param.b32	[param2+0], %r22;
.param .b64 param3;
st.param.b64	[param3+0], %rd32;
.param .b64 param4;
st.param.b64	[param4+0], %rd33;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB50_9:
mul.lo.s32 %r23, %r4, %r8;
mul.wide.s32 %rd34, %r13, 4;
add.s64 %rd35, %rd3, %rd34;
ld.local.u32 %rd36, [%rd35+108];
mul.lo.s64 %rd37, %rd36, %rd10;
add.s64 %rd38, %rd37, %rd47;
and.b64 %rd39, %rd38, 4294967295;
ld.local.u64 %rd40, [%rd3];
shl.b64 %rd41, %rd39, 1;
add.s64 %rd42, %rd40, %rd41;
mul.wide.u32 %rd43, %r23, 2;
add.s64 %rd44, %rd6, %rd43;
and.b64 %rd11, %rd42, 2;
sub.s64 %rd12, %rd42, %rd11;
ld.u32 %r36, [%rd12];
ld.global.u16 %rd45, [%rd44];
add.s64 %rd46, %rd42, %rd45;
and.b64 %rd13, %rd46, 2;

BB50_10:
mov.u32 %r10, %r36;
shl.b32 %r24, %r10, 16;
and.b32 %r25, %r10, -65536;
setp.eq.s64	%p7, %rd13, 0;
selp.b32	%r26, %r24, %r25, %p7;
and.b32 %r27, %r10, 65535;
or.b32 %r28, %r26, %r27;
shr.s32 %r29, %r26, 16;
or.b32 %r30, %r29, %r25;
setp.eq.s64	%p8, %rd11, 0;
selp.b32	%r31, %r30, %r28, %p8;
atom.cas.b32 %r36, [%rd12], %r10, %r31;
setp.ne.s32	%p9, %r10, %r36;
@%p9 bra BB50_10;

mov.u32 %r33, %nctaid.x;
mad.lo.s32 %r35, %r33, %r16, %r35;
setp.lt.u32	%p10, %r35, %r14;
@%p10 bra BB50_4;

BB50_12:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot51[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<12>;
.reg .b32 %r<52>;
.reg .b64 %rd<46>;


mov.u64 %rd45, __local_depot51;
cvta.local.u64 %SP, %rd45;
ld.param.u32 %r22, [_Z29THCudaTensor_scatterAddKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r23, [_Z29THCudaTensor_scatterAddKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjsLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd12, %SP, 0;
cvta.to.local.u64 %rd3, %rd12;
mov.u32 %r48, 0;
mov.pred %p1, 0;
@%p1 bra BB51_2;

BB51_1:
mul.wide.s32 %rd13, %r48, 8;
add.s64 %rd14, %rd4, %rd13;
ld.param.u64 %rd15, [%rd14];
add.s64 %rd16, %rd3, %rd13;
st.local.u64 [%rd16], %rd15;
add.s32 %r48, %r48, 1;
setp.lt.u32	%p2, %r48, 27;
@%p2 bra BB51_1;

BB51_2:
mov.u32 %r25, %ntid.x;
mov.u32 %r26, %ctaid.x;
mov.u32 %r27, %tid.x;
mad.lo.s32 %r49, %r25, %r26, %r27;
setp.ge.u32	%p3, %r49, %r23;
@%p3 bra BB51_14;

ld.param.u64 %rd17, [%rd1];
cvta.to.global.u64 %rd6, %rd17;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd18, [%rd2];
cvta.to.global.u64 %rd7, %rd18;
ld.param.v2.u32 {%r28, %r29}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB51_4:
rem.u32 %r11, %r49, %r29;
setp.eq.s32	%p4, %r22, 1;
mov.u32 %r50, 0;
@%p4 bra BB51_6;

ld.local.u32 %r31, [%rd3+112];
mul.lo.s32 %r50, %r31, %r11;

BB51_6:
div.u32 %r32, %r49, %r29;
rem.u32 %r14, %r32, %r28;
setp.eq.s32	%p5, %r22, 0;
@%p5 bra BB51_8;

ld.local.u32 %r33, [%rd3+108];
mad.lo.s32 %r50, %r33, %r14, %r50;

BB51_8:
mul.lo.s32 %r34, %r9, %r11;
mul.lo.s32 %r35, %r5, %r11;
mad.lo.s32 %r36, %r8, %r14, %r34;
mad.lo.s32 %r17, %r4, %r14, %r35;
mul.wide.u32 %rd19, %r36, 8;
add.s64 %rd20, %rd7, %rd19;
ld.global.u64 %rd8, [%rd20];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB51_10;

mul.wide.s32 %rd21, %r22, 4;
add.s64 %rd22, %rd3, %rd21;
ld.local.u32 %rd23, [%rd22+8];
setp.lt.s64	%p7, %rd8, %rd23;
@%p7 bra BB51_11;

BB51_10:
mov.u64 %rd24, $str2;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, $str1;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, __T268;
cvta.global.u64 %rd29, %rd28;
mov.u32 %r37, 151;
mov.u64 %rd30, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd25;
.param .b64 param1;
st.param.b64	[param1+0], %rd27;
.param .b32 param2;
st.param.b32	[param2+0], %r37;
.param .b64 param3;
st.param.b64	[param3+0], %rd29;
.param .b64 param4;
st.param.b64	[param4+0], %rd30;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB51_11:
mul.wide.s32 %rd31, %r22, 4;
add.s64 %rd32, %rd3, %rd31;
ld.local.u32 %rd33, [%rd32+108];
mul.lo.s64 %rd34, %rd33, %rd8;
cvt.u64.u32	%rd35, %r50;
add.s64 %rd36, %rd34, %rd35;
and.b64 %rd37, %rd36, 4294967295;
ld.local.u64 %rd38, [%rd3];
shl.b64 %rd39, %rd37, 1;
add.s64 %rd40, %rd38, %rd39;
mul.wide.u32 %rd41, %r17, 2;
add.s64 %rd42, %rd6, %rd41;
and.b64 %rd9, %rd40, 2;
sub.s64 %rd10, %rd40, %rd9;
ld.u32 %r51, [%rd10];
ld.global.u16 %rd43, [%rd42];
add.s64 %rd44, %rd40, %rd43;
and.b64 %rd11, %rd44, 2;

BB51_12:
mov.u32 %r19, %r51;
shl.b32 %r38, %r19, 16;
and.b32 %r39, %r19, -65536;
setp.eq.s64	%p8, %rd11, 0;
selp.b32	%r40, %r38, %r39, %p8;
and.b32 %r41, %r19, 65535;
or.b32 %r42, %r40, %r41;
shr.s32 %r43, %r40, 16;
or.b32 %r44, %r43, %r39;
setp.eq.s64	%p9, %rd9, 0;
selp.b32	%r45, %r44, %r42, %p9;
atom.cas.b32 %r51, [%rd10], %r19, %r45;
setp.ne.s32	%p10, %r19, %r51;
@%p10 bra BB51_12;

mov.u32 %r47, %nctaid.x;
mad.lo.s32 %r49, %r47, %r25, %r49;
setp.lt.u32	%p11, %r49, %r23;
@%p11 bra BB51_4;

BB51_14:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot52[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<13>;
.reg .b32 %r<66>;
.reg .b64 %rd<46>;


mov.u64 %rd45, __local_depot52;
cvta.local.u64 %SP, %rd45;
ld.param.u32 %r29, [_Z29THCudaTensor_scatterAddKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r30, [_Z29THCudaTensor_scatterAddKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjsLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd12, %SP, 0;
cvta.to.local.u64 %rd3, %rd12;
mov.u32 %r62, 0;
mov.pred %p1, 0;
@%p1 bra BB52_2;

BB52_1:
mul.wide.s32 %rd13, %r62, 8;
add.s64 %rd14, %rd4, %rd13;
ld.param.u64 %rd15, [%rd14];
add.s64 %rd16, %rd3, %rd13;
st.local.u64 [%rd16], %rd15;
add.s32 %r62, %r62, 1;
setp.lt.u32	%p2, %r62, 27;
@%p2 bra BB52_1;

BB52_2:
mov.u32 %r32, %ntid.x;
mov.u32 %r33, %ctaid.x;
mov.u32 %r34, %tid.x;
mad.lo.s32 %r63, %r32, %r33, %r34;
setp.ge.u32	%p3, %r63, %r30;
@%p3 bra BB52_16;

ld.param.u64 %rd17, [%rd1];
cvta.to.global.u64 %rd6, %rd17;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r35, %r36}, [%rd1+112];
ld.param.u64 %rd18, [%rd2];
cvta.to.global.u64 %rd7, %rd18;
ld.param.v2.u32 {%r37, %r38}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r39, %r40}, [%rd2+112];

BB52_4:
rem.u32 %r14, %r63, %r9;
setp.eq.s32	%p4, %r29, 2;
mov.u32 %r64, 0;
@%p4 bra BB52_6;

ld.local.u32 %r42, [%rd3+116];
mul.lo.s32 %r64, %r42, %r14;

BB52_6:
div.u32 %r17, %r63, %r9;
rem.u32 %r18, %r17, %r38;
setp.eq.s32	%p5, %r29, 1;
@%p5 bra BB52_8;

ld.local.u32 %r43, [%rd3+112];
mad.lo.s32 %r64, %r43, %r18, %r64;

BB52_8:
div.u32 %r44, %r17, %r38;
rem.u32 %r21, %r44, %r37;
setp.eq.s32	%p6, %r29, 0;
@%p6 bra BB52_10;

ld.local.u32 %r45, [%rd3+108];
mad.lo.s32 %r64, %r45, %r21, %r64;

BB52_10:
mul.lo.s32 %r46, %r40, %r14;
mul.lo.s32 %r47, %r36, %r14;
mad.lo.s32 %r48, %r39, %r18, %r46;
mad.lo.s32 %r49, %r35, %r18, %r47;
mad.lo.s32 %r50, %r10, %r21, %r48;
mad.lo.s32 %r24, %r4, %r21, %r49;
mul.wide.u32 %rd19, %r50, 8;
add.s64 %rd20, %rd7, %rd19;
ld.global.u64 %rd8, [%rd20];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB52_12;

mul.wide.s32 %rd21, %r29, 4;
add.s64 %rd22, %rd3, %rd21;
ld.local.u32 %rd23, [%rd22+8];
setp.lt.s64	%p8, %rd8, %rd23;
@%p8 bra BB52_13;

BB52_12:
mov.u64 %rd24, $str2;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, $str1;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, __T269;
cvta.global.u64 %rd29, %rd28;
mov.u32 %r51, 151;
mov.u64 %rd30, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd25;
.param .b64 param1;
st.param.b64	[param1+0], %rd27;
.param .b32 param2;
st.param.b32	[param2+0], %r51;
.param .b64 param3;
st.param.b64	[param3+0], %rd29;
.param .b64 param4;
st.param.b64	[param4+0], %rd30;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB52_13:
mul.wide.s32 %rd31, %r29, 4;
add.s64 %rd32, %rd3, %rd31;
ld.local.u32 %rd33, [%rd32+108];
mul.lo.s64 %rd34, %rd33, %rd8;
cvt.u64.u32	%rd35, %r64;
add.s64 %rd36, %rd34, %rd35;
and.b64 %rd37, %rd36, 4294967295;
ld.local.u64 %rd38, [%rd3];
shl.b64 %rd39, %rd37, 1;
add.s64 %rd40, %rd38, %rd39;
mul.wide.u32 %rd41, %r24, 2;
add.s64 %rd42, %rd6, %rd41;
and.b64 %rd9, %rd40, 2;
sub.s64 %rd10, %rd40, %rd9;
ld.u32 %r65, [%rd10];
ld.global.u16 %rd43, [%rd42];
add.s64 %rd44, %rd40, %rd43;
and.b64 %rd11, %rd44, 2;

BB52_14:
mov.u32 %r26, %r65;
shl.b32 %r52, %r26, 16;
and.b32 %r53, %r26, -65536;
setp.eq.s64	%p9, %rd11, 0;
selp.b32	%r54, %r52, %r53, %p9;
and.b32 %r55, %r26, 65535;
or.b32 %r56, %r54, %r55;
shr.s32 %r57, %r54, 16;
or.b32 %r58, %r57, %r53;
setp.eq.s64	%p10, %rd9, 0;
selp.b32	%r59, %r58, %r56, %p10;
atom.cas.b32 %r65, [%rd10], %r26, %r59;
setp.ne.s32	%p11, %r26, %r65;
@%p11 bra BB52_14;

mov.u32 %r61, %nctaid.x;
mad.lo.s32 %r63, %r61, %r32, %r63;
setp.lt.u32	%p12, %r63, %r30;
@%p12 bra BB52_4;

BB52_16:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot53[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<17>;
.reg .b32 %r<70>;
.reg .b64 %rd<75>;


mov.u64 %rd74, __local_depot53;
cvta.local.u64 %SP, %rd74;
ld.param.u32 %r33, [_Z29THCudaTensor_scatterAddKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r34, [_Z29THCudaTensor_scatterAddKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z29THCudaTensor_scatterAddKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd23, %SP, 216;
cvta.to.local.u64 %rd3, %rd23;
add.u64 %rd24, %SP, 432;
cvta.to.local.u64 %rd4, %rd24;
add.u64 %rd25, %SP, 0;
cvta.to.local.u64 %rd5, %rd25;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB53_2;

BB53_1:
mul.wide.s32 %rd26, %r58, 8;
add.s64 %rd27, %rd6, %rd26;
ld.param.u64 %rd28, [%rd27];
add.s64 %rd29, %rd3, %rd26;
st.local.u64 [%rd29], %rd28;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB53_1;

BB53_2:
mov.u32 %r59, 0;
@%p1 bra BB53_4;

BB53_3:
mul.wide.s32 %rd30, %r59, 8;
add.s64 %rd31, %rd1, %rd30;
ld.param.u64 %rd32, [%rd31];
add.s64 %rd33, %rd4, %rd30;
st.local.u64 [%rd33], %rd32;
add.s32 %r59, %r59, 1;
setp.lt.u32	%p4, %r59, 27;
@%p4 bra BB53_3;

BB53_4:
mov.u32 %r60, 0;
@%p1 bra BB53_6;

BB53_5:
mul.wide.s32 %rd34, %r60, 8;
add.s64 %rd35, %rd2, %rd34;
ld.param.u64 %rd36, [%rd35];
add.s64 %rd37, %rd5, %rd34;
st.local.u64 [%rd37], %rd36;
add.s32 %r60, %r60, 1;
setp.lt.u32	%p6, %r60, 27;
@%p6 bra BB53_5;

BB53_6:
mov.u32 %r38, %ntid.x;
mov.u32 %r39, %ctaid.x;
mov.u32 %r40, %tid.x;
mad.lo.s32 %r65, %r38, %r39, %r40;
setp.ge.u32	%p7, %r65, %r34;
@%p7 bra BB53_19;

BB53_7:
mov.u32 %r63, %r65;
mov.u32 %r8, %r63;
ld.local.u32 %r62, [%rd5+208];
mov.u32 %r68, 0;
mov.u64 %rd73, 0;
mov.u64 %rd72, %rd73;
setp.lt.s32	%p8, %r62, 1;
@%p8 bra BB53_13;

not.b32 %r45, %r33;
add.s32 %r61, %r45, %r62;
mul.wide.s32 %rd71, %r62, 4;
mov.u32 %r68, 0;
mov.u32 %r67, %r68;
mov.u32 %r66, %r68;
mov.u32 %r64, %r8;

BB53_9:
mov.u32 %r13, %r64;
add.s64 %rd40, %rd4, %rd71;
add.s32 %r62, %r62, -1;
add.s64 %rd41, %rd5, %rd71;
ld.local.u32 %r18, [%rd41+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r46, [%rd41+104];
mad.lo.s32 %r66, %r46, %r19, %r66;
ld.local.u32 %r47, [%rd40+104];
mad.lo.s32 %r67, %r47, %r19, %r67;
setp.eq.s32	%p9, %r61, 0;
@%p9 bra BB53_11;

add.s64 %rd42, %rd3, %rd71;
ld.local.u32 %r48, [%rd42+104];
mad.lo.s32 %r68, %r48, %r19, %r68;

BB53_11:
div.u32 %r24, %r13, %r18;
add.s32 %r61, %r61, -1;
add.s64 %rd71, %rd71, -4;
setp.gt.s32	%p10, %r62, 0;
mov.u32 %r64, %r24;
@%p10 bra BB53_9;

cvt.u64.u32	%rd72, %r66;
cvt.u64.u32	%rd73, %r67;

BB53_13:
ld.local.u64 %rd43, [%rd5];
shl.b64 %rd44, %rd72, 3;
add.s64 %rd45, %rd43, %rd44;
ld.u64 %rd19, [%rd45];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB53_15;

mul.wide.s32 %rd46, %r33, 4;
add.s64 %rd47, %rd3, %rd46;
ld.local.u32 %rd48, [%rd47+8];
setp.lt.s64	%p12, %rd19, %rd48;
@%p12 bra BB53_16;

BB53_15:
mov.u64 %rd49, $str2;
cvta.global.u64 %rd50, %rd49;
mov.u64 %rd51, $str1;
cvta.global.u64 %rd52, %rd51;
mov.u64 %rd53, __T270;
cvta.global.u64 %rd54, %rd53;
mov.u32 %r49, 151;
mov.u64 %rd55, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd50;
.param .b64 param1;
st.param.b64	[param1+0], %rd52;
.param .b32 param2;
st.param.b32	[param2+0], %r49;
.param .b64 param3;
st.param.b64	[param3+0], %rd54;
.param .b64 param4;
st.param.b64	[param4+0], %rd55;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB53_16:
mul.wide.s32 %rd56, %r33, 4;
add.s64 %rd57, %rd3, %rd56;
ld.local.u32 %rd58, [%rd57+108];
mul.lo.s64 %rd59, %rd58, %rd19;
cvt.u64.u32	%rd60, %r68;
add.s64 %rd61, %rd59, %rd60;
ld.local.u64 %rd62, [%rd3];
shl.b64 %rd63, %rd61, 1;
and.b64 %rd64, %rd63, 8589934590;
add.s64 %rd65, %rd62, %rd64;
ld.local.u64 %rd66, [%rd4];
shl.b64 %rd67, %rd73, 1;
add.s64 %rd68, %rd66, %rd67;
and.b64 %rd20, %rd65, 2;
sub.s64 %rd21, %rd65, %rd20;
ld.u32 %r69, [%rd21];
ld.u16 %rd69, [%rd68];
add.s64 %rd70, %rd65, %rd69;
and.b64 %rd22, %rd70, 2;
mov.u32 %r28, %nctaid.x;

BB53_17:
mov.u32 %r30, %r69;
shl.b32 %r50, %r30, 16;
and.b32 %r51, %r30, -65536;
setp.eq.s64	%p13, %rd22, 0;
selp.b32	%r52, %r50, %r51, %p13;
and.b32 %r53, %r30, 65535;
or.b32 %r54, %r52, %r53;
shr.s32 %r55, %r52, 16;
or.b32 %r56, %r55, %r51;
setp.eq.s64	%p14, %rd20, 0;
selp.b32	%r57, %r56, %r54, %p14;
atom.cas.b32 %r69, [%rd21], %r30, %r57;
setp.ne.s32	%p15, %r30, %r69;
@%p15 bra BB53_17;

mad.lo.s32 %r65, %r28, %r38, %r8;
setp.lt.u32	%p16, %r65, %r34;
@%p16 bra BB53_7;

BB53_19:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[416],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[416],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[416],
.param .u32 _Z29THCudaTensor_scatterAddKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u64 _Z29THCudaTensor_scatterAddKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot54[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<19>;
.reg .b32 %r<49>;
.reg .b64 %rd<113>;


mov.u64 %rd112, __local_depot54;
cvta.local.u64 %SP, %rd112;
ld.param.u32 %r17, [_Z29THCudaTensor_scatterAddKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u64 %rd41, [_Z29THCudaTensor_scatterAddKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z29THCudaTensor_scatterAddKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelImsLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd42, %SP, 416;
cvta.to.local.u64 %rd3, %rd42;
add.u64 %rd43, %SP, 832;
cvta.to.local.u64 %rd4, %rd43;
add.u64 %rd44, %SP, 0;
cvta.to.local.u64 %rd5, %rd44;
mov.u32 %r43, 0;
mov.pred %p1, 0;
@%p1 bra BB54_2;

BB54_1:
mul.wide.s32 %rd45, %r43, 8;
add.s64 %rd46, %rd6, %rd45;
ld.param.u64 %rd47, [%rd46];
add.s64 %rd48, %rd3, %rd45;
st.local.u64 [%rd48], %rd47;
add.s32 %r43, %r43, 1;
setp.lt.u32	%p2, %r43, 52;
@%p2 bra BB54_1;

BB54_2:
mov.u32 %r44, 0;
@%p1 bra BB54_4;

BB54_3:
mul.wide.s32 %rd49, %r44, 8;
add.s64 %rd50, %rd1, %rd49;
ld.param.u64 %rd51, [%rd50];
add.s64 %rd52, %rd4, %rd49;
st.local.u64 [%rd52], %rd51;
add.s32 %r44, %r44, 1;
setp.lt.u32	%p4, %r44, 52;
@%p4 bra BB54_3;

BB54_4:
mov.u32 %r45, 0;
@%p1 bra BB54_6;

BB54_5:
mul.wide.s32 %rd53, %r45, 8;
add.s64 %rd54, %rd2, %rd53;
ld.param.u64 %rd55, [%rd54];
add.s64 %rd56, %rd5, %rd53;
st.local.u64 [%rd56], %rd55;
add.s32 %r45, %r45, 1;
setp.lt.u32	%p6, %r45, 52;
@%p6 bra BB54_5;

BB54_6:
mov.u32 %r21, %ntid.x;
mov.u32 %r22, %ctaid.x;
mov.u32 %r23, %tid.x;
mad.lo.s32 %r24, %r21, %r22, %r23;
cvt.u64.u32	%rd107, %r24;
setp.ge.u64	%p7, %rd107, %rd41;
@%p7 bra BB54_24;

BB54_7:
mov.u64 %rd103, %rd107;
mov.u64 %rd13, %rd103;
ld.local.u32 %r47, [%rd5+408];
mov.u64 %rd111, 0;
mov.u64 %rd110, %rd111;
mov.u64 %rd109, %rd111;
setp.lt.s32	%p8, %r47, 1;
@%p8 bra BB54_18;

not.b32 %r25, %r17;
add.s32 %r46, %r25, %r47;
mul.wide.s32 %rd102, %r47, 8;
mov.u64 %rd111, 0;
mov.u64 %rd110, %rd111;
mov.u64 %rd109, %rd111;
mov.u64 %rd105, %rd13;

BB54_9:
mov.u64 %rd16, %rd105;
add.s32 %r47, %r47, -1;
add.s64 %rd20, %rd5, %rd102;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd63, %rd16, %rd21;
and.b64 %rd64, %rd63, -4294967296;
setp.eq.s64	%p9, %rd64, 0;
@%p9 bra BB54_11;
bra.uni BB54_10;

BB54_11:
cvt.u32.u64	%r26, %rd21;
cvt.u32.u64	%r27, %rd16;
rem.u32 %r28, %r27, %r26;
cvt.u64.u32	%rd108, %r28;
bra.uni BB54_12;

BB54_10:
rem.u64 %rd108, %rd16, %rd21;

BB54_12:
add.s64 %rd65, %rd4, %rd102;
ld.local.u64 %rd66, [%rd20+200];
mul.lo.s64 %rd67, %rd66, %rd108;
add.s64 %rd109, %rd67, %rd109;
ld.local.u64 %rd68, [%rd65+200];
mul.lo.s64 %rd69, %rd68, %rd108;
add.s64 %rd110, %rd69, %rd110;
setp.eq.s32	%p10, %r46, 0;
@%p10 bra BB54_14;

add.s64 %rd70, %rd3, %rd102;
ld.local.u64 %rd71, [%rd70+200];
mul.lo.s64 %rd72, %rd71, %rd108;
add.s64 %rd111, %rd72, %rd111;

BB54_14:
@%p9 bra BB54_16;
bra.uni BB54_15;

BB54_16:
cvt.u32.u64	%r29, %rd21;
cvt.u32.u64	%r30, %rd16;
div.u32 %r31, %r30, %r29;
cvt.u64.u32	%rd106, %r31;
bra.uni BB54_17;

BB54_15:
div.u64 %rd106, %rd16, %rd21;

BB54_17:
mov.u64 %rd31, %rd106;
add.s32 %r46, %r46, -1;
add.s64 %rd102, %rd102, -8;
setp.gt.s32	%p12, %r47, 0;
mov.u64 %rd105, %rd31;
@%p12 bra BB54_9;

BB54_18:
ld.local.u64 %rd75, [%rd5];
shl.b64 %rd76, %rd109, 3;
add.s64 %rd77, %rd75, %rd76;
ld.u64 %rd36, [%rd77];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB54_20;

mul.wide.s32 %rd78, %r17, 8;
add.s64 %rd79, %rd3, %rd78;
ld.local.u64 %rd80, [%rd79+8];
setp.lt.u64	%p14, %rd36, %rd80;
@%p14 bra BB54_21;

BB54_20:
mov.u64 %rd81, $str2;
cvta.global.u64 %rd82, %rd81;
mov.u64 %rd83, $str1;
cvta.global.u64 %rd84, %rd83;
mov.u64 %rd85, __T271;
cvta.global.u64 %rd86, %rd85;
mov.u32 %r32, 151;
mov.u64 %rd87, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd82;
.param .b64 param1;
st.param.b64	[param1+0], %rd84;
.param .b32 param2;
st.param.b32	[param2+0], %r32;
.param .b64 param3;
st.param.b64	[param3+0], %rd86;
.param .b64 param4;
st.param.b64	[param4+0], %rd87;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB54_21:
mul.wide.s32 %rd88, %r17, 8;
add.s64 %rd89, %rd3, %rd88;
ld.local.u64 %rd90, [%rd89+208];
mul.lo.s64 %rd91, %rd90, %rd36;
add.s64 %rd92, %rd91, %rd111;
ld.local.u64 %rd93, [%rd3];
shl.b64 %rd94, %rd92, 1;
add.s64 %rd95, %rd93, %rd94;
ld.local.u64 %rd96, [%rd4];
shl.b64 %rd97, %rd110, 1;
add.s64 %rd98, %rd96, %rd97;
and.b64 %rd37, %rd95, 2;
sub.s64 %rd38, %rd95, %rd37;
ld.u32 %r48, [%rd38];
ld.u16 %rd99, [%rd98];
add.s64 %rd100, %rd99, %rd95;
and.b64 %rd39, %rd100, 2;
mov.u32 %r34, %nctaid.x;
mul.lo.s32 %r14, %r34, %r21;

BB54_22:
mov.u32 %r15, %r48;
shl.b32 %r35, %r15, 16;
and.b32 %r36, %r15, -65536;
setp.eq.s64	%p15, %rd39, 0;
selp.b32	%r37, %r35, %r36, %p15;
and.b32 %r38, %r15, 65535;
or.b32 %r39, %r37, %r38;
shr.s32 %r40, %r37, 16;
or.b32 %r41, %r40, %r36;
setp.eq.s64	%p16, %rd37, 0;
selp.b32	%r42, %r41, %r39, %p16;
atom.cas.b32 %r48, [%rd38], %r15, %r42;
setp.ne.s32	%p17, %r15, %r48;
@%p17 bra BB54_22;

cvt.u64.u32	%rd101, %r14;
add.s64 %rd107, %rd101, %rd13;
setp.lt.u64	%p18, %rd107, %rd41;
@%p18 bra BB54_7;

BB54_24:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjsLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjsLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjsLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .u16 _Z30THCudaTensor_scatterFillKernelIjsLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjsLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjsLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot55[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .b32 %r<23>;
.reg .b64 %rd<38>;


mov.u64 %rd37, __local_depot55;
cvta.local.u64 %SP, %rd37;
ld.param.u16 %rs1, [_Z30THCudaTensor_scatterFillKernelIjsLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r11, [_Z30THCudaTensor_scatterFillKernelIjsLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r12, [_Z30THCudaTensor_scatterFillKernelIjsLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjsLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjsLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd2, %rd10;
mov.u32 %r21, 0;
mov.pred %p1, 0;
@%p1 bra BB55_2;

BB55_1:
mul.wide.s32 %rd11, %r21, 8;
add.s64 %rd12, %rd3, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd2, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r21, %r21, 1;
setp.lt.u32	%p2, %r21, 27;
@%p2 bra BB55_1;

BB55_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r22, %r3, %r14, %r15;
setp.ge.u32	%p3, %r22, %r12;
@%p3 bra BB55_10;

ld.param.u64 %rd15, [%rd1];
cvta.to.global.u64 %rd5, %rd15;
ld.param.u32 %r5, [%rd1+8];
ld.param.u32 %r6, [%rd1+108];
mul.wide.s32 %rd16, %r11, 4;
add.s64 %rd17, %rd2, %rd16;
add.s64 %rd6, %rd17, 8;
mov.u32 %r16, %nctaid.x;
mul.lo.s32 %r7, %r16, %r3;

BB55_4:
rem.u32 %r9, %r22, %r5;
setp.eq.s32	%p4, %r11, 0;
mov.u64 %rd36, 0;
@%p4 bra BB55_6;

ld.local.u32 %r17, [%rd2+108];
mul.lo.s32 %r18, %r17, %r9;
cvt.u64.u32	%rd36, %r18;

BB55_6:
mul.lo.s32 %r19, %r6, %r9;
mul.wide.u32 %rd19, %r19, 8;
add.s64 %rd20, %rd5, %rd19;
ld.global.u64 %rd9, [%rd20];
setp.lt.s64	%p5, %rd9, 0;
@%p5 bra BB55_8;

ld.local.u32 %rd21, [%rd6];
setp.lt.s64	%p6, %rd9, %rd21;
@%p6 bra BB55_9;

BB55_8:
mov.u64 %rd22, $str2;
cvta.global.u64 %rd23, %rd22;
mov.u64 %rd24, $str1;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, __T272;
cvta.global.u64 %rd27, %rd26;
mov.u32 %r20, 176;
mov.u64 %rd28, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd23;
.param .b64 param1;
st.param.b64	[param1+0], %rd25;
.param .b32 param2;
st.param.b32	[param2+0], %r20;
.param .b64 param3;
st.param.b64	[param3+0], %rd27;
.param .b64 param4;
st.param.b64	[param4+0], %rd28;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB55_9:
ld.local.u32 %rd29, [%rd6+100];
mul.lo.s64 %rd30, %rd29, %rd9;
add.s64 %rd31, %rd30, %rd36;
and.b64 %rd32, %rd31, 4294967295;
ld.local.u64 %rd33, [%rd2];
shl.b64 %rd34, %rd32, 1;
add.s64 %rd35, %rd33, %rd34;
st.u16 [%rd35], %rs1;
add.s32 %r22, %r7, %r22;
setp.lt.u32	%p7, %r22, %r12;
@%p7 bra BB55_4;

BB55_10:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjsLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjsLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjsLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .u16 _Z30THCudaTensor_scatterFillKernelIjsLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjsLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjsLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot56[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b16 %rs<2>;
.reg .b32 %r<36>;
.reg .b64 %rd<36>;


mov.u64 %rd35, __local_depot56;
cvta.local.u64 %SP, %rd35;
ld.param.u16 %rs1, [_Z30THCudaTensor_scatterFillKernelIjsLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r16, [_Z30THCudaTensor_scatterFillKernelIjsLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r17, [_Z30THCudaTensor_scatterFillKernelIjsLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjsLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjsLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd7, %SP, 0;
cvta.to.local.u64 %rd2, %rd7;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB56_2;

BB56_1:
mul.wide.s32 %rd8, %r33, 8;
add.s64 %rd9, %rd3, %rd8;
ld.param.u64 %rd10, [%rd9];
add.s64 %rd11, %rd2, %rd8;
st.local.u64 [%rd11], %rd10;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB56_1;

BB56_2:
mov.u32 %r19, %ntid.x;
mov.u32 %r20, %ctaid.x;
mov.u32 %r21, %tid.x;
mad.lo.s32 %r34, %r19, %r20, %r21;
setp.ge.u32	%p3, %r34, %r17;
@%p3 bra BB56_12;

ld.param.u64 %rd12, [%rd1];
cvta.to.global.u64 %rd5, %rd12;
ld.param.v2.u32 {%r22, %r23}, [%rd1+8];
ld.param.u32 %r6, [%rd1+108];
ld.param.u32 %r7, [%rd1+112];

BB56_4:
rem.u32 %r9, %r34, %r23;
setp.eq.s32	%p4, %r16, 1;
mov.u32 %r35, 0;
@%p4 bra BB56_6;

ld.local.u32 %r25, [%rd2+112];
mul.lo.s32 %r35, %r25, %r9;

BB56_6:
div.u32 %r26, %r34, %r23;
rem.u32 %r12, %r26, %r22;
setp.eq.s32	%p5, %r16, 0;
@%p5 bra BB56_8;

ld.local.u32 %r27, [%rd2+108];
mad.lo.s32 %r35, %r27, %r12, %r35;

BB56_8:
mul.lo.s32 %r28, %r7, %r9;
mad.lo.s32 %r29, %r6, %r12, %r28;
mul.wide.u32 %rd13, %r29, 8;
add.s64 %rd14, %rd5, %rd13;
ld.global.u64 %rd6, [%rd14];
setp.lt.s64	%p6, %rd6, 0;
@%p6 bra BB56_10;

mul.wide.s32 %rd15, %r16, 4;
add.s64 %rd16, %rd2, %rd15;
ld.local.u32 %rd17, [%rd16+8];
setp.lt.s64	%p7, %rd6, %rd17;
@%p7 bra BB56_11;

BB56_10:
mov.u64 %rd18, $str2;
cvta.global.u64 %rd19, %rd18;
mov.u64 %rd20, $str1;
cvta.global.u64 %rd21, %rd20;
mov.u64 %rd22, __T273;
cvta.global.u64 %rd23, %rd22;
mov.u32 %r30, 176;
mov.u64 %rd24, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd19;
.param .b64 param1;
st.param.b64	[param1+0], %rd21;
.param .b32 param2;
st.param.b32	[param2+0], %r30;
.param .b64 param3;
st.param.b64	[param3+0], %rd23;
.param .b64 param4;
st.param.b64	[param4+0], %rd24;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB56_11:
mul.wide.s32 %rd25, %r16, 4;
add.s64 %rd26, %rd2, %rd25;
ld.local.u32 %rd27, [%rd26+108];
mul.lo.s64 %rd28, %rd27, %rd6;
cvt.u64.u32	%rd29, %r35;
add.s64 %rd30, %rd28, %rd29;
and.b64 %rd31, %rd30, 4294967295;
ld.local.u64 %rd32, [%rd2];
shl.b64 %rd33, %rd31, 1;
add.s64 %rd34, %rd32, %rd33;
st.u16 [%rd34], %rs1;
mov.u32 %r32, %nctaid.x;
mad.lo.s32 %r34, %r32, %r19, %r34;
setp.lt.u32	%p8, %r34, %r17;
@%p8 bra BB56_4;

BB56_12:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjsLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjsLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjsLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .u16 _Z30THCudaTensor_scatterFillKernelIjsLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjsLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjsLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot57[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b16 %rs<2>;
.reg .b32 %r<46>;
.reg .b64 %rd<36>;


mov.u64 %rd35, __local_depot57;
cvta.local.u64 %SP, %rd35;
ld.param.u16 %rs1, [_Z30THCudaTensor_scatterFillKernelIjsLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r23, [_Z30THCudaTensor_scatterFillKernelIjsLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r24, [_Z30THCudaTensor_scatterFillKernelIjsLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjsLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjsLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd7, %SP, 0;
cvta.to.local.u64 %rd2, %rd7;
mov.u32 %r43, 0;
mov.pred %p1, 0;
@%p1 bra BB57_2;

BB57_1:
mul.wide.s32 %rd8, %r43, 8;
add.s64 %rd9, %rd3, %rd8;
ld.param.u64 %rd10, [%rd9];
add.s64 %rd11, %rd2, %rd8;
st.local.u64 [%rd11], %rd10;
add.s32 %r43, %r43, 1;
setp.lt.u32	%p2, %r43, 27;
@%p2 bra BB57_1;

BB57_2:
mov.u32 %r26, %ntid.x;
mov.u32 %r27, %ctaid.x;
mov.u32 %r28, %tid.x;
mad.lo.s32 %r44, %r26, %r27, %r28;
setp.ge.u32	%p3, %r44, %r24;
@%p3 bra BB57_14;

ld.param.u64 %rd12, [%rd1];
cvta.to.global.u64 %rd5, %rd12;
ld.param.v2.u32 {%r29, %r30}, [%rd1+8];
ld.param.u32 %r6, [%rd1+16];
ld.param.u32 %r7, [%rd1+108];
ld.param.v2.u32 {%r31, %r32}, [%rd1+112];

BB57_4:
rem.u32 %r11, %r44, %r6;
setp.eq.s32	%p4, %r23, 2;
mov.u32 %r45, 0;
@%p4 bra BB57_6;

ld.local.u32 %r34, [%rd2+116];
mul.lo.s32 %r45, %r34, %r11;

BB57_6:
div.u32 %r14, %r44, %r6;
rem.u32 %r15, %r14, %r30;
setp.eq.s32	%p5, %r23, 1;
@%p5 bra BB57_8;

ld.local.u32 %r35, [%rd2+112];
mad.lo.s32 %r45, %r35, %r15, %r45;

BB57_8:
mul.lo.s32 %r36, %r32, %r11;
mad.lo.s32 %r18, %r31, %r15, %r36;
div.u32 %r37, %r14, %r30;
rem.u32 %r19, %r37, %r29;
setp.eq.s32	%p6, %r23, 0;
@%p6 bra BB57_10;

ld.local.u32 %r38, [%rd2+108];
mad.lo.s32 %r45, %r38, %r19, %r45;

BB57_10:
mad.lo.s32 %r39, %r7, %r19, %r18;
mul.wide.u32 %rd13, %r39, 8;
add.s64 %rd14, %rd5, %rd13;
ld.global.u64 %rd6, [%rd14];
setp.lt.s64	%p7, %rd6, 0;
@%p7 bra BB57_12;

mul.wide.s32 %rd15, %r23, 4;
add.s64 %rd16, %rd2, %rd15;
ld.local.u32 %rd17, [%rd16+8];
setp.lt.s64	%p8, %rd6, %rd17;
@%p8 bra BB57_13;

BB57_12:
mov.u64 %rd18, $str2;
cvta.global.u64 %rd19, %rd18;
mov.u64 %rd20, $str1;
cvta.global.u64 %rd21, %rd20;
mov.u64 %rd22, __T274;
cvta.global.u64 %rd23, %rd22;
mov.u32 %r40, 176;
mov.u64 %rd24, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd19;
.param .b64 param1;
st.param.b64	[param1+0], %rd21;
.param .b32 param2;
st.param.b32	[param2+0], %r40;
.param .b64 param3;
st.param.b64	[param3+0], %rd23;
.param .b64 param4;
st.param.b64	[param4+0], %rd24;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB57_13:
mul.wide.s32 %rd25, %r23, 4;
add.s64 %rd26, %rd2, %rd25;
ld.local.u32 %rd27, [%rd26+108];
mul.lo.s64 %rd28, %rd27, %rd6;
cvt.u64.u32	%rd29, %r45;
add.s64 %rd30, %rd28, %rd29;
and.b64 %rd31, %rd30, 4294967295;
ld.local.u64 %rd32, [%rd2];
shl.b64 %rd33, %rd31, 1;
add.s64 %rd34, %rd32, %rd33;
st.u16 [%rd34], %rs1;
mov.u32 %r42, %nctaid.x;
mad.lo.s32 %r44, %r42, %r26, %r44;
setp.lt.u32	%p9, %r44, %r24;
@%p9 bra BB57_4;

BB57_14:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjsLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjsLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjsLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .u16 _Z30THCudaTensor_scatterFillKernelIjsLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjsLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjsLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot58[432];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<12>;
.reg .b16 %rs<2>;
.reg .b32 %r<54>;
.reg .b64 %rd<63>;


mov.u64 %rd62, __local_depot58;
cvta.local.u64 %SP, %rd62;
ld.param.u16 %rs1, [_Z30THCudaTensor_scatterFillKernelIjsLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r24, [_Z30THCudaTensor_scatterFillKernelIjsLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r25, [_Z30THCudaTensor_scatterFillKernelIjsLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd4, _Z30THCudaTensor_scatterFillKernelIjsLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjsLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd17, %SP, 216;
cvta.to.local.u64 %rd2, %rd17;
add.u64 %rd18, %SP, 0;
cvta.to.local.u64 %rd3, %rd18;
mov.u32 %r40, 0;
mov.pred %p1, 0;
@%p1 bra BB58_2;

BB58_1:
mul.wide.s32 %rd19, %r40, 8;
add.s64 %rd20, %rd4, %rd19;
ld.param.u64 %rd21, [%rd20];
add.s64 %rd22, %rd2, %rd19;
st.local.u64 [%rd22], %rd21;
add.s32 %r40, %r40, 1;
setp.lt.u32	%p2, %r40, 27;
@%p2 bra BB58_1;

BB58_2:
mov.u32 %r41, 0;
@%p1 bra BB58_4;

BB58_3:
mul.wide.s32 %rd23, %r41, 8;
add.s64 %rd24, %rd1, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r41, %r41, 1;
setp.lt.u32	%p4, %r41, 27;
@%p4 bra BB58_3;

BB58_4:
mov.u32 %r28, %ntid.x;
mov.u32 %r29, %ctaid.x;
mov.u32 %r30, %tid.x;
mad.lo.s32 %r46, %r28, %r29, %r30;
setp.ge.u32	%p5, %r46, %r25;
@%p5 bra BB58_15;

ld.local.u32 %r6, [%rd3+208];

BB58_6:
mov.u32 %r44, %r46;
mov.u32 %r7, %r44;
cvt.s64.s32	%rd28, %r6;
not.b64 %rd29, %rd28;
mov.u64 %rd30, -26;
sub.s64 %rd31, %rd30, %rd28;
add.s32 %r34, %r6, -1;
sub.s32 %r42, %r34, %r24;
neg.s64 %rd59, %rd29;
neg.s64 %rd60, %rd31;
mov.u32 %r51, 0;
mov.u64 %rd61, 0;
mov.u32 %r52, %r51;
mov.u32 %r47, %r51;
setp.lt.s32	%p6, %r6, 1;
mov.u32 %r43, %r6;
mov.u32 %r45, %r7;
@%p6 bra BB58_11;

BB58_7:
mov.u32 %r48, %r52;
mov.u32 %r53, %r48;
mov.u32 %r11, %r45;
mov.u32 %r10, %r43;
add.s32 %r14, %r10, -1;
shl.b64 %rd32, %rd59, 2;
add.s64 %rd33, %rd3, %rd32;
ld.local.u32 %r15, [%rd33];
rem.u32 %r16, %r11, %r15;
ld.local.u32 %r35, [%rd33+100];
mad.lo.s32 %r47, %r35, %r16, %r47;
setp.eq.s32	%p7, %r42, 0;
@%p7 bra BB58_9;

shl.b64 %rd34, %rd60, 2;
add.s64 %rd35, %rd2, %rd34;
ld.local.u32 %r36, [%rd35];
mad.lo.s32 %r53, %r36, %r16, %r53;

BB58_9:
mov.u32 %r52, %r53;
div.u32 %r20, %r11, %r15;
add.s32 %r42, %r42, -1;
add.s64 %rd60, %rd60, -1;
add.s64 %rd59, %rd59, -1;
setp.gt.s32	%p8, %r14, 0;
mov.u32 %r43, %r14;
mov.u32 %r45, %r20;
@%p8 bra BB58_7;

cvt.u64.u32	%rd61, %r47;
mov.u32 %r51, %r52;

BB58_11:
ld.local.u64 %rd36, [%rd3];
shl.b64 %rd37, %rd61, 3;
add.s64 %rd38, %rd36, %rd37;
ld.u64 %rd16, [%rd38];
setp.lt.s64	%p9, %rd16, 0;
@%p9 bra BB58_13;

mul.wide.s32 %rd39, %r24, 4;
add.s64 %rd40, %rd2, %rd39;
ld.local.u32 %rd41, [%rd40+8];
setp.lt.s64	%p10, %rd16, %rd41;
@%p10 bra BB58_14;

BB58_13:
mov.u64 %rd42, $str2;
cvta.global.u64 %rd43, %rd42;
mov.u64 %rd44, $str1;
cvta.global.u64 %rd45, %rd44;
mov.u64 %rd46, __T275;
cvta.global.u64 %rd47, %rd46;
mov.u32 %r37, 176;
mov.u64 %rd48, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd43;
.param .b64 param1;
st.param.b64	[param1+0], %rd45;
.param .b32 param2;
st.param.b32	[param2+0], %r37;
.param .b64 param3;
st.param.b64	[param3+0], %rd47;
.param .b64 param4;
st.param.b64	[param4+0], %rd48;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB58_14:
mul.wide.s32 %rd49, %r24, 4;
add.s64 %rd50, %rd2, %rd49;
ld.local.u32 %rd51, [%rd50+108];
mul.lo.s64 %rd52, %rd51, %rd16;
cvt.u64.u32	%rd53, %r51;
add.s64 %rd54, %rd52, %rd53;
and.b64 %rd55, %rd54, 4294967295;
ld.local.u64 %rd56, [%rd2];
shl.b64 %rd57, %rd55, 1;
add.s64 %rd58, %rd56, %rd57;
st.u16 [%rd58], %rs1;
mov.u32 %r39, %nctaid.x;
mad.lo.s32 %r46, %r39, %r28, %r7;
setp.lt.u32	%p11, %r46, %r25;
@%p11 bra BB58_6;

BB58_15:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelImsLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelImsLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[416],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelImsLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[416],
.param .u16 _Z30THCudaTensor_scatterFillKernelImsLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelImsLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u64 _Z30THCudaTensor_scatterFillKernelImsLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot59[832];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .b32 %r<33>;
.reg .b64 %rd<99>;


mov.u64 %rd98, __local_depot59;
cvta.local.u64 %SP, %rd98;
ld.param.u16 %rs1, [_Z30THCudaTensor_scatterFillKernelImsLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r11, [_Z30THCudaTensor_scatterFillKernelImsLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u64 %rd34, [_Z30THCudaTensor_scatterFillKernelImsLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd4, _Z30THCudaTensor_scatterFillKernelImsLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelImsLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd35, %SP, 416;
cvta.to.local.u64 %rd2, %rd35;
add.u64 %rd36, %SP, 0;
cvta.to.local.u64 %rd3, %rd36;
mov.u32 %r29, 0;
mov.pred %p1, 0;
@%p1 bra BB59_2;

BB59_1:
mul.wide.s32 %rd37, %r29, 8;
add.s64 %rd38, %rd4, %rd37;
ld.param.u64 %rd39, [%rd38];
add.s64 %rd40, %rd2, %rd37;
st.local.u64 [%rd40], %rd39;
add.s32 %r29, %r29, 1;
setp.lt.u32	%p2, %r29, 52;
@%p2 bra BB59_1;

BB59_2:
mov.u32 %r30, 0;
@%p1 bra BB59_4;

BB59_3:
mul.wide.s32 %rd41, %r30, 8;
add.s64 %rd42, %rd1, %rd41;
ld.param.u64 %rd43, [%rd42];
add.s64 %rd44, %rd3, %rd41;
st.local.u64 [%rd44], %rd43;
add.s32 %r30, %r30, 1;
setp.lt.u32	%p4, %r30, 52;
@%p4 bra BB59_3;

BB59_4:
mov.u32 %r14, %ntid.x;
mov.u32 %r15, %ctaid.x;
mov.u32 %r16, %tid.x;
mad.lo.s32 %r17, %r14, %r15, %r16;
cvt.u64.u32	%rd87, %r17;
setp.ge.u64	%p5, %rd87, %rd34;
@%p5 bra BB59_20;

ld.local.u32 %r5, [%rd3+408];

BB59_6:
mov.u64 %rd83, %rd87;
mov.u64 %rd9, %rd83;
mul.wide.s32 %rd49, %r5, 8;
add.s64 %rd81, %rd3, %rd49;
add.s64 %rd50, %rd49, %rd2;
add.s64 %rd82, %rd50, 200;
add.s32 %r18, %r5, -1;
sub.s32 %r31, %r18, %r11;
mov.u64 %rd95, 0;
mov.u64 %rd90, %rd95;
mov.u64 %rd96, %rd95;
mov.u64 %rd91, %rd95;
setp.lt.s32	%p6, %r5, 1;
mov.u32 %r32, %r5;
mov.u64 %rd85, %rd9;
@%p6 bra BB59_16;

BB59_7:
mov.u64 %rd97, %rd96;
mov.u64 %rd14, %rd85;
mov.u32 %r8, %r32;
add.s32 %r9, %r8, -1;
ld.local.u64 %rd18, [%rd81];
or.b64 %rd51, %rd14, %rd18;
and.b64 %rd52, %rd51, -4294967296;
setp.eq.s64	%p7, %rd52, 0;
@%p7 bra BB59_9;
bra.uni BB59_8;

BB59_9:
cvt.u32.u64	%r19, %rd18;
cvt.u32.u64	%r20, %rd14;
rem.u32 %r21, %r20, %r19;
cvt.u64.u32	%rd88, %r21;
bra.uni BB59_10;

BB59_8:
rem.u64 %rd88, %rd14, %rd18;

BB59_10:
ld.local.u64 %rd53, [%rd81+200];
mul.lo.s64 %rd54, %rd53, %rd88;
add.s64 %rd91, %rd54, %rd91;
setp.eq.s32	%p8, %r31, 0;
@%p8 bra BB59_12;

ld.local.u64 %rd55, [%rd82];
mul.lo.s64 %rd56, %rd55, %rd88;
add.s64 %rd97, %rd56, %rd97;

BB59_12:
mov.u64 %rd96, %rd97;
@%p7 bra BB59_14;
bra.uni BB59_13;

BB59_14:
cvt.u32.u64	%r22, %rd18;
cvt.u32.u64	%r23, %rd14;
div.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd86, %r24;
bra.uni BB59_15;

BB59_13:
div.u64 %rd86, %rd14, %rd18;

BB59_15:
mov.u64 %rd27, %rd86;
add.s32 %r31, %r31, -1;
add.s64 %rd82, %rd82, -8;
add.s64 %rd81, %rd81, -8;
setp.gt.s32	%p10, %r9, 0;
mov.u32 %r32, %r9;
mov.u64 %rd85, %rd27;
mov.u64 %rd90, %rd91;
mov.u64 %rd95, %rd96;
@%p10 bra BB59_7;

BB59_16:
ld.local.u64 %rd59, [%rd3];
shl.b64 %rd60, %rd90, 3;
add.s64 %rd61, %rd59, %rd60;
ld.u64 %rd32, [%rd61];
setp.lt.s64	%p11, %rd32, 0;
@%p11 bra BB59_18;

mul.wide.s32 %rd62, %r11, 8;
add.s64 %rd63, %rd2, %rd62;
ld.local.u64 %rd64, [%rd63+8];
setp.lt.u64	%p12, %rd32, %rd64;
@%p12 bra BB59_19;

BB59_18:
mov.u64 %rd65, $str2;
cvta.global.u64 %rd66, %rd65;
mov.u64 %rd67, $str1;
cvta.global.u64 %rd68, %rd67;
mov.u64 %rd69, __T276;
cvta.global.u64 %rd70, %rd69;
mov.u32 %r25, 176;
mov.u64 %rd71, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd66;
.param .b64 param1;
st.param.b64	[param1+0], %rd68;
.param .b32 param2;
st.param.b32	[param2+0], %r25;
.param .b64 param3;
st.param.b64	[param3+0], %rd70;
.param .b64 param4;
st.param.b64	[param4+0], %rd71;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB59_19:
mul.wide.s32 %rd72, %r11, 8;
add.s64 %rd73, %rd2, %rd72;
ld.local.u64 %rd74, [%rd73+208];
mul.lo.s64 %rd75, %rd74, %rd32;
add.s64 %rd76, %rd75, %rd95;
ld.local.u64 %rd77, [%rd2];
shl.b64 %rd78, %rd76, 1;
add.s64 %rd79, %rd77, %rd78;
st.u16 [%rd79], %rs1;
mov.u32 %r27, %nctaid.x;
mul.lo.s32 %r28, %r27, %r14;
cvt.u64.u32	%rd80, %r28;
add.s64 %rd87, %rd80, %rd9;
setp.lt.u64	%p13, %rd87, %rd34;
@%p13 bra BB59_6;

BB59_20:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot60[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b32 %r<26>;
.reg .b64 %rd<44>;


mov.u64 %rd43, __local_depot60;
cvta.local.u64 %SP, %rd43;
ld.param.u32 %r10, [_Z25THCudaTensor_gatherKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r11, [_Z25THCudaTensor_gatherKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd3, %rd11;
mov.u32 %r24, 0;
mov.pred %p1, 0;
@%p1 bra BB60_2;

BB60_1:
mul.wide.s32 %rd12, %r24, 8;
add.s64 %rd13, %rd4, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd3, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r24, %r24, 1;
setp.lt.u32	%p2, %r24, 27;
@%p2 bra BB60_1;

BB60_2:
mov.u32 %r13, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r25, %r13, %r14, %r15;
setp.ge.u32	%p3, %r25, %r11;
@%p3 bra BB60_10;

ld.param.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd6, %rd16;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd17, [%rd2];
cvta.to.global.u64 %rd7, %rd17;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB60_4:
rem.u32 %r8, %r25, %r5;
setp.eq.s32	%p4, %r10, 0;
mov.u64 %rd42, 0;
@%p4 bra BB60_6;

ld.local.u32 %r16, [%rd3+108];
mul.lo.s32 %r17, %r16, %r8;
cvt.u64.u32	%rd42, %r17;

BB60_6:
mul.lo.s32 %r18, %r6, %r8;
mul.wide.u32 %rd19, %r18, 8;
add.s64 %rd20, %rd7, %rd19;
ld.global.u64 %rd10, [%rd20];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB60_8;

mul.wide.s32 %rd21, %r10, 4;
add.s64 %rd22, %rd3, %rd21;
ld.local.u32 %rd23, [%rd22+8];
setp.lt.s64	%p6, %rd10, %rd23;
@%p6 bra BB60_9;

BB60_8:
mov.u64 %rd24, $str;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, $str1;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, __T279;
cvta.global.u64 %rd29, %rd28;
mov.u32 %r19, 97;
mov.u64 %rd30, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd25;
.param .b64 param1;
st.param.b64	[param1+0], %rd27;
.param .b32 param2;
st.param.b32	[param2+0], %r19;
.param .b64 param3;
st.param.b64	[param3+0], %rd29;
.param .b64 param4;
st.param.b64	[param4+0], %rd30;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB60_9:
mul.lo.s32 %r20, %r4, %r8;
mul.wide.s32 %rd31, %r10, 4;
add.s64 %rd32, %rd3, %rd31;
ld.local.u32 %rd33, [%rd32+108];
mul.lo.s64 %rd34, %rd33, %rd10;
add.s64 %rd35, %rd34, %rd42;
and.b64 %rd36, %rd35, 4294967295;
ld.local.u64 %rd37, [%rd3];
shl.b64 %rd38, %rd36, 2;
add.s64 %rd39, %rd37, %rd38;
ld.u32 %r21, [%rd39];
mul.wide.u32 %rd40, %r20, 4;
add.s64 %rd41, %rd6, %rd40;
st.global.u32 [%rd41], %r21;
mov.u32 %r23, %nctaid.x;
mad.lo.s32 %r25, %r23, %r13, %r25;
setp.lt.u32	%p7, %r25, %r11;
@%p7 bra BB60_4;

BB60_10:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot61[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot61;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r19, [_Z25THCudaTensor_gatherKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r20, [_Z25THCudaTensor_gatherKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r38, 0;
mov.pred %p1, 0;
@%p1 bra BB61_2;

BB61_1:
mul.wide.s32 %rd10, %r38, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r38, %r38, 1;
setp.lt.u32	%p2, %r38, 27;
@%p2 bra BB61_1;

BB61_2:
mov.u32 %r22, %ntid.x;
mov.u32 %r23, %ctaid.x;
mov.u32 %r24, %tid.x;
mad.lo.s32 %r39, %r22, %r23, %r24;
setp.ge.u32	%p3, %r39, %r20;
@%p3 bra BB61_12;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r25, %r26}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB61_4:
rem.u32 %r11, %r39, %r26;
setp.eq.s32	%p4, %r19, 1;
mov.u32 %r40, 0;
@%p4 bra BB61_6;

ld.local.u32 %r28, [%rd3+112];
mul.lo.s32 %r40, %r28, %r11;

BB61_6:
div.u32 %r29, %r39, %r26;
rem.u32 %r14, %r29, %r25;
setp.eq.s32	%p5, %r19, 0;
@%p5 bra BB61_8;

ld.local.u32 %r30, [%rd3+108];
mad.lo.s32 %r40, %r30, %r14, %r40;

BB61_8:
mul.lo.s32 %r31, %r9, %r11;
mul.lo.s32 %r32, %r5, %r11;
mad.lo.s32 %r33, %r8, %r14, %r31;
mad.lo.s32 %r17, %r4, %r14, %r32;
mul.wide.u32 %rd16, %r33, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB61_10;

mul.wide.s32 %rd18, %r19, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p7, %rd8, %rd20;
@%p7 bra BB61_11;

BB61_10:
mov.u64 %rd21, $str;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T280;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r34, 97;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r34;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB61_11:
mul.wide.s32 %rd28, %r19, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r40;
add.s64 %rd33, %rd31, %rd32;
and.b64 %rd34, %rd33, 4294967295;
ld.local.u64 %rd35, [%rd3];
shl.b64 %rd36, %rd34, 2;
add.s64 %rd37, %rd35, %rd36;
ld.u32 %r35, [%rd37];
mul.wide.u32 %rd38, %r17, 4;
add.s64 %rd39, %rd6, %rd38;
st.global.u32 [%rd39], %r35;
mov.u32 %r37, %nctaid.x;
mad.lo.s32 %r39, %r37, %r22, %r39;
setp.lt.u32	%p8, %r39, %r20;
@%p8 bra BB61_4;

BB61_12:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot62[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b32 %r<55>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot62;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r26, [_Z25THCudaTensor_gatherKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r27, [_Z25THCudaTensor_gatherKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r52, 0;
mov.pred %p1, 0;
@%p1 bra BB62_2;

BB62_1:
mul.wide.s32 %rd10, %r52, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r52, %r52, 1;
setp.lt.u32	%p2, %r52, 27;
@%p2 bra BB62_1;

BB62_2:
mov.u32 %r29, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r53, %r29, %r30, %r31;
setp.ge.u32	%p3, %r53, %r27;
@%p3 bra BB62_14;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r32, %r33}, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r34, %r35}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r36, %r37}, [%rd2+112];

BB62_4:
rem.u32 %r14, %r53, %r9;
setp.eq.s32	%p4, %r26, 2;
mov.u32 %r54, 0;
@%p4 bra BB62_6;

ld.local.u32 %r39, [%rd3+116];
mul.lo.s32 %r54, %r39, %r14;

BB62_6:
div.u32 %r17, %r53, %r9;
rem.u32 %r18, %r17, %r35;
setp.eq.s32	%p5, %r26, 1;
@%p5 bra BB62_8;

ld.local.u32 %r40, [%rd3+112];
mad.lo.s32 %r54, %r40, %r18, %r54;

BB62_8:
div.u32 %r41, %r17, %r35;
rem.u32 %r21, %r41, %r34;
setp.eq.s32	%p6, %r26, 0;
@%p6 bra BB62_10;

ld.local.u32 %r42, [%rd3+108];
mad.lo.s32 %r54, %r42, %r21, %r54;

BB62_10:
mul.lo.s32 %r43, %r37, %r14;
mul.lo.s32 %r44, %r33, %r14;
mad.lo.s32 %r45, %r36, %r18, %r43;
mad.lo.s32 %r46, %r32, %r18, %r44;
mad.lo.s32 %r47, %r10, %r21, %r45;
mad.lo.s32 %r24, %r4, %r21, %r46;
mul.wide.u32 %rd16, %r47, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB62_12;

mul.wide.s32 %rd18, %r26, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p8, %rd8, %rd20;
@%p8 bra BB62_13;

BB62_12:
mov.u64 %rd21, $str;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T281;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r48, 97;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r48;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB62_13:
mul.wide.s32 %rd28, %r26, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r54;
add.s64 %rd33, %rd31, %rd32;
and.b64 %rd34, %rd33, 4294967295;
ld.local.u64 %rd35, [%rd3];
shl.b64 %rd36, %rd34, 2;
add.s64 %rd37, %rd35, %rd36;
ld.u32 %r49, [%rd37];
mul.wide.u32 %rd38, %r24, 4;
add.s64 %rd39, %rd6, %rd38;
st.global.u32 [%rd39], %r49;
mov.u32 %r51, %nctaid.x;
mad.lo.s32 %r53, %r51, %r29, %r53;
setp.lt.u32	%p9, %r53, %r27;
@%p9 bra BB62_4;

BB62_14:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot63[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b32 %r<64>;
.reg .b64 %rd<70>;


mov.u64 %rd69, __local_depot63;
cvta.local.u64 %SP, %rd69;
ld.param.u32 %r28, [_Z25THCudaTensor_gatherKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r29, [_Z25THCudaTensor_gatherKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z25THCudaTensor_gatherKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd20, %SP, 216;
cvta.to.local.u64 %rd3, %rd20;
add.u64 %rd21, %SP, 432;
cvta.to.local.u64 %rd4, %rd21;
add.u64 %rd22, %SP, 0;
cvta.to.local.u64 %rd5, %rd22;
mov.u32 %r48, 0;
mov.pred %p1, 0;
@%p1 bra BB63_2;

BB63_1:
mul.wide.s32 %rd23, %r48, 8;
add.s64 %rd24, %rd6, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r48, %r48, 1;
setp.lt.u32	%p2, %r48, 27;
@%p2 bra BB63_1;

BB63_2:
mov.u32 %r49, 0;
@%p1 bra BB63_4;

BB63_3:
mul.wide.s32 %rd27, %r49, 8;
add.s64 %rd28, %rd1, %rd27;
ld.param.u64 %rd29, [%rd28];
add.s64 %rd30, %rd4, %rd27;
st.local.u64 [%rd30], %rd29;
add.s32 %r49, %r49, 1;
setp.lt.u32	%p4, %r49, 27;
@%p4 bra BB63_3;

BB63_4:
mov.u32 %r50, 0;
@%p1 bra BB63_6;

BB63_5:
mul.wide.s32 %rd31, %r50, 8;
add.s64 %rd32, %rd2, %rd31;
ld.param.u64 %rd33, [%rd32];
add.s64 %rd34, %rd5, %rd31;
st.local.u64 [%rd34], %rd33;
add.s32 %r50, %r50, 1;
setp.lt.u32	%p6, %r50, 27;
@%p6 bra BB63_5;

BB63_6:
mov.u32 %r33, %ntid.x;
mov.u32 %r34, %ctaid.x;
mov.u32 %r35, %tid.x;
mad.lo.s32 %r55, %r33, %r34, %r35;
setp.ge.u32	%p7, %r55, %r29;
@%p7 bra BB63_17;

ld.local.u32 %r8, [%rd5+208];

BB63_8:
mov.u32 %r53, %r55;
mov.u32 %r9, %r53;
mul.wide.s32 %rd66, %r8, 4;
add.s32 %r40, %r8, -1;
sub.s32 %r51, %r40, %r28;
mov.u64 %rd68, 0;
mov.u32 %r61, 0;
mov.u64 %rd67, %rd68;
mov.u32 %r57, %r61;
mov.u32 %r62, %r61;
mov.u32 %r56, %r61;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r52, %r8;
mov.u32 %r54, %r9;
@%p8 bra BB63_13;

BB63_9:
mov.u32 %r58, %r62;
mov.u32 %r63, %r58;
mov.u32 %r13, %r54;
mov.u32 %r12, %r52;
add.s64 %rd37, %rd3, %rd66;
add.s32 %r17, %r12, -1;
add.s64 %rd38, %rd5, %rd66;
ld.local.u32 %r18, [%rd38+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r41, [%rd38+104];
mad.lo.s32 %r56, %r41, %r19, %r56;
ld.local.u32 %r42, [%rd37+104];
mad.lo.s32 %r57, %r42, %r19, %r57;
setp.eq.s32	%p9, %r51, 0;
@%p9 bra BB63_11;

add.s64 %rd39, %rd4, %rd66;
ld.local.u32 %r43, [%rd39+104];
mad.lo.s32 %r63, %r43, %r19, %r63;

BB63_11:
mov.u32 %r62, %r63;
div.u32 %r24, %r13, %r18;
add.s32 %r51, %r51, -1;
add.s64 %rd66, %rd66, -4;
setp.gt.s32	%p10, %r17, 0;
mov.u32 %r52, %r17;
mov.u32 %r54, %r24;
@%p10 bra BB63_9;

cvt.u64.u32	%rd67, %r56;
cvt.u64.u32	%rd68, %r57;
mov.u32 %r61, %r62;

BB63_13:
ld.local.u64 %rd40, [%rd5];
shl.b64 %rd41, %rd67, 3;
add.s64 %rd42, %rd40, %rd41;
ld.u64 %rd19, [%rd42];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB63_15;

mul.wide.s32 %rd43, %r28, 4;
add.s64 %rd44, %rd4, %rd43;
ld.local.u32 %rd45, [%rd44+8];
setp.lt.s64	%p12, %rd19, %rd45;
@%p12 bra BB63_16;

BB63_15:
mov.u64 %rd46, $str;
cvta.global.u64 %rd47, %rd46;
mov.u64 %rd48, $str1;
cvta.global.u64 %rd49, %rd48;
mov.u64 %rd50, __T282;
cvta.global.u64 %rd51, %rd50;
mov.u32 %r44, 97;
mov.u64 %rd52, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd47;
.param .b64 param1;
st.param.b64	[param1+0], %rd49;
.param .b32 param2;
st.param.b32	[param2+0], %r44;
.param .b64 param3;
st.param.b64	[param3+0], %rd51;
.param .b64 param4;
st.param.b64	[param4+0], %rd52;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB63_16:
mul.wide.s32 %rd53, %r28, 4;
add.s64 %rd54, %rd4, %rd53;
ld.local.u32 %rd55, [%rd54+108];
mul.lo.s64 %rd56, %rd55, %rd19;
cvt.u64.u32	%rd57, %r61;
add.s64 %rd58, %rd56, %rd57;
ld.local.u64 %rd59, [%rd4];
shl.b64 %rd60, %rd58, 2;
and.b64 %rd61, %rd60, 17179869180;
add.s64 %rd62, %rd59, %rd61;
ld.u32 %r45, [%rd62];
ld.local.u64 %rd63, [%rd3];
shl.b64 %rd64, %rd68, 2;
add.s64 %rd65, %rd63, %rd64;
st.u32 [%rd65], %r45;
mov.u32 %r47, %nctaid.x;
mad.lo.s32 %r55, %r47, %r33, %r9;
setp.lt.u32	%p13, %r55, %r29;
@%p13 bra BB63_8;

BB63_17:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[416],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[416],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[416],
.param .u32 _Z25THCudaTensor_gatherKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u64 _Z25THCudaTensor_gatherKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot64[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<16>;
.reg .b32 %r<38>;
.reg .b64 %rd<117>;


mov.u64 %rd116, __local_depot64;
cvta.local.u64 %SP, %rd116;
ld.param.u32 %r13, [_Z25THCudaTensor_gatherKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u64 %rd38, [_Z25THCudaTensor_gatherKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z25THCudaTensor_gatherKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd39, %SP, 416;
cvta.to.local.u64 %rd3, %rd39;
add.u64 %rd40, %SP, 832;
cvta.to.local.u64 %rd4, %rd40;
add.u64 %rd41, %SP, 0;
cvta.to.local.u64 %rd5, %rd41;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB64_2;

BB64_1:
mul.wide.s32 %rd42, %r33, 8;
add.s64 %rd43, %rd6, %rd42;
ld.param.u64 %rd44, [%rd43];
add.s64 %rd45, %rd3, %rd42;
st.local.u64 [%rd45], %rd44;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 52;
@%p2 bra BB64_1;

BB64_2:
mov.u32 %r34, 0;
@%p1 bra BB64_4;

BB64_3:
mul.wide.s32 %rd46, %r34, 8;
add.s64 %rd47, %rd1, %rd46;
ld.param.u64 %rd48, [%rd47];
add.s64 %rd49, %rd4, %rd46;
st.local.u64 [%rd49], %rd48;
add.s32 %r34, %r34, 1;
setp.lt.u32	%p4, %r34, 52;
@%p4 bra BB64_3;

BB64_4:
mov.u32 %r35, 0;
@%p1 bra BB64_6;

BB64_5:
mul.wide.s32 %rd50, %r35, 8;
add.s64 %rd51, %rd2, %rd50;
ld.param.u64 %rd52, [%rd51];
add.s64 %rd53, %rd5, %rd50;
st.local.u64 [%rd53], %rd52;
add.s32 %r35, %r35, 1;
setp.lt.u32	%p6, %r35, 52;
@%p6 bra BB64_5;

BB64_6:
mov.u32 %r17, %ntid.x;
mov.u32 %r18, %ctaid.x;
mov.u32 %r19, %tid.x;
mad.lo.s32 %r20, %r17, %r18, %r19;
cvt.u64.u32	%rd102, %r20;
setp.ge.u64	%p7, %rd102, %rd38;
@%p7 bra BB64_22;

ld.local.u32 %r7, [%rd5+408];

BB64_8:
mov.u64 %rd98, %rd102;
mov.u64 %rd13, %rd98;
mul.wide.s32 %rd97, %r7, 8;
add.s32 %r21, %r7, -1;
sub.s32 %r36, %r21, %r13;
mov.u64 %rd114, 0;
mov.u64 %rd110, %rd114;
mov.u64 %rd105, %rd114;
mov.u64 %rd115, %rd114;
mov.u64 %rd111, %rd114;
mov.u64 %rd106, %rd114;
setp.lt.s32	%p8, %r7, 1;
mov.u32 %r37, %r7;
mov.u64 %rd100, %rd13;
@%p8 bra BB64_18;

BB64_9:
mov.u64 %rd112, %rd111;
mov.u64 %rd16, %rd100;
mov.u32 %r10, %r37;
add.s32 %r11, %r10, -1;
add.s64 %rd20, %rd5, %rd97;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd60, %rd16, %rd21;
and.b64 %rd61, %rd60, -4294967296;
setp.eq.s64	%p9, %rd61, 0;
@%p9 bra BB64_11;
bra.uni BB64_10;

BB64_11:
cvt.u32.u64	%r22, %rd21;
cvt.u32.u64	%r23, %rd16;
rem.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd103, %r24;
bra.uni BB64_12;

BB64_10:
rem.u64 %rd103, %rd16, %rd21;

BB64_12:
add.s64 %rd62, %rd3, %rd97;
ld.local.u64 %rd63, [%rd20+200];
mul.lo.s64 %rd64, %rd63, %rd103;
add.s64 %rd106, %rd64, %rd106;
ld.local.u64 %rd65, [%rd62+200];
mul.lo.s64 %rd66, %rd65, %rd103;
add.s64 %rd115, %rd66, %rd115;
setp.eq.s32	%p10, %r36, 0;
@%p10 bra BB64_14;

add.s64 %rd67, %rd4, %rd97;
ld.local.u64 %rd68, [%rd67+200];
mul.lo.s64 %rd69, %rd68, %rd103;
add.s64 %rd112, %rd69, %rd112;

BB64_14:
mov.u64 %rd111, %rd112;
@%p9 bra BB64_16;
bra.uni BB64_15;

BB64_16:
cvt.u32.u64	%r25, %rd21;
cvt.u32.u64	%r26, %rd16;
div.u32 %r27, %r26, %r25;
cvt.u64.u32	%rd101, %r27;
bra.uni BB64_17;

BB64_15:
div.u64 %rd101, %rd16, %rd21;

BB64_17:
mov.u64 %rd31, %rd101;
add.s32 %r36, %r36, -1;
add.s64 %rd97, %rd97, -8;
setp.gt.s32	%p12, %r11, 0;
mov.u32 %r37, %r11;
mov.u64 %rd100, %rd31;
mov.u64 %rd105, %rd106;
mov.u64 %rd110, %rd111;
mov.u64 %rd114, %rd115;
@%p12 bra BB64_9;

BB64_18:
ld.local.u64 %rd72, [%rd5];
shl.b64 %rd73, %rd105, 3;
add.s64 %rd74, %rd72, %rd73;
ld.u64 %rd36, [%rd74];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB64_20;

mul.wide.s32 %rd75, %r13, 8;
add.s64 %rd76, %rd4, %rd75;
ld.local.u64 %rd77, [%rd76+8];
setp.lt.u64	%p14, %rd36, %rd77;
@%p14 bra BB64_21;

BB64_20:
mov.u64 %rd78, $str;
cvta.global.u64 %rd79, %rd78;
mov.u64 %rd80, $str1;
cvta.global.u64 %rd81, %rd80;
mov.u64 %rd82, __T284;
cvta.global.u64 %rd83, %rd82;
mov.u32 %r28, 97;
mov.u64 %rd84, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd79;
.param .b64 param1;
st.param.b64	[param1+0], %rd81;
.param .b32 param2;
st.param.b32	[param2+0], %r28;
.param .b64 param3;
st.param.b64	[param3+0], %rd83;
.param .b64 param4;
st.param.b64	[param4+0], %rd84;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB64_21:
mul.wide.s32 %rd85, %r13, 8;
add.s64 %rd86, %rd4, %rd85;
ld.local.u64 %rd87, [%rd86+208];
mul.lo.s64 %rd88, %rd87, %rd36;
add.s64 %rd89, %rd88, %rd110;
ld.local.u64 %rd90, [%rd4];
shl.b64 %rd91, %rd89, 2;
add.s64 %rd92, %rd90, %rd91;
ld.u32 %r29, [%rd92];
ld.local.u64 %rd93, [%rd3];
shl.b64 %rd94, %rd114, 2;
add.s64 %rd95, %rd93, %rd94;
st.u32 [%rd95], %r29;
mov.u32 %r31, %nctaid.x;
mul.lo.s32 %r32, %r31, %r17;
cvt.u64.u32	%rd96, %r32;
add.s64 %rd102, %rd96, %rd13;
setp.lt.u64	%p15, %rd102, %rd38;
@%p15 bra BB64_8;

BB64_22:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot65[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b32 %r<26>;
.reg .b64 %rd<44>;


mov.u64 %rd43, __local_depot65;
cvta.local.u64 %SP, %rd43;
ld.param.u32 %r10, [_Z26THCudaTensor_scatterKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r11, [_Z26THCudaTensor_scatterKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd3, %rd11;
mov.u32 %r24, 0;
mov.pred %p1, 0;
@%p1 bra BB65_2;

BB65_1:
mul.wide.s32 %rd12, %r24, 8;
add.s64 %rd13, %rd4, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd3, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r24, %r24, 1;
setp.lt.u32	%p2, %r24, 27;
@%p2 bra BB65_1;

BB65_2:
mov.u32 %r13, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r25, %r13, %r14, %r15;
setp.ge.u32	%p3, %r25, %r11;
@%p3 bra BB65_10;

ld.param.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd6, %rd16;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd17, [%rd2];
cvta.to.global.u64 %rd7, %rd17;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB65_4:
rem.u32 %r8, %r25, %r5;
setp.eq.s32	%p4, %r10, 0;
mov.u64 %rd42, 0;
@%p4 bra BB65_6;

ld.local.u32 %r16, [%rd3+108];
mul.lo.s32 %r17, %r16, %r8;
cvt.u64.u32	%rd42, %r17;

BB65_6:
mul.lo.s32 %r18, %r6, %r8;
mul.wide.u32 %rd19, %r18, 8;
add.s64 %rd20, %rd7, %rd19;
ld.global.u64 %rd10, [%rd20];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB65_8;

mul.wide.s32 %rd21, %r10, 4;
add.s64 %rd22, %rd3, %rd21;
ld.local.u32 %rd23, [%rd22+8];
setp.lt.s64	%p6, %rd10, %rd23;
@%p6 bra BB65_9;

BB65_8:
mov.u64 %rd24, $str2;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, $str1;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, __T285;
cvta.global.u64 %rd29, %rd28;
mov.u32 %r19, 124;
mov.u64 %rd30, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd25;
.param .b64 param1;
st.param.b64	[param1+0], %rd27;
.param .b32 param2;
st.param.b32	[param2+0], %r19;
.param .b64 param3;
st.param.b64	[param3+0], %rd29;
.param .b64 param4;
st.param.b64	[param4+0], %rd30;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB65_9:
mul.lo.s32 %r20, %r4, %r8;
mul.wide.s32 %rd31, %r10, 4;
add.s64 %rd32, %rd3, %rd31;
ld.local.u32 %rd33, [%rd32+108];
mul.lo.s64 %rd34, %rd33, %rd10;
add.s64 %rd35, %rd34, %rd42;
mul.wide.u32 %rd36, %r20, 4;
add.s64 %rd37, %rd6, %rd36;
ld.global.u32 %r21, [%rd37];
ld.local.u64 %rd38, [%rd3];
shl.b64 %rd39, %rd35, 2;
and.b64 %rd40, %rd39, 17179869180;
add.s64 %rd41, %rd38, %rd40;
st.u32 [%rd41], %r21;
mov.u32 %r23, %nctaid.x;
mad.lo.s32 %r25, %r23, %r13, %r25;
setp.lt.u32	%p7, %r25, %r11;
@%p7 bra BB65_4;

BB65_10:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot66[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot66;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r19, [_Z26THCudaTensor_scatterKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r20, [_Z26THCudaTensor_scatterKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r38, 0;
mov.pred %p1, 0;
@%p1 bra BB66_2;

BB66_1:
mul.wide.s32 %rd10, %r38, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r38, %r38, 1;
setp.lt.u32	%p2, %r38, 27;
@%p2 bra BB66_1;

BB66_2:
mov.u32 %r22, %ntid.x;
mov.u32 %r23, %ctaid.x;
mov.u32 %r24, %tid.x;
mad.lo.s32 %r39, %r22, %r23, %r24;
setp.ge.u32	%p3, %r39, %r20;
@%p3 bra BB66_12;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r25, %r26}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB66_4:
rem.u32 %r11, %r39, %r26;
setp.eq.s32	%p4, %r19, 1;
mov.u32 %r40, 0;
@%p4 bra BB66_6;

ld.local.u32 %r28, [%rd3+112];
mul.lo.s32 %r40, %r28, %r11;

BB66_6:
div.u32 %r29, %r39, %r26;
rem.u32 %r14, %r29, %r25;
setp.eq.s32	%p5, %r19, 0;
@%p5 bra BB66_8;

ld.local.u32 %r30, [%rd3+108];
mad.lo.s32 %r40, %r30, %r14, %r40;

BB66_8:
mul.lo.s32 %r31, %r9, %r11;
mul.lo.s32 %r32, %r5, %r11;
mad.lo.s32 %r33, %r8, %r14, %r31;
mad.lo.s32 %r17, %r4, %r14, %r32;
mul.wide.u32 %rd16, %r33, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB66_10;

mul.wide.s32 %rd18, %r19, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p7, %rd8, %rd20;
@%p7 bra BB66_11;

BB66_10:
mov.u64 %rd21, $str2;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T286;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r34, 124;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r34;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB66_11:
mul.wide.s32 %rd28, %r19, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r40;
add.s64 %rd33, %rd31, %rd32;
mul.wide.u32 %rd34, %r17, 4;
add.s64 %rd35, %rd6, %rd34;
ld.global.u32 %r35, [%rd35];
ld.local.u64 %rd36, [%rd3];
shl.b64 %rd37, %rd33, 2;
and.b64 %rd38, %rd37, 17179869180;
add.s64 %rd39, %rd36, %rd38;
st.u32 [%rd39], %r35;
mov.u32 %r37, %nctaid.x;
mad.lo.s32 %r39, %r37, %r22, %r39;
setp.lt.u32	%p8, %r39, %r20;
@%p8 bra BB66_4;

BB66_12:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot67[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b32 %r<55>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot67;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r26, [_Z26THCudaTensor_scatterKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r27, [_Z26THCudaTensor_scatterKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r52, 0;
mov.pred %p1, 0;
@%p1 bra BB67_2;

BB67_1:
mul.wide.s32 %rd10, %r52, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r52, %r52, 1;
setp.lt.u32	%p2, %r52, 27;
@%p2 bra BB67_1;

BB67_2:
mov.u32 %r29, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r53, %r29, %r30, %r31;
setp.ge.u32	%p3, %r53, %r27;
@%p3 bra BB67_14;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r32, %r33}, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r34, %r35}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r36, %r37}, [%rd2+112];

BB67_4:
rem.u32 %r14, %r53, %r9;
setp.eq.s32	%p4, %r26, 2;
mov.u32 %r54, 0;
@%p4 bra BB67_6;

ld.local.u32 %r39, [%rd3+116];
mul.lo.s32 %r54, %r39, %r14;

BB67_6:
div.u32 %r17, %r53, %r9;
rem.u32 %r18, %r17, %r35;
setp.eq.s32	%p5, %r26, 1;
@%p5 bra BB67_8;

ld.local.u32 %r40, [%rd3+112];
mad.lo.s32 %r54, %r40, %r18, %r54;

BB67_8:
div.u32 %r41, %r17, %r35;
rem.u32 %r21, %r41, %r34;
setp.eq.s32	%p6, %r26, 0;
@%p6 bra BB67_10;

ld.local.u32 %r42, [%rd3+108];
mad.lo.s32 %r54, %r42, %r21, %r54;

BB67_10:
mul.lo.s32 %r43, %r37, %r14;
mul.lo.s32 %r44, %r33, %r14;
mad.lo.s32 %r45, %r36, %r18, %r43;
mad.lo.s32 %r46, %r32, %r18, %r44;
mad.lo.s32 %r47, %r10, %r21, %r45;
mad.lo.s32 %r24, %r4, %r21, %r46;
mul.wide.u32 %rd16, %r47, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB67_12;

mul.wide.s32 %rd18, %r26, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p8, %rd8, %rd20;
@%p8 bra BB67_13;

BB67_12:
mov.u64 %rd21, $str2;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T287;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r48, 124;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r48;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB67_13:
mul.wide.s32 %rd28, %r26, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r54;
add.s64 %rd33, %rd31, %rd32;
mul.wide.u32 %rd34, %r24, 4;
add.s64 %rd35, %rd6, %rd34;
ld.global.u32 %r49, [%rd35];
ld.local.u64 %rd36, [%rd3];
shl.b64 %rd37, %rd33, 2;
and.b64 %rd38, %rd37, 17179869180;
add.s64 %rd39, %rd36, %rd38;
st.u32 [%rd39], %r49;
mov.u32 %r51, %nctaid.x;
mad.lo.s32 %r53, %r51, %r29, %r53;
setp.lt.u32	%p9, %r53, %r27;
@%p9 bra BB67_4;

BB67_14:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot68[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b32 %r<64>;
.reg .b64 %rd<70>;


mov.u64 %rd69, __local_depot68;
cvta.local.u64 %SP, %rd69;
ld.param.u32 %r28, [_Z26THCudaTensor_scatterKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r29, [_Z26THCudaTensor_scatterKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z26THCudaTensor_scatterKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd20, %SP, 216;
cvta.to.local.u64 %rd3, %rd20;
add.u64 %rd21, %SP, 432;
cvta.to.local.u64 %rd4, %rd21;
add.u64 %rd22, %SP, 0;
cvta.to.local.u64 %rd5, %rd22;
mov.u32 %r48, 0;
mov.pred %p1, 0;
@%p1 bra BB68_2;

BB68_1:
mul.wide.s32 %rd23, %r48, 8;
add.s64 %rd24, %rd6, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r48, %r48, 1;
setp.lt.u32	%p2, %r48, 27;
@%p2 bra BB68_1;

BB68_2:
mov.u32 %r49, 0;
@%p1 bra BB68_4;

BB68_3:
mul.wide.s32 %rd27, %r49, 8;
add.s64 %rd28, %rd1, %rd27;
ld.param.u64 %rd29, [%rd28];
add.s64 %rd30, %rd4, %rd27;
st.local.u64 [%rd30], %rd29;
add.s32 %r49, %r49, 1;
setp.lt.u32	%p4, %r49, 27;
@%p4 bra BB68_3;

BB68_4:
mov.u32 %r50, 0;
@%p1 bra BB68_6;

BB68_5:
mul.wide.s32 %rd31, %r50, 8;
add.s64 %rd32, %rd2, %rd31;
ld.param.u64 %rd33, [%rd32];
add.s64 %rd34, %rd5, %rd31;
st.local.u64 [%rd34], %rd33;
add.s32 %r50, %r50, 1;
setp.lt.u32	%p6, %r50, 27;
@%p6 bra BB68_5;

BB68_6:
mov.u32 %r33, %ntid.x;
mov.u32 %r34, %ctaid.x;
mov.u32 %r35, %tid.x;
mad.lo.s32 %r55, %r33, %r34, %r35;
setp.ge.u32	%p7, %r55, %r29;
@%p7 bra BB68_17;

ld.local.u32 %r8, [%rd5+208];

BB68_8:
mov.u32 %r53, %r55;
mov.u32 %r9, %r53;
mul.wide.s32 %rd66, %r8, 4;
add.s32 %r40, %r8, -1;
sub.s32 %r51, %r40, %r28;
mov.u32 %r61, 0;
mov.u64 %rd68, 0;
mov.u64 %rd67, %rd68;
mov.u32 %r62, %r61;
mov.u32 %r57, %r61;
mov.u32 %r56, %r61;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r52, %r8;
mov.u32 %r54, %r9;
@%p8 bra BB68_13;

BB68_9:
mov.u32 %r58, %r62;
mov.u32 %r63, %r58;
mov.u32 %r13, %r54;
mov.u32 %r12, %r52;
add.s64 %rd37, %rd4, %rd66;
add.s32 %r17, %r12, -1;
add.s64 %rd38, %rd5, %rd66;
ld.local.u32 %r18, [%rd38+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r41, [%rd38+104];
mad.lo.s32 %r56, %r41, %r19, %r56;
ld.local.u32 %r42, [%rd37+104];
mad.lo.s32 %r57, %r42, %r19, %r57;
setp.eq.s32	%p9, %r51, 0;
@%p9 bra BB68_11;

add.s64 %rd39, %rd3, %rd66;
ld.local.u32 %r43, [%rd39+104];
mad.lo.s32 %r63, %r43, %r19, %r63;

BB68_11:
mov.u32 %r62, %r63;
div.u32 %r24, %r13, %r18;
add.s32 %r51, %r51, -1;
add.s64 %rd66, %rd66, -4;
setp.gt.s32	%p10, %r17, 0;
mov.u32 %r52, %r17;
mov.u32 %r54, %r24;
@%p10 bra BB68_9;

cvt.u64.u32	%rd67, %r56;
cvt.u64.u32	%rd68, %r57;
mov.u32 %r61, %r62;

BB68_13:
ld.local.u64 %rd40, [%rd5];
shl.b64 %rd41, %rd67, 3;
add.s64 %rd42, %rd40, %rd41;
ld.u64 %rd19, [%rd42];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB68_15;

mul.wide.s32 %rd43, %r28, 4;
add.s64 %rd44, %rd3, %rd43;
ld.local.u32 %rd45, [%rd44+8];
setp.lt.s64	%p12, %rd19, %rd45;
@%p12 bra BB68_16;

BB68_15:
mov.u64 %rd46, $str2;
cvta.global.u64 %rd47, %rd46;
mov.u64 %rd48, $str1;
cvta.global.u64 %rd49, %rd48;
mov.u64 %rd50, __T288;
cvta.global.u64 %rd51, %rd50;
mov.u32 %r44, 124;
mov.u64 %rd52, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd47;
.param .b64 param1;
st.param.b64	[param1+0], %rd49;
.param .b32 param2;
st.param.b32	[param2+0], %r44;
.param .b64 param3;
st.param.b64	[param3+0], %rd51;
.param .b64 param4;
st.param.b64	[param4+0], %rd52;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB68_16:
mul.wide.s32 %rd53, %r28, 4;
add.s64 %rd54, %rd3, %rd53;
ld.local.u32 %rd55, [%rd54+108];
mul.lo.s64 %rd56, %rd55, %rd19;
cvt.u64.u32	%rd57, %r61;
add.s64 %rd58, %rd56, %rd57;
ld.local.u64 %rd59, [%rd4];
shl.b64 %rd60, %rd68, 2;
add.s64 %rd61, %rd59, %rd60;
ld.u32 %r45, [%rd61];
ld.local.u64 %rd62, [%rd3];
shl.b64 %rd63, %rd58, 2;
and.b64 %rd64, %rd63, 17179869180;
add.s64 %rd65, %rd62, %rd64;
st.u32 [%rd65], %r45;
mov.u32 %r47, %nctaid.x;
mad.lo.s32 %r55, %r47, %r33, %r9;
setp.lt.u32	%p13, %r55, %r29;
@%p13 bra BB68_8;

BB68_17:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[416],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[416],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[416],
.param .u32 _Z26THCudaTensor_scatterKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u64 _Z26THCudaTensor_scatterKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot69[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<16>;
.reg .b32 %r<38>;
.reg .b64 %rd<117>;


mov.u64 %rd116, __local_depot69;
cvta.local.u64 %SP, %rd116;
ld.param.u32 %r13, [_Z26THCudaTensor_scatterKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u64 %rd38, [_Z26THCudaTensor_scatterKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z26THCudaTensor_scatterKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd39, %SP, 416;
cvta.to.local.u64 %rd3, %rd39;
add.u64 %rd40, %SP, 832;
cvta.to.local.u64 %rd4, %rd40;
add.u64 %rd41, %SP, 0;
cvta.to.local.u64 %rd5, %rd41;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB69_2;

BB69_1:
mul.wide.s32 %rd42, %r33, 8;
add.s64 %rd43, %rd6, %rd42;
ld.param.u64 %rd44, [%rd43];
add.s64 %rd45, %rd3, %rd42;
st.local.u64 [%rd45], %rd44;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 52;
@%p2 bra BB69_1;

BB69_2:
mov.u32 %r34, 0;
@%p1 bra BB69_4;

BB69_3:
mul.wide.s32 %rd46, %r34, 8;
add.s64 %rd47, %rd1, %rd46;
ld.param.u64 %rd48, [%rd47];
add.s64 %rd49, %rd4, %rd46;
st.local.u64 [%rd49], %rd48;
add.s32 %r34, %r34, 1;
setp.lt.u32	%p4, %r34, 52;
@%p4 bra BB69_3;

BB69_4:
mov.u32 %r35, 0;
@%p1 bra BB69_6;

BB69_5:
mul.wide.s32 %rd50, %r35, 8;
add.s64 %rd51, %rd2, %rd50;
ld.param.u64 %rd52, [%rd51];
add.s64 %rd53, %rd5, %rd50;
st.local.u64 [%rd53], %rd52;
add.s32 %r35, %r35, 1;
setp.lt.u32	%p6, %r35, 52;
@%p6 bra BB69_5;

BB69_6:
mov.u32 %r17, %ntid.x;
mov.u32 %r18, %ctaid.x;
mov.u32 %r19, %tid.x;
mad.lo.s32 %r20, %r17, %r18, %r19;
cvt.u64.u32	%rd102, %r20;
setp.ge.u64	%p7, %rd102, %rd38;
@%p7 bra BB69_22;

ld.local.u32 %r7, [%rd5+408];

BB69_8:
mov.u64 %rd98, %rd102;
mov.u64 %rd13, %rd98;
mul.wide.s32 %rd97, %r7, 8;
add.s32 %r21, %r7, -1;
sub.s32 %r36, %r21, %r13;
mov.u64 %rd113, 0;
mov.u64 %rd108, %rd113;
mov.u64 %rd105, %rd113;
mov.u64 %rd114, %rd113;
mov.u64 %rd109, %rd113;
mov.u64 %rd106, %rd113;
setp.lt.s32	%p8, %r7, 1;
mov.u32 %r37, %r7;
mov.u64 %rd100, %rd13;
@%p8 bra BB69_18;

BB69_9:
mov.u64 %rd115, %rd114;
mov.u64 %rd16, %rd100;
mov.u32 %r10, %r37;
add.s32 %r11, %r10, -1;
add.s64 %rd20, %rd5, %rd97;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd60, %rd16, %rd21;
and.b64 %rd61, %rd60, -4294967296;
setp.eq.s64	%p9, %rd61, 0;
@%p9 bra BB69_11;
bra.uni BB69_10;

BB69_11:
cvt.u32.u64	%r22, %rd21;
cvt.u32.u64	%r23, %rd16;
rem.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd103, %r24;
bra.uni BB69_12;

BB69_10:
rem.u64 %rd103, %rd16, %rd21;

BB69_12:
add.s64 %rd62, %rd4, %rd97;
ld.local.u64 %rd63, [%rd20+200];
mul.lo.s64 %rd64, %rd63, %rd103;
add.s64 %rd106, %rd64, %rd106;
ld.local.u64 %rd65, [%rd62+200];
mul.lo.s64 %rd66, %rd65, %rd103;
add.s64 %rd109, %rd66, %rd109;
setp.eq.s32	%p10, %r36, 0;
@%p10 bra BB69_14;

add.s64 %rd67, %rd3, %rd97;
ld.local.u64 %rd68, [%rd67+200];
mul.lo.s64 %rd69, %rd68, %rd103;
add.s64 %rd115, %rd69, %rd115;

BB69_14:
mov.u64 %rd114, %rd115;
@%p9 bra BB69_16;
bra.uni BB69_15;

BB69_16:
cvt.u32.u64	%r25, %rd21;
cvt.u32.u64	%r26, %rd16;
div.u32 %r27, %r26, %r25;
cvt.u64.u32	%rd101, %r27;
bra.uni BB69_17;

BB69_15:
div.u64 %rd101, %rd16, %rd21;

BB69_17:
mov.u64 %rd31, %rd101;
add.s32 %r36, %r36, -1;
add.s64 %rd97, %rd97, -8;
setp.gt.s32	%p12, %r11, 0;
mov.u32 %r37, %r11;
mov.u64 %rd100, %rd31;
mov.u64 %rd105, %rd106;
mov.u64 %rd108, %rd109;
mov.u64 %rd113, %rd114;
@%p12 bra BB69_9;

BB69_18:
ld.local.u64 %rd72, [%rd5];
shl.b64 %rd73, %rd105, 3;
add.s64 %rd74, %rd72, %rd73;
ld.u64 %rd36, [%rd74];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB69_20;

mul.wide.s32 %rd75, %r13, 8;
add.s64 %rd76, %rd3, %rd75;
ld.local.u64 %rd77, [%rd76+8];
setp.lt.u64	%p14, %rd36, %rd77;
@%p14 bra BB69_21;

BB69_20:
mov.u64 %rd78, $str2;
cvta.global.u64 %rd79, %rd78;
mov.u64 %rd80, $str1;
cvta.global.u64 %rd81, %rd80;
mov.u64 %rd82, __T289;
cvta.global.u64 %rd83, %rd82;
mov.u32 %r28, 124;
mov.u64 %rd84, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd79;
.param .b64 param1;
st.param.b64	[param1+0], %rd81;
.param .b32 param2;
st.param.b32	[param2+0], %r28;
.param .b64 param3;
st.param.b64	[param3+0], %rd83;
.param .b64 param4;
st.param.b64	[param4+0], %rd84;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB69_21:
mul.wide.s32 %rd85, %r13, 8;
add.s64 %rd86, %rd3, %rd85;
ld.local.u64 %rd87, [%rd86+208];
mul.lo.s64 %rd88, %rd87, %rd36;
add.s64 %rd89, %rd88, %rd113;
ld.local.u64 %rd90, [%rd4];
shl.b64 %rd91, %rd108, 2;
add.s64 %rd92, %rd90, %rd91;
ld.u32 %r29, [%rd92];
ld.local.u64 %rd93, [%rd3];
shl.b64 %rd94, %rd89, 2;
add.s64 %rd95, %rd93, %rd94;
st.u32 [%rd95], %r29;
mov.u32 %r31, %nctaid.x;
mul.lo.s32 %r32, %r31, %r17;
cvt.u64.u32	%rd96, %r32;
add.s64 %rd102, %rd96, %rd13;
setp.lt.u64	%p15, %rd102, %rd38;
@%p15 bra BB69_8;

BB69_22:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot70[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b32 %r<27>;
.reg .b64 %rd<44>;


mov.u64 %rd43, __local_depot70;
cvta.local.u64 %SP, %rd43;
ld.param.u32 %r10, [_Z29THCudaTensor_scatterAddKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r11, [_Z29THCudaTensor_scatterAddKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjiLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd3, %rd11;
mov.u32 %r25, 0;
mov.pred %p1, 0;
@%p1 bra BB70_2;

BB70_1:
mul.wide.s32 %rd12, %r25, 8;
add.s64 %rd13, %rd4, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd3, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r25, %r25, 1;
setp.lt.u32	%p2, %r25, 27;
@%p2 bra BB70_1;

BB70_2:
mov.u32 %r13, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r26, %r13, %r14, %r15;
setp.ge.u32	%p3, %r26, %r11;
@%p3 bra BB70_10;

ld.param.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd6, %rd16;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd17, [%rd2];
cvta.to.global.u64 %rd7, %rd17;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB70_4:
rem.u32 %r8, %r26, %r5;
setp.eq.s32	%p4, %r10, 0;
mov.u64 %rd42, 0;
@%p4 bra BB70_6;

ld.local.u32 %r16, [%rd3+108];
mul.lo.s32 %r17, %r16, %r8;
cvt.u64.u32	%rd42, %r17;

BB70_6:
mul.lo.s32 %r18, %r6, %r8;
mul.wide.u32 %rd19, %r18, 8;
add.s64 %rd20, %rd7, %rd19;
ld.global.u64 %rd10, [%rd20];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB70_8;

mul.wide.s32 %rd21, %r10, 4;
add.s64 %rd22, %rd3, %rd21;
ld.local.u32 %rd23, [%rd22+8];
setp.lt.s64	%p6, %rd10, %rd23;
@%p6 bra BB70_9;

BB70_8:
mov.u64 %rd24, $str2;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, $str1;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, __T290;
cvta.global.u64 %rd29, %rd28;
mov.u32 %r19, 151;
mov.u64 %rd30, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd25;
.param .b64 param1;
st.param.b64	[param1+0], %rd27;
.param .b32 param2;
st.param.b32	[param2+0], %r19;
.param .b64 param3;
st.param.b64	[param3+0], %rd29;
.param .b64 param4;
st.param.b64	[param4+0], %rd30;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB70_9:
mul.lo.s32 %r20, %r4, %r8;
mul.wide.s32 %rd31, %r10, 4;
add.s64 %rd32, %rd3, %rd31;
ld.local.u32 %rd33, [%rd32+108];
mul.lo.s64 %rd34, %rd33, %rd10;
add.s64 %rd35, %rd34, %rd42;
and.b64 %rd36, %rd35, 4294967295;
ld.local.u64 %rd37, [%rd3];
shl.b64 %rd38, %rd36, 2;
add.s64 %rd39, %rd37, %rd38;
mul.wide.u32 %rd40, %r20, 4;
add.s64 %rd41, %rd6, %rd40;
ld.global.u32 %r21, [%rd41];
atom.add.u32 %r22, [%rd39], %r21;
mov.u32 %r24, %nctaid.x;
mad.lo.s32 %r26, %r24, %r13, %r26;
setp.lt.u32	%p7, %r26, %r11;
@%p7 bra BB70_4;

BB70_10:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot71[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b32 %r<42>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot71;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r19, [_Z29THCudaTensor_scatterAddKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r20, [_Z29THCudaTensor_scatterAddKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjiLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r39, 0;
mov.pred %p1, 0;
@%p1 bra BB71_2;

BB71_1:
mul.wide.s32 %rd10, %r39, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r39, %r39, 1;
setp.lt.u32	%p2, %r39, 27;
@%p2 bra BB71_1;

BB71_2:
mov.u32 %r22, %ntid.x;
mov.u32 %r23, %ctaid.x;
mov.u32 %r24, %tid.x;
mad.lo.s32 %r40, %r22, %r23, %r24;
setp.ge.u32	%p3, %r40, %r20;
@%p3 bra BB71_12;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r25, %r26}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB71_4:
rem.u32 %r11, %r40, %r26;
setp.eq.s32	%p4, %r19, 1;
mov.u32 %r41, 0;
@%p4 bra BB71_6;

ld.local.u32 %r28, [%rd3+112];
mul.lo.s32 %r41, %r28, %r11;

BB71_6:
div.u32 %r29, %r40, %r26;
rem.u32 %r14, %r29, %r25;
setp.eq.s32	%p5, %r19, 0;
@%p5 bra BB71_8;

ld.local.u32 %r30, [%rd3+108];
mad.lo.s32 %r41, %r30, %r14, %r41;

BB71_8:
mul.lo.s32 %r31, %r9, %r11;
mul.lo.s32 %r32, %r5, %r11;
mad.lo.s32 %r33, %r8, %r14, %r31;
mad.lo.s32 %r17, %r4, %r14, %r32;
mul.wide.u32 %rd16, %r33, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB71_10;

mul.wide.s32 %rd18, %r19, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p7, %rd8, %rd20;
@%p7 bra BB71_11;

BB71_10:
mov.u64 %rd21, $str2;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T291;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r34, 151;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r34;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB71_11:
mul.wide.s32 %rd28, %r19, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r41;
add.s64 %rd33, %rd31, %rd32;
and.b64 %rd34, %rd33, 4294967295;
ld.local.u64 %rd35, [%rd3];
shl.b64 %rd36, %rd34, 2;
add.s64 %rd37, %rd35, %rd36;
mul.wide.u32 %rd38, %r17, 4;
add.s64 %rd39, %rd6, %rd38;
ld.global.u32 %r35, [%rd39];
atom.add.u32 %r36, [%rd37], %r35;
mov.u32 %r38, %nctaid.x;
mad.lo.s32 %r40, %r38, %r22, %r40;
setp.lt.u32	%p8, %r40, %r20;
@%p8 bra BB71_4;

BB71_12:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot72[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b32 %r<56>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot72;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r26, [_Z29THCudaTensor_scatterAddKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r27, [_Z29THCudaTensor_scatterAddKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjiLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r53, 0;
mov.pred %p1, 0;
@%p1 bra BB72_2;

BB72_1:
mul.wide.s32 %rd10, %r53, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r53, %r53, 1;
setp.lt.u32	%p2, %r53, 27;
@%p2 bra BB72_1;

BB72_2:
mov.u32 %r29, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r54, %r29, %r30, %r31;
setp.ge.u32	%p3, %r54, %r27;
@%p3 bra BB72_14;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r32, %r33}, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r34, %r35}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r36, %r37}, [%rd2+112];

BB72_4:
rem.u32 %r14, %r54, %r9;
setp.eq.s32	%p4, %r26, 2;
mov.u32 %r55, 0;
@%p4 bra BB72_6;

ld.local.u32 %r39, [%rd3+116];
mul.lo.s32 %r55, %r39, %r14;

BB72_6:
div.u32 %r17, %r54, %r9;
rem.u32 %r18, %r17, %r35;
setp.eq.s32	%p5, %r26, 1;
@%p5 bra BB72_8;

ld.local.u32 %r40, [%rd3+112];
mad.lo.s32 %r55, %r40, %r18, %r55;

BB72_8:
div.u32 %r41, %r17, %r35;
rem.u32 %r21, %r41, %r34;
setp.eq.s32	%p6, %r26, 0;
@%p6 bra BB72_10;

ld.local.u32 %r42, [%rd3+108];
mad.lo.s32 %r55, %r42, %r21, %r55;

BB72_10:
mul.lo.s32 %r43, %r37, %r14;
mul.lo.s32 %r44, %r33, %r14;
mad.lo.s32 %r45, %r36, %r18, %r43;
mad.lo.s32 %r46, %r32, %r18, %r44;
mad.lo.s32 %r47, %r10, %r21, %r45;
mad.lo.s32 %r24, %r4, %r21, %r46;
mul.wide.u32 %rd16, %r47, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB72_12;

mul.wide.s32 %rd18, %r26, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p8, %rd8, %rd20;
@%p8 bra BB72_13;

BB72_12:
mov.u64 %rd21, $str2;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T292;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r48, 151;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r48;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB72_13:
mul.wide.s32 %rd28, %r26, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r55;
add.s64 %rd33, %rd31, %rd32;
and.b64 %rd34, %rd33, 4294967295;
ld.local.u64 %rd35, [%rd3];
shl.b64 %rd36, %rd34, 2;
add.s64 %rd37, %rd35, %rd36;
mul.wide.u32 %rd38, %r24, 4;
add.s64 %rd39, %rd6, %rd38;
ld.global.u32 %r49, [%rd39];
atom.add.u32 %r50, [%rd37], %r49;
mov.u32 %r52, %nctaid.x;
mad.lo.s32 %r54, %r52, %r29, %r54;
setp.lt.u32	%p9, %r54, %r27;
@%p9 bra BB72_4;

BB72_14:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot73[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b32 %r<60>;
.reg .b64 %rd<70>;


mov.u64 %rd69, __local_depot73;
cvta.local.u64 %SP, %rd69;
ld.param.u32 %r28, [_Z29THCudaTensor_scatterAddKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r29, [_Z29THCudaTensor_scatterAddKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z29THCudaTensor_scatterAddKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd20, %SP, 216;
cvta.to.local.u64 %rd3, %rd20;
add.u64 %rd21, %SP, 432;
cvta.to.local.u64 %rd4, %rd21;
add.u64 %rd22, %SP, 0;
cvta.to.local.u64 %rd5, %rd22;
mov.u32 %r49, 0;
mov.pred %p1, 0;
@%p1 bra BB73_2;

BB73_1:
mul.wide.s32 %rd23, %r49, 8;
add.s64 %rd24, %rd6, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r49, %r49, 1;
setp.lt.u32	%p2, %r49, 27;
@%p2 bra BB73_1;

BB73_2:
mov.u32 %r50, 0;
@%p1 bra BB73_4;

BB73_3:
mul.wide.s32 %rd27, %r50, 8;
add.s64 %rd28, %rd1, %rd27;
ld.param.u64 %rd29, [%rd28];
add.s64 %rd30, %rd4, %rd27;
st.local.u64 [%rd30], %rd29;
add.s32 %r50, %r50, 1;
setp.lt.u32	%p4, %r50, 27;
@%p4 bra BB73_3;

BB73_4:
mov.u32 %r51, 0;
@%p1 bra BB73_6;

BB73_5:
mul.wide.s32 %rd31, %r51, 8;
add.s64 %rd32, %rd2, %rd31;
ld.param.u64 %rd33, [%rd32];
add.s64 %rd34, %rd5, %rd31;
st.local.u64 [%rd34], %rd33;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p6, %r51, 27;
@%p6 bra BB73_5;

BB73_6:
mov.u32 %r33, %ntid.x;
mov.u32 %r34, %ctaid.x;
mov.u32 %r35, %tid.x;
mad.lo.s32 %r56, %r33, %r34, %r35;
setp.ge.u32	%p7, %r56, %r29;
@%p7 bra BB73_17;

BB73_7:
mov.u32 %r54, %r56;
mov.u32 %r8, %r54;
ld.local.u32 %r53, [%rd5+208];
mov.u32 %r59, 0;
mov.u64 %rd68, 0;
mov.u64 %rd67, %rd68;
setp.lt.s32	%p8, %r53, 1;
@%p8 bra BB73_13;

not.b32 %r40, %r28;
add.s32 %r52, %r40, %r53;
mul.wide.s32 %rd66, %r53, 4;
mov.u32 %r59, 0;
mov.u32 %r58, %r59;
mov.u32 %r57, %r59;
mov.u32 %r55, %r8;

BB73_9:
mov.u32 %r13, %r55;
add.s64 %rd37, %rd4, %rd66;
add.s32 %r53, %r53, -1;
add.s64 %rd38, %rd5, %rd66;
ld.local.u32 %r18, [%rd38+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r41, [%rd38+104];
mad.lo.s32 %r57, %r41, %r19, %r57;
ld.local.u32 %r42, [%rd37+104];
mad.lo.s32 %r58, %r42, %r19, %r58;
setp.eq.s32	%p9, %r52, 0;
@%p9 bra BB73_11;

add.s64 %rd39, %rd3, %rd66;
ld.local.u32 %r43, [%rd39+104];
mad.lo.s32 %r59, %r43, %r19, %r59;

BB73_11:
div.u32 %r24, %r13, %r18;
add.s32 %r52, %r52, -1;
add.s64 %rd66, %rd66, -4;
setp.gt.s32	%p10, %r53, 0;
mov.u32 %r55, %r24;
@%p10 bra BB73_9;

cvt.u64.u32	%rd67, %r57;
cvt.u64.u32	%rd68, %r58;

BB73_13:
ld.local.u64 %rd40, [%rd5];
shl.b64 %rd41, %rd67, 3;
add.s64 %rd42, %rd40, %rd41;
ld.u64 %rd19, [%rd42];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB73_15;

mul.wide.s32 %rd43, %r28, 4;
add.s64 %rd44, %rd3, %rd43;
ld.local.u32 %rd45, [%rd44+8];
setp.lt.s64	%p12, %rd19, %rd45;
@%p12 bra BB73_16;

BB73_15:
mov.u64 %rd46, $str2;
cvta.global.u64 %rd47, %rd46;
mov.u64 %rd48, $str1;
cvta.global.u64 %rd49, %rd48;
mov.u64 %rd50, __T293;
cvta.global.u64 %rd51, %rd50;
mov.u32 %r44, 151;
mov.u64 %rd52, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd47;
.param .b64 param1;
st.param.b64	[param1+0], %rd49;
.param .b32 param2;
st.param.b32	[param2+0], %r44;
.param .b64 param3;
st.param.b64	[param3+0], %rd51;
.param .b64 param4;
st.param.b64	[param4+0], %rd52;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB73_16:
mul.wide.s32 %rd53, %r28, 4;
add.s64 %rd54, %rd3, %rd53;
ld.local.u32 %rd55, [%rd54+108];
mul.lo.s64 %rd56, %rd55, %rd19;
cvt.u64.u32	%rd57, %r59;
add.s64 %rd58, %rd56, %rd57;
ld.local.u64 %rd59, [%rd3];
shl.b64 %rd60, %rd58, 2;
and.b64 %rd61, %rd60, 17179869180;
add.s64 %rd62, %rd59, %rd61;
ld.local.u64 %rd63, [%rd4];
shl.b64 %rd64, %rd68, 2;
add.s64 %rd65, %rd63, %rd64;
ld.u32 %r45, [%rd65];
atom.add.u32 %r46, [%rd62], %r45;
mov.u32 %r48, %nctaid.x;
mad.lo.s32 %r56, %r48, %r33, %r8;
setp.lt.u32	%p13, %r56, %r29;
@%p13 bra BB73_7;

BB73_17:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[416],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[416],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[416],
.param .u32 _Z29THCudaTensor_scatterAddKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u64 _Z29THCudaTensor_scatterAddKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot74[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<16>;
.reg .b32 %r<39>;
.reg .b64 %rd<108>;


mov.u64 %rd107, __local_depot74;
cvta.local.u64 %SP, %rd107;
ld.param.u32 %r13, [_Z29THCudaTensor_scatterAddKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u64 %rd38, [_Z29THCudaTensor_scatterAddKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z29THCudaTensor_scatterAddKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelImiLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd39, %SP, 416;
cvta.to.local.u64 %rd3, %rd39;
add.u64 %rd40, %SP, 832;
cvta.to.local.u64 %rd4, %rd40;
add.u64 %rd41, %SP, 0;
cvta.to.local.u64 %rd5, %rd41;
mov.u32 %r34, 0;
mov.pred %p1, 0;
@%p1 bra BB74_2;

BB74_1:
mul.wide.s32 %rd42, %r34, 8;
add.s64 %rd43, %rd6, %rd42;
ld.param.u64 %rd44, [%rd43];
add.s64 %rd45, %rd3, %rd42;
st.local.u64 [%rd45], %rd44;
add.s32 %r34, %r34, 1;
setp.lt.u32	%p2, %r34, 52;
@%p2 bra BB74_1;

BB74_2:
mov.u32 %r35, 0;
@%p1 bra BB74_4;

BB74_3:
mul.wide.s32 %rd46, %r35, 8;
add.s64 %rd47, %rd1, %rd46;
ld.param.u64 %rd48, [%rd47];
add.s64 %rd49, %rd4, %rd46;
st.local.u64 [%rd49], %rd48;
add.s32 %r35, %r35, 1;
setp.lt.u32	%p4, %r35, 52;
@%p4 bra BB74_3;

BB74_4:
mov.u32 %r36, 0;
@%p1 bra BB74_6;

BB74_5:
mul.wide.s32 %rd50, %r36, 8;
add.s64 %rd51, %rd2, %rd50;
ld.param.u64 %rd52, [%rd51];
add.s64 %rd53, %rd5, %rd50;
st.local.u64 [%rd53], %rd52;
add.s32 %r36, %r36, 1;
setp.lt.u32	%p6, %r36, 52;
@%p6 bra BB74_5;

BB74_6:
mov.u32 %r17, %ntid.x;
mov.u32 %r18, %ctaid.x;
mov.u32 %r19, %tid.x;
mad.lo.s32 %r20, %r17, %r18, %r19;
cvt.u64.u32	%rd102, %r20;
setp.ge.u64	%p7, %rd102, %rd38;
@%p7 bra BB74_22;

BB74_7:
mov.u64 %rd98, %rd102;
mov.u64 %rd13, %rd98;
ld.local.u32 %r38, [%rd5+408];
mov.u64 %rd106, 0;
mov.u64 %rd105, %rd106;
mov.u64 %rd104, %rd106;
setp.lt.s32	%p8, %r38, 1;
@%p8 bra BB74_18;

not.b32 %r21, %r13;
add.s32 %r37, %r21, %r38;
mul.wide.s32 %rd97, %r38, 8;
mov.u64 %rd106, 0;
mov.u64 %rd105, %rd106;
mov.u64 %rd104, %rd106;
mov.u64 %rd100, %rd13;

BB74_9:
mov.u64 %rd16, %rd100;
add.s32 %r38, %r38, -1;
add.s64 %rd20, %rd5, %rd97;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd60, %rd16, %rd21;
and.b64 %rd61, %rd60, -4294967296;
setp.eq.s64	%p9, %rd61, 0;
@%p9 bra BB74_11;
bra.uni BB74_10;

BB74_11:
cvt.u32.u64	%r22, %rd21;
cvt.u32.u64	%r23, %rd16;
rem.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd103, %r24;
bra.uni BB74_12;

BB74_10:
rem.u64 %rd103, %rd16, %rd21;

BB74_12:
add.s64 %rd62, %rd4, %rd97;
ld.local.u64 %rd63, [%rd20+200];
mul.lo.s64 %rd64, %rd63, %rd103;
add.s64 %rd104, %rd64, %rd104;
ld.local.u64 %rd65, [%rd62+200];
mul.lo.s64 %rd66, %rd65, %rd103;
add.s64 %rd105, %rd66, %rd105;
setp.eq.s32	%p10, %r37, 0;
@%p10 bra BB74_14;

add.s64 %rd67, %rd3, %rd97;
ld.local.u64 %rd68, [%rd67+200];
mul.lo.s64 %rd69, %rd68, %rd103;
add.s64 %rd106, %rd69, %rd106;

BB74_14:
@%p9 bra BB74_16;
bra.uni BB74_15;

BB74_16:
cvt.u32.u64	%r25, %rd21;
cvt.u32.u64	%r26, %rd16;
div.u32 %r27, %r26, %r25;
cvt.u64.u32	%rd101, %r27;
bra.uni BB74_17;

BB74_15:
div.u64 %rd101, %rd16, %rd21;

BB74_17:
mov.u64 %rd31, %rd101;
add.s32 %r37, %r37, -1;
add.s64 %rd97, %rd97, -8;
setp.gt.s32	%p12, %r38, 0;
mov.u64 %rd100, %rd31;
@%p12 bra BB74_9;

BB74_18:
ld.local.u64 %rd72, [%rd5];
shl.b64 %rd73, %rd104, 3;
add.s64 %rd74, %rd72, %rd73;
ld.u64 %rd36, [%rd74];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB74_20;

mul.wide.s32 %rd75, %r13, 8;
add.s64 %rd76, %rd3, %rd75;
ld.local.u64 %rd77, [%rd76+8];
setp.lt.u64	%p14, %rd36, %rd77;
@%p14 bra BB74_21;

BB74_20:
mov.u64 %rd78, $str2;
cvta.global.u64 %rd79, %rd78;
mov.u64 %rd80, $str1;
cvta.global.u64 %rd81, %rd80;
mov.u64 %rd82, __T294;
cvta.global.u64 %rd83, %rd82;
mov.u32 %r28, 151;
mov.u64 %rd84, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd79;
.param .b64 param1;
st.param.b64	[param1+0], %rd81;
.param .b32 param2;
st.param.b32	[param2+0], %r28;
.param .b64 param3;
st.param.b64	[param3+0], %rd83;
.param .b64 param4;
st.param.b64	[param4+0], %rd84;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB74_21:
mul.wide.s32 %rd85, %r13, 8;
add.s64 %rd86, %rd3, %rd85;
ld.local.u64 %rd87, [%rd86+208];
mul.lo.s64 %rd88, %rd87, %rd36;
add.s64 %rd89, %rd88, %rd106;
ld.local.u64 %rd90, [%rd3];
shl.b64 %rd91, %rd89, 2;
add.s64 %rd92, %rd90, %rd91;
ld.local.u64 %rd93, [%rd4];
shl.b64 %rd94, %rd105, 2;
add.s64 %rd95, %rd93, %rd94;
ld.u32 %r29, [%rd95];
atom.add.u32 %r30, [%rd92], %r29;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r33, %r32, %r17;
cvt.u64.u32	%rd96, %r33;
add.s64 %rd102, %rd96, %rd13;
setp.lt.u64	%p15, %rd102, %rd38;
@%p15 bra BB74_7;

BB74_22:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjiLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjiLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjiLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .u32 _Z30THCudaTensor_scatterFillKernelIjiLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjiLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjiLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot75[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b32 %r<24>;
.reg .b64 %rd<38>;


mov.u64 %rd37, __local_depot75;
cvta.local.u64 %SP, %rd37;
ld.param.u32 %r11, [_Z30THCudaTensor_scatterFillKernelIjiLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r12, [_Z30THCudaTensor_scatterFillKernelIjiLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r13, [_Z30THCudaTensor_scatterFillKernelIjiLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjiLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjiLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd2, %rd10;
mov.u32 %r22, 0;
mov.pred %p1, 0;
@%p1 bra BB75_2;

BB75_1:
mul.wide.s32 %rd11, %r22, 8;
add.s64 %rd12, %rd3, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd2, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r22, %r22, 1;
setp.lt.u32	%p2, %r22, 27;
@%p2 bra BB75_1;

BB75_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r15, %ctaid.x;
mov.u32 %r16, %tid.x;
mad.lo.s32 %r23, %r3, %r15, %r16;
setp.ge.u32	%p3, %r23, %r13;
@%p3 bra BB75_10;

ld.param.u64 %rd15, [%rd1];
cvta.to.global.u64 %rd5, %rd15;
ld.param.u32 %r5, [%rd1+8];
ld.param.u32 %r6, [%rd1+108];
mul.wide.s32 %rd16, %r12, 4;
add.s64 %rd17, %rd2, %rd16;
add.s64 %rd6, %rd17, 8;
mov.u32 %r17, %nctaid.x;
mul.lo.s32 %r7, %r17, %r3;

BB75_4:
rem.u32 %r9, %r23, %r5;
setp.eq.s32	%p4, %r12, 0;
mov.u64 %rd36, 0;
@%p4 bra BB75_6;

ld.local.u32 %r18, [%rd2+108];
mul.lo.s32 %r19, %r18, %r9;
cvt.u64.u32	%rd36, %r19;

BB75_6:
mul.lo.s32 %r20, %r6, %r9;
mul.wide.u32 %rd19, %r20, 8;
add.s64 %rd20, %rd5, %rd19;
ld.global.u64 %rd9, [%rd20];
setp.lt.s64	%p5, %rd9, 0;
@%p5 bra BB75_8;

ld.local.u32 %rd21, [%rd6];
setp.lt.s64	%p6, %rd9, %rd21;
@%p6 bra BB75_9;

BB75_8:
mov.u64 %rd22, $str2;
cvta.global.u64 %rd23, %rd22;
mov.u64 %rd24, $str1;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, __T295;
cvta.global.u64 %rd27, %rd26;
mov.u32 %r21, 176;
mov.u64 %rd28, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd23;
.param .b64 param1;
st.param.b64	[param1+0], %rd25;
.param .b32 param2;
st.param.b32	[param2+0], %r21;
.param .b64 param3;
st.param.b64	[param3+0], %rd27;
.param .b64 param4;
st.param.b64	[param4+0], %rd28;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB75_9:
ld.local.u32 %rd29, [%rd6+100];
mul.lo.s64 %rd30, %rd29, %rd9;
add.s64 %rd31, %rd30, %rd36;
and.b64 %rd32, %rd31, 4294967295;
ld.local.u64 %rd33, [%rd2];
shl.b64 %rd34, %rd32, 2;
add.s64 %rd35, %rd33, %rd34;
st.u32 [%rd35], %r11;
add.s32 %r23, %r7, %r23;
setp.lt.u32	%p7, %r23, %r13;
@%p7 bra BB75_4;

BB75_10:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjiLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjiLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjiLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .u32 _Z30THCudaTensor_scatterFillKernelIjiLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjiLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjiLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot76[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b32 %r<37>;
.reg .b64 %rd<36>;


mov.u64 %rd35, __local_depot76;
cvta.local.u64 %SP, %rd35;
ld.param.u32 %r16, [_Z30THCudaTensor_scatterFillKernelIjiLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r17, [_Z30THCudaTensor_scatterFillKernelIjiLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r18, [_Z30THCudaTensor_scatterFillKernelIjiLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjiLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjiLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd7, %SP, 0;
cvta.to.local.u64 %rd2, %rd7;
mov.u32 %r34, 0;
mov.pred %p1, 0;
@%p1 bra BB76_2;

BB76_1:
mul.wide.s32 %rd8, %r34, 8;
add.s64 %rd9, %rd3, %rd8;
ld.param.u64 %rd10, [%rd9];
add.s64 %rd11, %rd2, %rd8;
st.local.u64 [%rd11], %rd10;
add.s32 %r34, %r34, 1;
setp.lt.u32	%p2, %r34, 27;
@%p2 bra BB76_1;

BB76_2:
mov.u32 %r20, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r35, %r20, %r21, %r22;
setp.ge.u32	%p3, %r35, %r18;
@%p3 bra BB76_12;

ld.param.u64 %rd12, [%rd1];
cvta.to.global.u64 %rd5, %rd12;
ld.param.v2.u32 {%r23, %r24}, [%rd1+8];
ld.param.u32 %r6, [%rd1+108];
ld.param.u32 %r7, [%rd1+112];

BB76_4:
rem.u32 %r9, %r35, %r24;
setp.eq.s32	%p4, %r17, 1;
mov.u32 %r36, 0;
@%p4 bra BB76_6;

ld.local.u32 %r26, [%rd2+112];
mul.lo.s32 %r36, %r26, %r9;

BB76_6:
div.u32 %r27, %r35, %r24;
rem.u32 %r12, %r27, %r23;
setp.eq.s32	%p5, %r17, 0;
@%p5 bra BB76_8;

ld.local.u32 %r28, [%rd2+108];
mad.lo.s32 %r36, %r28, %r12, %r36;

BB76_8:
mul.lo.s32 %r29, %r7, %r9;
mad.lo.s32 %r30, %r6, %r12, %r29;
mul.wide.u32 %rd13, %r30, 8;
add.s64 %rd14, %rd5, %rd13;
ld.global.u64 %rd6, [%rd14];
setp.lt.s64	%p6, %rd6, 0;
@%p6 bra BB76_10;

mul.wide.s32 %rd15, %r17, 4;
add.s64 %rd16, %rd2, %rd15;
ld.local.u32 %rd17, [%rd16+8];
setp.lt.s64	%p7, %rd6, %rd17;
@%p7 bra BB76_11;

BB76_10:
mov.u64 %rd18, $str2;
cvta.global.u64 %rd19, %rd18;
mov.u64 %rd20, $str1;
cvta.global.u64 %rd21, %rd20;
mov.u64 %rd22, __T296;
cvta.global.u64 %rd23, %rd22;
mov.u32 %r31, 176;
mov.u64 %rd24, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd19;
.param .b64 param1;
st.param.b64	[param1+0], %rd21;
.param .b32 param2;
st.param.b32	[param2+0], %r31;
.param .b64 param3;
st.param.b64	[param3+0], %rd23;
.param .b64 param4;
st.param.b64	[param4+0], %rd24;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB76_11:
mul.wide.s32 %rd25, %r17, 4;
add.s64 %rd26, %rd2, %rd25;
ld.local.u32 %rd27, [%rd26+108];
mul.lo.s64 %rd28, %rd27, %rd6;
cvt.u64.u32	%rd29, %r36;
add.s64 %rd30, %rd28, %rd29;
and.b64 %rd31, %rd30, 4294967295;
ld.local.u64 %rd32, [%rd2];
shl.b64 %rd33, %rd31, 2;
add.s64 %rd34, %rd32, %rd33;
st.u32 [%rd34], %r16;
mov.u32 %r33, %nctaid.x;
mad.lo.s32 %r35, %r33, %r20, %r35;
setp.lt.u32	%p8, %r35, %r18;
@%p8 bra BB76_4;

BB76_12:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjiLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjiLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjiLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .u32 _Z30THCudaTensor_scatterFillKernelIjiLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjiLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjiLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot77[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b32 %r<47>;
.reg .b64 %rd<36>;


mov.u64 %rd35, __local_depot77;
cvta.local.u64 %SP, %rd35;
ld.param.u32 %r23, [_Z30THCudaTensor_scatterFillKernelIjiLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r24, [_Z30THCudaTensor_scatterFillKernelIjiLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r25, [_Z30THCudaTensor_scatterFillKernelIjiLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjiLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjiLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd7, %SP, 0;
cvta.to.local.u64 %rd2, %rd7;
mov.u32 %r44, 0;
mov.pred %p1, 0;
@%p1 bra BB77_2;

BB77_1:
mul.wide.s32 %rd8, %r44, 8;
add.s64 %rd9, %rd3, %rd8;
ld.param.u64 %rd10, [%rd9];
add.s64 %rd11, %rd2, %rd8;
st.local.u64 [%rd11], %rd10;
add.s32 %r44, %r44, 1;
setp.lt.u32	%p2, %r44, 27;
@%p2 bra BB77_1;

BB77_2:
mov.u32 %r27, %ntid.x;
mov.u32 %r28, %ctaid.x;
mov.u32 %r29, %tid.x;
mad.lo.s32 %r45, %r27, %r28, %r29;
setp.ge.u32	%p3, %r45, %r25;
@%p3 bra BB77_14;

ld.param.u64 %rd12, [%rd1];
cvta.to.global.u64 %rd5, %rd12;
ld.param.v2.u32 {%r30, %r31}, [%rd1+8];
ld.param.u32 %r6, [%rd1+16];
ld.param.u32 %r7, [%rd1+108];
ld.param.v2.u32 {%r32, %r33}, [%rd1+112];

BB77_4:
rem.u32 %r11, %r45, %r6;
setp.eq.s32	%p4, %r24, 2;
mov.u32 %r46, 0;
@%p4 bra BB77_6;

ld.local.u32 %r35, [%rd2+116];
mul.lo.s32 %r46, %r35, %r11;

BB77_6:
div.u32 %r14, %r45, %r6;
rem.u32 %r15, %r14, %r31;
setp.eq.s32	%p5, %r24, 1;
@%p5 bra BB77_8;

ld.local.u32 %r36, [%rd2+112];
mad.lo.s32 %r46, %r36, %r15, %r46;

BB77_8:
mul.lo.s32 %r37, %r33, %r11;
mad.lo.s32 %r18, %r32, %r15, %r37;
div.u32 %r38, %r14, %r31;
rem.u32 %r19, %r38, %r30;
setp.eq.s32	%p6, %r24, 0;
@%p6 bra BB77_10;

ld.local.u32 %r39, [%rd2+108];
mad.lo.s32 %r46, %r39, %r19, %r46;

BB77_10:
mad.lo.s32 %r40, %r7, %r19, %r18;
mul.wide.u32 %rd13, %r40, 8;
add.s64 %rd14, %rd5, %rd13;
ld.global.u64 %rd6, [%rd14];
setp.lt.s64	%p7, %rd6, 0;
@%p7 bra BB77_12;

mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd16, %rd2, %rd15;
ld.local.u32 %rd17, [%rd16+8];
setp.lt.s64	%p8, %rd6, %rd17;
@%p8 bra BB77_13;

BB77_12:
mov.u64 %rd18, $str2;
cvta.global.u64 %rd19, %rd18;
mov.u64 %rd20, $str1;
cvta.global.u64 %rd21, %rd20;
mov.u64 %rd22, __T297;
cvta.global.u64 %rd23, %rd22;
mov.u32 %r41, 176;
mov.u64 %rd24, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd19;
.param .b64 param1;
st.param.b64	[param1+0], %rd21;
.param .b32 param2;
st.param.b32	[param2+0], %r41;
.param .b64 param3;
st.param.b64	[param3+0], %rd23;
.param .b64 param4;
st.param.b64	[param4+0], %rd24;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB77_13:
mul.wide.s32 %rd25, %r24, 4;
add.s64 %rd26, %rd2, %rd25;
ld.local.u32 %rd27, [%rd26+108];
mul.lo.s64 %rd28, %rd27, %rd6;
cvt.u64.u32	%rd29, %r46;
add.s64 %rd30, %rd28, %rd29;
and.b64 %rd31, %rd30, 4294967295;
ld.local.u64 %rd32, [%rd2];
shl.b64 %rd33, %rd31, 2;
add.s64 %rd34, %rd32, %rd33;
st.u32 [%rd34], %r23;
mov.u32 %r43, %nctaid.x;
mad.lo.s32 %r45, %r43, %r27, %r45;
setp.lt.u32	%p9, %r45, %r25;
@%p9 bra BB77_4;

BB77_14:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjiLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjiLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjiLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .u32 _Z30THCudaTensor_scatterFillKernelIjiLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjiLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjiLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot78[432];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<12>;
.reg .b32 %r<55>;
.reg .b64 %rd<63>;


mov.u64 %rd62, __local_depot78;
cvta.local.u64 %SP, %rd62;
ld.param.u32 %r24, [_Z30THCudaTensor_scatterFillKernelIjiLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r25, [_Z30THCudaTensor_scatterFillKernelIjiLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r26, [_Z30THCudaTensor_scatterFillKernelIjiLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd4, _Z30THCudaTensor_scatterFillKernelIjiLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjiLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd17, %SP, 216;
cvta.to.local.u64 %rd2, %rd17;
add.u64 %rd18, %SP, 0;
cvta.to.local.u64 %rd3, %rd18;
mov.u32 %r41, 0;
mov.pred %p1, 0;
@%p1 bra BB78_2;

BB78_1:
mul.wide.s32 %rd19, %r41, 8;
add.s64 %rd20, %rd4, %rd19;
ld.param.u64 %rd21, [%rd20];
add.s64 %rd22, %rd2, %rd19;
st.local.u64 [%rd22], %rd21;
add.s32 %r41, %r41, 1;
setp.lt.u32	%p2, %r41, 27;
@%p2 bra BB78_1;

BB78_2:
mov.u32 %r42, 0;
@%p1 bra BB78_4;

BB78_3:
mul.wide.s32 %rd23, %r42, 8;
add.s64 %rd24, %rd1, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r42, %r42, 1;
setp.lt.u32	%p4, %r42, 27;
@%p4 bra BB78_3;

BB78_4:
mov.u32 %r29, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r47, %r29, %r30, %r31;
setp.ge.u32	%p5, %r47, %r26;
@%p5 bra BB78_15;

ld.local.u32 %r6, [%rd3+208];

BB78_6:
mov.u32 %r45, %r47;
mov.u32 %r7, %r45;
cvt.s64.s32	%rd28, %r6;
not.b64 %rd29, %rd28;
mov.u64 %rd30, -26;
sub.s64 %rd31, %rd30, %rd28;
add.s32 %r35, %r6, -1;
sub.s32 %r43, %r35, %r25;
neg.s64 %rd59, %rd29;
neg.s64 %rd60, %rd31;
mov.u32 %r52, 0;
mov.u64 %rd61, 0;
mov.u32 %r53, %r52;
mov.u32 %r48, %r52;
setp.lt.s32	%p6, %r6, 1;
mov.u32 %r44, %r6;
mov.u32 %r46, %r7;
@%p6 bra BB78_11;

BB78_7:
mov.u32 %r49, %r53;
mov.u32 %r54, %r49;
mov.u32 %r11, %r46;
mov.u32 %r10, %r44;
add.s32 %r14, %r10, -1;
shl.b64 %rd32, %rd59, 2;
add.s64 %rd33, %rd3, %rd32;
ld.local.u32 %r15, [%rd33];
rem.u32 %r16, %r11, %r15;
ld.local.u32 %r36, [%rd33+100];
mad.lo.s32 %r48, %r36, %r16, %r48;
setp.eq.s32	%p7, %r43, 0;
@%p7 bra BB78_9;

shl.b64 %rd34, %rd60, 2;
add.s64 %rd35, %rd2, %rd34;
ld.local.u32 %r37, [%rd35];
mad.lo.s32 %r54, %r37, %r16, %r54;

BB78_9:
mov.u32 %r53, %r54;
div.u32 %r20, %r11, %r15;
add.s32 %r43, %r43, -1;
add.s64 %rd60, %rd60, -1;
add.s64 %rd59, %rd59, -1;
setp.gt.s32	%p8, %r14, 0;
mov.u32 %r44, %r14;
mov.u32 %r46, %r20;
@%p8 bra BB78_7;

cvt.u64.u32	%rd61, %r48;
mov.u32 %r52, %r53;

BB78_11:
ld.local.u64 %rd36, [%rd3];
shl.b64 %rd37, %rd61, 3;
add.s64 %rd38, %rd36, %rd37;
ld.u64 %rd16, [%rd38];
setp.lt.s64	%p9, %rd16, 0;
@%p9 bra BB78_13;

mul.wide.s32 %rd39, %r25, 4;
add.s64 %rd40, %rd2, %rd39;
ld.local.u32 %rd41, [%rd40+8];
setp.lt.s64	%p10, %rd16, %rd41;
@%p10 bra BB78_14;

BB78_13:
mov.u64 %rd42, $str2;
cvta.global.u64 %rd43, %rd42;
mov.u64 %rd44, $str1;
cvta.global.u64 %rd45, %rd44;
mov.u64 %rd46, __T298;
cvta.global.u64 %rd47, %rd46;
mov.u32 %r38, 176;
mov.u64 %rd48, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd43;
.param .b64 param1;
st.param.b64	[param1+0], %rd45;
.param .b32 param2;
st.param.b32	[param2+0], %r38;
.param .b64 param3;
st.param.b64	[param3+0], %rd47;
.param .b64 param4;
st.param.b64	[param4+0], %rd48;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB78_14:
mul.wide.s32 %rd49, %r25, 4;
add.s64 %rd50, %rd2, %rd49;
ld.local.u32 %rd51, [%rd50+108];
mul.lo.s64 %rd52, %rd51, %rd16;
cvt.u64.u32	%rd53, %r52;
add.s64 %rd54, %rd52, %rd53;
and.b64 %rd55, %rd54, 4294967295;
ld.local.u64 %rd56, [%rd2];
shl.b64 %rd57, %rd55, 2;
add.s64 %rd58, %rd56, %rd57;
st.u32 [%rd58], %r24;
mov.u32 %r40, %nctaid.x;
mad.lo.s32 %r47, %r40, %r29, %r7;
setp.lt.u32	%p11, %r47, %r26;
@%p11 bra BB78_6;

BB78_15:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelImiLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelImiLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[416],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelImiLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[416],
.param .u32 _Z30THCudaTensor_scatterFillKernelImiLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelImiLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u64 _Z30THCudaTensor_scatterFillKernelImiLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot79[832];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b32 %r<34>;
.reg .b64 %rd<99>;


mov.u64 %rd98, __local_depot79;
cvta.local.u64 %SP, %rd98;
ld.param.u32 %r11, [_Z30THCudaTensor_scatterFillKernelImiLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r12, [_Z30THCudaTensor_scatterFillKernelImiLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u64 %rd34, [_Z30THCudaTensor_scatterFillKernelImiLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd4, _Z30THCudaTensor_scatterFillKernelImiLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelImiLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd35, %SP, 416;
cvta.to.local.u64 %rd2, %rd35;
add.u64 %rd36, %SP, 0;
cvta.to.local.u64 %rd3, %rd36;
mov.u32 %r30, 0;
mov.pred %p1, 0;
@%p1 bra BB79_2;

BB79_1:
mul.wide.s32 %rd37, %r30, 8;
add.s64 %rd38, %rd4, %rd37;
ld.param.u64 %rd39, [%rd38];
add.s64 %rd40, %rd2, %rd37;
st.local.u64 [%rd40], %rd39;
add.s32 %r30, %r30, 1;
setp.lt.u32	%p2, %r30, 52;
@%p2 bra BB79_1;

BB79_2:
mov.u32 %r31, 0;
@%p1 bra BB79_4;

BB79_3:
mul.wide.s32 %rd41, %r31, 8;
add.s64 %rd42, %rd1, %rd41;
ld.param.u64 %rd43, [%rd42];
add.s64 %rd44, %rd3, %rd41;
st.local.u64 [%rd44], %rd43;
add.s32 %r31, %r31, 1;
setp.lt.u32	%p4, %r31, 52;
@%p4 bra BB79_3;

BB79_4:
mov.u32 %r15, %ntid.x;
mov.u32 %r16, %ctaid.x;
mov.u32 %r17, %tid.x;
mad.lo.s32 %r18, %r15, %r16, %r17;
cvt.u64.u32	%rd87, %r18;
setp.ge.u64	%p5, %rd87, %rd34;
@%p5 bra BB79_20;

ld.local.u32 %r5, [%rd3+408];

BB79_6:
mov.u64 %rd83, %rd87;
mov.u64 %rd9, %rd83;
mul.wide.s32 %rd49, %r5, 8;
add.s64 %rd81, %rd3, %rd49;
add.s64 %rd50, %rd49, %rd2;
add.s64 %rd82, %rd50, 200;
add.s32 %r19, %r5, -1;
sub.s32 %r32, %r19, %r12;
mov.u64 %rd95, 0;
mov.u64 %rd90, %rd95;
mov.u64 %rd96, %rd95;
mov.u64 %rd91, %rd95;
setp.lt.s32	%p6, %r5, 1;
mov.u32 %r33, %r5;
mov.u64 %rd85, %rd9;
@%p6 bra BB79_16;

BB79_7:
mov.u64 %rd97, %rd96;
mov.u64 %rd14, %rd85;
mov.u32 %r8, %r33;
add.s32 %r9, %r8, -1;
ld.local.u64 %rd18, [%rd81];
or.b64 %rd51, %rd14, %rd18;
and.b64 %rd52, %rd51, -4294967296;
setp.eq.s64	%p7, %rd52, 0;
@%p7 bra BB79_9;
bra.uni BB79_8;

BB79_9:
cvt.u32.u64	%r20, %rd18;
cvt.u32.u64	%r21, %rd14;
rem.u32 %r22, %r21, %r20;
cvt.u64.u32	%rd88, %r22;
bra.uni BB79_10;

BB79_8:
rem.u64 %rd88, %rd14, %rd18;

BB79_10:
ld.local.u64 %rd53, [%rd81+200];
mul.lo.s64 %rd54, %rd53, %rd88;
add.s64 %rd91, %rd54, %rd91;
setp.eq.s32	%p8, %r32, 0;
@%p8 bra BB79_12;

ld.local.u64 %rd55, [%rd82];
mul.lo.s64 %rd56, %rd55, %rd88;
add.s64 %rd97, %rd56, %rd97;

BB79_12:
mov.u64 %rd96, %rd97;
@%p7 bra BB79_14;
bra.uni BB79_13;

BB79_14:
cvt.u32.u64	%r23, %rd18;
cvt.u32.u64	%r24, %rd14;
div.u32 %r25, %r24, %r23;
cvt.u64.u32	%rd86, %r25;
bra.uni BB79_15;

BB79_13:
div.u64 %rd86, %rd14, %rd18;

BB79_15:
mov.u64 %rd27, %rd86;
add.s32 %r32, %r32, -1;
add.s64 %rd82, %rd82, -8;
add.s64 %rd81, %rd81, -8;
setp.gt.s32	%p10, %r9, 0;
mov.u32 %r33, %r9;
mov.u64 %rd85, %rd27;
mov.u64 %rd90, %rd91;
mov.u64 %rd95, %rd96;
@%p10 bra BB79_7;

BB79_16:
ld.local.u64 %rd59, [%rd3];
shl.b64 %rd60, %rd90, 3;
add.s64 %rd61, %rd59, %rd60;
ld.u64 %rd32, [%rd61];
setp.lt.s64	%p11, %rd32, 0;
@%p11 bra BB79_18;

mul.wide.s32 %rd62, %r12, 8;
add.s64 %rd63, %rd2, %rd62;
ld.local.u64 %rd64, [%rd63+8];
setp.lt.u64	%p12, %rd32, %rd64;
@%p12 bra BB79_19;

BB79_18:
mov.u64 %rd65, $str2;
cvta.global.u64 %rd66, %rd65;
mov.u64 %rd67, $str1;
cvta.global.u64 %rd68, %rd67;
mov.u64 %rd69, __T299;
cvta.global.u64 %rd70, %rd69;
mov.u32 %r26, 176;
mov.u64 %rd71, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd66;
.param .b64 param1;
st.param.b64	[param1+0], %rd68;
.param .b32 param2;
st.param.b32	[param2+0], %r26;
.param .b64 param3;
st.param.b64	[param3+0], %rd70;
.param .b64 param4;
st.param.b64	[param4+0], %rd71;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB79_19:
mul.wide.s32 %rd72, %r12, 8;
add.s64 %rd73, %rd2, %rd72;
ld.local.u64 %rd74, [%rd73+208];
mul.lo.s64 %rd75, %rd74, %rd32;
add.s64 %rd76, %rd75, %rd95;
ld.local.u64 %rd77, [%rd2];
shl.b64 %rd78, %rd76, 2;
add.s64 %rd79, %rd77, %rd78;
st.u32 [%rd79], %r11;
mov.u32 %r28, %nctaid.x;
mul.lo.s32 %r29, %r28, %r15;
cvt.u64.u32	%rd80, %r29;
add.s64 %rd87, %rd80, %rd9;
setp.lt.u64	%p13, %rd87, %rd34;
@%p13 bra BB79_6;

BB79_20:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot80[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b32 %r<25>;
.reg .b64 %rd<45>;


mov.u64 %rd44, __local_depot80;
cvta.local.u64 %SP, %rd44;
ld.param.u32 %r10, [_Z25THCudaTensor_gatherKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r11, [_Z25THCudaTensor_gatherKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd3, %rd11;
mov.u32 %r23, 0;
mov.pred %p1, 0;
@%p1 bra BB80_2;

BB80_1:
mul.wide.s32 %rd12, %r23, 8;
add.s64 %rd13, %rd4, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd3, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r23, %r23, 1;
setp.lt.u32	%p2, %r23, 27;
@%p2 bra BB80_1;

BB80_2:
mov.u32 %r13, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r24, %r13, %r14, %r15;
setp.ge.u32	%p3, %r24, %r11;
@%p3 bra BB80_10;

ld.param.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd6, %rd16;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd17, [%rd2];
cvta.to.global.u64 %rd7, %rd17;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB80_4:
rem.u32 %r8, %r24, %r5;
setp.eq.s32	%p4, %r10, 0;
mov.u64 %rd43, 0;
@%p4 bra BB80_6;

ld.local.u32 %r16, [%rd3+108];
mul.lo.s32 %r17, %r16, %r8;
cvt.u64.u32	%rd43, %r17;

BB80_6:
mul.lo.s32 %r18, %r6, %r8;
mul.wide.u32 %rd19, %r18, 8;
add.s64 %rd20, %rd7, %rd19;
ld.global.u64 %rd10, [%rd20];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB80_8;

mul.wide.s32 %rd21, %r10, 4;
add.s64 %rd22, %rd3, %rd21;
ld.local.u32 %rd23, [%rd22+8];
setp.lt.s64	%p6, %rd10, %rd23;
@%p6 bra BB80_9;

BB80_8:
mov.u64 %rd24, $str;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, $str1;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, __T2100;
cvta.global.u64 %rd29, %rd28;
mov.u32 %r19, 97;
mov.u64 %rd30, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd25;
.param .b64 param1;
st.param.b64	[param1+0], %rd27;
.param .b32 param2;
st.param.b32	[param2+0], %r19;
.param .b64 param3;
st.param.b64	[param3+0], %rd29;
.param .b64 param4;
st.param.b64	[param4+0], %rd30;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB80_9:
mul.lo.s32 %r20, %r4, %r8;
mul.wide.s32 %rd31, %r10, 4;
add.s64 %rd32, %rd3, %rd31;
ld.local.u32 %rd33, [%rd32+108];
mul.lo.s64 %rd34, %rd33, %rd10;
add.s64 %rd35, %rd34, %rd43;
and.b64 %rd36, %rd35, 4294967295;
ld.local.u64 %rd37, [%rd3];
shl.b64 %rd38, %rd36, 3;
add.s64 %rd39, %rd37, %rd38;
ld.u64 %rd40, [%rd39];
mul.wide.u32 %rd41, %r20, 8;
add.s64 %rd42, %rd6, %rd41;
st.global.u64 [%rd42], %rd40;
mov.u32 %r22, %nctaid.x;
mad.lo.s32 %r24, %r22, %r13, %r24;
setp.lt.u32	%p7, %r24, %r11;
@%p7 bra BB80_4;

BB80_10:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot81[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b32 %r<40>;
.reg .b64 %rd<42>;


mov.u64 %rd41, __local_depot81;
cvta.local.u64 %SP, %rd41;
ld.param.u32 %r19, [_Z25THCudaTensor_gatherKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r20, [_Z25THCudaTensor_gatherKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r37, 0;
mov.pred %p1, 0;
@%p1 bra BB81_2;

BB81_1:
mul.wide.s32 %rd10, %r37, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r37, %r37, 1;
setp.lt.u32	%p2, %r37, 27;
@%p2 bra BB81_1;

BB81_2:
mov.u32 %r22, %ntid.x;
mov.u32 %r23, %ctaid.x;
mov.u32 %r24, %tid.x;
mad.lo.s32 %r38, %r22, %r23, %r24;
setp.ge.u32	%p3, %r38, %r20;
@%p3 bra BB81_12;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r25, %r26}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB81_4:
rem.u32 %r11, %r38, %r26;
setp.eq.s32	%p4, %r19, 1;
mov.u32 %r39, 0;
@%p4 bra BB81_6;

ld.local.u32 %r28, [%rd3+112];
mul.lo.s32 %r39, %r28, %r11;

BB81_6:
div.u32 %r29, %r38, %r26;
rem.u32 %r14, %r29, %r25;
setp.eq.s32	%p5, %r19, 0;
@%p5 bra BB81_8;

ld.local.u32 %r30, [%rd3+108];
mad.lo.s32 %r39, %r30, %r14, %r39;

BB81_8:
mul.lo.s32 %r31, %r9, %r11;
mul.lo.s32 %r32, %r5, %r11;
mad.lo.s32 %r33, %r8, %r14, %r31;
mad.lo.s32 %r17, %r4, %r14, %r32;
mul.wide.u32 %rd16, %r33, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB81_10;

mul.wide.s32 %rd18, %r19, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p7, %rd8, %rd20;
@%p7 bra BB81_11;

BB81_10:
mov.u64 %rd21, $str;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T2101;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r34, 97;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r34;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB81_11:
mul.wide.s32 %rd28, %r19, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r39;
add.s64 %rd33, %rd31, %rd32;
and.b64 %rd34, %rd33, 4294967295;
ld.local.u64 %rd35, [%rd3];
shl.b64 %rd36, %rd34, 3;
add.s64 %rd37, %rd35, %rd36;
ld.u64 %rd38, [%rd37];
mul.wide.u32 %rd39, %r17, 8;
add.s64 %rd40, %rd6, %rd39;
st.global.u64 [%rd40], %rd38;
mov.u32 %r36, %nctaid.x;
mad.lo.s32 %r38, %r36, %r22, %r38;
setp.lt.u32	%p8, %r38, %r20;
@%p8 bra BB81_4;

BB81_12:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot82[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b32 %r<54>;
.reg .b64 %rd<42>;


mov.u64 %rd41, __local_depot82;
cvta.local.u64 %SP, %rd41;
ld.param.u32 %r26, [_Z25THCudaTensor_gatherKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r27, [_Z25THCudaTensor_gatherKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r51, 0;
mov.pred %p1, 0;
@%p1 bra BB82_2;

BB82_1:
mul.wide.s32 %rd10, %r51, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p2, %r51, 27;
@%p2 bra BB82_1;

BB82_2:
mov.u32 %r29, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r52, %r29, %r30, %r31;
setp.ge.u32	%p3, %r52, %r27;
@%p3 bra BB82_14;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r32, %r33}, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r34, %r35}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r36, %r37}, [%rd2+112];

BB82_4:
rem.u32 %r14, %r52, %r9;
setp.eq.s32	%p4, %r26, 2;
mov.u32 %r53, 0;
@%p4 bra BB82_6;

ld.local.u32 %r39, [%rd3+116];
mul.lo.s32 %r53, %r39, %r14;

BB82_6:
div.u32 %r17, %r52, %r9;
rem.u32 %r18, %r17, %r35;
setp.eq.s32	%p5, %r26, 1;
@%p5 bra BB82_8;

ld.local.u32 %r40, [%rd3+112];
mad.lo.s32 %r53, %r40, %r18, %r53;

BB82_8:
div.u32 %r41, %r17, %r35;
rem.u32 %r21, %r41, %r34;
setp.eq.s32	%p6, %r26, 0;
@%p6 bra BB82_10;

ld.local.u32 %r42, [%rd3+108];
mad.lo.s32 %r53, %r42, %r21, %r53;

BB82_10:
mul.lo.s32 %r43, %r37, %r14;
mul.lo.s32 %r44, %r33, %r14;
mad.lo.s32 %r45, %r36, %r18, %r43;
mad.lo.s32 %r46, %r32, %r18, %r44;
mad.lo.s32 %r47, %r10, %r21, %r45;
mad.lo.s32 %r24, %r4, %r21, %r46;
mul.wide.u32 %rd16, %r47, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB82_12;

mul.wide.s32 %rd18, %r26, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p8, %rd8, %rd20;
@%p8 bra BB82_13;

BB82_12:
mov.u64 %rd21, $str;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T2102;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r48, 97;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r48;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB82_13:
mul.wide.s32 %rd28, %r26, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r53;
add.s64 %rd33, %rd31, %rd32;
and.b64 %rd34, %rd33, 4294967295;
ld.local.u64 %rd35, [%rd3];
shl.b64 %rd36, %rd34, 3;
add.s64 %rd37, %rd35, %rd36;
ld.u64 %rd38, [%rd37];
mul.wide.u32 %rd39, %r24, 8;
add.s64 %rd40, %rd6, %rd39;
st.global.u64 [%rd40], %rd38;
mov.u32 %r50, %nctaid.x;
mad.lo.s32 %r52, %r50, %r29, %r52;
setp.lt.u32	%p9, %r52, %r27;
@%p9 bra BB82_4;

BB82_14:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot83[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b32 %r<63>;
.reg .b64 %rd<71>;


mov.u64 %rd70, __local_depot83;
cvta.local.u64 %SP, %rd70;
ld.param.u32 %r28, [_Z25THCudaTensor_gatherKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r29, [_Z25THCudaTensor_gatherKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z25THCudaTensor_gatherKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd20, %SP, 216;
cvta.to.local.u64 %rd3, %rd20;
add.u64 %rd21, %SP, 432;
cvta.to.local.u64 %rd4, %rd21;
add.u64 %rd22, %SP, 0;
cvta.to.local.u64 %rd5, %rd22;
mov.u32 %r47, 0;
mov.pred %p1, 0;
@%p1 bra BB83_2;

BB83_1:
mul.wide.s32 %rd23, %r47, 8;
add.s64 %rd24, %rd6, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r47, %r47, 1;
setp.lt.u32	%p2, %r47, 27;
@%p2 bra BB83_1;

BB83_2:
mov.u32 %r48, 0;
@%p1 bra BB83_4;

BB83_3:
mul.wide.s32 %rd27, %r48, 8;
add.s64 %rd28, %rd1, %rd27;
ld.param.u64 %rd29, [%rd28];
add.s64 %rd30, %rd4, %rd27;
st.local.u64 [%rd30], %rd29;
add.s32 %r48, %r48, 1;
setp.lt.u32	%p4, %r48, 27;
@%p4 bra BB83_3;

BB83_4:
mov.u32 %r49, 0;
@%p1 bra BB83_6;

BB83_5:
mul.wide.s32 %rd31, %r49, 8;
add.s64 %rd32, %rd2, %rd31;
ld.param.u64 %rd33, [%rd32];
add.s64 %rd34, %rd5, %rd31;
st.local.u64 [%rd34], %rd33;
add.s32 %r49, %r49, 1;
setp.lt.u32	%p6, %r49, 27;
@%p6 bra BB83_5;

BB83_6:
mov.u32 %r33, %ntid.x;
mov.u32 %r34, %ctaid.x;
mov.u32 %r35, %tid.x;
mad.lo.s32 %r54, %r33, %r34, %r35;
setp.ge.u32	%p7, %r54, %r29;
@%p7 bra BB83_17;

ld.local.u32 %r8, [%rd5+208];

BB83_8:
mov.u32 %r52, %r54;
mov.u32 %r9, %r52;
mul.wide.s32 %rd67, %r8, 4;
add.s32 %r40, %r8, -1;
sub.s32 %r50, %r40, %r28;
mov.u64 %rd69, 0;
mov.u32 %r60, 0;
mov.u64 %rd68, %rd69;
mov.u32 %r56, %r60;
mov.u32 %r61, %r60;
mov.u32 %r55, %r60;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r51, %r8;
mov.u32 %r53, %r9;
@%p8 bra BB83_13;

BB83_9:
mov.u32 %r57, %r61;
mov.u32 %r62, %r57;
mov.u32 %r13, %r53;
mov.u32 %r12, %r51;
add.s64 %rd37, %rd3, %rd67;
add.s32 %r17, %r12, -1;
add.s64 %rd38, %rd5, %rd67;
ld.local.u32 %r18, [%rd38+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r41, [%rd38+104];
mad.lo.s32 %r55, %r41, %r19, %r55;
ld.local.u32 %r42, [%rd37+104];
mad.lo.s32 %r56, %r42, %r19, %r56;
setp.eq.s32	%p9, %r50, 0;
@%p9 bra BB83_11;

add.s64 %rd39, %rd4, %rd67;
ld.local.u32 %r43, [%rd39+104];
mad.lo.s32 %r62, %r43, %r19, %r62;

BB83_11:
mov.u32 %r61, %r62;
div.u32 %r24, %r13, %r18;
add.s32 %r50, %r50, -1;
add.s64 %rd67, %rd67, -4;
setp.gt.s32	%p10, %r17, 0;
mov.u32 %r51, %r17;
mov.u32 %r53, %r24;
@%p10 bra BB83_9;

cvt.u64.u32	%rd68, %r55;
cvt.u64.u32	%rd69, %r56;
mov.u32 %r60, %r61;

BB83_13:
ld.local.u64 %rd40, [%rd5];
shl.b64 %rd41, %rd68, 3;
add.s64 %rd42, %rd40, %rd41;
ld.u64 %rd19, [%rd42];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB83_15;

mul.wide.s32 %rd43, %r28, 4;
add.s64 %rd44, %rd4, %rd43;
ld.local.u32 %rd45, [%rd44+8];
setp.lt.s64	%p12, %rd19, %rd45;
@%p12 bra BB83_16;

BB83_15:
mov.u64 %rd46, $str;
cvta.global.u64 %rd47, %rd46;
mov.u64 %rd48, $str1;
cvta.global.u64 %rd49, %rd48;
mov.u64 %rd50, __T2103;
cvta.global.u64 %rd51, %rd50;
mov.u32 %r44, 97;
mov.u64 %rd52, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd47;
.param .b64 param1;
st.param.b64	[param1+0], %rd49;
.param .b32 param2;
st.param.b32	[param2+0], %r44;
.param .b64 param3;
st.param.b64	[param3+0], %rd51;
.param .b64 param4;
st.param.b64	[param4+0], %rd52;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB83_16:
mul.wide.s32 %rd53, %r28, 4;
add.s64 %rd54, %rd4, %rd53;
ld.local.u32 %rd55, [%rd54+108];
mul.lo.s64 %rd56, %rd55, %rd19;
cvt.u64.u32	%rd57, %r60;
add.s64 %rd58, %rd56, %rd57;
ld.local.u64 %rd59, [%rd4];
shl.b64 %rd60, %rd58, 3;
and.b64 %rd61, %rd60, 34359738360;
add.s64 %rd62, %rd59, %rd61;
ld.u64 %rd63, [%rd62];
ld.local.u64 %rd64, [%rd3];
shl.b64 %rd65, %rd69, 3;
add.s64 %rd66, %rd64, %rd65;
st.u64 [%rd66], %rd63;
mov.u32 %r46, %nctaid.x;
mad.lo.s32 %r54, %r46, %r33, %r9;
setp.lt.u32	%p13, %r54, %r29;
@%p13 bra BB83_8;

BB83_17:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[416],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[416],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[416],
.param .u32 _Z25THCudaTensor_gatherKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u64 _Z25THCudaTensor_gatherKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot84[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<16>;
.reg .b32 %r<37>;
.reg .b64 %rd<118>;


mov.u64 %rd117, __local_depot84;
cvta.local.u64 %SP, %rd117;
ld.param.u32 %r13, [_Z25THCudaTensor_gatherKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u64 %rd38, [_Z25THCudaTensor_gatherKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z25THCudaTensor_gatherKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd39, %SP, 416;
cvta.to.local.u64 %rd3, %rd39;
add.u64 %rd40, %SP, 832;
cvta.to.local.u64 %rd4, %rd40;
add.u64 %rd41, %SP, 0;
cvta.to.local.u64 %rd5, %rd41;
mov.u32 %r32, 0;
mov.pred %p1, 0;
@%p1 bra BB84_2;

BB84_1:
mul.wide.s32 %rd42, %r32, 8;
add.s64 %rd43, %rd6, %rd42;
ld.param.u64 %rd44, [%rd43];
add.s64 %rd45, %rd3, %rd42;
st.local.u64 [%rd45], %rd44;
add.s32 %r32, %r32, 1;
setp.lt.u32	%p2, %r32, 52;
@%p2 bra BB84_1;

BB84_2:
mov.u32 %r33, 0;
@%p1 bra BB84_4;

BB84_3:
mul.wide.s32 %rd46, %r33, 8;
add.s64 %rd47, %rd1, %rd46;
ld.param.u64 %rd48, [%rd47];
add.s64 %rd49, %rd4, %rd46;
st.local.u64 [%rd49], %rd48;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p4, %r33, 52;
@%p4 bra BB84_3;

BB84_4:
mov.u32 %r34, 0;
@%p1 bra BB84_6;

BB84_5:
mul.wide.s32 %rd50, %r34, 8;
add.s64 %rd51, %rd2, %rd50;
ld.param.u64 %rd52, [%rd51];
add.s64 %rd53, %rd5, %rd50;
st.local.u64 [%rd53], %rd52;
add.s32 %r34, %r34, 1;
setp.lt.u32	%p6, %r34, 52;
@%p6 bra BB84_5;

BB84_6:
mov.u32 %r17, %ntid.x;
mov.u32 %r18, %ctaid.x;
mov.u32 %r19, %tid.x;
mad.lo.s32 %r20, %r17, %r18, %r19;
cvt.u64.u32	%rd103, %r20;
setp.ge.u64	%p7, %rd103, %rd38;
@%p7 bra BB84_22;

ld.local.u32 %r7, [%rd5+408];

BB84_8:
mov.u64 %rd99, %rd103;
mov.u64 %rd13, %rd99;
mul.wide.s32 %rd98, %r7, 8;
add.s32 %r21, %r7, -1;
sub.s32 %r35, %r21, %r13;
mov.u64 %rd115, 0;
mov.u64 %rd111, %rd115;
mov.u64 %rd106, %rd115;
mov.u64 %rd116, %rd115;
mov.u64 %rd112, %rd115;
mov.u64 %rd107, %rd115;
setp.lt.s32	%p8, %r7, 1;
mov.u32 %r36, %r7;
mov.u64 %rd101, %rd13;
@%p8 bra BB84_18;

BB84_9:
mov.u64 %rd113, %rd112;
mov.u64 %rd16, %rd101;
mov.u32 %r10, %r36;
add.s32 %r11, %r10, -1;
add.s64 %rd20, %rd5, %rd98;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd60, %rd16, %rd21;
and.b64 %rd61, %rd60, -4294967296;
setp.eq.s64	%p9, %rd61, 0;
@%p9 bra BB84_11;
bra.uni BB84_10;

BB84_11:
cvt.u32.u64	%r22, %rd21;
cvt.u32.u64	%r23, %rd16;
rem.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd104, %r24;
bra.uni BB84_12;

BB84_10:
rem.u64 %rd104, %rd16, %rd21;

BB84_12:
add.s64 %rd62, %rd3, %rd98;
ld.local.u64 %rd63, [%rd20+200];
mul.lo.s64 %rd64, %rd63, %rd104;
add.s64 %rd107, %rd64, %rd107;
ld.local.u64 %rd65, [%rd62+200];
mul.lo.s64 %rd66, %rd65, %rd104;
add.s64 %rd116, %rd66, %rd116;
setp.eq.s32	%p10, %r35, 0;
@%p10 bra BB84_14;

add.s64 %rd67, %rd4, %rd98;
ld.local.u64 %rd68, [%rd67+200];
mul.lo.s64 %rd69, %rd68, %rd104;
add.s64 %rd113, %rd69, %rd113;

BB84_14:
mov.u64 %rd112, %rd113;
@%p9 bra BB84_16;
bra.uni BB84_15;

BB84_16:
cvt.u32.u64	%r25, %rd21;
cvt.u32.u64	%r26, %rd16;
div.u32 %r27, %r26, %r25;
cvt.u64.u32	%rd102, %r27;
bra.uni BB84_17;

BB84_15:
div.u64 %rd102, %rd16, %rd21;

BB84_17:
mov.u64 %rd31, %rd102;
add.s32 %r35, %r35, -1;
add.s64 %rd98, %rd98, -8;
setp.gt.s32	%p12, %r11, 0;
mov.u32 %r36, %r11;
mov.u64 %rd101, %rd31;
mov.u64 %rd106, %rd107;
mov.u64 %rd111, %rd112;
mov.u64 %rd115, %rd116;
@%p12 bra BB84_9;

BB84_18:
ld.local.u64 %rd72, [%rd5];
shl.b64 %rd73, %rd106, 3;
add.s64 %rd74, %rd72, %rd73;
ld.u64 %rd36, [%rd74];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB84_20;

mul.wide.s32 %rd75, %r13, 8;
add.s64 %rd76, %rd4, %rd75;
ld.local.u64 %rd77, [%rd76+8];
setp.lt.u64	%p14, %rd36, %rd77;
@%p14 bra BB84_21;

BB84_20:
mov.u64 %rd78, $str;
cvta.global.u64 %rd79, %rd78;
mov.u64 %rd80, $str1;
cvta.global.u64 %rd81, %rd80;
mov.u64 %rd82, __T2104;
cvta.global.u64 %rd83, %rd82;
mov.u32 %r28, 97;
mov.u64 %rd84, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd79;
.param .b64 param1;
st.param.b64	[param1+0], %rd81;
.param .b32 param2;
st.param.b32	[param2+0], %r28;
.param .b64 param3;
st.param.b64	[param3+0], %rd83;
.param .b64 param4;
st.param.b64	[param4+0], %rd84;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB84_21:
mul.wide.s32 %rd85, %r13, 8;
add.s64 %rd86, %rd4, %rd85;
ld.local.u64 %rd87, [%rd86+208];
mul.lo.s64 %rd88, %rd87, %rd36;
add.s64 %rd89, %rd88, %rd111;
ld.local.u64 %rd90, [%rd4];
shl.b64 %rd91, %rd89, 3;
add.s64 %rd92, %rd90, %rd91;
ld.u64 %rd93, [%rd92];
ld.local.u64 %rd94, [%rd3];
shl.b64 %rd95, %rd115, 3;
add.s64 %rd96, %rd94, %rd95;
st.u64 [%rd96], %rd93;
mov.u32 %r30, %nctaid.x;
mul.lo.s32 %r31, %r30, %r17;
cvt.u64.u32	%rd97, %r31;
add.s64 %rd103, %rd97, %rd13;
setp.lt.u64	%p15, %rd103, %rd38;
@%p15 bra BB84_8;

BB84_22:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot85[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b32 %r<25>;
.reg .b64 %rd<45>;


mov.u64 %rd44, __local_depot85;
cvta.local.u64 %SP, %rd44;
ld.param.u32 %r10, [_Z26THCudaTensor_scatterKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r11, [_Z26THCudaTensor_scatterKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd3, %rd11;
mov.u32 %r23, 0;
mov.pred %p1, 0;
@%p1 bra BB85_2;

BB85_1:
mul.wide.s32 %rd12, %r23, 8;
add.s64 %rd13, %rd4, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd3, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r23, %r23, 1;
setp.lt.u32	%p2, %r23, 27;
@%p2 bra BB85_1;

BB85_2:
mov.u32 %r13, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r24, %r13, %r14, %r15;
setp.ge.u32	%p3, %r24, %r11;
@%p3 bra BB85_10;

ld.param.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd6, %rd16;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd17, [%rd2];
cvta.to.global.u64 %rd7, %rd17;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB85_4:
rem.u32 %r8, %r24, %r5;
setp.eq.s32	%p4, %r10, 0;
mov.u64 %rd43, 0;
@%p4 bra BB85_6;

ld.local.u32 %r16, [%rd3+108];
mul.lo.s32 %r17, %r16, %r8;
cvt.u64.u32	%rd43, %r17;

BB85_6:
mul.lo.s32 %r18, %r6, %r8;
mul.wide.u32 %rd19, %r18, 8;
add.s64 %rd20, %rd7, %rd19;
ld.global.u64 %rd10, [%rd20];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB85_8;

mul.wide.s32 %rd21, %r10, 4;
add.s64 %rd22, %rd3, %rd21;
ld.local.u32 %rd23, [%rd22+8];
setp.lt.s64	%p6, %rd10, %rd23;
@%p6 bra BB85_9;

BB85_8:
mov.u64 %rd24, $str2;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, $str1;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, __T2105;
cvta.global.u64 %rd29, %rd28;
mov.u32 %r19, 124;
mov.u64 %rd30, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd25;
.param .b64 param1;
st.param.b64	[param1+0], %rd27;
.param .b32 param2;
st.param.b32	[param2+0], %r19;
.param .b64 param3;
st.param.b64	[param3+0], %rd29;
.param .b64 param4;
st.param.b64	[param4+0], %rd30;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB85_9:
mul.lo.s32 %r20, %r4, %r8;
mul.wide.s32 %rd31, %r10, 4;
add.s64 %rd32, %rd3, %rd31;
ld.local.u32 %rd33, [%rd32+108];
mul.lo.s64 %rd34, %rd33, %rd10;
add.s64 %rd35, %rd34, %rd43;
mul.wide.u32 %rd36, %r20, 8;
add.s64 %rd37, %rd6, %rd36;
ld.global.u64 %rd38, [%rd37];
ld.local.u64 %rd39, [%rd3];
shl.b64 %rd40, %rd35, 3;
and.b64 %rd41, %rd40, 34359738360;
add.s64 %rd42, %rd39, %rd41;
st.u64 [%rd42], %rd38;
mov.u32 %r22, %nctaid.x;
mad.lo.s32 %r24, %r22, %r13, %r24;
setp.lt.u32	%p7, %r24, %r11;
@%p7 bra BB85_4;

BB85_10:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot86[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b32 %r<40>;
.reg .b64 %rd<42>;


mov.u64 %rd41, __local_depot86;
cvta.local.u64 %SP, %rd41;
ld.param.u32 %r19, [_Z26THCudaTensor_scatterKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r20, [_Z26THCudaTensor_scatterKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r37, 0;
mov.pred %p1, 0;
@%p1 bra BB86_2;

BB86_1:
mul.wide.s32 %rd10, %r37, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r37, %r37, 1;
setp.lt.u32	%p2, %r37, 27;
@%p2 bra BB86_1;

BB86_2:
mov.u32 %r22, %ntid.x;
mov.u32 %r23, %ctaid.x;
mov.u32 %r24, %tid.x;
mad.lo.s32 %r38, %r22, %r23, %r24;
setp.ge.u32	%p3, %r38, %r20;
@%p3 bra BB86_12;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r25, %r26}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB86_4:
rem.u32 %r11, %r38, %r26;
setp.eq.s32	%p4, %r19, 1;
mov.u32 %r39, 0;
@%p4 bra BB86_6;

ld.local.u32 %r28, [%rd3+112];
mul.lo.s32 %r39, %r28, %r11;

BB86_6:
div.u32 %r29, %r38, %r26;
rem.u32 %r14, %r29, %r25;
setp.eq.s32	%p5, %r19, 0;
@%p5 bra BB86_8;

ld.local.u32 %r30, [%rd3+108];
mad.lo.s32 %r39, %r30, %r14, %r39;

BB86_8:
mul.lo.s32 %r31, %r9, %r11;
mul.lo.s32 %r32, %r5, %r11;
mad.lo.s32 %r33, %r8, %r14, %r31;
mad.lo.s32 %r17, %r4, %r14, %r32;
mul.wide.u32 %rd16, %r33, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB86_10;

mul.wide.s32 %rd18, %r19, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p7, %rd8, %rd20;
@%p7 bra BB86_11;

BB86_10:
mov.u64 %rd21, $str2;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T2106;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r34, 124;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r34;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB86_11:
mul.wide.s32 %rd28, %r19, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r39;
add.s64 %rd33, %rd31, %rd32;
mul.wide.u32 %rd34, %r17, 8;
add.s64 %rd35, %rd6, %rd34;
ld.global.u64 %rd36, [%rd35];
ld.local.u64 %rd37, [%rd3];
shl.b64 %rd38, %rd33, 3;
and.b64 %rd39, %rd38, 34359738360;
add.s64 %rd40, %rd37, %rd39;
st.u64 [%rd40], %rd36;
mov.u32 %r36, %nctaid.x;
mad.lo.s32 %r38, %r36, %r22, %r38;
setp.lt.u32	%p8, %r38, %r20;
@%p8 bra BB86_4;

BB86_12:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot87[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b32 %r<54>;
.reg .b64 %rd<42>;


mov.u64 %rd41, __local_depot87;
cvta.local.u64 %SP, %rd41;
ld.param.u32 %r26, [_Z26THCudaTensor_scatterKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r27, [_Z26THCudaTensor_scatterKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r51, 0;
mov.pred %p1, 0;
@%p1 bra BB87_2;

BB87_1:
mul.wide.s32 %rd10, %r51, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p2, %r51, 27;
@%p2 bra BB87_1;

BB87_2:
mov.u32 %r29, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r52, %r29, %r30, %r31;
setp.ge.u32	%p3, %r52, %r27;
@%p3 bra BB87_14;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r32, %r33}, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r34, %r35}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r36, %r37}, [%rd2+112];

BB87_4:
rem.u32 %r14, %r52, %r9;
setp.eq.s32	%p4, %r26, 2;
mov.u32 %r53, 0;
@%p4 bra BB87_6;

ld.local.u32 %r39, [%rd3+116];
mul.lo.s32 %r53, %r39, %r14;

BB87_6:
div.u32 %r17, %r52, %r9;
rem.u32 %r18, %r17, %r35;
setp.eq.s32	%p5, %r26, 1;
@%p5 bra BB87_8;

ld.local.u32 %r40, [%rd3+112];
mad.lo.s32 %r53, %r40, %r18, %r53;

BB87_8:
div.u32 %r41, %r17, %r35;
rem.u32 %r21, %r41, %r34;
setp.eq.s32	%p6, %r26, 0;
@%p6 bra BB87_10;

ld.local.u32 %r42, [%rd3+108];
mad.lo.s32 %r53, %r42, %r21, %r53;

BB87_10:
mul.lo.s32 %r43, %r37, %r14;
mul.lo.s32 %r44, %r33, %r14;
mad.lo.s32 %r45, %r36, %r18, %r43;
mad.lo.s32 %r46, %r32, %r18, %r44;
mad.lo.s32 %r47, %r10, %r21, %r45;
mad.lo.s32 %r24, %r4, %r21, %r46;
mul.wide.u32 %rd16, %r47, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB87_12;

mul.wide.s32 %rd18, %r26, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p8, %rd8, %rd20;
@%p8 bra BB87_13;

BB87_12:
mov.u64 %rd21, $str2;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T2107;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r48, 124;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r48;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB87_13:
mul.wide.s32 %rd28, %r26, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r53;
add.s64 %rd33, %rd31, %rd32;
mul.wide.u32 %rd34, %r24, 8;
add.s64 %rd35, %rd6, %rd34;
ld.global.u64 %rd36, [%rd35];
ld.local.u64 %rd37, [%rd3];
shl.b64 %rd38, %rd33, 3;
and.b64 %rd39, %rd38, 34359738360;
add.s64 %rd40, %rd37, %rd39;
st.u64 [%rd40], %rd36;
mov.u32 %r50, %nctaid.x;
mad.lo.s32 %r52, %r50, %r29, %r52;
setp.lt.u32	%p9, %r52, %r27;
@%p9 bra BB87_4;

BB87_14:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot88[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b32 %r<63>;
.reg .b64 %rd<71>;


mov.u64 %rd70, __local_depot88;
cvta.local.u64 %SP, %rd70;
ld.param.u32 %r28, [_Z26THCudaTensor_scatterKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r29, [_Z26THCudaTensor_scatterKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z26THCudaTensor_scatterKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd20, %SP, 216;
cvta.to.local.u64 %rd3, %rd20;
add.u64 %rd21, %SP, 432;
cvta.to.local.u64 %rd4, %rd21;
add.u64 %rd22, %SP, 0;
cvta.to.local.u64 %rd5, %rd22;
mov.u32 %r47, 0;
mov.pred %p1, 0;
@%p1 bra BB88_2;

BB88_1:
mul.wide.s32 %rd23, %r47, 8;
add.s64 %rd24, %rd6, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r47, %r47, 1;
setp.lt.u32	%p2, %r47, 27;
@%p2 bra BB88_1;

BB88_2:
mov.u32 %r48, 0;
@%p1 bra BB88_4;

BB88_3:
mul.wide.s32 %rd27, %r48, 8;
add.s64 %rd28, %rd1, %rd27;
ld.param.u64 %rd29, [%rd28];
add.s64 %rd30, %rd4, %rd27;
st.local.u64 [%rd30], %rd29;
add.s32 %r48, %r48, 1;
setp.lt.u32	%p4, %r48, 27;
@%p4 bra BB88_3;

BB88_4:
mov.u32 %r49, 0;
@%p1 bra BB88_6;

BB88_5:
mul.wide.s32 %rd31, %r49, 8;
add.s64 %rd32, %rd2, %rd31;
ld.param.u64 %rd33, [%rd32];
add.s64 %rd34, %rd5, %rd31;
st.local.u64 [%rd34], %rd33;
add.s32 %r49, %r49, 1;
setp.lt.u32	%p6, %r49, 27;
@%p6 bra BB88_5;

BB88_6:
mov.u32 %r33, %ntid.x;
mov.u32 %r34, %ctaid.x;
mov.u32 %r35, %tid.x;
mad.lo.s32 %r54, %r33, %r34, %r35;
setp.ge.u32	%p7, %r54, %r29;
@%p7 bra BB88_17;

ld.local.u32 %r8, [%rd5+208];

BB88_8:
mov.u32 %r52, %r54;
mov.u32 %r9, %r52;
mul.wide.s32 %rd67, %r8, 4;
add.s32 %r40, %r8, -1;
sub.s32 %r50, %r40, %r28;
mov.u32 %r60, 0;
mov.u64 %rd69, 0;
mov.u64 %rd68, %rd69;
mov.u32 %r61, %r60;
mov.u32 %r56, %r60;
mov.u32 %r55, %r60;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r51, %r8;
mov.u32 %r53, %r9;
@%p8 bra BB88_13;

BB88_9:
mov.u32 %r57, %r61;
mov.u32 %r62, %r57;
mov.u32 %r13, %r53;
mov.u32 %r12, %r51;
add.s64 %rd37, %rd4, %rd67;
add.s32 %r17, %r12, -1;
add.s64 %rd38, %rd5, %rd67;
ld.local.u32 %r18, [%rd38+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r41, [%rd38+104];
mad.lo.s32 %r55, %r41, %r19, %r55;
ld.local.u32 %r42, [%rd37+104];
mad.lo.s32 %r56, %r42, %r19, %r56;
setp.eq.s32	%p9, %r50, 0;
@%p9 bra BB88_11;

add.s64 %rd39, %rd3, %rd67;
ld.local.u32 %r43, [%rd39+104];
mad.lo.s32 %r62, %r43, %r19, %r62;

BB88_11:
mov.u32 %r61, %r62;
div.u32 %r24, %r13, %r18;
add.s32 %r50, %r50, -1;
add.s64 %rd67, %rd67, -4;
setp.gt.s32	%p10, %r17, 0;
mov.u32 %r51, %r17;
mov.u32 %r53, %r24;
@%p10 bra BB88_9;

cvt.u64.u32	%rd68, %r55;
cvt.u64.u32	%rd69, %r56;
mov.u32 %r60, %r61;

BB88_13:
ld.local.u64 %rd40, [%rd5];
shl.b64 %rd41, %rd68, 3;
add.s64 %rd42, %rd40, %rd41;
ld.u64 %rd19, [%rd42];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB88_15;

mul.wide.s32 %rd43, %r28, 4;
add.s64 %rd44, %rd3, %rd43;
ld.local.u32 %rd45, [%rd44+8];
setp.lt.s64	%p12, %rd19, %rd45;
@%p12 bra BB88_16;

BB88_15:
mov.u64 %rd46, $str2;
cvta.global.u64 %rd47, %rd46;
mov.u64 %rd48, $str1;
cvta.global.u64 %rd49, %rd48;
mov.u64 %rd50, __T2108;
cvta.global.u64 %rd51, %rd50;
mov.u32 %r44, 124;
mov.u64 %rd52, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd47;
.param .b64 param1;
st.param.b64	[param1+0], %rd49;
.param .b32 param2;
st.param.b32	[param2+0], %r44;
.param .b64 param3;
st.param.b64	[param3+0], %rd51;
.param .b64 param4;
st.param.b64	[param4+0], %rd52;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB88_16:
mul.wide.s32 %rd53, %r28, 4;
add.s64 %rd54, %rd3, %rd53;
ld.local.u32 %rd55, [%rd54+108];
mul.lo.s64 %rd56, %rd55, %rd19;
cvt.u64.u32	%rd57, %r60;
add.s64 %rd58, %rd56, %rd57;
ld.local.u64 %rd59, [%rd4];
shl.b64 %rd60, %rd69, 3;
add.s64 %rd61, %rd59, %rd60;
ld.u64 %rd62, [%rd61];
ld.local.u64 %rd63, [%rd3];
shl.b64 %rd64, %rd58, 3;
and.b64 %rd65, %rd64, 34359738360;
add.s64 %rd66, %rd63, %rd65;
st.u64 [%rd66], %rd62;
mov.u32 %r46, %nctaid.x;
mad.lo.s32 %r54, %r46, %r33, %r9;
setp.lt.u32	%p13, %r54, %r29;
@%p13 bra BB88_8;

BB88_17:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[416],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[416],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[416],
.param .u32 _Z26THCudaTensor_scatterKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u64 _Z26THCudaTensor_scatterKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot89[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<16>;
.reg .b32 %r<37>;
.reg .b64 %rd<118>;


mov.u64 %rd117, __local_depot89;
cvta.local.u64 %SP, %rd117;
ld.param.u32 %r13, [_Z26THCudaTensor_scatterKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u64 %rd38, [_Z26THCudaTensor_scatterKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z26THCudaTensor_scatterKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd39, %SP, 416;
cvta.to.local.u64 %rd3, %rd39;
add.u64 %rd40, %SP, 832;
cvta.to.local.u64 %rd4, %rd40;
add.u64 %rd41, %SP, 0;
cvta.to.local.u64 %rd5, %rd41;
mov.u32 %r32, 0;
mov.pred %p1, 0;
@%p1 bra BB89_2;

BB89_1:
mul.wide.s32 %rd42, %r32, 8;
add.s64 %rd43, %rd6, %rd42;
ld.param.u64 %rd44, [%rd43];
add.s64 %rd45, %rd3, %rd42;
st.local.u64 [%rd45], %rd44;
add.s32 %r32, %r32, 1;
setp.lt.u32	%p2, %r32, 52;
@%p2 bra BB89_1;

BB89_2:
mov.u32 %r33, 0;
@%p1 bra BB89_4;

BB89_3:
mul.wide.s32 %rd46, %r33, 8;
add.s64 %rd47, %rd1, %rd46;
ld.param.u64 %rd48, [%rd47];
add.s64 %rd49, %rd4, %rd46;
st.local.u64 [%rd49], %rd48;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p4, %r33, 52;
@%p4 bra BB89_3;

BB89_4:
mov.u32 %r34, 0;
@%p1 bra BB89_6;

BB89_5:
mul.wide.s32 %rd50, %r34, 8;
add.s64 %rd51, %rd2, %rd50;
ld.param.u64 %rd52, [%rd51];
add.s64 %rd53, %rd5, %rd50;
st.local.u64 [%rd53], %rd52;
add.s32 %r34, %r34, 1;
setp.lt.u32	%p6, %r34, 52;
@%p6 bra BB89_5;

BB89_6:
mov.u32 %r17, %ntid.x;
mov.u32 %r18, %ctaid.x;
mov.u32 %r19, %tid.x;
mad.lo.s32 %r20, %r17, %r18, %r19;
cvt.u64.u32	%rd103, %r20;
setp.ge.u64	%p7, %rd103, %rd38;
@%p7 bra BB89_22;

ld.local.u32 %r7, [%rd5+408];

BB89_8:
mov.u64 %rd99, %rd103;
mov.u64 %rd13, %rd99;
mul.wide.s32 %rd98, %r7, 8;
add.s32 %r21, %r7, -1;
sub.s32 %r35, %r21, %r13;
mov.u64 %rd114, 0;
mov.u64 %rd109, %rd114;
mov.u64 %rd106, %rd114;
mov.u64 %rd115, %rd114;
mov.u64 %rd110, %rd114;
mov.u64 %rd107, %rd114;
setp.lt.s32	%p8, %r7, 1;
mov.u32 %r36, %r7;
mov.u64 %rd101, %rd13;
@%p8 bra BB89_18;

BB89_9:
mov.u64 %rd116, %rd115;
mov.u64 %rd16, %rd101;
mov.u32 %r10, %r36;
add.s32 %r11, %r10, -1;
add.s64 %rd20, %rd5, %rd98;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd60, %rd16, %rd21;
and.b64 %rd61, %rd60, -4294967296;
setp.eq.s64	%p9, %rd61, 0;
@%p9 bra BB89_11;
bra.uni BB89_10;

BB89_11:
cvt.u32.u64	%r22, %rd21;
cvt.u32.u64	%r23, %rd16;
rem.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd104, %r24;
bra.uni BB89_12;

BB89_10:
rem.u64 %rd104, %rd16, %rd21;

BB89_12:
add.s64 %rd62, %rd4, %rd98;
ld.local.u64 %rd63, [%rd20+200];
mul.lo.s64 %rd64, %rd63, %rd104;
add.s64 %rd107, %rd64, %rd107;
ld.local.u64 %rd65, [%rd62+200];
mul.lo.s64 %rd66, %rd65, %rd104;
add.s64 %rd110, %rd66, %rd110;
setp.eq.s32	%p10, %r35, 0;
@%p10 bra BB89_14;

add.s64 %rd67, %rd3, %rd98;
ld.local.u64 %rd68, [%rd67+200];
mul.lo.s64 %rd69, %rd68, %rd104;
add.s64 %rd116, %rd69, %rd116;

BB89_14:
mov.u64 %rd115, %rd116;
@%p9 bra BB89_16;
bra.uni BB89_15;

BB89_16:
cvt.u32.u64	%r25, %rd21;
cvt.u32.u64	%r26, %rd16;
div.u32 %r27, %r26, %r25;
cvt.u64.u32	%rd102, %r27;
bra.uni BB89_17;

BB89_15:
div.u64 %rd102, %rd16, %rd21;

BB89_17:
mov.u64 %rd31, %rd102;
add.s32 %r35, %r35, -1;
add.s64 %rd98, %rd98, -8;
setp.gt.s32	%p12, %r11, 0;
mov.u32 %r36, %r11;
mov.u64 %rd101, %rd31;
mov.u64 %rd106, %rd107;
mov.u64 %rd109, %rd110;
mov.u64 %rd114, %rd115;
@%p12 bra BB89_9;

BB89_18:
ld.local.u64 %rd72, [%rd5];
shl.b64 %rd73, %rd106, 3;
add.s64 %rd74, %rd72, %rd73;
ld.u64 %rd36, [%rd74];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB89_20;

mul.wide.s32 %rd75, %r13, 8;
add.s64 %rd76, %rd3, %rd75;
ld.local.u64 %rd77, [%rd76+8];
setp.lt.u64	%p14, %rd36, %rd77;
@%p14 bra BB89_21;

BB89_20:
mov.u64 %rd78, $str2;
cvta.global.u64 %rd79, %rd78;
mov.u64 %rd80, $str1;
cvta.global.u64 %rd81, %rd80;
mov.u64 %rd82, __T2109;
cvta.global.u64 %rd83, %rd82;
mov.u32 %r28, 124;
mov.u64 %rd84, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd79;
.param .b64 param1;
st.param.b64	[param1+0], %rd81;
.param .b32 param2;
st.param.b32	[param2+0], %r28;
.param .b64 param3;
st.param.b64	[param3+0], %rd83;
.param .b64 param4;
st.param.b64	[param4+0], %rd84;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB89_21:
mul.wide.s32 %rd85, %r13, 8;
add.s64 %rd86, %rd3, %rd85;
ld.local.u64 %rd87, [%rd86+208];
mul.lo.s64 %rd88, %rd87, %rd36;
add.s64 %rd89, %rd88, %rd114;
ld.local.u64 %rd90, [%rd4];
shl.b64 %rd91, %rd109, 3;
add.s64 %rd92, %rd90, %rd91;
ld.u64 %rd93, [%rd92];
ld.local.u64 %rd94, [%rd3];
shl.b64 %rd95, %rd89, 3;
add.s64 %rd96, %rd94, %rd95;
st.u64 [%rd96], %rd93;
mov.u32 %r30, %nctaid.x;
mul.lo.s32 %r31, %r30, %r17;
cvt.u64.u32	%rd97, %r31;
add.s64 %rd103, %rd97, %rd13;
setp.lt.u64	%p15, %rd103, %rd38;
@%p15 bra BB89_8;

BB89_22:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot90[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b32 %r<25>;
.reg .b64 %rd<50>;


mov.u64 %rd49, __local_depot90;
cvta.local.u64 %SP, %rd49;
ld.param.u32 %r11, [_Z29THCudaTensor_scatterAddKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r12, [_Z29THCudaTensor_scatterAddKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjlLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd16, %SP, 0;
cvta.to.local.u64 %rd3, %rd16;
mov.u32 %r23, 0;
mov.pred %p1, 0;
@%p1 bra BB90_2;

BB90_1:
mul.wide.s32 %rd17, %r23, 8;
add.s64 %rd18, %rd4, %rd17;
ld.param.u64 %rd19, [%rd18];
add.s64 %rd20, %rd3, %rd17;
st.local.u64 [%rd20], %rd19;
add.s32 %r23, %r23, 1;
setp.lt.u32	%p2, %r23, 27;
@%p2 bra BB90_1;

BB90_2:
mov.u32 %r14, %ntid.x;
mov.u32 %r15, %ctaid.x;
mov.u32 %r16, %tid.x;
mad.lo.s32 %r24, %r14, %r15, %r16;
setp.ge.u32	%p3, %r24, %r12;
@%p3 bra BB90_12;

ld.param.u64 %rd21, [%rd1];
cvta.to.global.u64 %rd6, %rd21;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd22, [%rd2];
cvta.to.global.u64 %rd7, %rd22;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB90_4:
rem.u32 %r8, %r24, %r5;
setp.eq.s32	%p4, %r11, 0;
mov.u64 %rd47, 0;
@%p4 bra BB90_6;

ld.local.u32 %r17, [%rd3+108];
mul.lo.s32 %r18, %r17, %r8;
cvt.u64.u32	%rd47, %r18;

BB90_6:
mul.lo.s32 %r19, %r6, %r8;
mul.wide.u32 %rd24, %r19, 8;
add.s64 %rd25, %rd7, %rd24;
ld.global.u64 %rd10, [%rd25];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB90_8;

mul.wide.s32 %rd26, %r11, 4;
add.s64 %rd27, %rd3, %rd26;
ld.local.u32 %rd28, [%rd27+8];
setp.lt.s64	%p6, %rd10, %rd28;
@%p6 bra BB90_9;

BB90_8:
mov.u64 %rd29, $str2;
cvta.global.u64 %rd30, %rd29;
mov.u64 %rd31, $str1;
cvta.global.u64 %rd32, %rd31;
mov.u64 %rd33, __T2110;
cvta.global.u64 %rd34, %rd33;
mov.u32 %r20, 151;
mov.u64 %rd35, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd30;
.param .b64 param1;
st.param.b64	[param1+0], %rd32;
.param .b32 param2;
st.param.b32	[param2+0], %r20;
.param .b64 param3;
st.param.b64	[param3+0], %rd34;
.param .b64 param4;
st.param.b64	[param4+0], %rd35;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB90_9:
mul.lo.s32 %r21, %r4, %r8;
mul.wide.s32 %rd36, %r11, 4;
add.s64 %rd37, %rd3, %rd36;
ld.local.u32 %rd38, [%rd37+108];
mul.lo.s64 %rd39, %rd38, %rd10;
add.s64 %rd40, %rd39, %rd47;
and.b64 %rd41, %rd40, 4294967295;
ld.local.u64 %rd42, [%rd3];
shl.b64 %rd43, %rd41, 3;
add.s64 %rd11, %rd42, %rd43;
mul.wide.u32 %rd44, %r21, 8;
add.s64 %rd45, %rd6, %rd44;
ld.global.u64 %rd12, [%rd45];
ld.u64 %rd48, [%rd11];

BB90_10:
mov.u64 %rd14, %rd48;
add.s64 %rd46, %rd14, %rd12;
atom.cas.b64 %rd48, [%rd11], %rd14, %rd46;
setp.ne.s64	%p7, %rd14, %rd48;
@%p7 bra BB90_10;

mov.u32 %r22, %nctaid.x;
mad.lo.s32 %r24, %r22, %r14, %r24;
setp.lt.u32	%p8, %r24, %r12;
@%p8 bra BB90_4;

BB90_12:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot91[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b32 %r<40>;
.reg .b64 %rd<47>;


mov.u64 %rd46, __local_depot91;
cvta.local.u64 %SP, %rd46;
ld.param.u32 %r19, [_Z29THCudaTensor_scatterAddKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r20, [_Z29THCudaTensor_scatterAddKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjlLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd14, %SP, 0;
cvta.to.local.u64 %rd3, %rd14;
mov.u32 %r37, 0;
mov.pred %p1, 0;
@%p1 bra BB91_2;

BB91_1:
mul.wide.s32 %rd15, %r37, 8;
add.s64 %rd16, %rd4, %rd15;
ld.param.u64 %rd17, [%rd16];
add.s64 %rd18, %rd3, %rd15;
st.local.u64 [%rd18], %rd17;
add.s32 %r37, %r37, 1;
setp.lt.u32	%p2, %r37, 27;
@%p2 bra BB91_1;

BB91_2:
mov.u32 %r22, %ntid.x;
mov.u32 %r23, %ctaid.x;
mov.u32 %r24, %tid.x;
mad.lo.s32 %r38, %r22, %r23, %r24;
setp.ge.u32	%p3, %r38, %r20;
@%p3 bra BB91_14;

ld.param.u64 %rd19, [%rd1];
cvta.to.global.u64 %rd6, %rd19;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd20, [%rd2];
cvta.to.global.u64 %rd7, %rd20;
ld.param.v2.u32 {%r25, %r26}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB91_4:
rem.u32 %r11, %r38, %r26;
setp.eq.s32	%p4, %r19, 1;
mov.u32 %r39, 0;
@%p4 bra BB91_6;

ld.local.u32 %r28, [%rd3+112];
mul.lo.s32 %r39, %r28, %r11;

BB91_6:
div.u32 %r29, %r38, %r26;
rem.u32 %r14, %r29, %r25;
setp.eq.s32	%p5, %r19, 0;
@%p5 bra BB91_8;

ld.local.u32 %r30, [%rd3+108];
mad.lo.s32 %r39, %r30, %r14, %r39;

BB91_8:
mul.lo.s32 %r31, %r9, %r11;
mul.lo.s32 %r32, %r5, %r11;
mad.lo.s32 %r33, %r8, %r14, %r31;
mad.lo.s32 %r17, %r4, %r14, %r32;
mul.wide.u32 %rd21, %r33, 8;
add.s64 %rd22, %rd7, %rd21;
ld.global.u64 %rd8, [%rd22];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB91_10;

mul.wide.s32 %rd23, %r19, 4;
add.s64 %rd24, %rd3, %rd23;
ld.local.u32 %rd25, [%rd24+8];
setp.lt.s64	%p7, %rd8, %rd25;
@%p7 bra BB91_11;

BB91_10:
mov.u64 %rd26, $str2;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, $str1;
cvta.global.u64 %rd29, %rd28;
mov.u64 %rd30, __T2111;
cvta.global.u64 %rd31, %rd30;
mov.u32 %r34, 151;
mov.u64 %rd32, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd27;
.param .b64 param1;
st.param.b64	[param1+0], %rd29;
.param .b32 param2;
st.param.b32	[param2+0], %r34;
.param .b64 param3;
st.param.b64	[param3+0], %rd31;
.param .b64 param4;
st.param.b64	[param4+0], %rd32;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB91_11:
mul.wide.s32 %rd33, %r19, 4;
add.s64 %rd34, %rd3, %rd33;
ld.local.u32 %rd35, [%rd34+108];
mul.lo.s64 %rd36, %rd35, %rd8;
cvt.u64.u32	%rd37, %r39;
add.s64 %rd38, %rd36, %rd37;
and.b64 %rd39, %rd38, 4294967295;
ld.local.u64 %rd40, [%rd3];
shl.b64 %rd41, %rd39, 3;
add.s64 %rd9, %rd40, %rd41;
mul.wide.u32 %rd42, %r17, 8;
add.s64 %rd43, %rd6, %rd42;
ld.global.u64 %rd10, [%rd43];
ld.u64 %rd45, [%rd9];

BB91_12:
mov.u64 %rd12, %rd45;
add.s64 %rd44, %rd12, %rd10;
atom.cas.b64 %rd45, [%rd9], %rd12, %rd44;
setp.ne.s64	%p8, %rd12, %rd45;
@%p8 bra BB91_12;

mov.u32 %r36, %nctaid.x;
mad.lo.s32 %r38, %r36, %r22, %r38;
setp.lt.u32	%p9, %r38, %r20;
@%p9 bra BB91_4;

BB91_14:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot92[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<11>;
.reg .b32 %r<54>;
.reg .b64 %rd<47>;


mov.u64 %rd46, __local_depot92;
cvta.local.u64 %SP, %rd46;
ld.param.u32 %r28, [_Z29THCudaTensor_scatterAddKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r29, [_Z29THCudaTensor_scatterAddKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjlLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd14, %SP, 0;
cvta.to.local.u64 %rd3, %rd14;
mov.u32 %r51, 0;
mov.pred %p1, 0;
@%p1 bra BB92_2;

BB92_1:
mul.wide.s32 %rd15, %r51, 8;
add.s64 %rd16, %rd4, %rd15;
ld.param.u64 %rd17, [%rd16];
add.s64 %rd18, %rd3, %rd15;
st.local.u64 [%rd18], %rd17;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p2, %r51, 27;
@%p2 bra BB92_1;

BB92_2:
mov.u32 %r31, %ntid.x;
mov.u32 %r32, %ctaid.x;
mov.u32 %r33, %tid.x;
mad.lo.s32 %r52, %r31, %r32, %r33;
setp.ge.u32	%p3, %r52, %r29;
@%p3 bra BB92_16;

ld.param.u64 %rd19, [%rd1];
cvta.to.global.u64 %rd6, %rd19;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r34, %r35}, [%rd1+112];
ld.param.u64 %rd20, [%rd2];
cvta.to.global.u64 %rd7, %rd20;
ld.param.v2.u32 {%r36, %r37}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r38, %r39}, [%rd2+112];

BB92_4:
rem.u32 %r14, %r52, %r9;
setp.eq.s32	%p4, %r28, 2;
mov.u32 %r53, 0;
@%p4 bra BB92_6;

ld.local.u32 %r41, [%rd3+116];
mul.lo.s32 %r53, %r41, %r14;

BB92_6:
div.u32 %r17, %r52, %r9;
rem.u32 %r18, %r17, %r37;
setp.eq.s32	%p5, %r28, 1;
@%p5 bra BB92_8;

ld.local.u32 %r42, [%rd3+112];
mad.lo.s32 %r53, %r42, %r18, %r53;

BB92_8:
div.u32 %r43, %r17, %r37;
rem.u32 %r21, %r43, %r36;
setp.eq.s32	%p6, %r28, 0;
@%p6 bra BB92_10;

ld.local.u32 %r44, [%rd3+108];
mad.lo.s32 %r53, %r44, %r21, %r53;

BB92_10:
mul.lo.s32 %r45, %r39, %r14;
mul.lo.s32 %r46, %r35, %r14;
mad.lo.s32 %r47, %r38, %r18, %r45;
mad.lo.s32 %r48, %r34, %r18, %r46;
mad.lo.s32 %r49, %r10, %r21, %r47;
mad.lo.s32 %r24, %r4, %r21, %r48;
mul.wide.u32 %rd21, %r49, 8;
add.s64 %rd22, %rd7, %rd21;
ld.global.u64 %rd8, [%rd22];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB92_12;

mul.wide.s32 %rd23, %r28, 4;
add.s64 %rd24, %rd3, %rd23;
ld.local.u32 %rd25, [%rd24+8];
setp.lt.s64	%p8, %rd8, %rd25;
@%p8 bra BB92_13;

BB92_12:
mov.u64 %rd26, $str2;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, $str1;
cvta.global.u64 %rd29, %rd28;
mov.u64 %rd30, __T2112;
cvta.global.u64 %rd31, %rd30;
mov.u32 %r50, 151;
mov.u64 %rd32, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd27;
.param .b64 param1;
st.param.b64	[param1+0], %rd29;
.param .b32 param2;
st.param.b32	[param2+0], %r50;
.param .b64 param3;
st.param.b64	[param3+0], %rd31;
.param .b64 param4;
st.param.b64	[param4+0], %rd32;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB92_13:
mul.wide.s32 %rd33, %r28, 4;
add.s64 %rd34, %rd3, %rd33;
ld.local.u32 %rd35, [%rd34+108];
mul.lo.s64 %rd36, %rd35, %rd8;
cvt.u64.u32	%rd37, %r53;
add.s64 %rd38, %rd36, %rd37;
and.b64 %rd39, %rd38, 4294967295;
ld.local.u64 %rd40, [%rd3];
shl.b64 %rd41, %rd39, 3;
add.s64 %rd9, %rd40, %rd41;
mul.wide.u32 %rd42, %r24, 8;
add.s64 %rd43, %rd6, %rd42;
ld.global.u64 %rd10, [%rd43];
ld.u64 %rd45, [%rd9];
mov.u32 %r25, %nctaid.x;

BB92_14:
mov.u64 %rd12, %rd45;
add.s64 %rd44, %rd12, %rd10;
atom.cas.b64 %rd45, [%rd9], %rd12, %rd44;
setp.ne.s64	%p9, %rd12, %rd45;
@%p9 bra BB92_14;

mad.lo.s32 %r52, %r25, %r31, %r52;
setp.lt.u32	%p10, %r52, %r29;
@%p10 bra BB92_4;

BB92_16:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot93[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<15>;
.reg .b32 %r<58>;
.reg .b64 %rd<76>;


mov.u64 %rd75, __local_depot93;
cvta.local.u64 %SP, %rd75;
ld.param.u32 %r30, [_Z29THCudaTensor_scatterAddKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r31, [_Z29THCudaTensor_scatterAddKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z29THCudaTensor_scatterAddKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd25, %SP, 216;
cvta.to.local.u64 %rd3, %rd25;
add.u64 %rd26, %SP, 432;
cvta.to.local.u64 %rd4, %rd26;
add.u64 %rd27, %SP, 0;
cvta.to.local.u64 %rd5, %rd27;
mov.u32 %r47, 0;
mov.pred %p1, 0;
@%p1 bra BB93_2;

BB93_1:
mul.wide.s32 %rd28, %r47, 8;
add.s64 %rd29, %rd6, %rd28;
ld.param.u64 %rd30, [%rd29];
add.s64 %rd31, %rd3, %rd28;
st.local.u64 [%rd31], %rd30;
add.s32 %r47, %r47, 1;
setp.lt.u32	%p2, %r47, 27;
@%p2 bra BB93_1;

BB93_2:
mov.u32 %r48, 0;
@%p1 bra BB93_4;

BB93_3:
mul.wide.s32 %rd32, %r48, 8;
add.s64 %rd33, %rd1, %rd32;
ld.param.u64 %rd34, [%rd33];
add.s64 %rd35, %rd4, %rd32;
st.local.u64 [%rd35], %rd34;
add.s32 %r48, %r48, 1;
setp.lt.u32	%p4, %r48, 27;
@%p4 bra BB93_3;

BB93_4:
mov.u32 %r49, 0;
@%p1 bra BB93_6;

BB93_5:
mul.wide.s32 %rd36, %r49, 8;
add.s64 %rd37, %rd2, %rd36;
ld.param.u64 %rd38, [%rd37];
add.s64 %rd39, %rd5, %rd36;
st.local.u64 [%rd39], %rd38;
add.s32 %r49, %r49, 1;
setp.lt.u32	%p6, %r49, 27;
@%p6 bra BB93_5;

BB93_6:
mov.u32 %r35, %ntid.x;
mov.u32 %r36, %ctaid.x;
mov.u32 %r37, %tid.x;
mad.lo.s32 %r54, %r35, %r36, %r37;
setp.ge.u32	%p7, %r54, %r31;
@%p7 bra BB93_19;

BB93_7:
mov.u32 %r52, %r54;
mov.u32 %r8, %r52;
ld.local.u32 %r51, [%rd5+208];
mov.u32 %r57, 0;
mov.u64 %rd73, 0;
mov.u64 %rd72, %rd73;
setp.lt.s32	%p8, %r51, 1;
@%p8 bra BB93_13;

not.b32 %r42, %r30;
add.s32 %r50, %r42, %r51;
mul.wide.s32 %rd71, %r51, 4;
mov.u32 %r57, 0;
mov.u32 %r56, %r57;
mov.u32 %r55, %r57;
mov.u32 %r53, %r8;

BB93_9:
mov.u32 %r13, %r53;
add.s64 %rd42, %rd4, %rd71;
add.s32 %r51, %r51, -1;
add.s64 %rd43, %rd5, %rd71;
ld.local.u32 %r18, [%rd43+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r43, [%rd43+104];
mad.lo.s32 %r55, %r43, %r19, %r55;
ld.local.u32 %r44, [%rd42+104];
mad.lo.s32 %r56, %r44, %r19, %r56;
setp.eq.s32	%p9, %r50, 0;
@%p9 bra BB93_11;

add.s64 %rd44, %rd3, %rd71;
ld.local.u32 %r45, [%rd44+104];
mad.lo.s32 %r57, %r45, %r19, %r57;

BB93_11:
div.u32 %r24, %r13, %r18;
add.s32 %r50, %r50, -1;
add.s64 %rd71, %rd71, -4;
setp.gt.s32	%p10, %r51, 0;
mov.u32 %r53, %r24;
@%p10 bra BB93_9;

cvt.u64.u32	%rd72, %r55;
cvt.u64.u32	%rd73, %r56;

BB93_13:
ld.local.u64 %rd45, [%rd5];
shl.b64 %rd46, %rd72, 3;
add.s64 %rd47, %rd45, %rd46;
ld.u64 %rd19, [%rd47];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB93_15;

mul.wide.s32 %rd48, %r30, 4;
add.s64 %rd49, %rd3, %rd48;
ld.local.u32 %rd50, [%rd49+8];
setp.lt.s64	%p12, %rd19, %rd50;
@%p12 bra BB93_16;

BB93_15:
mov.u64 %rd51, $str2;
cvta.global.u64 %rd52, %rd51;
mov.u64 %rd53, $str1;
cvta.global.u64 %rd54, %rd53;
mov.u64 %rd55, __T2113;
cvta.global.u64 %rd56, %rd55;
mov.u32 %r46, 151;
mov.u64 %rd57, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd52;
.param .b64 param1;
st.param.b64	[param1+0], %rd54;
.param .b32 param2;
st.param.b32	[param2+0], %r46;
.param .b64 param3;
st.param.b64	[param3+0], %rd56;
.param .b64 param4;
st.param.b64	[param4+0], %rd57;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB93_16:
mul.wide.s32 %rd58, %r30, 4;
add.s64 %rd59, %rd3, %rd58;
ld.local.u32 %rd60, [%rd59+108];
mul.lo.s64 %rd61, %rd60, %rd19;
cvt.u64.u32	%rd62, %r57;
add.s64 %rd63, %rd61, %rd62;
ld.local.u64 %rd64, [%rd3];
shl.b64 %rd65, %rd63, 3;
and.b64 %rd66, %rd65, 34359738360;
add.s64 %rd20, %rd64, %rd66;
ld.local.u64 %rd67, [%rd4];
shl.b64 %rd68, %rd73, 3;
add.s64 %rd69, %rd67, %rd68;
ld.u64 %rd21, [%rd69];
ld.u64 %rd74, [%rd20];
mov.u32 %r27, %nctaid.x;

BB93_17:
mov.u64 %rd23, %rd74;
add.s64 %rd70, %rd23, %rd21;
atom.cas.b64 %rd74, [%rd20], %rd23, %rd70;
setp.ne.s64	%p13, %rd23, %rd74;
@%p13 bra BB93_17;

mad.lo.s32 %r54, %r27, %r35, %r8;
setp.lt.u32	%p14, %r54, %r31;
@%p14 bra BB93_7;

BB93_19:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[416],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[416],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[416],
.param .u32 _Z29THCudaTensor_scatterAddKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u64 _Z29THCudaTensor_scatterAddKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot94[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<17>;
.reg .b32 %r<37>;
.reg .b64 %rd<114>;


mov.u64 %rd113, __local_depot94;
cvta.local.u64 %SP, %rd113;
ld.param.u32 %r14, [_Z29THCudaTensor_scatterAddKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u64 %rd43, [_Z29THCudaTensor_scatterAddKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z29THCudaTensor_scatterAddKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelImlLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd44, %SP, 416;
cvta.to.local.u64 %rd3, %rd44;
add.u64 %rd45, %SP, 832;
cvta.to.local.u64 %rd4, %rd45;
add.u64 %rd46, %SP, 0;
cvta.to.local.u64 %rd5, %rd46;
mov.u32 %r32, 0;
mov.pred %p1, 0;
@%p1 bra BB94_2;

BB94_1:
mul.wide.s32 %rd47, %r32, 8;
add.s64 %rd48, %rd6, %rd47;
ld.param.u64 %rd49, [%rd48];
add.s64 %rd50, %rd3, %rd47;
st.local.u64 [%rd50], %rd49;
add.s32 %r32, %r32, 1;
setp.lt.u32	%p2, %r32, 52;
@%p2 bra BB94_1;

BB94_2:
mov.u32 %r33, 0;
@%p1 bra BB94_4;

BB94_3:
mul.wide.s32 %rd51, %r33, 8;
add.s64 %rd52, %rd1, %rd51;
ld.param.u64 %rd53, [%rd52];
add.s64 %rd54, %rd4, %rd51;
st.local.u64 [%rd54], %rd53;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p4, %r33, 52;
@%p4 bra BB94_3;

BB94_4:
mov.u32 %r34, 0;
@%p1 bra BB94_6;

BB94_5:
mul.wide.s32 %rd55, %r34, 8;
add.s64 %rd56, %rd2, %rd55;
ld.param.u64 %rd57, [%rd56];
add.s64 %rd58, %rd5, %rd55;
st.local.u64 [%rd58], %rd57;
add.s32 %r34, %r34, 1;
setp.lt.u32	%p6, %r34, 52;
@%p6 bra BB94_5;

BB94_6:
mov.u32 %r18, %ntid.x;
mov.u32 %r19, %ctaid.x;
mov.u32 %r20, %tid.x;
mad.lo.s32 %r21, %r18, %r19, %r20;
cvt.u64.u32	%rd107, %r21;
setp.ge.u64	%p7, %rd107, %rd43;
@%p7 bra BB94_24;

BB94_7:
mov.u64 %rd103, %rd107;
mov.u64 %rd13, %rd103;
ld.local.u32 %r36, [%rd5+408];
mov.u64 %rd111, 0;
mov.u64 %rd110, %rd111;
mov.u64 %rd109, %rd111;
setp.lt.s32	%p8, %r36, 1;
@%p8 bra BB94_18;

not.b32 %r22, %r14;
add.s32 %r35, %r22, %r36;
mul.wide.s32 %rd102, %r36, 8;
mov.u64 %rd111, 0;
mov.u64 %rd110, %rd111;
mov.u64 %rd109, %rd111;
mov.u64 %rd105, %rd13;

BB94_9:
mov.u64 %rd16, %rd105;
add.s32 %r36, %r36, -1;
add.s64 %rd20, %rd5, %rd102;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd65, %rd16, %rd21;
and.b64 %rd66, %rd65, -4294967296;
setp.eq.s64	%p9, %rd66, 0;
@%p9 bra BB94_11;
bra.uni BB94_10;

BB94_11:
cvt.u32.u64	%r23, %rd21;
cvt.u32.u64	%r24, %rd16;
rem.u32 %r25, %r24, %r23;
cvt.u64.u32	%rd108, %r25;
bra.uni BB94_12;

BB94_10:
rem.u64 %rd108, %rd16, %rd21;

BB94_12:
add.s64 %rd67, %rd4, %rd102;
ld.local.u64 %rd68, [%rd20+200];
mul.lo.s64 %rd69, %rd68, %rd108;
add.s64 %rd109, %rd69, %rd109;
ld.local.u64 %rd70, [%rd67+200];
mul.lo.s64 %rd71, %rd70, %rd108;
add.s64 %rd110, %rd71, %rd110;
setp.eq.s32	%p10, %r35, 0;
@%p10 bra BB94_14;

add.s64 %rd72, %rd3, %rd102;
ld.local.u64 %rd73, [%rd72+200];
mul.lo.s64 %rd74, %rd73, %rd108;
add.s64 %rd111, %rd74, %rd111;

BB94_14:
@%p9 bra BB94_16;
bra.uni BB94_15;

BB94_16:
cvt.u32.u64	%r26, %rd21;
cvt.u32.u64	%r27, %rd16;
div.u32 %r28, %r27, %r26;
cvt.u64.u32	%rd106, %r28;
bra.uni BB94_17;

BB94_15:
div.u64 %rd106, %rd16, %rd21;

BB94_17:
mov.u64 %rd31, %rd106;
add.s32 %r35, %r35, -1;
add.s64 %rd102, %rd102, -8;
setp.gt.s32	%p12, %r36, 0;
mov.u64 %rd105, %rd31;
@%p12 bra BB94_9;

BB94_18:
ld.local.u64 %rd77, [%rd5];
shl.b64 %rd78, %rd109, 3;
add.s64 %rd79, %rd77, %rd78;
ld.u64 %rd36, [%rd79];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB94_20;

mul.wide.s32 %rd80, %r14, 8;
add.s64 %rd81, %rd3, %rd80;
ld.local.u64 %rd82, [%rd81+8];
setp.lt.u64	%p14, %rd36, %rd82;
@%p14 bra BB94_21;

BB94_20:
mov.u64 %rd83, $str2;
cvta.global.u64 %rd84, %rd83;
mov.u64 %rd85, $str1;
cvta.global.u64 %rd86, %rd85;
mov.u64 %rd87, __T2114;
cvta.global.u64 %rd88, %rd87;
mov.u32 %r29, 151;
mov.u64 %rd89, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd84;
.param .b64 param1;
st.param.b64	[param1+0], %rd86;
.param .b32 param2;
st.param.b32	[param2+0], %r29;
.param .b64 param3;
st.param.b64	[param3+0], %rd88;
.param .b64 param4;
st.param.b64	[param4+0], %rd89;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB94_21:
mul.wide.s32 %rd90, %r14, 8;
add.s64 %rd91, %rd3, %rd90;
ld.local.u64 %rd92, [%rd91+208];
mul.lo.s64 %rd93, %rd92, %rd36;
add.s64 %rd94, %rd93, %rd111;
ld.local.u64 %rd95, [%rd3];
shl.b64 %rd96, %rd94, 3;
add.s64 %rd37, %rd95, %rd96;
ld.local.u64 %rd97, [%rd4];
shl.b64 %rd98, %rd110, 3;
add.s64 %rd99, %rd97, %rd98;
ld.u64 %rd38, [%rd99];
ld.u64 %rd112, [%rd37];
mov.u32 %r31, %nctaid.x;
mul.lo.s32 %r13, %r31, %r18;

BB94_22:
mov.u64 %rd40, %rd112;
add.s64 %rd100, %rd40, %rd38;
atom.cas.b64 %rd112, [%rd37], %rd40, %rd100;
setp.ne.s64	%p15, %rd40, %rd112;
@%p15 bra BB94_22;

cvt.u64.u32	%rd101, %r13;
add.s64 %rd107, %rd101, %rd13;
setp.lt.u64	%p16, %rd107, %rd43;
@%p16 bra BB94_7;

BB94_24:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjlLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjlLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjlLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .u64 _Z30THCudaTensor_scatterFillKernelIjlLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjlLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjlLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot95[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b32 %r<23>;
.reg .b64 %rd<39>;


mov.u64 %rd38, __local_depot95;
cvta.local.u64 %SP, %rd38;
ld.param.u64 %rd10, [_Z30THCudaTensor_scatterFillKernelIjlLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r11, [_Z30THCudaTensor_scatterFillKernelIjlLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r12, [_Z30THCudaTensor_scatterFillKernelIjlLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjlLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjlLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd2, %rd11;
mov.u32 %r21, 0;
mov.pred %p1, 0;
@%p1 bra BB95_2;

BB95_1:
mul.wide.s32 %rd12, %r21, 8;
add.s64 %rd13, %rd3, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd2, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r21, %r21, 1;
setp.lt.u32	%p2, %r21, 27;
@%p2 bra BB95_1;

BB95_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r22, %r3, %r14, %r15;
setp.ge.u32	%p3, %r22, %r12;
@%p3 bra BB95_10;

ld.param.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd5, %rd16;
ld.param.u32 %r5, [%rd1+8];
ld.param.u32 %r6, [%rd1+108];
mul.wide.s32 %rd17, %r11, 4;
add.s64 %rd18, %rd2, %rd17;
add.s64 %rd6, %rd18, 8;
mov.u32 %r16, %nctaid.x;
mul.lo.s32 %r7, %r16, %r3;

BB95_4:
rem.u32 %r9, %r22, %r5;
setp.eq.s32	%p4, %r11, 0;
mov.u64 %rd37, 0;
@%p4 bra BB95_6;

ld.local.u32 %r17, [%rd2+108];
mul.lo.s32 %r18, %r17, %r9;
cvt.u64.u32	%rd37, %r18;

BB95_6:
mul.lo.s32 %r19, %r6, %r9;
mul.wide.u32 %rd20, %r19, 8;
add.s64 %rd21, %rd5, %rd20;
ld.global.u64 %rd9, [%rd21];
setp.lt.s64	%p5, %rd9, 0;
@%p5 bra BB95_8;

ld.local.u32 %rd22, [%rd6];
setp.lt.s64	%p6, %rd9, %rd22;
@%p6 bra BB95_9;

BB95_8:
mov.u64 %rd23, $str2;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, $str1;
cvta.global.u64 %rd26, %rd25;
mov.u64 %rd27, __T2115;
cvta.global.u64 %rd28, %rd27;
mov.u32 %r20, 176;
mov.u64 %rd29, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd24;
.param .b64 param1;
st.param.b64	[param1+0], %rd26;
.param .b32 param2;
st.param.b32	[param2+0], %r20;
.param .b64 param3;
st.param.b64	[param3+0], %rd28;
.param .b64 param4;
st.param.b64	[param4+0], %rd29;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB95_9:
ld.local.u32 %rd30, [%rd6+100];
mul.lo.s64 %rd31, %rd30, %rd9;
add.s64 %rd32, %rd31, %rd37;
and.b64 %rd33, %rd32, 4294967295;
ld.local.u64 %rd34, [%rd2];
shl.b64 %rd35, %rd33, 3;
add.s64 %rd36, %rd34, %rd35;
st.u64 [%rd36], %rd10;
add.s32 %r22, %r7, %r22;
setp.lt.u32	%p7, %r22, %r12;
@%p7 bra BB95_4;

BB95_10:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjlLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjlLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjlLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .u64 _Z30THCudaTensor_scatterFillKernelIjlLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjlLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjlLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot96[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b32 %r<36>;
.reg .b64 %rd<37>;


mov.u64 %rd36, __local_depot96;
cvta.local.u64 %SP, %rd36;
ld.param.u64 %rd7, [_Z30THCudaTensor_scatterFillKernelIjlLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r16, [_Z30THCudaTensor_scatterFillKernelIjlLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r17, [_Z30THCudaTensor_scatterFillKernelIjlLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjlLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjlLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd8, %SP, 0;
cvta.to.local.u64 %rd2, %rd8;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB96_2;

BB96_1:
mul.wide.s32 %rd9, %r33, 8;
add.s64 %rd10, %rd3, %rd9;
ld.param.u64 %rd11, [%rd10];
add.s64 %rd12, %rd2, %rd9;
st.local.u64 [%rd12], %rd11;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB96_1;

BB96_2:
mov.u32 %r19, %ntid.x;
mov.u32 %r20, %ctaid.x;
mov.u32 %r21, %tid.x;
mad.lo.s32 %r34, %r19, %r20, %r21;
setp.ge.u32	%p3, %r34, %r17;
@%p3 bra BB96_12;

ld.param.u64 %rd13, [%rd1];
cvta.to.global.u64 %rd5, %rd13;
ld.param.v2.u32 {%r22, %r23}, [%rd1+8];
ld.param.u32 %r6, [%rd1+108];
ld.param.u32 %r7, [%rd1+112];

BB96_4:
rem.u32 %r9, %r34, %r23;
setp.eq.s32	%p4, %r16, 1;
mov.u32 %r35, 0;
@%p4 bra BB96_6;

ld.local.u32 %r25, [%rd2+112];
mul.lo.s32 %r35, %r25, %r9;

BB96_6:
div.u32 %r26, %r34, %r23;
rem.u32 %r12, %r26, %r22;
setp.eq.s32	%p5, %r16, 0;
@%p5 bra BB96_8;

ld.local.u32 %r27, [%rd2+108];
mad.lo.s32 %r35, %r27, %r12, %r35;

BB96_8:
mul.lo.s32 %r28, %r7, %r9;
mad.lo.s32 %r29, %r6, %r12, %r28;
mul.wide.u32 %rd14, %r29, 8;
add.s64 %rd15, %rd5, %rd14;
ld.global.u64 %rd6, [%rd15];
setp.lt.s64	%p6, %rd6, 0;
@%p6 bra BB96_10;

mul.wide.s32 %rd16, %r16, 4;
add.s64 %rd17, %rd2, %rd16;
ld.local.u32 %rd18, [%rd17+8];
setp.lt.s64	%p7, %rd6, %rd18;
@%p7 bra BB96_11;

BB96_10:
mov.u64 %rd19, $str2;
cvta.global.u64 %rd20, %rd19;
mov.u64 %rd21, $str1;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, __T2116;
cvta.global.u64 %rd24, %rd23;
mov.u32 %r30, 176;
mov.u64 %rd25, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd20;
.param .b64 param1;
st.param.b64	[param1+0], %rd22;
.param .b32 param2;
st.param.b32	[param2+0], %r30;
.param .b64 param3;
st.param.b64	[param3+0], %rd24;
.param .b64 param4;
st.param.b64	[param4+0], %rd25;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB96_11:
mul.wide.s32 %rd26, %r16, 4;
add.s64 %rd27, %rd2, %rd26;
ld.local.u32 %rd28, [%rd27+108];
mul.lo.s64 %rd29, %rd28, %rd6;
cvt.u64.u32	%rd30, %r35;
add.s64 %rd31, %rd29, %rd30;
and.b64 %rd32, %rd31, 4294967295;
ld.local.u64 %rd33, [%rd2];
shl.b64 %rd34, %rd32, 3;
add.s64 %rd35, %rd33, %rd34;
st.u64 [%rd35], %rd7;
mov.u32 %r32, %nctaid.x;
mad.lo.s32 %r34, %r32, %r19, %r34;
setp.lt.u32	%p8, %r34, %r17;
@%p8 bra BB96_4;

BB96_12:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjlLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjlLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjlLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .u64 _Z30THCudaTensor_scatterFillKernelIjlLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjlLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjlLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot97[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<37>;


mov.u64 %rd36, __local_depot97;
cvta.local.u64 %SP, %rd36;
ld.param.u64 %rd7, [_Z30THCudaTensor_scatterFillKernelIjlLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r23, [_Z30THCudaTensor_scatterFillKernelIjlLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r24, [_Z30THCudaTensor_scatterFillKernelIjlLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjlLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjlLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd8, %SP, 0;
cvta.to.local.u64 %rd2, %rd8;
mov.u32 %r43, 0;
mov.pred %p1, 0;
@%p1 bra BB97_2;

BB97_1:
mul.wide.s32 %rd9, %r43, 8;
add.s64 %rd10, %rd3, %rd9;
ld.param.u64 %rd11, [%rd10];
add.s64 %rd12, %rd2, %rd9;
st.local.u64 [%rd12], %rd11;
add.s32 %r43, %r43, 1;
setp.lt.u32	%p2, %r43, 27;
@%p2 bra BB97_1;

BB97_2:
mov.u32 %r26, %ntid.x;
mov.u32 %r27, %ctaid.x;
mov.u32 %r28, %tid.x;
mad.lo.s32 %r44, %r26, %r27, %r28;
setp.ge.u32	%p3, %r44, %r24;
@%p3 bra BB97_14;

ld.param.u64 %rd13, [%rd1];
cvta.to.global.u64 %rd5, %rd13;
ld.param.v2.u32 {%r29, %r30}, [%rd1+8];
ld.param.u32 %r6, [%rd1+16];
ld.param.u32 %r7, [%rd1+108];
ld.param.v2.u32 {%r31, %r32}, [%rd1+112];

BB97_4:
rem.u32 %r11, %r44, %r6;
setp.eq.s32	%p4, %r23, 2;
mov.u32 %r45, 0;
@%p4 bra BB97_6;

ld.local.u32 %r34, [%rd2+116];
mul.lo.s32 %r45, %r34, %r11;

BB97_6:
div.u32 %r14, %r44, %r6;
rem.u32 %r15, %r14, %r30;
setp.eq.s32	%p5, %r23, 1;
@%p5 bra BB97_8;

ld.local.u32 %r35, [%rd2+112];
mad.lo.s32 %r45, %r35, %r15, %r45;

BB97_8:
mul.lo.s32 %r36, %r32, %r11;
mad.lo.s32 %r18, %r31, %r15, %r36;
div.u32 %r37, %r14, %r30;
rem.u32 %r19, %r37, %r29;
setp.eq.s32	%p6, %r23, 0;
@%p6 bra BB97_10;

ld.local.u32 %r38, [%rd2+108];
mad.lo.s32 %r45, %r38, %r19, %r45;

BB97_10:
mad.lo.s32 %r39, %r7, %r19, %r18;
mul.wide.u32 %rd14, %r39, 8;
add.s64 %rd15, %rd5, %rd14;
ld.global.u64 %rd6, [%rd15];
setp.lt.s64	%p7, %rd6, 0;
@%p7 bra BB97_12;

mul.wide.s32 %rd16, %r23, 4;
add.s64 %rd17, %rd2, %rd16;
ld.local.u32 %rd18, [%rd17+8];
setp.lt.s64	%p8, %rd6, %rd18;
@%p8 bra BB97_13;

BB97_12:
mov.u64 %rd19, $str2;
cvta.global.u64 %rd20, %rd19;
mov.u64 %rd21, $str1;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, __T2117;
cvta.global.u64 %rd24, %rd23;
mov.u32 %r40, 176;
mov.u64 %rd25, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd20;
.param .b64 param1;
st.param.b64	[param1+0], %rd22;
.param .b32 param2;
st.param.b32	[param2+0], %r40;
.param .b64 param3;
st.param.b64	[param3+0], %rd24;
.param .b64 param4;
st.param.b64	[param4+0], %rd25;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB97_13:
mul.wide.s32 %rd26, %r23, 4;
add.s64 %rd27, %rd2, %rd26;
ld.local.u32 %rd28, [%rd27+108];
mul.lo.s64 %rd29, %rd28, %rd6;
cvt.u64.u32	%rd30, %r45;
add.s64 %rd31, %rd29, %rd30;
and.b64 %rd32, %rd31, 4294967295;
ld.local.u64 %rd33, [%rd2];
shl.b64 %rd34, %rd32, 3;
add.s64 %rd35, %rd33, %rd34;
st.u64 [%rd35], %rd7;
mov.u32 %r42, %nctaid.x;
mad.lo.s32 %r44, %r42, %r26, %r44;
setp.lt.u32	%p9, %r44, %r24;
@%p9 bra BB97_4;

BB97_14:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjlLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjlLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjlLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .u64 _Z30THCudaTensor_scatterFillKernelIjlLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjlLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjlLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot98[432];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<12>;
.reg .b32 %r<54>;
.reg .b64 %rd<64>;


mov.u64 %rd63, __local_depot98;
cvta.local.u64 %SP, %rd63;
ld.param.u64 %rd17, [_Z30THCudaTensor_scatterFillKernelIjlLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r24, [_Z30THCudaTensor_scatterFillKernelIjlLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r25, [_Z30THCudaTensor_scatterFillKernelIjlLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd4, _Z30THCudaTensor_scatterFillKernelIjlLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjlLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd18, %SP, 216;
cvta.to.local.u64 %rd2, %rd18;
add.u64 %rd19, %SP, 0;
cvta.to.local.u64 %rd3, %rd19;
mov.u32 %r40, 0;
mov.pred %p1, 0;
@%p1 bra BB98_2;

BB98_1:
mul.wide.s32 %rd20, %r40, 8;
add.s64 %rd21, %rd4, %rd20;
ld.param.u64 %rd22, [%rd21];
add.s64 %rd23, %rd2, %rd20;
st.local.u64 [%rd23], %rd22;
add.s32 %r40, %r40, 1;
setp.lt.u32	%p2, %r40, 27;
@%p2 bra BB98_1;

BB98_2:
mov.u32 %r41, 0;
@%p1 bra BB98_4;

BB98_3:
mul.wide.s32 %rd24, %r41, 8;
add.s64 %rd25, %rd1, %rd24;
ld.param.u64 %rd26, [%rd25];
add.s64 %rd27, %rd3, %rd24;
st.local.u64 [%rd27], %rd26;
add.s32 %r41, %r41, 1;
setp.lt.u32	%p4, %r41, 27;
@%p4 bra BB98_3;

BB98_4:
mov.u32 %r28, %ntid.x;
mov.u32 %r29, %ctaid.x;
mov.u32 %r30, %tid.x;
mad.lo.s32 %r46, %r28, %r29, %r30;
setp.ge.u32	%p5, %r46, %r25;
@%p5 bra BB98_15;

ld.local.u32 %r6, [%rd3+208];

BB98_6:
mov.u32 %r44, %r46;
mov.u32 %r7, %r44;
cvt.s64.s32	%rd29, %r6;
not.b64 %rd30, %rd29;
mov.u64 %rd31, -26;
sub.s64 %rd32, %rd31, %rd29;
add.s32 %r34, %r6, -1;
sub.s32 %r42, %r34, %r24;
neg.s64 %rd60, %rd30;
neg.s64 %rd61, %rd32;
mov.u32 %r51, 0;
mov.u64 %rd62, 0;
mov.u32 %r52, %r51;
mov.u32 %r47, %r51;
setp.lt.s32	%p6, %r6, 1;
mov.u32 %r43, %r6;
mov.u32 %r45, %r7;
@%p6 bra BB98_11;

BB98_7:
mov.u32 %r48, %r52;
mov.u32 %r53, %r48;
mov.u32 %r11, %r45;
mov.u32 %r10, %r43;
add.s32 %r14, %r10, -1;
shl.b64 %rd33, %rd60, 2;
add.s64 %rd34, %rd3, %rd33;
ld.local.u32 %r15, [%rd34];
rem.u32 %r16, %r11, %r15;
ld.local.u32 %r35, [%rd34+100];
mad.lo.s32 %r47, %r35, %r16, %r47;
setp.eq.s32	%p7, %r42, 0;
@%p7 bra BB98_9;

shl.b64 %rd35, %rd61, 2;
add.s64 %rd36, %rd2, %rd35;
ld.local.u32 %r36, [%rd36];
mad.lo.s32 %r53, %r36, %r16, %r53;

BB98_9:
mov.u32 %r52, %r53;
div.u32 %r20, %r11, %r15;
add.s32 %r42, %r42, -1;
add.s64 %rd61, %rd61, -1;
add.s64 %rd60, %rd60, -1;
setp.gt.s32	%p8, %r14, 0;
mov.u32 %r43, %r14;
mov.u32 %r45, %r20;
@%p8 bra BB98_7;

cvt.u64.u32	%rd62, %r47;
mov.u32 %r51, %r52;

BB98_11:
ld.local.u64 %rd37, [%rd3];
shl.b64 %rd38, %rd62, 3;
add.s64 %rd39, %rd37, %rd38;
ld.u64 %rd16, [%rd39];
setp.lt.s64	%p9, %rd16, 0;
@%p9 bra BB98_13;

mul.wide.s32 %rd40, %r24, 4;
add.s64 %rd41, %rd2, %rd40;
ld.local.u32 %rd42, [%rd41+8];
setp.lt.s64	%p10, %rd16, %rd42;
@%p10 bra BB98_14;

BB98_13:
mov.u64 %rd43, $str2;
cvta.global.u64 %rd44, %rd43;
mov.u64 %rd45, $str1;
cvta.global.u64 %rd46, %rd45;
mov.u64 %rd47, __T2118;
cvta.global.u64 %rd48, %rd47;
mov.u32 %r37, 176;
mov.u64 %rd49, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd44;
.param .b64 param1;
st.param.b64	[param1+0], %rd46;
.param .b32 param2;
st.param.b32	[param2+0], %r37;
.param .b64 param3;
st.param.b64	[param3+0], %rd48;
.param .b64 param4;
st.param.b64	[param4+0], %rd49;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB98_14:
mul.wide.s32 %rd50, %r24, 4;
add.s64 %rd51, %rd2, %rd50;
ld.local.u32 %rd52, [%rd51+108];
mul.lo.s64 %rd53, %rd52, %rd16;
cvt.u64.u32	%rd54, %r51;
add.s64 %rd55, %rd53, %rd54;
and.b64 %rd56, %rd55, 4294967295;
ld.local.u64 %rd57, [%rd2];
shl.b64 %rd58, %rd56, 3;
add.s64 %rd59, %rd57, %rd58;
st.u64 [%rd59], %rd17;
mov.u32 %r39, %nctaid.x;
mad.lo.s32 %r46, %r39, %r28, %r7;
setp.lt.u32	%p11, %r46, %r25;
@%p11 bra BB98_6;

BB98_15:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelImlLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelImlLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[416],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelImlLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[416],
.param .u64 _Z30THCudaTensor_scatterFillKernelImlLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelImlLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u64 _Z30THCudaTensor_scatterFillKernelImlLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot99[832];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b32 %r<33>;
.reg .b64 %rd<100>;


mov.u64 %rd99, __local_depot99;
cvta.local.u64 %SP, %rd99;
ld.param.u64 %rd34, [_Z30THCudaTensor_scatterFillKernelImlLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r11, [_Z30THCudaTensor_scatterFillKernelImlLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u64 %rd35, [_Z30THCudaTensor_scatterFillKernelImlLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd4, _Z30THCudaTensor_scatterFillKernelImlLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelImlLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd36, %SP, 416;
cvta.to.local.u64 %rd2, %rd36;
add.u64 %rd37, %SP, 0;
cvta.to.local.u64 %rd3, %rd37;
mov.u32 %r29, 0;
mov.pred %p1, 0;
@%p1 bra BB99_2;

BB99_1:
mul.wide.s32 %rd38, %r29, 8;
add.s64 %rd39, %rd4, %rd38;
ld.param.u64 %rd40, [%rd39];
add.s64 %rd41, %rd2, %rd38;
st.local.u64 [%rd41], %rd40;
add.s32 %r29, %r29, 1;
setp.lt.u32	%p2, %r29, 52;
@%p2 bra BB99_1;

BB99_2:
mov.u32 %r30, 0;
@%p1 bra BB99_4;

BB99_3:
mul.wide.s32 %rd42, %r30, 8;
add.s64 %rd43, %rd1, %rd42;
ld.param.u64 %rd44, [%rd43];
add.s64 %rd45, %rd3, %rd42;
st.local.u64 [%rd45], %rd44;
add.s32 %r30, %r30, 1;
setp.lt.u32	%p4, %r30, 52;
@%p4 bra BB99_3;

BB99_4:
mov.u32 %r14, %ntid.x;
mov.u32 %r15, %ctaid.x;
mov.u32 %r16, %tid.x;
mad.lo.s32 %r17, %r14, %r15, %r16;
cvt.u64.u32	%rd88, %r17;
setp.ge.u64	%p5, %rd88, %rd35;
@%p5 bra BB99_20;

ld.local.u32 %r5, [%rd3+408];

BB99_6:
mov.u64 %rd84, %rd88;
mov.u64 %rd9, %rd84;
mul.wide.s32 %rd50, %r5, 8;
add.s64 %rd82, %rd3, %rd50;
add.s64 %rd51, %rd50, %rd2;
add.s64 %rd83, %rd51, 200;
add.s32 %r18, %r5, -1;
sub.s32 %r31, %r18, %r11;
mov.u64 %rd96, 0;
mov.u64 %rd91, %rd96;
mov.u64 %rd97, %rd96;
mov.u64 %rd92, %rd96;
setp.lt.s32	%p6, %r5, 1;
mov.u32 %r32, %r5;
mov.u64 %rd86, %rd9;
@%p6 bra BB99_16;

BB99_7:
mov.u64 %rd98, %rd97;
mov.u64 %rd14, %rd86;
mov.u32 %r8, %r32;
add.s32 %r9, %r8, -1;
ld.local.u64 %rd18, [%rd82];
or.b64 %rd52, %rd14, %rd18;
and.b64 %rd53, %rd52, -4294967296;
setp.eq.s64	%p7, %rd53, 0;
@%p7 bra BB99_9;
bra.uni BB99_8;

BB99_9:
cvt.u32.u64	%r19, %rd18;
cvt.u32.u64	%r20, %rd14;
rem.u32 %r21, %r20, %r19;
cvt.u64.u32	%rd89, %r21;
bra.uni BB99_10;

BB99_8:
rem.u64 %rd89, %rd14, %rd18;

BB99_10:
ld.local.u64 %rd54, [%rd82+200];
mul.lo.s64 %rd55, %rd54, %rd89;
add.s64 %rd92, %rd55, %rd92;
setp.eq.s32	%p8, %r31, 0;
@%p8 bra BB99_12;

ld.local.u64 %rd56, [%rd83];
mul.lo.s64 %rd57, %rd56, %rd89;
add.s64 %rd98, %rd57, %rd98;

BB99_12:
mov.u64 %rd97, %rd98;
@%p7 bra BB99_14;
bra.uni BB99_13;

BB99_14:
cvt.u32.u64	%r22, %rd18;
cvt.u32.u64	%r23, %rd14;
div.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd87, %r24;
bra.uni BB99_15;

BB99_13:
div.u64 %rd87, %rd14, %rd18;

BB99_15:
mov.u64 %rd27, %rd87;
add.s32 %r31, %r31, -1;
add.s64 %rd83, %rd83, -8;
add.s64 %rd82, %rd82, -8;
setp.gt.s32	%p10, %r9, 0;
mov.u32 %r32, %r9;
mov.u64 %rd86, %rd27;
mov.u64 %rd91, %rd92;
mov.u64 %rd96, %rd97;
@%p10 bra BB99_7;

BB99_16:
ld.local.u64 %rd60, [%rd3];
shl.b64 %rd61, %rd91, 3;
add.s64 %rd62, %rd60, %rd61;
ld.u64 %rd32, [%rd62];
setp.lt.s64	%p11, %rd32, 0;
@%p11 bra BB99_18;

mul.wide.s32 %rd63, %r11, 8;
add.s64 %rd64, %rd2, %rd63;
ld.local.u64 %rd65, [%rd64+8];
setp.lt.u64	%p12, %rd32, %rd65;
@%p12 bra BB99_19;

BB99_18:
mov.u64 %rd66, $str2;
cvta.global.u64 %rd67, %rd66;
mov.u64 %rd68, $str1;
cvta.global.u64 %rd69, %rd68;
mov.u64 %rd70, __T2119;
cvta.global.u64 %rd71, %rd70;
mov.u32 %r25, 176;
mov.u64 %rd72, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd67;
.param .b64 param1;
st.param.b64	[param1+0], %rd69;
.param .b32 param2;
st.param.b32	[param2+0], %r25;
.param .b64 param3;
st.param.b64	[param3+0], %rd71;
.param .b64 param4;
st.param.b64	[param4+0], %rd72;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB99_19:
mul.wide.s32 %rd73, %r11, 8;
add.s64 %rd74, %rd2, %rd73;
ld.local.u64 %rd75, [%rd74+208];
mul.lo.s64 %rd76, %rd75, %rd32;
add.s64 %rd77, %rd76, %rd96;
ld.local.u64 %rd78, [%rd2];
shl.b64 %rd79, %rd77, 3;
add.s64 %rd80, %rd78, %rd79;
st.u64 [%rd80], %rd34;
mov.u32 %r27, %nctaid.x;
mul.lo.s32 %r28, %r27, %r14;
cvt.u64.u32	%rd81, %r28;
add.s64 %rd88, %rd81, %rd9;
setp.lt.u64	%p13, %rd88, %rd35;
@%p13 bra BB99_6;

BB99_20:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4
)
{
.local .align 8 .b8 __local_depot100[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .b32 %r<25>;
.reg .b64 %rd<44>;


mov.u64 %rd43, __local_depot100;
cvta.local.u64 %SP, %rd43;
ld.param.u32 %r10, [_Z25THCudaTensor_gatherKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3];
ld.param.u32 %r11, [_Z25THCudaTensor_gatherKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd3, %rd11;
mov.u32 %r23, 0;
mov.pred %p1, 0;
@%p1 bra BB100_2;

BB100_1:
mul.wide.s32 %rd12, %r23, 8;
add.s64 %rd13, %rd4, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd3, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r23, %r23, 1;
setp.lt.u32	%p2, %r23, 27;
@%p2 bra BB100_1;

BB100_2:
mov.u32 %r13, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r24, %r13, %r14, %r15;
setp.ge.u32	%p3, %r24, %r11;
@%p3 bra BB100_10;

ld.param.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd6, %rd16;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd17, [%rd2];
cvta.to.global.u64 %rd7, %rd17;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB100_4:
rem.u32 %r8, %r24, %r5;
setp.eq.s32	%p4, %r10, 0;
mov.u64 %rd42, 0;
@%p4 bra BB100_6;

ld.local.u32 %r16, [%rd3+108];
mul.lo.s32 %r17, %r16, %r8;
cvt.u64.u32	%rd42, %r17;

BB100_6:
mul.lo.s32 %r18, %r6, %r8;
mul.wide.u32 %rd19, %r18, 8;
add.s64 %rd20, %rd7, %rd19;
ld.global.u64 %rd10, [%rd20];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB100_8;

mul.wide.s32 %rd21, %r10, 4;
add.s64 %rd22, %rd3, %rd21;
ld.local.u32 %rd23, [%rd22+8];
setp.lt.s64	%p6, %rd10, %rd23;
@%p6 bra BB100_9;

BB100_8:
mov.u64 %rd24, $str;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, $str1;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, __T2122;
cvta.global.u64 %rd29, %rd28;
mov.u32 %r19, 97;
mov.u64 %rd30, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd25;
.param .b64 param1;
st.param.b64	[param1+0], %rd27;
.param .b32 param2;
st.param.b32	[param2+0], %r19;
.param .b64 param3;
st.param.b64	[param3+0], %rd29;
.param .b64 param4;
st.param.b64	[param4+0], %rd30;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB100_9:
mul.lo.s32 %r20, %r4, %r8;
mul.wide.s32 %rd31, %r10, 4;
add.s64 %rd32, %rd3, %rd31;
ld.local.u32 %rd33, [%rd32+108];
mul.lo.s64 %rd34, %rd33, %rd10;
add.s64 %rd35, %rd34, %rd42;
mul.wide.u32 %rd36, %r20, 2;
add.s64 %rd37, %rd6, %rd36;
ld.local.u64 %rd38, [%rd3];
shl.b64 %rd39, %rd35, 1;
and.b64 %rd40, %rd39, 8589934590;
add.s64 %rd41, %rd38, %rd40;
ld.u16 %rs1, [%rd41];
st.global.u16 [%rd37], %rs1;
mov.u32 %r22, %nctaid.x;
mad.lo.s32 %r24, %r22, %r13, %r24;
setp.lt.u32	%p7, %r24, %r11;
@%p7 bra BB100_4;

BB100_10:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4
)
{
.local .align 8 .b8 __local_depot101[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b16 %rs<2>;
.reg .b32 %r<40>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot101;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r19, [_Z25THCudaTensor_gatherKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3];
ld.param.u32 %r20, [_Z25THCudaTensor_gatherKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r37, 0;
mov.pred %p1, 0;
@%p1 bra BB101_2;

BB101_1:
mul.wide.s32 %rd10, %r37, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r37, %r37, 1;
setp.lt.u32	%p2, %r37, 27;
@%p2 bra BB101_1;

BB101_2:
mov.u32 %r22, %ntid.x;
mov.u32 %r23, %ctaid.x;
mov.u32 %r24, %tid.x;
mad.lo.s32 %r38, %r22, %r23, %r24;
setp.ge.u32	%p3, %r38, %r20;
@%p3 bra BB101_12;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r25, %r26}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB101_4:
rem.u32 %r11, %r38, %r26;
setp.eq.s32	%p4, %r19, 1;
mov.u32 %r39, 0;
@%p4 bra BB101_6;

ld.local.u32 %r28, [%rd3+112];
mul.lo.s32 %r39, %r28, %r11;

BB101_6:
div.u32 %r29, %r38, %r26;
rem.u32 %r14, %r29, %r25;
setp.eq.s32	%p5, %r19, 0;
@%p5 bra BB101_8;

ld.local.u32 %r30, [%rd3+108];
mad.lo.s32 %r39, %r30, %r14, %r39;

BB101_8:
mul.lo.s32 %r31, %r9, %r11;
mul.lo.s32 %r32, %r5, %r11;
mad.lo.s32 %r33, %r8, %r14, %r31;
mad.lo.s32 %r17, %r4, %r14, %r32;
mul.wide.u32 %rd16, %r33, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB101_10;

mul.wide.s32 %rd18, %r19, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p7, %rd8, %rd20;
@%p7 bra BB101_11;

BB101_10:
mov.u64 %rd21, $str;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T2123;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r34, 97;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r34;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB101_11:
mul.wide.s32 %rd28, %r19, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r39;
add.s64 %rd33, %rd31, %rd32;
mul.wide.u32 %rd34, %r17, 2;
add.s64 %rd35, %rd6, %rd34;
ld.local.u64 %rd36, [%rd3];
shl.b64 %rd37, %rd33, 1;
and.b64 %rd38, %rd37, 8589934590;
add.s64 %rd39, %rd36, %rd38;
ld.u16 %rs1, [%rd39];
st.global.u16 [%rd35], %rs1;
mov.u32 %r36, %nctaid.x;
mad.lo.s32 %r38, %r36, %r22, %r38;
setp.lt.u32	%p8, %r38, %r20;
@%p8 bra BB101_4;

BB101_12:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4
)
{
.local .align 8 .b8 __local_depot102[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b16 %rs<2>;
.reg .b32 %r<54>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot102;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r26, [_Z25THCudaTensor_gatherKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3];
ld.param.u32 %r27, [_Z25THCudaTensor_gatherKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r51, 0;
mov.pred %p1, 0;
@%p1 bra BB102_2;

BB102_1:
mul.wide.s32 %rd10, %r51, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p2, %r51, 27;
@%p2 bra BB102_1;

BB102_2:
mov.u32 %r29, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r52, %r29, %r30, %r31;
setp.ge.u32	%p3, %r52, %r27;
@%p3 bra BB102_14;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r32, %r33}, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r34, %r35}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r36, %r37}, [%rd2+112];

BB102_4:
rem.u32 %r14, %r52, %r9;
setp.eq.s32	%p4, %r26, 2;
mov.u32 %r53, 0;
@%p4 bra BB102_6;

ld.local.u32 %r39, [%rd3+116];
mul.lo.s32 %r53, %r39, %r14;

BB102_6:
div.u32 %r17, %r52, %r9;
rem.u32 %r18, %r17, %r35;
setp.eq.s32	%p5, %r26, 1;
@%p5 bra BB102_8;

ld.local.u32 %r40, [%rd3+112];
mad.lo.s32 %r53, %r40, %r18, %r53;

BB102_8:
div.u32 %r41, %r17, %r35;
rem.u32 %r21, %r41, %r34;
setp.eq.s32	%p6, %r26, 0;
@%p6 bra BB102_10;

ld.local.u32 %r42, [%rd3+108];
mad.lo.s32 %r53, %r42, %r21, %r53;

BB102_10:
mul.lo.s32 %r43, %r37, %r14;
mul.lo.s32 %r44, %r33, %r14;
mad.lo.s32 %r45, %r36, %r18, %r43;
mad.lo.s32 %r46, %r32, %r18, %r44;
mad.lo.s32 %r47, %r10, %r21, %r45;
mad.lo.s32 %r24, %r4, %r21, %r46;
mul.wide.u32 %rd16, %r47, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB102_12;

mul.wide.s32 %rd18, %r26, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p8, %rd8, %rd20;
@%p8 bra BB102_13;

BB102_12:
mov.u64 %rd21, $str;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T2124;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r48, 97;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r48;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB102_13:
mul.wide.s32 %rd28, %r26, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r53;
add.s64 %rd33, %rd31, %rd32;
mul.wide.u32 %rd34, %r24, 2;
add.s64 %rd35, %rd6, %rd34;
ld.local.u64 %rd36, [%rd3];
shl.b64 %rd37, %rd33, 1;
and.b64 %rd38, %rd37, 8589934590;
add.s64 %rd39, %rd36, %rd38;
ld.u16 %rs1, [%rd39];
st.global.u16 [%rd35], %rs1;
mov.u32 %r50, %nctaid.x;
mad.lo.s32 %r52, %r50, %r29, %r52;
setp.lt.u32	%p9, %r52, %r27;
@%p9 bra BB102_4;

BB102_14:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4
)
{
.local .align 8 .b8 __local_depot103[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .b32 %r<63>;
.reg .b64 %rd<70>;


mov.u64 %rd69, __local_depot103;
cvta.local.u64 %SP, %rd69;
ld.param.u32 %r28, [_Z25THCudaTensor_gatherKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3];
ld.param.u32 %r29, [_Z25THCudaTensor_gatherKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4];
mov.u64 %rd6, _Z25THCudaTensor_gatherKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0;
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2;
add.u64 %rd20, %SP, 216;
cvta.to.local.u64 %rd3, %rd20;
add.u64 %rd21, %SP, 432;
cvta.to.local.u64 %rd4, %rd21;
add.u64 %rd22, %SP, 0;
cvta.to.local.u64 %rd5, %rd22;
mov.u32 %r47, 0;
mov.pred %p1, 0;
@%p1 bra BB103_2;

BB103_1:
mul.wide.s32 %rd23, %r47, 8;
add.s64 %rd24, %rd6, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r47, %r47, 1;
setp.lt.u32	%p2, %r47, 27;
@%p2 bra BB103_1;

BB103_2:
mov.u32 %r48, 0;
@%p1 bra BB103_4;

BB103_3:
mul.wide.s32 %rd27, %r48, 8;
add.s64 %rd28, %rd1, %rd27;
ld.param.u64 %rd29, [%rd28];
add.s64 %rd30, %rd4, %rd27;
st.local.u64 [%rd30], %rd29;
add.s32 %r48, %r48, 1;
setp.lt.u32	%p4, %r48, 27;
@%p4 bra BB103_3;

BB103_4:
mov.u32 %r49, 0;
@%p1 bra BB103_6;

BB103_5:
mul.wide.s32 %rd31, %r49, 8;
add.s64 %rd32, %rd2, %rd31;
ld.param.u64 %rd33, [%rd32];
add.s64 %rd34, %rd5, %rd31;
st.local.u64 [%rd34], %rd33;
add.s32 %r49, %r49, 1;
setp.lt.u32	%p6, %r49, 27;
@%p6 bra BB103_5;

BB103_6:
mov.u32 %r33, %ntid.x;
mov.u32 %r34, %ctaid.x;
mov.u32 %r35, %tid.x;
mad.lo.s32 %r54, %r33, %r34, %r35;
setp.ge.u32	%p7, %r54, %r29;
@%p7 bra BB103_17;

ld.local.u32 %r8, [%rd5+208];

BB103_8:
mov.u32 %r52, %r54;
mov.u32 %r9, %r52;
mul.wide.s32 %rd66, %r8, 4;
add.s32 %r40, %r8, -1;
sub.s32 %r50, %r40, %r28;
mov.u64 %rd68, 0;
mov.u32 %r60, 0;
mov.u64 %rd67, %rd68;
mov.u32 %r56, %r60;
mov.u32 %r61, %r60;
mov.u32 %r55, %r60;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r51, %r8;
mov.u32 %r53, %r9;
@%p8 bra BB103_13;

BB103_9:
mov.u32 %r57, %r61;
mov.u32 %r62, %r57;
mov.u32 %r13, %r53;
mov.u32 %r12, %r51;
add.s64 %rd37, %rd3, %rd66;
add.s32 %r17, %r12, -1;
add.s64 %rd38, %rd5, %rd66;
ld.local.u32 %r18, [%rd38+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r41, [%rd38+104];
mad.lo.s32 %r55, %r41, %r19, %r55;
ld.local.u32 %r42, [%rd37+104];
mad.lo.s32 %r56, %r42, %r19, %r56;
setp.eq.s32	%p9, %r50, 0;
@%p9 bra BB103_11;

add.s64 %rd39, %rd4, %rd66;
ld.local.u32 %r43, [%rd39+104];
mad.lo.s32 %r62, %r43, %r19, %r62;

BB103_11:
mov.u32 %r61, %r62;
div.u32 %r24, %r13, %r18;
add.s32 %r50, %r50, -1;
add.s64 %rd66, %rd66, -4;
setp.gt.s32	%p10, %r17, 0;
mov.u32 %r51, %r17;
mov.u32 %r53, %r24;
@%p10 bra BB103_9;

cvt.u64.u32	%rd67, %r55;
cvt.u64.u32	%rd68, %r56;
mov.u32 %r60, %r61;

BB103_13:
ld.local.u64 %rd40, [%rd5];
shl.b64 %rd41, %rd67, 3;
add.s64 %rd42, %rd40, %rd41;
ld.u64 %rd19, [%rd42];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB103_15;

mul.wide.s32 %rd43, %r28, 4;
add.s64 %rd44, %rd4, %rd43;
ld.local.u32 %rd45, [%rd44+8];
setp.lt.s64	%p12, %rd19, %rd45;
@%p12 bra BB103_16;

BB103_15:
mov.u64 %rd46, $str;
cvta.global.u64 %rd47, %rd46;
mov.u64 %rd48, $str1;
cvta.global.u64 %rd49, %rd48;
mov.u64 %rd50, __T2125;
cvta.global.u64 %rd51, %rd50;
mov.u32 %r44, 97;
mov.u64 %rd52, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd47;
.param .b64 param1;
st.param.b64	[param1+0], %rd49;
.param .b32 param2;
st.param.b32	[param2+0], %r44;
.param .b64 param3;
st.param.b64	[param3+0], %rd51;
.param .b64 param4;
st.param.b64	[param4+0], %rd52;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB103_16:
mul.wide.s32 %rd53, %r28, 4;
add.s64 %rd54, %rd4, %rd53;
ld.local.u32 %rd55, [%rd54+108];
mul.lo.s64 %rd56, %rd55, %rd19;
cvt.u64.u32	%rd57, %r60;
add.s64 %rd58, %rd56, %rd57;
ld.local.u64 %rd59, [%rd3];
shl.b64 %rd60, %rd68, 1;
add.s64 %rd61, %rd59, %rd60;
ld.local.u64 %rd62, [%rd4];
shl.b64 %rd63, %rd58, 1;
and.b64 %rd64, %rd63, 8589934590;
add.s64 %rd65, %rd62, %rd64;
ld.u16 %rs1, [%rd65];
st.u16 [%rd61], %rs1;
mov.u32 %r46, %nctaid.x;
mad.lo.s32 %r54, %r46, %r33, %r9;
setp.lt.u32	%p13, %r54, %r29;
@%p13 bra BB103_8;

BB103_17:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0[416],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1[416],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2[416],
.param .u32 _Z25THCudaTensor_gatherKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3,
.param .u64 _Z25THCudaTensor_gatherKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4
)
{
.local .align 8 .b8 __local_depot104[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<16>;
.reg .b16 %rs<2>;
.reg .b32 %r<37>;
.reg .b64 %rd<117>;


mov.u64 %rd116, __local_depot104;
cvta.local.u64 %SP, %rd116;
ld.param.u32 %r13, [_Z25THCudaTensor_gatherKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3];
ld.param.u64 %rd38, [_Z25THCudaTensor_gatherKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4];
mov.u64 %rd6, _Z25THCudaTensor_gatherKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0;
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2;
add.u64 %rd39, %SP, 416;
cvta.to.local.u64 %rd3, %rd39;
add.u64 %rd40, %SP, 832;
cvta.to.local.u64 %rd4, %rd40;
add.u64 %rd41, %SP, 0;
cvta.to.local.u64 %rd5, %rd41;
mov.u32 %r32, 0;
mov.pred %p1, 0;
@%p1 bra BB104_2;

BB104_1:
mul.wide.s32 %rd42, %r32, 8;
add.s64 %rd43, %rd6, %rd42;
ld.param.u64 %rd44, [%rd43];
add.s64 %rd45, %rd3, %rd42;
st.local.u64 [%rd45], %rd44;
add.s32 %r32, %r32, 1;
setp.lt.u32	%p2, %r32, 52;
@%p2 bra BB104_1;

BB104_2:
mov.u32 %r33, 0;
@%p1 bra BB104_4;

BB104_3:
mul.wide.s32 %rd46, %r33, 8;
add.s64 %rd47, %rd1, %rd46;
ld.param.u64 %rd48, [%rd47];
add.s64 %rd49, %rd4, %rd46;
st.local.u64 [%rd49], %rd48;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p4, %r33, 52;
@%p4 bra BB104_3;

BB104_4:
mov.u32 %r34, 0;
@%p1 bra BB104_6;

BB104_5:
mul.wide.s32 %rd50, %r34, 8;
add.s64 %rd51, %rd2, %rd50;
ld.param.u64 %rd52, [%rd51];
add.s64 %rd53, %rd5, %rd50;
st.local.u64 [%rd53], %rd52;
add.s32 %r34, %r34, 1;
setp.lt.u32	%p6, %r34, 52;
@%p6 bra BB104_5;

BB104_6:
mov.u32 %r17, %ntid.x;
mov.u32 %r18, %ctaid.x;
mov.u32 %r19, %tid.x;
mad.lo.s32 %r20, %r17, %r18, %r19;
cvt.u64.u32	%rd102, %r20;
setp.ge.u64	%p7, %rd102, %rd38;
@%p7 bra BB104_22;

ld.local.u32 %r7, [%rd5+408];

BB104_8:
mov.u64 %rd98, %rd102;
mov.u64 %rd13, %rd98;
mul.wide.s32 %rd97, %r7, 8;
add.s32 %r21, %r7, -1;
sub.s32 %r35, %r21, %r13;
mov.u64 %rd114, 0;
mov.u64 %rd110, %rd114;
mov.u64 %rd105, %rd114;
mov.u64 %rd115, %rd114;
mov.u64 %rd111, %rd114;
mov.u64 %rd106, %rd114;
setp.lt.s32	%p8, %r7, 1;
mov.u32 %r36, %r7;
mov.u64 %rd100, %rd13;
@%p8 bra BB104_18;

BB104_9:
mov.u64 %rd112, %rd111;
mov.u64 %rd16, %rd100;
mov.u32 %r10, %r36;
add.s32 %r11, %r10, -1;
add.s64 %rd20, %rd5, %rd97;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd60, %rd16, %rd21;
and.b64 %rd61, %rd60, -4294967296;
setp.eq.s64	%p9, %rd61, 0;
@%p9 bra BB104_11;
bra.uni BB104_10;

BB104_11:
cvt.u32.u64	%r22, %rd21;
cvt.u32.u64	%r23, %rd16;
rem.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd103, %r24;
bra.uni BB104_12;

BB104_10:
rem.u64 %rd103, %rd16, %rd21;

BB104_12:
add.s64 %rd62, %rd3, %rd97;
ld.local.u64 %rd63, [%rd20+200];
mul.lo.s64 %rd64, %rd63, %rd103;
add.s64 %rd106, %rd64, %rd106;
ld.local.u64 %rd65, [%rd62+200];
mul.lo.s64 %rd66, %rd65, %rd103;
add.s64 %rd115, %rd66, %rd115;
setp.eq.s32	%p10, %r35, 0;
@%p10 bra BB104_14;

add.s64 %rd67, %rd4, %rd97;
ld.local.u64 %rd68, [%rd67+200];
mul.lo.s64 %rd69, %rd68, %rd103;
add.s64 %rd112, %rd69, %rd112;

BB104_14:
mov.u64 %rd111, %rd112;
@%p9 bra BB104_16;
bra.uni BB104_15;

BB104_16:
cvt.u32.u64	%r25, %rd21;
cvt.u32.u64	%r26, %rd16;
div.u32 %r27, %r26, %r25;
cvt.u64.u32	%rd101, %r27;
bra.uni BB104_17;

BB104_15:
div.u64 %rd101, %rd16, %rd21;

BB104_17:
mov.u64 %rd31, %rd101;
add.s32 %r35, %r35, -1;
add.s64 %rd97, %rd97, -8;
setp.gt.s32	%p12, %r11, 0;
mov.u32 %r36, %r11;
mov.u64 %rd100, %rd31;
mov.u64 %rd105, %rd106;
mov.u64 %rd110, %rd111;
mov.u64 %rd114, %rd115;
@%p12 bra BB104_9;

BB104_18:
ld.local.u64 %rd72, [%rd5];
shl.b64 %rd73, %rd105, 3;
add.s64 %rd74, %rd72, %rd73;
ld.u64 %rd36, [%rd74];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB104_20;

mul.wide.s32 %rd75, %r13, 8;
add.s64 %rd76, %rd4, %rd75;
ld.local.u64 %rd77, [%rd76+8];
setp.lt.u64	%p14, %rd36, %rd77;
@%p14 bra BB104_21;

BB104_20:
mov.u64 %rd78, $str;
cvta.global.u64 %rd79, %rd78;
mov.u64 %rd80, $str1;
cvta.global.u64 %rd81, %rd80;
mov.u64 %rd82, __T2127;
cvta.global.u64 %rd83, %rd82;
mov.u32 %r28, 97;
mov.u64 %rd84, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd79;
.param .b64 param1;
st.param.b64	[param1+0], %rd81;
.param .b32 param2;
st.param.b32	[param2+0], %r28;
.param .b64 param3;
st.param.b64	[param3+0], %rd83;
.param .b64 param4;
st.param.b64	[param4+0], %rd84;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB104_21:
mul.wide.s32 %rd85, %r13, 8;
add.s64 %rd86, %rd4, %rd85;
ld.local.u64 %rd87, [%rd86+208];
mul.lo.s64 %rd88, %rd87, %rd36;
add.s64 %rd89, %rd88, %rd110;
ld.local.u64 %rd90, [%rd3];
shl.b64 %rd91, %rd114, 1;
add.s64 %rd92, %rd90, %rd91;
ld.local.u64 %rd93, [%rd4];
shl.b64 %rd94, %rd89, 1;
add.s64 %rd95, %rd93, %rd94;
ld.u16 %rs1, [%rd95];
st.u16 [%rd92], %rs1;
mov.u32 %r30, %nctaid.x;
mul.lo.s32 %r31, %r30, %r17;
cvt.u64.u32	%rd96, %r31;
add.s64 %rd102, %rd96, %rd13;
setp.lt.u64	%p15, %rd102, %rd38;
@%p15 bra BB104_8;

BB104_22:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4
)
{
.local .align 8 .b8 __local_depot105[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .b32 %r<25>;
.reg .b64 %rd<44>;


mov.u64 %rd43, __local_depot105;
cvta.local.u64 %SP, %rd43;
ld.param.u32 %r10, [_Z26THCudaTensor_scatterKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3];
ld.param.u32 %r11, [_Z26THCudaTensor_scatterKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd3, %rd11;
mov.u32 %r23, 0;
mov.pred %p1, 0;
@%p1 bra BB105_2;

BB105_1:
mul.wide.s32 %rd12, %r23, 8;
add.s64 %rd13, %rd4, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd3, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r23, %r23, 1;
setp.lt.u32	%p2, %r23, 27;
@%p2 bra BB105_1;

BB105_2:
mov.u32 %r13, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r24, %r13, %r14, %r15;
setp.ge.u32	%p3, %r24, %r11;
@%p3 bra BB105_10;

ld.param.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd6, %rd16;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd17, [%rd2];
cvta.to.global.u64 %rd7, %rd17;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB105_4:
rem.u32 %r8, %r24, %r5;
setp.eq.s32	%p4, %r10, 0;
mov.u64 %rd42, 0;
@%p4 bra BB105_6;

ld.local.u32 %r16, [%rd3+108];
mul.lo.s32 %r17, %r16, %r8;
cvt.u64.u32	%rd42, %r17;

BB105_6:
mul.lo.s32 %r18, %r6, %r8;
mul.wide.u32 %rd19, %r18, 8;
add.s64 %rd20, %rd7, %rd19;
ld.global.u64 %rd10, [%rd20];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB105_8;

mul.wide.s32 %rd21, %r10, 4;
add.s64 %rd22, %rd3, %rd21;
ld.local.u32 %rd23, [%rd22+8];
setp.lt.s64	%p6, %rd10, %rd23;
@%p6 bra BB105_9;

BB105_8:
mov.u64 %rd24, $str2;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, $str1;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, __T2128;
cvta.global.u64 %rd29, %rd28;
mov.u32 %r19, 124;
mov.u64 %rd30, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd25;
.param .b64 param1;
st.param.b64	[param1+0], %rd27;
.param .b32 param2;
st.param.b32	[param2+0], %r19;
.param .b64 param3;
st.param.b64	[param3+0], %rd29;
.param .b64 param4;
st.param.b64	[param4+0], %rd30;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB105_9:
mul.lo.s32 %r20, %r4, %r8;
mul.wide.s32 %rd31, %r10, 4;
add.s64 %rd32, %rd3, %rd31;
ld.local.u32 %rd33, [%rd32+108];
mul.lo.s64 %rd34, %rd33, %rd10;
add.s64 %rd35, %rd34, %rd42;
and.b64 %rd36, %rd35, 4294967295;
ld.local.u64 %rd37, [%rd3];
shl.b64 %rd38, %rd36, 1;
add.s64 %rd39, %rd37, %rd38;
mul.wide.u32 %rd40, %r20, 2;
add.s64 %rd41, %rd6, %rd40;
ld.global.u16 %rs1, [%rd41];
st.u16 [%rd39], %rs1;
mov.u32 %r22, %nctaid.x;
mad.lo.s32 %r24, %r22, %r13, %r24;
setp.lt.u32	%p7, %r24, %r11;
@%p7 bra BB105_4;

BB105_10:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4
)
{
.local .align 8 .b8 __local_depot106[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b16 %rs<2>;
.reg .b32 %r<40>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot106;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r19, [_Z26THCudaTensor_scatterKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3];
ld.param.u32 %r20, [_Z26THCudaTensor_scatterKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r37, 0;
mov.pred %p1, 0;
@%p1 bra BB106_2;

BB106_1:
mul.wide.s32 %rd10, %r37, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r37, %r37, 1;
setp.lt.u32	%p2, %r37, 27;
@%p2 bra BB106_1;

BB106_2:
mov.u32 %r22, %ntid.x;
mov.u32 %r23, %ctaid.x;
mov.u32 %r24, %tid.x;
mad.lo.s32 %r38, %r22, %r23, %r24;
setp.ge.u32	%p3, %r38, %r20;
@%p3 bra BB106_12;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r25, %r26}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB106_4:
rem.u32 %r11, %r38, %r26;
setp.eq.s32	%p4, %r19, 1;
mov.u32 %r39, 0;
@%p4 bra BB106_6;

ld.local.u32 %r28, [%rd3+112];
mul.lo.s32 %r39, %r28, %r11;

BB106_6:
div.u32 %r29, %r38, %r26;
rem.u32 %r14, %r29, %r25;
setp.eq.s32	%p5, %r19, 0;
@%p5 bra BB106_8;

ld.local.u32 %r30, [%rd3+108];
mad.lo.s32 %r39, %r30, %r14, %r39;

BB106_8:
mul.lo.s32 %r31, %r9, %r11;
mul.lo.s32 %r32, %r5, %r11;
mad.lo.s32 %r33, %r8, %r14, %r31;
mad.lo.s32 %r17, %r4, %r14, %r32;
mul.wide.u32 %rd16, %r33, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB106_10;

mul.wide.s32 %rd18, %r19, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p7, %rd8, %rd20;
@%p7 bra BB106_11;

BB106_10:
mov.u64 %rd21, $str2;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T2129;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r34, 124;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r34;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB106_11:
mul.wide.s32 %rd28, %r19, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r39;
add.s64 %rd33, %rd31, %rd32;
and.b64 %rd34, %rd33, 4294967295;
ld.local.u64 %rd35, [%rd3];
shl.b64 %rd36, %rd34, 1;
add.s64 %rd37, %rd35, %rd36;
mul.wide.u32 %rd38, %r17, 2;
add.s64 %rd39, %rd6, %rd38;
ld.global.u16 %rs1, [%rd39];
st.u16 [%rd37], %rs1;
mov.u32 %r36, %nctaid.x;
mad.lo.s32 %r38, %r36, %r22, %r38;
setp.lt.u32	%p8, %r38, %r20;
@%p8 bra BB106_4;

BB106_12:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4
)
{
.local .align 8 .b8 __local_depot107[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b16 %rs<2>;
.reg .b32 %r<54>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot107;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r26, [_Z26THCudaTensor_scatterKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3];
ld.param.u32 %r27, [_Z26THCudaTensor_scatterKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r51, 0;
mov.pred %p1, 0;
@%p1 bra BB107_2;

BB107_1:
mul.wide.s32 %rd10, %r51, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p2, %r51, 27;
@%p2 bra BB107_1;

BB107_2:
mov.u32 %r29, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r52, %r29, %r30, %r31;
setp.ge.u32	%p3, %r52, %r27;
@%p3 bra BB107_14;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r32, %r33}, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r34, %r35}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r36, %r37}, [%rd2+112];

BB107_4:
rem.u32 %r14, %r52, %r9;
setp.eq.s32	%p4, %r26, 2;
mov.u32 %r53, 0;
@%p4 bra BB107_6;

ld.local.u32 %r39, [%rd3+116];
mul.lo.s32 %r53, %r39, %r14;

BB107_6:
div.u32 %r17, %r52, %r9;
rem.u32 %r18, %r17, %r35;
setp.eq.s32	%p5, %r26, 1;
@%p5 bra BB107_8;

ld.local.u32 %r40, [%rd3+112];
mad.lo.s32 %r53, %r40, %r18, %r53;

BB107_8:
div.u32 %r41, %r17, %r35;
rem.u32 %r21, %r41, %r34;
setp.eq.s32	%p6, %r26, 0;
@%p6 bra BB107_10;

ld.local.u32 %r42, [%rd3+108];
mad.lo.s32 %r53, %r42, %r21, %r53;

BB107_10:
mul.lo.s32 %r43, %r37, %r14;
mul.lo.s32 %r44, %r33, %r14;
mad.lo.s32 %r45, %r36, %r18, %r43;
mad.lo.s32 %r46, %r32, %r18, %r44;
mad.lo.s32 %r47, %r10, %r21, %r45;
mad.lo.s32 %r24, %r4, %r21, %r46;
mul.wide.u32 %rd16, %r47, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB107_12;

mul.wide.s32 %rd18, %r26, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p8, %rd8, %rd20;
@%p8 bra BB107_13;

BB107_12:
mov.u64 %rd21, $str2;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T2130;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r48, 124;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r48;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB107_13:
mul.wide.s32 %rd28, %r26, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r53;
add.s64 %rd33, %rd31, %rd32;
and.b64 %rd34, %rd33, 4294967295;
ld.local.u64 %rd35, [%rd3];
shl.b64 %rd36, %rd34, 1;
add.s64 %rd37, %rd35, %rd36;
mul.wide.u32 %rd38, %r24, 2;
add.s64 %rd39, %rd6, %rd38;
ld.global.u16 %rs1, [%rd39];
st.u16 [%rd37], %rs1;
mov.u32 %r50, %nctaid.x;
mad.lo.s32 %r52, %r50, %r29, %r52;
setp.lt.u32	%p9, %r52, %r27;
@%p9 bra BB107_4;

BB107_14:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4
)
{
.local .align 8 .b8 __local_depot108[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .b32 %r<63>;
.reg .b64 %rd<70>;


mov.u64 %rd69, __local_depot108;
cvta.local.u64 %SP, %rd69;
ld.param.u32 %r28, [_Z26THCudaTensor_scatterKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3];
ld.param.u32 %r29, [_Z26THCudaTensor_scatterKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4];
mov.u64 %rd6, _Z26THCudaTensor_scatterKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2;
add.u64 %rd20, %SP, 216;
cvta.to.local.u64 %rd3, %rd20;
add.u64 %rd21, %SP, 432;
cvta.to.local.u64 %rd4, %rd21;
add.u64 %rd22, %SP, 0;
cvta.to.local.u64 %rd5, %rd22;
mov.u32 %r47, 0;
mov.pred %p1, 0;
@%p1 bra BB108_2;

BB108_1:
mul.wide.s32 %rd23, %r47, 8;
add.s64 %rd24, %rd6, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r47, %r47, 1;
setp.lt.u32	%p2, %r47, 27;
@%p2 bra BB108_1;

BB108_2:
mov.u32 %r48, 0;
@%p1 bra BB108_4;

BB108_3:
mul.wide.s32 %rd27, %r48, 8;
add.s64 %rd28, %rd1, %rd27;
ld.param.u64 %rd29, [%rd28];
add.s64 %rd30, %rd4, %rd27;
st.local.u64 [%rd30], %rd29;
add.s32 %r48, %r48, 1;
setp.lt.u32	%p4, %r48, 27;
@%p4 bra BB108_3;

BB108_4:
mov.u32 %r49, 0;
@%p1 bra BB108_6;

BB108_5:
mul.wide.s32 %rd31, %r49, 8;
add.s64 %rd32, %rd2, %rd31;
ld.param.u64 %rd33, [%rd32];
add.s64 %rd34, %rd5, %rd31;
st.local.u64 [%rd34], %rd33;
add.s32 %r49, %r49, 1;
setp.lt.u32	%p6, %r49, 27;
@%p6 bra BB108_5;

BB108_6:
mov.u32 %r33, %ntid.x;
mov.u32 %r34, %ctaid.x;
mov.u32 %r35, %tid.x;
mad.lo.s32 %r54, %r33, %r34, %r35;
setp.ge.u32	%p7, %r54, %r29;
@%p7 bra BB108_17;

ld.local.u32 %r8, [%rd5+208];

BB108_8:
mov.u32 %r52, %r54;
mov.u32 %r9, %r52;
mul.wide.s32 %rd66, %r8, 4;
add.s32 %r40, %r8, -1;
sub.s32 %r50, %r40, %r28;
mov.u32 %r60, 0;
mov.u64 %rd68, 0;
mov.u64 %rd67, %rd68;
mov.u32 %r61, %r60;
mov.u32 %r56, %r60;
mov.u32 %r55, %r60;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r51, %r8;
mov.u32 %r53, %r9;
@%p8 bra BB108_13;

BB108_9:
mov.u32 %r57, %r61;
mov.u32 %r62, %r57;
mov.u32 %r13, %r53;
mov.u32 %r12, %r51;
add.s64 %rd37, %rd4, %rd66;
add.s32 %r17, %r12, -1;
add.s64 %rd38, %rd5, %rd66;
ld.local.u32 %r18, [%rd38+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r41, [%rd38+104];
mad.lo.s32 %r55, %r41, %r19, %r55;
ld.local.u32 %r42, [%rd37+104];
mad.lo.s32 %r56, %r42, %r19, %r56;
setp.eq.s32	%p9, %r50, 0;
@%p9 bra BB108_11;

add.s64 %rd39, %rd3, %rd66;
ld.local.u32 %r43, [%rd39+104];
mad.lo.s32 %r62, %r43, %r19, %r62;

BB108_11:
mov.u32 %r61, %r62;
div.u32 %r24, %r13, %r18;
add.s32 %r50, %r50, -1;
add.s64 %rd66, %rd66, -4;
setp.gt.s32	%p10, %r17, 0;
mov.u32 %r51, %r17;
mov.u32 %r53, %r24;
@%p10 bra BB108_9;

cvt.u64.u32	%rd67, %r55;
cvt.u64.u32	%rd68, %r56;
mov.u32 %r60, %r61;

BB108_13:
ld.local.u64 %rd40, [%rd5];
shl.b64 %rd41, %rd67, 3;
add.s64 %rd42, %rd40, %rd41;
ld.u64 %rd19, [%rd42];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB108_15;

mul.wide.s32 %rd43, %r28, 4;
add.s64 %rd44, %rd3, %rd43;
ld.local.u32 %rd45, [%rd44+8];
setp.lt.s64	%p12, %rd19, %rd45;
@%p12 bra BB108_16;

BB108_15:
mov.u64 %rd46, $str2;
cvta.global.u64 %rd47, %rd46;
mov.u64 %rd48, $str1;
cvta.global.u64 %rd49, %rd48;
mov.u64 %rd50, __T2131;
cvta.global.u64 %rd51, %rd50;
mov.u32 %r44, 124;
mov.u64 %rd52, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd47;
.param .b64 param1;
st.param.b64	[param1+0], %rd49;
.param .b32 param2;
st.param.b32	[param2+0], %r44;
.param .b64 param3;
st.param.b64	[param3+0], %rd51;
.param .b64 param4;
st.param.b64	[param4+0], %rd52;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB108_16:
mul.wide.s32 %rd53, %r28, 4;
add.s64 %rd54, %rd3, %rd53;
ld.local.u32 %rd55, [%rd54+108];
mul.lo.s64 %rd56, %rd55, %rd19;
cvt.u64.u32	%rd57, %r60;
add.s64 %rd58, %rd56, %rd57;
ld.local.u64 %rd59, [%rd3];
shl.b64 %rd60, %rd58, 1;
and.b64 %rd61, %rd60, 8589934590;
add.s64 %rd62, %rd59, %rd61;
ld.local.u64 %rd63, [%rd4];
shl.b64 %rd64, %rd68, 1;
add.s64 %rd65, %rd63, %rd64;
ld.u16 %rs1, [%rd65];
st.u16 [%rd62], %rs1;
mov.u32 %r46, %nctaid.x;
mad.lo.s32 %r54, %r46, %r33, %r9;
setp.lt.u32	%p13, %r54, %r29;
@%p13 bra BB108_8;

BB108_17:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0[416],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1[416],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2[416],
.param .u32 _Z26THCudaTensor_scatterKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3,
.param .u64 _Z26THCudaTensor_scatterKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4
)
{
.local .align 8 .b8 __local_depot109[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<16>;
.reg .b16 %rs<2>;
.reg .b32 %r<37>;
.reg .b64 %rd<117>;


mov.u64 %rd116, __local_depot109;
cvta.local.u64 %SP, %rd116;
ld.param.u32 %r13, [_Z26THCudaTensor_scatterKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3];
ld.param.u64 %rd38, [_Z26THCudaTensor_scatterKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4];
mov.u64 %rd6, _Z26THCudaTensor_scatterKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2;
add.u64 %rd39, %SP, 416;
cvta.to.local.u64 %rd3, %rd39;
add.u64 %rd40, %SP, 832;
cvta.to.local.u64 %rd4, %rd40;
add.u64 %rd41, %SP, 0;
cvta.to.local.u64 %rd5, %rd41;
mov.u32 %r32, 0;
mov.pred %p1, 0;
@%p1 bra BB109_2;

BB109_1:
mul.wide.s32 %rd42, %r32, 8;
add.s64 %rd43, %rd6, %rd42;
ld.param.u64 %rd44, [%rd43];
add.s64 %rd45, %rd3, %rd42;
st.local.u64 [%rd45], %rd44;
add.s32 %r32, %r32, 1;
setp.lt.u32	%p2, %r32, 52;
@%p2 bra BB109_1;

BB109_2:
mov.u32 %r33, 0;
@%p1 bra BB109_4;

BB109_3:
mul.wide.s32 %rd46, %r33, 8;
add.s64 %rd47, %rd1, %rd46;
ld.param.u64 %rd48, [%rd47];
add.s64 %rd49, %rd4, %rd46;
st.local.u64 [%rd49], %rd48;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p4, %r33, 52;
@%p4 bra BB109_3;

BB109_4:
mov.u32 %r34, 0;
@%p1 bra BB109_6;

BB109_5:
mul.wide.s32 %rd50, %r34, 8;
add.s64 %rd51, %rd2, %rd50;
ld.param.u64 %rd52, [%rd51];
add.s64 %rd53, %rd5, %rd50;
st.local.u64 [%rd53], %rd52;
add.s32 %r34, %r34, 1;
setp.lt.u32	%p6, %r34, 52;
@%p6 bra BB109_5;

BB109_6:
mov.u32 %r17, %ntid.x;
mov.u32 %r18, %ctaid.x;
mov.u32 %r19, %tid.x;
mad.lo.s32 %r20, %r17, %r18, %r19;
cvt.u64.u32	%rd102, %r20;
setp.ge.u64	%p7, %rd102, %rd38;
@%p7 bra BB109_22;

ld.local.u32 %r7, [%rd5+408];

BB109_8:
mov.u64 %rd98, %rd102;
mov.u64 %rd13, %rd98;
mul.wide.s32 %rd97, %r7, 8;
add.s32 %r21, %r7, -1;
sub.s32 %r35, %r21, %r13;
mov.u64 %rd113, 0;
mov.u64 %rd108, %rd113;
mov.u64 %rd105, %rd113;
mov.u64 %rd114, %rd113;
mov.u64 %rd109, %rd113;
mov.u64 %rd106, %rd113;
setp.lt.s32	%p8, %r7, 1;
mov.u32 %r36, %r7;
mov.u64 %rd100, %rd13;
@%p8 bra BB109_18;

BB109_9:
mov.u64 %rd115, %rd114;
mov.u64 %rd16, %rd100;
mov.u32 %r10, %r36;
add.s32 %r11, %r10, -1;
add.s64 %rd20, %rd5, %rd97;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd60, %rd16, %rd21;
and.b64 %rd61, %rd60, -4294967296;
setp.eq.s64	%p9, %rd61, 0;
@%p9 bra BB109_11;
bra.uni BB109_10;

BB109_11:
cvt.u32.u64	%r22, %rd21;
cvt.u32.u64	%r23, %rd16;
rem.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd103, %r24;
bra.uni BB109_12;

BB109_10:
rem.u64 %rd103, %rd16, %rd21;

BB109_12:
add.s64 %rd62, %rd4, %rd97;
ld.local.u64 %rd63, [%rd20+200];
mul.lo.s64 %rd64, %rd63, %rd103;
add.s64 %rd106, %rd64, %rd106;
ld.local.u64 %rd65, [%rd62+200];
mul.lo.s64 %rd66, %rd65, %rd103;
add.s64 %rd109, %rd66, %rd109;
setp.eq.s32	%p10, %r35, 0;
@%p10 bra BB109_14;

add.s64 %rd67, %rd3, %rd97;
ld.local.u64 %rd68, [%rd67+200];
mul.lo.s64 %rd69, %rd68, %rd103;
add.s64 %rd115, %rd69, %rd115;

BB109_14:
mov.u64 %rd114, %rd115;
@%p9 bra BB109_16;
bra.uni BB109_15;

BB109_16:
cvt.u32.u64	%r25, %rd21;
cvt.u32.u64	%r26, %rd16;
div.u32 %r27, %r26, %r25;
cvt.u64.u32	%rd101, %r27;
bra.uni BB109_17;

BB109_15:
div.u64 %rd101, %rd16, %rd21;

BB109_17:
mov.u64 %rd31, %rd101;
add.s32 %r35, %r35, -1;
add.s64 %rd97, %rd97, -8;
setp.gt.s32	%p12, %r11, 0;
mov.u32 %r36, %r11;
mov.u64 %rd100, %rd31;
mov.u64 %rd105, %rd106;
mov.u64 %rd108, %rd109;
mov.u64 %rd113, %rd114;
@%p12 bra BB109_9;

BB109_18:
ld.local.u64 %rd72, [%rd5];
shl.b64 %rd73, %rd105, 3;
add.s64 %rd74, %rd72, %rd73;
ld.u64 %rd36, [%rd74];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB109_20;

mul.wide.s32 %rd75, %r13, 8;
add.s64 %rd76, %rd3, %rd75;
ld.local.u64 %rd77, [%rd76+8];
setp.lt.u64	%p14, %rd36, %rd77;
@%p14 bra BB109_21;

BB109_20:
mov.u64 %rd78, $str2;
cvta.global.u64 %rd79, %rd78;
mov.u64 %rd80, $str1;
cvta.global.u64 %rd81, %rd80;
mov.u64 %rd82, __T2132;
cvta.global.u64 %rd83, %rd82;
mov.u32 %r28, 124;
mov.u64 %rd84, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd79;
.param .b64 param1;
st.param.b64	[param1+0], %rd81;
.param .b32 param2;
st.param.b32	[param2+0], %r28;
.param .b64 param3;
st.param.b64	[param3+0], %rd83;
.param .b64 param4;
st.param.b64	[param4+0], %rd84;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB109_21:
mul.wide.s32 %rd85, %r13, 8;
add.s64 %rd86, %rd3, %rd85;
ld.local.u64 %rd87, [%rd86+208];
mul.lo.s64 %rd88, %rd87, %rd36;
add.s64 %rd89, %rd88, %rd113;
ld.local.u64 %rd90, [%rd3];
shl.b64 %rd91, %rd89, 1;
add.s64 %rd92, %rd90, %rd91;
ld.local.u64 %rd93, [%rd4];
shl.b64 %rd94, %rd108, 1;
add.s64 %rd95, %rd93, %rd94;
ld.u16 %rs1, [%rd95];
st.u16 [%rd92], %rs1;
mov.u32 %r30, %nctaid.x;
mul.lo.s32 %r31, %r30, %r17;
cvt.u64.u32	%rd96, %r31;
add.s64 %rd102, %rd96, %rd13;
setp.lt.u64	%p15, %rd102, %rd38;
@%p15 bra BB109_8;

BB109_22:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4
)
{
.local .align 8 .b8 __local_depot110[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b16 %rs<5>;
.reg .f32 %f<4>;
.reg .b32 %r<38>;
.reg .b64 %rd<46>;


mov.u64 %rd45, __local_depot110;
cvta.local.u64 %SP, %rd45;
ld.param.u32 %r13, [_Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3];
ld.param.u32 %r14, [_Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2;
add.u64 %rd13, %SP, 0;
cvta.to.local.u64 %rd3, %rd13;
mov.u32 %r35, 0;
mov.pred %p1, 0;
@%p1 bra BB110_2;

BB110_1:
mul.wide.s32 %rd14, %r35, 8;
add.s64 %rd15, %rd4, %rd14;
ld.param.u64 %rd16, [%rd15];
add.s64 %rd17, %rd3, %rd14;
st.local.u64 [%rd17], %rd16;
add.s32 %r35, %r35, 1;
setp.lt.u32	%p2, %r35, 27;
@%p2 bra BB110_1;

BB110_2:
mov.u32 %r16, %ntid.x;
mov.u32 %r17, %ctaid.x;
mov.u32 %r18, %tid.x;
mad.lo.s32 %r36, %r16, %r17, %r18;
setp.ge.u32	%p3, %r36, %r14;
@%p3 bra BB110_12;

ld.param.u64 %rd18, [%rd1];
cvta.to.global.u64 %rd6, %rd18;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd19, [%rd2];
cvta.to.global.u64 %rd7, %rd19;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB110_4:
rem.u32 %r8, %r36, %r5;
setp.eq.s32	%p4, %r13, 0;
mov.u64 %rd44, 0;
@%p4 bra BB110_6;

ld.local.u32 %r19, [%rd3+108];
mul.lo.s32 %r20, %r19, %r8;
cvt.u64.u32	%rd44, %r20;

BB110_6:
mul.lo.s32 %r21, %r6, %r8;
mul.wide.u32 %rd21, %r21, 8;
add.s64 %rd22, %rd7, %rd21;
ld.global.u64 %rd10, [%rd22];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB110_8;

mul.wide.s32 %rd23, %r13, 4;
add.s64 %rd24, %rd3, %rd23;
ld.local.u32 %rd25, [%rd24+8];
setp.lt.s64	%p6, %rd10, %rd25;
@%p6 bra BB110_9;

BB110_8:
mov.u64 %rd26, $str2;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, $str1;
cvta.global.u64 %rd29, %rd28;
mov.u64 %rd30, __T2133;
cvta.global.u64 %rd31, %rd30;
mov.u32 %r22, 151;
mov.u64 %rd32, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd27;
.param .b64 param1;
st.param.b64	[param1+0], %rd29;
.param .b32 param2;
st.param.b32	[param2+0], %r22;
.param .b64 param3;
st.param.b64	[param3+0], %rd31;
.param .b64 param4;
st.param.b64	[param4+0], %rd32;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB110_9:
mul.lo.s32 %r23, %r4, %r8;
mul.wide.s32 %rd33, %r13, 4;
add.s64 %rd34, %rd3, %rd33;
ld.local.u32 %rd35, [%rd34+108];
mul.lo.s64 %rd36, %rd35, %rd10;
add.s64 %rd37, %rd36, %rd44;
and.b64 %rd38, %rd37, 4294967295;
ld.local.u64 %rd39, [%rd3];
shl.b64 %rd40, %rd38, 1;
add.s64 %rd41, %rd39, %rd40;
mul.wide.u32 %rd42, %r23, 2;
add.s64 %rd43, %rd6, %rd42;
ld.global.u16 %rs1, [%rd43];
and.b64 %rd11, %rd41, 2;
sub.s64 %rd12, %rd41, %rd11;
ld.u32 %r37, [%rd12];

BB110_10:
mov.u32 %r10, %r37;
shr.u32 %r24, %r10, 16;
setp.eq.s64	%p7, %rd11, 0;
selp.b32	%r25, %r10, %r24, %p7;
cvt.u16.u32	%rs2, %r25;

	{ cvt.f32.f16 %f1, %rs2;}


	
	{ cvt.f32.f16 %f2, %rs1;}


	add.f32 %f3, %f1, %f2;

	{ cvt.rn.f16.f32 %rs4, %f3;}


	cvt.u32.u16	%r26, %rs4;
shl.b32 %r27, %r26, 16;
and.b32 %r28, %r10, 65535;
or.b32 %r29, %r27, %r28;
and.b32 %r30, %r10, -65536;
or.b32 %r31, %r26, %r30;
selp.b32	%r32, %r31, %r29, %p7;
atom.cas.b32 %r37, [%rd12], %r10, %r32;
setp.ne.s32	%p8, %r10, %r37;
@%p8 bra BB110_10;

mov.u32 %r34, %nctaid.x;
mad.lo.s32 %r36, %r34, %r16, %r36;
setp.lt.u32	%p9, %r36, %r14;
@%p9 bra BB110_4;

BB110_12:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4
)
{
.local .align 8 .b8 __local_depot111[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<11>;
.reg .b16 %rs<5>;
.reg .f32 %f<4>;
.reg .b32 %r<53>;
.reg .b64 %rd<43>;


mov.u64 %rd42, __local_depot111;
cvta.local.u64 %SP, %rd42;
ld.param.u32 %r22, [_Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3];
ld.param.u32 %r23, [_Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd3, %rd11;
mov.u32 %r49, 0;
mov.pred %p1, 0;
@%p1 bra BB111_2;

BB111_1:
mul.wide.s32 %rd12, %r49, 8;
add.s64 %rd13, %rd4, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd3, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r49, %r49, 1;
setp.lt.u32	%p2, %r49, 27;
@%p2 bra BB111_1;

BB111_2:
mov.u32 %r25, %ntid.x;
mov.u32 %r26, %ctaid.x;
mov.u32 %r27, %tid.x;
mad.lo.s32 %r50, %r25, %r26, %r27;
setp.ge.u32	%p3, %r50, %r23;
@%p3 bra BB111_14;

ld.param.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd6, %rd16;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd17, [%rd2];
cvta.to.global.u64 %rd7, %rd17;
ld.param.v2.u32 {%r28, %r29}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB111_4:
rem.u32 %r11, %r50, %r29;
setp.eq.s32	%p4, %r22, 1;
mov.u32 %r51, 0;
@%p4 bra BB111_6;

ld.local.u32 %r31, [%rd3+112];
mul.lo.s32 %r51, %r31, %r11;

BB111_6:
div.u32 %r32, %r50, %r29;
rem.u32 %r14, %r32, %r28;
setp.eq.s32	%p5, %r22, 0;
@%p5 bra BB111_8;

ld.local.u32 %r33, [%rd3+108];
mad.lo.s32 %r51, %r33, %r14, %r51;

BB111_8:
mul.lo.s32 %r34, %r9, %r11;
mul.lo.s32 %r35, %r5, %r11;
mad.lo.s32 %r36, %r8, %r14, %r34;
mad.lo.s32 %r17, %r4, %r14, %r35;
mul.wide.u32 %rd18, %r36, 8;
add.s64 %rd19, %rd7, %rd18;
ld.global.u64 %rd8, [%rd19];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB111_10;

mul.wide.s32 %rd20, %r22, 4;
add.s64 %rd21, %rd3, %rd20;
ld.local.u32 %rd22, [%rd21+8];
setp.lt.s64	%p7, %rd8, %rd22;
@%p7 bra BB111_11;

BB111_10:
mov.u64 %rd23, $str2;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, $str1;
cvta.global.u64 %rd26, %rd25;
mov.u64 %rd27, __T2134;
cvta.global.u64 %rd28, %rd27;
mov.u32 %r37, 151;
mov.u64 %rd29, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd24;
.param .b64 param1;
st.param.b64	[param1+0], %rd26;
.param .b32 param2;
st.param.b32	[param2+0], %r37;
.param .b64 param3;
st.param.b64	[param3+0], %rd28;
.param .b64 param4;
st.param.b64	[param4+0], %rd29;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB111_11:
mul.wide.s32 %rd30, %r22, 4;
add.s64 %rd31, %rd3, %rd30;
ld.local.u32 %rd32, [%rd31+108];
mul.lo.s64 %rd33, %rd32, %rd8;
cvt.u64.u32	%rd34, %r51;
add.s64 %rd35, %rd33, %rd34;
and.b64 %rd36, %rd35, 4294967295;
ld.local.u64 %rd37, [%rd3];
shl.b64 %rd38, %rd36, 1;
add.s64 %rd39, %rd37, %rd38;
mul.wide.u32 %rd40, %r17, 2;
add.s64 %rd41, %rd6, %rd40;
ld.global.u16 %rs1, [%rd41];
and.b64 %rd9, %rd39, 2;
sub.s64 %rd10, %rd39, %rd9;
ld.u32 %r52, [%rd10];

BB111_12:
mov.u32 %r19, %r52;
shr.u32 %r38, %r19, 16;
setp.eq.s64	%p8, %rd9, 0;
selp.b32	%r39, %r19, %r38, %p8;
cvt.u16.u32	%rs2, %r39;

	{ cvt.f32.f16 %f1, %rs2;}


	
	{ cvt.f32.f16 %f2, %rs1;}


	add.f32 %f3, %f1, %f2;

	{ cvt.rn.f16.f32 %rs4, %f3;}


	cvt.u32.u16	%r40, %rs4;
shl.b32 %r41, %r40, 16;
and.b32 %r42, %r19, 65535;
or.b32 %r43, %r41, %r42;
and.b32 %r44, %r19, -65536;
or.b32 %r45, %r40, %r44;
selp.b32	%r46, %r45, %r43, %p8;
atom.cas.b32 %r52, [%rd10], %r19, %r46;
setp.ne.s32	%p9, %r19, %r52;
@%p9 bra BB111_12;

mov.u32 %r48, %nctaid.x;
mad.lo.s32 %r50, %r48, %r25, %r50;
setp.lt.u32	%p10, %r50, %r23;
@%p10 bra BB111_4;

BB111_14:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4
)
{
.local .align 8 .b8 __local_depot112[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<12>;
.reg .b16 %rs<5>;
.reg .f32 %f<4>;
.reg .b32 %r<67>;
.reg .b64 %rd<43>;


mov.u64 %rd42, __local_depot112;
cvta.local.u64 %SP, %rd42;
ld.param.u32 %r29, [_Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3];
ld.param.u32 %r30, [_Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd3, %rd11;
mov.u32 %r63, 0;
mov.pred %p1, 0;
@%p1 bra BB112_2;

BB112_1:
mul.wide.s32 %rd12, %r63, 8;
add.s64 %rd13, %rd4, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd3, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r63, %r63, 1;
setp.lt.u32	%p2, %r63, 27;
@%p2 bra BB112_1;

BB112_2:
mov.u32 %r32, %ntid.x;
mov.u32 %r33, %ctaid.x;
mov.u32 %r34, %tid.x;
mad.lo.s32 %r64, %r32, %r33, %r34;
setp.ge.u32	%p3, %r64, %r30;
@%p3 bra BB112_16;

ld.param.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd6, %rd16;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r35, %r36}, [%rd1+112];
ld.param.u64 %rd17, [%rd2];
cvta.to.global.u64 %rd7, %rd17;
ld.param.v2.u32 {%r37, %r38}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r39, %r40}, [%rd2+112];

BB112_4:
rem.u32 %r14, %r64, %r9;
setp.eq.s32	%p4, %r29, 2;
mov.u32 %r65, 0;
@%p4 bra BB112_6;

ld.local.u32 %r42, [%rd3+116];
mul.lo.s32 %r65, %r42, %r14;

BB112_6:
div.u32 %r17, %r64, %r9;
rem.u32 %r18, %r17, %r38;
setp.eq.s32	%p5, %r29, 1;
@%p5 bra BB112_8;

ld.local.u32 %r43, [%rd3+112];
mad.lo.s32 %r65, %r43, %r18, %r65;

BB112_8:
div.u32 %r44, %r17, %r38;
rem.u32 %r21, %r44, %r37;
setp.eq.s32	%p6, %r29, 0;
@%p6 bra BB112_10;

ld.local.u32 %r45, [%rd3+108];
mad.lo.s32 %r65, %r45, %r21, %r65;

BB112_10:
mul.lo.s32 %r46, %r40, %r14;
mul.lo.s32 %r47, %r36, %r14;
mad.lo.s32 %r48, %r39, %r18, %r46;
mad.lo.s32 %r49, %r35, %r18, %r47;
mad.lo.s32 %r50, %r10, %r21, %r48;
mad.lo.s32 %r24, %r4, %r21, %r49;
mul.wide.u32 %rd18, %r50, 8;
add.s64 %rd19, %rd7, %rd18;
ld.global.u64 %rd8, [%rd19];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB112_12;

mul.wide.s32 %rd20, %r29, 4;
add.s64 %rd21, %rd3, %rd20;
ld.local.u32 %rd22, [%rd21+8];
setp.lt.s64	%p8, %rd8, %rd22;
@%p8 bra BB112_13;

BB112_12:
mov.u64 %rd23, $str2;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, $str1;
cvta.global.u64 %rd26, %rd25;
mov.u64 %rd27, __T2135;
cvta.global.u64 %rd28, %rd27;
mov.u32 %r51, 151;
mov.u64 %rd29, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd24;
.param .b64 param1;
st.param.b64	[param1+0], %rd26;
.param .b32 param2;
st.param.b32	[param2+0], %r51;
.param .b64 param3;
st.param.b64	[param3+0], %rd28;
.param .b64 param4;
st.param.b64	[param4+0], %rd29;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB112_13:
mul.wide.s32 %rd30, %r29, 4;
add.s64 %rd31, %rd3, %rd30;
ld.local.u32 %rd32, [%rd31+108];
mul.lo.s64 %rd33, %rd32, %rd8;
cvt.u64.u32	%rd34, %r65;
add.s64 %rd35, %rd33, %rd34;
and.b64 %rd36, %rd35, 4294967295;
ld.local.u64 %rd37, [%rd3];
shl.b64 %rd38, %rd36, 1;
add.s64 %rd39, %rd37, %rd38;
mul.wide.u32 %rd40, %r24, 2;
add.s64 %rd41, %rd6, %rd40;
ld.global.u16 %rs1, [%rd41];
and.b64 %rd9, %rd39, 2;
sub.s64 %rd10, %rd39, %rd9;
ld.u32 %r66, [%rd10];

BB112_14:
mov.u32 %r26, %r66;
shr.u32 %r52, %r26, 16;
setp.eq.s64	%p9, %rd9, 0;
selp.b32	%r53, %r26, %r52, %p9;
cvt.u16.u32	%rs2, %r53;

	{ cvt.f32.f16 %f1, %rs2;}


	
	{ cvt.f32.f16 %f2, %rs1;}


	add.f32 %f3, %f1, %f2;

	{ cvt.rn.f16.f32 %rs4, %f3;}


	cvt.u32.u16	%r54, %rs4;
shl.b32 %r55, %r54, 16;
and.b32 %r56, %r26, 65535;
or.b32 %r57, %r55, %r56;
and.b32 %r58, %r26, -65536;
or.b32 %r59, %r54, %r58;
selp.b32	%r60, %r59, %r57, %p9;
atom.cas.b32 %r66, [%rd10], %r26, %r60;
setp.ne.s32	%p10, %r26, %r66;
@%p10 bra BB112_14;

mov.u32 %r62, %nctaid.x;
mad.lo.s32 %r64, %r62, %r32, %r64;
setp.lt.u32	%p11, %r64, %r30;
@%p11 bra BB112_4;

BB112_16:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4
)
{
.local .align 8 .b8 __local_depot113[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<16>;
.reg .b16 %rs<5>;
.reg .f32 %f<4>;
.reg .b32 %r<71>;
.reg .b64 %rd<72>;


mov.u64 %rd71, __local_depot113;
cvta.local.u64 %SP, %rd71;
ld.param.u32 %r33, [_Z29THCudaTensor_scatterAddKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3];
ld.param.u32 %r34, [_Z29THCudaTensor_scatterAddKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4];
mov.u64 %rd6, _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2;
add.u64 %rd22, %SP, 216;
cvta.to.local.u64 %rd3, %rd22;
add.u64 %rd23, %SP, 432;
cvta.to.local.u64 %rd4, %rd23;
add.u64 %rd24, %SP, 0;
cvta.to.local.u64 %rd5, %rd24;
mov.u32 %r59, 0;
mov.pred %p1, 0;
@%p1 bra BB113_2;

BB113_1:
mul.wide.s32 %rd25, %r59, 8;
add.s64 %rd26, %rd6, %rd25;
ld.param.u64 %rd27, [%rd26];
add.s64 %rd28, %rd3, %rd25;
st.local.u64 [%rd28], %rd27;
add.s32 %r59, %r59, 1;
setp.lt.u32	%p2, %r59, 27;
@%p2 bra BB113_1;

BB113_2:
mov.u32 %r60, 0;
@%p1 bra BB113_4;

BB113_3:
mul.wide.s32 %rd29, %r60, 8;
add.s64 %rd30, %rd1, %rd29;
ld.param.u64 %rd31, [%rd30];
add.s64 %rd32, %rd4, %rd29;
st.local.u64 [%rd32], %rd31;
add.s32 %r60, %r60, 1;
setp.lt.u32	%p4, %r60, 27;
@%p4 bra BB113_3;

BB113_4:
mov.u32 %r61, 0;
@%p1 bra BB113_6;

BB113_5:
mul.wide.s32 %rd33, %r61, 8;
add.s64 %rd34, %rd2, %rd33;
ld.param.u64 %rd35, [%rd34];
add.s64 %rd36, %rd5, %rd33;
st.local.u64 [%rd36], %rd35;
add.s32 %r61, %r61, 1;
setp.lt.u32	%p6, %r61, 27;
@%p6 bra BB113_5;

BB113_6:
mov.u32 %r38, %ntid.x;
mov.u32 %r39, %ctaid.x;
mov.u32 %r40, %tid.x;
mad.lo.s32 %r66, %r38, %r39, %r40;
setp.ge.u32	%p7, %r66, %r34;
@%p7 bra BB113_19;

BB113_7:
mov.u32 %r64, %r66;
mov.u32 %r8, %r64;
ld.local.u32 %r63, [%rd5+208];
mov.u32 %r69, 0;
mov.u64 %rd70, 0;
mov.u64 %rd69, %rd70;
setp.lt.s32	%p8, %r63, 1;
@%p8 bra BB113_13;

not.b32 %r45, %r33;
add.s32 %r62, %r45, %r63;
mul.wide.s32 %rd68, %r63, 4;
mov.u32 %r69, 0;
mov.u32 %r68, %r69;
mov.u32 %r67, %r69;
mov.u32 %r65, %r8;

BB113_9:
mov.u32 %r13, %r65;
add.s64 %rd39, %rd4, %rd68;
add.s32 %r63, %r63, -1;
add.s64 %rd40, %rd5, %rd68;
ld.local.u32 %r18, [%rd40+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r46, [%rd40+104];
mad.lo.s32 %r67, %r46, %r19, %r67;
ld.local.u32 %r47, [%rd39+104];
mad.lo.s32 %r68, %r47, %r19, %r68;
setp.eq.s32	%p9, %r62, 0;
@%p9 bra BB113_11;

add.s64 %rd41, %rd3, %rd68;
ld.local.u32 %r48, [%rd41+104];
mad.lo.s32 %r69, %r48, %r19, %r69;

BB113_11:
div.u32 %r24, %r13, %r18;
add.s32 %r62, %r62, -1;
add.s64 %rd68, %rd68, -4;
setp.gt.s32	%p10, %r63, 0;
mov.u32 %r65, %r24;
@%p10 bra BB113_9;

cvt.u64.u32	%rd69, %r67;
cvt.u64.u32	%rd70, %r68;

BB113_13:
ld.local.u64 %rd42, [%rd5];
shl.b64 %rd43, %rd69, 3;
add.s64 %rd44, %rd42, %rd43;
ld.u64 %rd19, [%rd44];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB113_15;

mul.wide.s32 %rd45, %r33, 4;
add.s64 %rd46, %rd3, %rd45;
ld.local.u32 %rd47, [%rd46+8];
setp.lt.s64	%p12, %rd19, %rd47;
@%p12 bra BB113_16;

BB113_15:
mov.u64 %rd48, $str2;
cvta.global.u64 %rd49, %rd48;
mov.u64 %rd50, $str1;
cvta.global.u64 %rd51, %rd50;
mov.u64 %rd52, __T2136;
cvta.global.u64 %rd53, %rd52;
mov.u32 %r49, 151;
mov.u64 %rd54, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd49;
.param .b64 param1;
st.param.b64	[param1+0], %rd51;
.param .b32 param2;
st.param.b32	[param2+0], %r49;
.param .b64 param3;
st.param.b64	[param3+0], %rd53;
.param .b64 param4;
st.param.b64	[param4+0], %rd54;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB113_16:
mul.wide.s32 %rd55, %r33, 4;
add.s64 %rd56, %rd3, %rd55;
ld.local.u32 %rd57, [%rd56+108];
mul.lo.s64 %rd58, %rd57, %rd19;
cvt.u64.u32	%rd59, %r69;
add.s64 %rd60, %rd58, %rd59;
ld.local.u64 %rd61, [%rd3];
shl.b64 %rd62, %rd60, 1;
and.b64 %rd63, %rd62, 8589934590;
add.s64 %rd64, %rd61, %rd63;
ld.local.u64 %rd65, [%rd4];
shl.b64 %rd66, %rd70, 1;
add.s64 %rd67, %rd65, %rd66;
ld.u16 %rs1, [%rd67];
and.b64 %rd20, %rd64, 2;
sub.s64 %rd21, %rd64, %rd20;
ld.u32 %r70, [%rd21];
mov.u32 %r28, %nctaid.x;

BB113_17:
mov.u32 %r30, %r70;
shr.u32 %r50, %r30, 16;
setp.eq.s64	%p13, %rd20, 0;
selp.b32	%r51, %r30, %r50, %p13;
cvt.u16.u32	%rs2, %r51;

	{ cvt.f32.f16 %f1, %rs2;}


	
	{ cvt.f32.f16 %f2, %rs1;}


	add.f32 %f3, %f1, %f2;

	{ cvt.rn.f16.f32 %rs4, %f3;}


	cvt.u32.u16	%r52, %rs4;
shl.b32 %r53, %r52, 16;
and.b32 %r54, %r30, 65535;
or.b32 %r55, %r53, %r54;
and.b32 %r56, %r30, -65536;
or.b32 %r57, %r52, %r56;
selp.b32	%r58, %r57, %r55, %p13;
atom.cas.b32 %r70, [%rd21], %r30, %r58;
setp.ne.s32	%p14, %r30, %r70;
@%p14 bra BB113_17;

mad.lo.s32 %r66, %r28, %r38, %r8;
setp.lt.u32	%p15, %r66, %r34;
@%p15 bra BB113_7;

BB113_19:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0[416],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1[416],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2[416],
.param .u32 _Z29THCudaTensor_scatterAddKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3,
.param .u64 _Z29THCudaTensor_scatterAddKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4
)
{
.local .align 8 .b8 __local_depot114[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<18>;
.reg .b16 %rs<5>;
.reg .f32 %f<4>;
.reg .b32 %r<50>;
.reg .b64 %rd<110>;


mov.u64 %rd109, __local_depot114;
cvta.local.u64 %SP, %rd109;
ld.param.u32 %r17, [_Z29THCudaTensor_scatterAddKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_3];
ld.param.u64 %rd40, [_Z29THCudaTensor_scatterAddKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_4];
mov.u64 %rd6, _Z29THCudaTensor_scatterAddKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES5_S2_IlS4_EiS4__param_2;
add.u64 %rd41, %SP, 416;
cvta.to.local.u64 %rd3, %rd41;
add.u64 %rd42, %SP, 832;
cvta.to.local.u64 %rd4, %rd42;
add.u64 %rd43, %SP, 0;
cvta.to.local.u64 %rd5, %rd43;
mov.u32 %r44, 0;
mov.pred %p1, 0;
@%p1 bra BB114_2;

BB114_1:
mul.wide.s32 %rd44, %r44, 8;
add.s64 %rd45, %rd6, %rd44;
ld.param.u64 %rd46, [%rd45];
add.s64 %rd47, %rd3, %rd44;
st.local.u64 [%rd47], %rd46;
add.s32 %r44, %r44, 1;
setp.lt.u32	%p2, %r44, 52;
@%p2 bra BB114_1;

BB114_2:
mov.u32 %r45, 0;
@%p1 bra BB114_4;

BB114_3:
mul.wide.s32 %rd48, %r45, 8;
add.s64 %rd49, %rd1, %rd48;
ld.param.u64 %rd50, [%rd49];
add.s64 %rd51, %rd4, %rd48;
st.local.u64 [%rd51], %rd50;
add.s32 %r45, %r45, 1;
setp.lt.u32	%p4, %r45, 52;
@%p4 bra BB114_3;

BB114_4:
mov.u32 %r46, 0;
@%p1 bra BB114_6;

BB114_5:
mul.wide.s32 %rd52, %r46, 8;
add.s64 %rd53, %rd2, %rd52;
ld.param.u64 %rd54, [%rd53];
add.s64 %rd55, %rd5, %rd52;
st.local.u64 [%rd55], %rd54;
add.s32 %r46, %r46, 1;
setp.lt.u32	%p6, %r46, 52;
@%p6 bra BB114_5;

BB114_6:
mov.u32 %r21, %ntid.x;
mov.u32 %r22, %ctaid.x;
mov.u32 %r23, %tid.x;
mad.lo.s32 %r24, %r21, %r22, %r23;
cvt.u64.u32	%rd104, %r24;
setp.ge.u64	%p7, %rd104, %rd40;
@%p7 bra BB114_24;

BB114_7:
mov.u64 %rd100, %rd104;
mov.u64 %rd13, %rd100;
ld.local.u32 %r48, [%rd5+408];
mov.u64 %rd108, 0;
mov.u64 %rd107, %rd108;
mov.u64 %rd106, %rd108;
setp.lt.s32	%p8, %r48, 1;
@%p8 bra BB114_18;

not.b32 %r25, %r17;
add.s32 %r47, %r25, %r48;
mul.wide.s32 %rd99, %r48, 8;
mov.u64 %rd108, 0;
mov.u64 %rd107, %rd108;
mov.u64 %rd106, %rd108;
mov.u64 %rd102, %rd13;

BB114_9:
mov.u64 %rd16, %rd102;
add.s32 %r48, %r48, -1;
add.s64 %rd20, %rd5, %rd99;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd62, %rd16, %rd21;
and.b64 %rd63, %rd62, -4294967296;
setp.eq.s64	%p9, %rd63, 0;
@%p9 bra BB114_11;
bra.uni BB114_10;

BB114_11:
cvt.u32.u64	%r26, %rd21;
cvt.u32.u64	%r27, %rd16;
rem.u32 %r28, %r27, %r26;
cvt.u64.u32	%rd105, %r28;
bra.uni BB114_12;

BB114_10:
rem.u64 %rd105, %rd16, %rd21;

BB114_12:
add.s64 %rd64, %rd4, %rd99;
ld.local.u64 %rd65, [%rd20+200];
mul.lo.s64 %rd66, %rd65, %rd105;
add.s64 %rd106, %rd66, %rd106;
ld.local.u64 %rd67, [%rd64+200];
mul.lo.s64 %rd68, %rd67, %rd105;
add.s64 %rd107, %rd68, %rd107;
setp.eq.s32	%p10, %r47, 0;
@%p10 bra BB114_14;

add.s64 %rd69, %rd3, %rd99;
ld.local.u64 %rd70, [%rd69+200];
mul.lo.s64 %rd71, %rd70, %rd105;
add.s64 %rd108, %rd71, %rd108;

BB114_14:
@%p9 bra BB114_16;
bra.uni BB114_15;

BB114_16:
cvt.u32.u64	%r29, %rd21;
cvt.u32.u64	%r30, %rd16;
div.u32 %r31, %r30, %r29;
cvt.u64.u32	%rd103, %r31;
bra.uni BB114_17;

BB114_15:
div.u64 %rd103, %rd16, %rd21;

BB114_17:
mov.u64 %rd31, %rd103;
add.s32 %r47, %r47, -1;
add.s64 %rd99, %rd99, -8;
setp.gt.s32	%p12, %r48, 0;
mov.u64 %rd102, %rd31;
@%p12 bra BB114_9;

BB114_18:
ld.local.u64 %rd74, [%rd5];
shl.b64 %rd75, %rd106, 3;
add.s64 %rd76, %rd74, %rd75;
ld.u64 %rd36, [%rd76];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB114_20;

mul.wide.s32 %rd77, %r17, 8;
add.s64 %rd78, %rd3, %rd77;
ld.local.u64 %rd79, [%rd78+8];
setp.lt.u64	%p14, %rd36, %rd79;
@%p14 bra BB114_21;

BB114_20:
mov.u64 %rd80, $str2;
cvta.global.u64 %rd81, %rd80;
mov.u64 %rd82, $str1;
cvta.global.u64 %rd83, %rd82;
mov.u64 %rd84, __T2137;
cvta.global.u64 %rd85, %rd84;
mov.u32 %r32, 151;
mov.u64 %rd86, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd81;
.param .b64 param1;
st.param.b64	[param1+0], %rd83;
.param .b32 param2;
st.param.b32	[param2+0], %r32;
.param .b64 param3;
st.param.b64	[param3+0], %rd85;
.param .b64 param4;
st.param.b64	[param4+0], %rd86;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB114_21:
mul.wide.s32 %rd87, %r17, 8;
add.s64 %rd88, %rd3, %rd87;
ld.local.u64 %rd89, [%rd88+208];
mul.lo.s64 %rd90, %rd89, %rd36;
add.s64 %rd91, %rd90, %rd108;
ld.local.u64 %rd92, [%rd3];
shl.b64 %rd93, %rd91, 1;
add.s64 %rd94, %rd92, %rd93;
ld.local.u64 %rd95, [%rd4];
shl.b64 %rd96, %rd107, 1;
add.s64 %rd97, %rd95, %rd96;
ld.u16 %rs1, [%rd97];
and.b64 %rd37, %rd94, 2;
sub.s64 %rd38, %rd94, %rd37;
ld.u32 %r49, [%rd38];
mov.u32 %r34, %nctaid.x;
mul.lo.s32 %r14, %r34, %r21;

BB114_22:
mov.u32 %r15, %r49;
shr.u32 %r35, %r15, 16;
setp.eq.s64	%p15, %rd37, 0;
selp.b32	%r36, %r15, %r35, %p15;
cvt.u16.u32	%rs2, %r36;

	{ cvt.f32.f16 %f1, %rs2;}


	
	{ cvt.f32.f16 %f2, %rs1;}


	add.f32 %f3, %f1, %f2;

	{ cvt.rn.f16.f32 %rs4, %f3;}


	cvt.u32.u16	%r37, %rs4;
shl.b32 %r38, %r37, 16;
and.b32 %r39, %r15, 65535;
or.b32 %r40, %r38, %r39;
and.b32 %r41, %r15, -65536;
or.b32 %r42, %r37, %r41;
selp.b32	%r43, %r42, %r40, %p15;
atom.cas.b32 %r49, [%rd38], %r15, %r43;
setp.ne.s32	%p16, %r15, %r49;
@%p16 bra BB114_22;

cvt.u64.u32	%rd98, %r14;
add.s64 %rd104, %rd98, %rd13;
setp.lt.u64	%p17, %rd104, %rd40;
@%p17 bra BB114_7;

BB114_24:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_1[216],
.param .align 2 .b8 _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_2[2],
.param .u32 _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_4
)
{
.local .align 8 .b8 __local_depot115[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .b32 %r<23>;
.reg .b64 %rd<38>;


mov.u64 %rd37, __local_depot115;
cvta.local.u64 %SP, %rd37;
ld.param.u16 %rs1, [_Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_2];
ld.param.u32 %r11, [_Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_3];
ld.param.u32 %r12, [_Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_4];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_1;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd2, %rd10;
mov.u32 %r21, 0;
mov.pred %p1, 0;
@%p1 bra BB115_2;

BB115_1:
mul.wide.s32 %rd11, %r21, 8;
add.s64 %rd12, %rd3, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd2, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r21, %r21, 1;
setp.lt.u32	%p2, %r21, 27;
@%p2 bra BB115_1;

BB115_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r22, %r3, %r14, %r15;
setp.ge.u32	%p3, %r22, %r12;
@%p3 bra BB115_10;

ld.param.u64 %rd15, [%rd1];
cvta.to.global.u64 %rd5, %rd15;
ld.param.u32 %r5, [%rd1+8];
ld.param.u32 %r6, [%rd1+108];
mul.wide.s32 %rd16, %r11, 4;
add.s64 %rd17, %rd2, %rd16;
add.s64 %rd6, %rd17, 8;
mov.u32 %r16, %nctaid.x;
mul.lo.s32 %r7, %r16, %r3;

BB115_4:
rem.u32 %r9, %r22, %r5;
setp.eq.s32	%p4, %r11, 0;
mov.u64 %rd36, 0;
@%p4 bra BB115_6;

ld.local.u32 %r17, [%rd2+108];
mul.lo.s32 %r18, %r17, %r9;
cvt.u64.u32	%rd36, %r18;

BB115_6:
mul.lo.s32 %r19, %r6, %r9;
mul.wide.u32 %rd19, %r19, 8;
add.s64 %rd20, %rd5, %rd19;
ld.global.u64 %rd9, [%rd20];
setp.lt.s64	%p5, %rd9, 0;
@%p5 bra BB115_8;

ld.local.u32 %rd21, [%rd6];
setp.lt.s64	%p6, %rd9, %rd21;
@%p6 bra BB115_9;

BB115_8:
mov.u64 %rd22, $str2;
cvta.global.u64 %rd23, %rd22;
mov.u64 %rd24, $str1;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, __T2138;
cvta.global.u64 %rd27, %rd26;
mov.u32 %r20, 176;
mov.u64 %rd28, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd23;
.param .b64 param1;
st.param.b64	[param1+0], %rd25;
.param .b32 param2;
st.param.b32	[param2+0], %r20;
.param .b64 param3;
st.param.b64	[param3+0], %rd27;
.param .b64 param4;
st.param.b64	[param4+0], %rd28;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB115_9:
ld.local.u32 %rd29, [%rd6+100];
mul.lo.s64 %rd30, %rd29, %rd9;
add.s64 %rd31, %rd30, %rd36;
and.b64 %rd32, %rd31, 4294967295;
ld.local.u64 %rd33, [%rd2];
shl.b64 %rd34, %rd32, 1;
add.s64 %rd35, %rd33, %rd34;
st.u16 [%rd35], %rs1;
add.s32 %r22, %r7, %r22;
setp.lt.u32	%p7, %r22, %r12;
@%p7 bra BB115_4;

BB115_10:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_1[216],
.param .align 2 .b8 _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_2[2],
.param .u32 _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_4
)
{
.local .align 8 .b8 __local_depot116[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b16 %rs<2>;
.reg .b32 %r<36>;
.reg .b64 %rd<36>;


mov.u64 %rd35, __local_depot116;
cvta.local.u64 %SP, %rd35;
ld.param.u16 %rs1, [_Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_2];
ld.param.u32 %r16, [_Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_3];
ld.param.u32 %r17, [_Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_4];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi2EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_1;
add.u64 %rd7, %SP, 0;
cvta.to.local.u64 %rd2, %rd7;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB116_2;

BB116_1:
mul.wide.s32 %rd8, %r33, 8;
add.s64 %rd9, %rd3, %rd8;
ld.param.u64 %rd10, [%rd9];
add.s64 %rd11, %rd2, %rd8;
st.local.u64 [%rd11], %rd10;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB116_1;

BB116_2:
mov.u32 %r19, %ntid.x;
mov.u32 %r20, %ctaid.x;
mov.u32 %r21, %tid.x;
mad.lo.s32 %r34, %r19, %r20, %r21;
setp.ge.u32	%p3, %r34, %r17;
@%p3 bra BB116_12;

ld.param.u64 %rd12, [%rd1];
cvta.to.global.u64 %rd5, %rd12;
ld.param.v2.u32 {%r22, %r23}, [%rd1+8];
ld.param.u32 %r6, [%rd1+108];
ld.param.u32 %r7, [%rd1+112];

BB116_4:
rem.u32 %r9, %r34, %r23;
setp.eq.s32	%p4, %r16, 1;
mov.u32 %r35, 0;
@%p4 bra BB116_6;

ld.local.u32 %r25, [%rd2+112];
mul.lo.s32 %r35, %r25, %r9;

BB116_6:
div.u32 %r26, %r34, %r23;
rem.u32 %r12, %r26, %r22;
setp.eq.s32	%p5, %r16, 0;
@%p5 bra BB116_8;

ld.local.u32 %r27, [%rd2+108];
mad.lo.s32 %r35, %r27, %r12, %r35;

BB116_8:
mul.lo.s32 %r28, %r7, %r9;
mad.lo.s32 %r29, %r6, %r12, %r28;
mul.wide.u32 %rd13, %r29, 8;
add.s64 %rd14, %rd5, %rd13;
ld.global.u64 %rd6, [%rd14];
setp.lt.s64	%p6, %rd6, 0;
@%p6 bra BB116_10;

mul.wide.s32 %rd15, %r16, 4;
add.s64 %rd16, %rd2, %rd15;
ld.local.u32 %rd17, [%rd16+8];
setp.lt.s64	%p7, %rd6, %rd17;
@%p7 bra BB116_11;

BB116_10:
mov.u64 %rd18, $str2;
cvta.global.u64 %rd19, %rd18;
mov.u64 %rd20, $str1;
cvta.global.u64 %rd21, %rd20;
mov.u64 %rd22, __T2139;
cvta.global.u64 %rd23, %rd22;
mov.u32 %r30, 176;
mov.u64 %rd24, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd19;
.param .b64 param1;
st.param.b64	[param1+0], %rd21;
.param .b32 param2;
st.param.b32	[param2+0], %r30;
.param .b64 param3;
st.param.b64	[param3+0], %rd23;
.param .b64 param4;
st.param.b64	[param4+0], %rd24;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB116_11:
mul.wide.s32 %rd25, %r16, 4;
add.s64 %rd26, %rd2, %rd25;
ld.local.u32 %rd27, [%rd26+108];
mul.lo.s64 %rd28, %rd27, %rd6;
cvt.u64.u32	%rd29, %r35;
add.s64 %rd30, %rd28, %rd29;
and.b64 %rd31, %rd30, 4294967295;
ld.local.u64 %rd32, [%rd2];
shl.b64 %rd33, %rd31, 1;
add.s64 %rd34, %rd32, %rd33;
st.u16 [%rd34], %rs1;
mov.u32 %r32, %nctaid.x;
mad.lo.s32 %r34, %r32, %r19, %r34;
setp.lt.u32	%p8, %r34, %r17;
@%p8 bra BB116_4;

BB116_12:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_1[216],
.param .align 2 .b8 _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_2[2],
.param .u32 _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_4
)
{
.local .align 8 .b8 __local_depot117[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b16 %rs<2>;
.reg .b32 %r<46>;
.reg .b64 %rd<36>;


mov.u64 %rd35, __local_depot117;
cvta.local.u64 %SP, %rd35;
ld.param.u16 %rs1, [_Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_2];
ld.param.u32 %r23, [_Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_3];
ld.param.u32 %r24, [_Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_4];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELi3EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_1;
add.u64 %rd7, %SP, 0;
cvta.to.local.u64 %rd2, %rd7;
mov.u32 %r43, 0;
mov.pred %p1, 0;
@%p1 bra BB117_2;

BB117_1:
mul.wide.s32 %rd8, %r43, 8;
add.s64 %rd9, %rd3, %rd8;
ld.param.u64 %rd10, [%rd9];
add.s64 %rd11, %rd2, %rd8;
st.local.u64 [%rd11], %rd10;
add.s32 %r43, %r43, 1;
setp.lt.u32	%p2, %r43, 27;
@%p2 bra BB117_1;

BB117_2:
mov.u32 %r26, %ntid.x;
mov.u32 %r27, %ctaid.x;
mov.u32 %r28, %tid.x;
mad.lo.s32 %r44, %r26, %r27, %r28;
setp.ge.u32	%p3, %r44, %r24;
@%p3 bra BB117_14;

ld.param.u64 %rd12, [%rd1];
cvta.to.global.u64 %rd5, %rd12;
ld.param.v2.u32 {%r29, %r30}, [%rd1+8];
ld.param.u32 %r6, [%rd1+16];
ld.param.u32 %r7, [%rd1+108];
ld.param.v2.u32 {%r31, %r32}, [%rd1+112];

BB117_4:
rem.u32 %r11, %r44, %r6;
setp.eq.s32	%p4, %r23, 2;
mov.u32 %r45, 0;
@%p4 bra BB117_6;

ld.local.u32 %r34, [%rd2+116];
mul.lo.s32 %r45, %r34, %r11;

BB117_6:
div.u32 %r14, %r44, %r6;
rem.u32 %r15, %r14, %r30;
setp.eq.s32	%p5, %r23, 1;
@%p5 bra BB117_8;

ld.local.u32 %r35, [%rd2+112];
mad.lo.s32 %r45, %r35, %r15, %r45;

BB117_8:
mul.lo.s32 %r36, %r32, %r11;
mad.lo.s32 %r18, %r31, %r15, %r36;
div.u32 %r37, %r14, %r30;
rem.u32 %r19, %r37, %r29;
setp.eq.s32	%p6, %r23, 0;
@%p6 bra BB117_10;

ld.local.u32 %r38, [%rd2+108];
mad.lo.s32 %r45, %r38, %r19, %r45;

BB117_10:
mad.lo.s32 %r39, %r7, %r19, %r18;
mul.wide.u32 %rd13, %r39, 8;
add.s64 %rd14, %rd5, %rd13;
ld.global.u64 %rd6, [%rd14];
setp.lt.s64	%p7, %rd6, 0;
@%p7 bra BB117_12;

mul.wide.s32 %rd15, %r23, 4;
add.s64 %rd16, %rd2, %rd15;
ld.local.u32 %rd17, [%rd16+8];
setp.lt.s64	%p8, %rd6, %rd17;
@%p8 bra BB117_13;

BB117_12:
mov.u64 %rd18, $str2;
cvta.global.u64 %rd19, %rd18;
mov.u64 %rd20, $str1;
cvta.global.u64 %rd21, %rd20;
mov.u64 %rd22, __T2140;
cvta.global.u64 %rd23, %rd22;
mov.u32 %r40, 176;
mov.u64 %rd24, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd19;
.param .b64 param1;
st.param.b64	[param1+0], %rd21;
.param .b32 param2;
st.param.b32	[param2+0], %r40;
.param .b64 param3;
st.param.b64	[param3+0], %rd23;
.param .b64 param4;
st.param.b64	[param4+0], %rd24;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB117_13:
mul.wide.s32 %rd25, %r23, 4;
add.s64 %rd26, %rd2, %rd25;
ld.local.u32 %rd27, [%rd26+108];
mul.lo.s64 %rd28, %rd27, %rd6;
cvt.u64.u32	%rd29, %r45;
add.s64 %rd30, %rd28, %rd29;
and.b64 %rd31, %rd30, 4294967295;
ld.local.u64 %rd32, [%rd2];
shl.b64 %rd33, %rd31, 1;
add.s64 %rd34, %rd32, %rd33;
st.u16 [%rd34], %rs1;
mov.u32 %r42, %nctaid.x;
mad.lo.s32 %r44, %r42, %r26, %r44;
setp.lt.u32	%p9, %r44, %r24;
@%p9 bra BB117_4;

BB117_14:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_1[216],
.param .align 2 .b8 _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_2[2],
.param .u32 _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_4
)
{
.local .align 8 .b8 __local_depot118[432];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<12>;
.reg .b16 %rs<2>;
.reg .b32 %r<54>;
.reg .b64 %rd<63>;


mov.u64 %rd62, __local_depot118;
cvta.local.u64 %SP, %rd62;
ld.param.u16 %rs1, [_Z30THCudaTensor_scatterFillKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_2];
ld.param.u32 %r24, [_Z30THCudaTensor_scatterFillKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_3];
ld.param.u32 %r25, [_Z30THCudaTensor_scatterFillKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_4];
mov.u64 %rd4, _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjN3c104HalfELin1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_1;
add.u64 %rd17, %SP, 216;
cvta.to.local.u64 %rd2, %rd17;
add.u64 %rd18, %SP, 0;
cvta.to.local.u64 %rd3, %rd18;
mov.u32 %r40, 0;
mov.pred %p1, 0;
@%p1 bra BB118_2;

BB118_1:
mul.wide.s32 %rd19, %r40, 8;
add.s64 %rd20, %rd4, %rd19;
ld.param.u64 %rd21, [%rd20];
add.s64 %rd22, %rd2, %rd19;
st.local.u64 [%rd22], %rd21;
add.s32 %r40, %r40, 1;
setp.lt.u32	%p2, %r40, 27;
@%p2 bra BB118_1;

BB118_2:
mov.u32 %r41, 0;
@%p1 bra BB118_4;

BB118_3:
mul.wide.s32 %rd23, %r41, 8;
add.s64 %rd24, %rd1, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r41, %r41, 1;
setp.lt.u32	%p4, %r41, 27;
@%p4 bra BB118_3;

BB118_4:
mov.u32 %r28, %ntid.x;
mov.u32 %r29, %ctaid.x;
mov.u32 %r30, %tid.x;
mad.lo.s32 %r46, %r28, %r29, %r30;
setp.ge.u32	%p5, %r46, %r25;
@%p5 bra BB118_15;

ld.local.u32 %r6, [%rd3+208];

BB118_6:
mov.u32 %r44, %r46;
mov.u32 %r7, %r44;
cvt.s64.s32	%rd28, %r6;
not.b64 %rd29, %rd28;
mov.u64 %rd30, -26;
sub.s64 %rd31, %rd30, %rd28;
add.s32 %r34, %r6, -1;
sub.s32 %r42, %r34, %r24;
neg.s64 %rd59, %rd29;
neg.s64 %rd60, %rd31;
mov.u32 %r51, 0;
mov.u64 %rd61, 0;
mov.u32 %r52, %r51;
mov.u32 %r47, %r51;
setp.lt.s32	%p6, %r6, 1;
mov.u32 %r43, %r6;
mov.u32 %r45, %r7;
@%p6 bra BB118_11;

BB118_7:
mov.u32 %r48, %r52;
mov.u32 %r53, %r48;
mov.u32 %r11, %r45;
mov.u32 %r10, %r43;
add.s32 %r14, %r10, -1;
shl.b64 %rd32, %rd59, 2;
add.s64 %rd33, %rd3, %rd32;
ld.local.u32 %r15, [%rd33];
rem.u32 %r16, %r11, %r15;
ld.local.u32 %r35, [%rd33+100];
mad.lo.s32 %r47, %r35, %r16, %r47;
setp.eq.s32	%p7, %r42, 0;
@%p7 bra BB118_9;

shl.b64 %rd34, %rd60, 2;
add.s64 %rd35, %rd2, %rd34;
ld.local.u32 %r36, [%rd35];
mad.lo.s32 %r53, %r36, %r16, %r53;

BB118_9:
mov.u32 %r52, %r53;
div.u32 %r20, %r11, %r15;
add.s32 %r42, %r42, -1;
add.s64 %rd60, %rd60, -1;
add.s64 %rd59, %rd59, -1;
setp.gt.s32	%p8, %r14, 0;
mov.u32 %r43, %r14;
mov.u32 %r45, %r20;
@%p8 bra BB118_7;

cvt.u64.u32	%rd61, %r47;
mov.u32 %r51, %r52;

BB118_11:
ld.local.u64 %rd36, [%rd3];
shl.b64 %rd37, %rd61, 3;
add.s64 %rd38, %rd36, %rd37;
ld.u64 %rd16, [%rd38];
setp.lt.s64	%p9, %rd16, 0;
@%p9 bra BB118_13;

mul.wide.s32 %rd39, %r24, 4;
add.s64 %rd40, %rd2, %rd39;
ld.local.u32 %rd41, [%rd40+8];
setp.lt.s64	%p10, %rd16, %rd41;
@%p10 bra BB118_14;

BB118_13:
mov.u64 %rd42, $str2;
cvta.global.u64 %rd43, %rd42;
mov.u64 %rd44, $str1;
cvta.global.u64 %rd45, %rd44;
mov.u64 %rd46, __T2141;
cvta.global.u64 %rd47, %rd46;
mov.u32 %r37, 176;
mov.u64 %rd48, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd43;
.param .b64 param1;
st.param.b64	[param1+0], %rd45;
.param .b32 param2;
st.param.b32	[param2+0], %r37;
.param .b64 param3;
st.param.b64	[param3+0], %rd47;
.param .b64 param4;
st.param.b64	[param4+0], %rd48;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB118_14:
mul.wide.s32 %rd49, %r24, 4;
add.s64 %rd50, %rd2, %rd49;
ld.local.u32 %rd51, [%rd50+108];
mul.lo.s64 %rd52, %rd51, %rd16;
cvt.u64.u32	%rd53, %r51;
add.s64 %rd54, %rd52, %rd53;
and.b64 %rd55, %rd54, 4294967295;
ld.local.u64 %rd56, [%rd2];
shl.b64 %rd57, %rd55, 1;
add.s64 %rd58, %rd56, %rd57;
st.u16 [%rd58], %rs1;
mov.u32 %r39, %nctaid.x;
mad.lo.s32 %r46, %r39, %r28, %r7;
setp.lt.u32	%p11, %r46, %r25;
@%p11 bra BB118_6;

BB118_15:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_0[416],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_1[416],
.param .align 2 .b8 _Z30THCudaTensor_scatterFillKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_2[2],
.param .u32 _Z30THCudaTensor_scatterFillKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_3,
.param .u64 _Z30THCudaTensor_scatterFillKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_4
)
{
.local .align 8 .b8 __local_depot119[832];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .b32 %r<33>;
.reg .b64 %rd<99>;


mov.u64 %rd98, __local_depot119;
cvta.local.u64 %SP, %rd98;
ld.param.u16 %rs1, [_Z30THCudaTensor_scatterFillKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_2];
ld.param.u32 %r11, [_Z30THCudaTensor_scatterFillKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_3];
ld.param.u64 %rd34, [_Z30THCudaTensor_scatterFillKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_4];
mov.u64 %rd4, _Z30THCudaTensor_scatterFillKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelImN3c104HalfELin1EEv10TensorInfoIT0_T_ES2_IlS4_ES3_iS4__param_1;
add.u64 %rd35, %SP, 416;
cvta.to.local.u64 %rd2, %rd35;
add.u64 %rd36, %SP, 0;
cvta.to.local.u64 %rd3, %rd36;
mov.u32 %r29, 0;
mov.pred %p1, 0;
@%p1 bra BB119_2;

BB119_1:
mul.wide.s32 %rd37, %r29, 8;
add.s64 %rd38, %rd4, %rd37;
ld.param.u64 %rd39, [%rd38];
add.s64 %rd40, %rd2, %rd37;
st.local.u64 [%rd40], %rd39;
add.s32 %r29, %r29, 1;
setp.lt.u32	%p2, %r29, 52;
@%p2 bra BB119_1;

BB119_2:
mov.u32 %r30, 0;
@%p1 bra BB119_4;

BB119_3:
mul.wide.s32 %rd41, %r30, 8;
add.s64 %rd42, %rd1, %rd41;
ld.param.u64 %rd43, [%rd42];
add.s64 %rd44, %rd3, %rd41;
st.local.u64 [%rd44], %rd43;
add.s32 %r30, %r30, 1;
setp.lt.u32	%p4, %r30, 52;
@%p4 bra BB119_3;

BB119_4:
mov.u32 %r14, %ntid.x;
mov.u32 %r15, %ctaid.x;
mov.u32 %r16, %tid.x;
mad.lo.s32 %r17, %r14, %r15, %r16;
cvt.u64.u32	%rd87, %r17;
setp.ge.u64	%p5, %rd87, %rd34;
@%p5 bra BB119_20;

ld.local.u32 %r5, [%rd3+408];

BB119_6:
mov.u64 %rd83, %rd87;
mov.u64 %rd9, %rd83;
mul.wide.s32 %rd49, %r5, 8;
add.s64 %rd81, %rd3, %rd49;
add.s64 %rd50, %rd49, %rd2;
add.s64 %rd82, %rd50, 200;
add.s32 %r18, %r5, -1;
sub.s32 %r31, %r18, %r11;
mov.u64 %rd95, 0;
mov.u64 %rd90, %rd95;
mov.u64 %rd96, %rd95;
mov.u64 %rd91, %rd95;
setp.lt.s32	%p6, %r5, 1;
mov.u32 %r32, %r5;
mov.u64 %rd85, %rd9;
@%p6 bra BB119_16;

BB119_7:
mov.u64 %rd97, %rd96;
mov.u64 %rd14, %rd85;
mov.u32 %r8, %r32;
add.s32 %r9, %r8, -1;
ld.local.u64 %rd18, [%rd81];
or.b64 %rd51, %rd14, %rd18;
and.b64 %rd52, %rd51, -4294967296;
setp.eq.s64	%p7, %rd52, 0;
@%p7 bra BB119_9;
bra.uni BB119_8;

BB119_9:
cvt.u32.u64	%r19, %rd18;
cvt.u32.u64	%r20, %rd14;
rem.u32 %r21, %r20, %r19;
cvt.u64.u32	%rd88, %r21;
bra.uni BB119_10;

BB119_8:
rem.u64 %rd88, %rd14, %rd18;

BB119_10:
ld.local.u64 %rd53, [%rd81+200];
mul.lo.s64 %rd54, %rd53, %rd88;
add.s64 %rd91, %rd54, %rd91;
setp.eq.s32	%p8, %r31, 0;
@%p8 bra BB119_12;

ld.local.u64 %rd55, [%rd82];
mul.lo.s64 %rd56, %rd55, %rd88;
add.s64 %rd97, %rd56, %rd97;

BB119_12:
mov.u64 %rd96, %rd97;
@%p7 bra BB119_14;
bra.uni BB119_13;

BB119_14:
cvt.u32.u64	%r22, %rd18;
cvt.u32.u64	%r23, %rd14;
div.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd86, %r24;
bra.uni BB119_15;

BB119_13:
div.u64 %rd86, %rd14, %rd18;

BB119_15:
mov.u64 %rd27, %rd86;
add.s32 %r31, %r31, -1;
add.s64 %rd82, %rd82, -8;
add.s64 %rd81, %rd81, -8;
setp.gt.s32	%p10, %r9, 0;
mov.u32 %r32, %r9;
mov.u64 %rd85, %rd27;
mov.u64 %rd90, %rd91;
mov.u64 %rd95, %rd96;
@%p10 bra BB119_7;

BB119_16:
ld.local.u64 %rd59, [%rd3];
shl.b64 %rd60, %rd90, 3;
add.s64 %rd61, %rd59, %rd60;
ld.u64 %rd32, [%rd61];
setp.lt.s64	%p11, %rd32, 0;
@%p11 bra BB119_18;

mul.wide.s32 %rd62, %r11, 8;
add.s64 %rd63, %rd2, %rd62;
ld.local.u64 %rd64, [%rd63+8];
setp.lt.u64	%p12, %rd32, %rd64;
@%p12 bra BB119_19;

BB119_18:
mov.u64 %rd65, $str2;
cvta.global.u64 %rd66, %rd65;
mov.u64 %rd67, $str1;
cvta.global.u64 %rd68, %rd67;
mov.u64 %rd69, __T2142;
cvta.global.u64 %rd70, %rd69;
mov.u32 %r25, 176;
mov.u64 %rd71, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd66;
.param .b64 param1;
st.param.b64	[param1+0], %rd68;
.param .b32 param2;
st.param.b32	[param2+0], %r25;
.param .b64 param3;
st.param.b64	[param3+0], %rd70;
.param .b64 param4;
st.param.b64	[param4+0], %rd71;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB119_19:
mul.wide.s32 %rd72, %r11, 8;
add.s64 %rd73, %rd2, %rd72;
ld.local.u64 %rd74, [%rd73+208];
mul.lo.s64 %rd75, %rd74, %rd32;
add.s64 %rd76, %rd75, %rd95;
ld.local.u64 %rd77, [%rd2];
shl.b64 %rd78, %rd76, 1;
add.s64 %rd79, %rd77, %rd78;
st.u16 [%rd79], %rs1;
mov.u32 %r27, %nctaid.x;
mul.lo.s32 %r28, %r27, %r14;
cvt.u64.u32	%rd80, %r28;
add.s64 %rd87, %rd80, %rd9;
setp.lt.u64	%p13, %rd87, %rd34;
@%p13 bra BB119_6;

BB119_20:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot120[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .f32 %f<2>;
.reg .b32 %r<25>;
.reg .b64 %rd<44>;


mov.u64 %rd43, __local_depot120;
cvta.local.u64 %SP, %rd43;
ld.param.u32 %r10, [_Z25THCudaTensor_gatherKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r11, [_Z25THCudaTensor_gatherKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd3, %rd11;
mov.u32 %r23, 0;
mov.pred %p1, 0;
@%p1 bra BB120_2;

BB120_1:
mul.wide.s32 %rd12, %r23, 8;
add.s64 %rd13, %rd4, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd3, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r23, %r23, 1;
setp.lt.u32	%p2, %r23, 27;
@%p2 bra BB120_1;

BB120_2:
mov.u32 %r13, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r24, %r13, %r14, %r15;
setp.ge.u32	%p3, %r24, %r11;
@%p3 bra BB120_10;

ld.param.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd6, %rd16;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd17, [%rd2];
cvta.to.global.u64 %rd7, %rd17;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB120_4:
rem.u32 %r8, %r24, %r5;
setp.eq.s32	%p4, %r10, 0;
mov.u64 %rd42, 0;
@%p4 bra BB120_6;

ld.local.u32 %r16, [%rd3+108];
mul.lo.s32 %r17, %r16, %r8;
cvt.u64.u32	%rd42, %r17;

BB120_6:
mul.lo.s32 %r18, %r6, %r8;
mul.wide.u32 %rd19, %r18, 8;
add.s64 %rd20, %rd7, %rd19;
ld.global.u64 %rd10, [%rd20];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB120_8;

mul.wide.s32 %rd21, %r10, 4;
add.s64 %rd22, %rd3, %rd21;
ld.local.u32 %rd23, [%rd22+8];
setp.lt.s64	%p6, %rd10, %rd23;
@%p6 bra BB120_9;

BB120_8:
mov.u64 %rd24, $str;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, $str1;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, __T2145;
cvta.global.u64 %rd29, %rd28;
mov.u32 %r19, 97;
mov.u64 %rd30, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd25;
.param .b64 param1;
st.param.b64	[param1+0], %rd27;
.param .b32 param2;
st.param.b32	[param2+0], %r19;
.param .b64 param3;
st.param.b64	[param3+0], %rd29;
.param .b64 param4;
st.param.b64	[param4+0], %rd30;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB120_9:
mul.lo.s32 %r20, %r4, %r8;
mul.wide.s32 %rd31, %r10, 4;
add.s64 %rd32, %rd3, %rd31;
ld.local.u32 %rd33, [%rd32+108];
mul.lo.s64 %rd34, %rd33, %rd10;
add.s64 %rd35, %rd34, %rd42;
and.b64 %rd36, %rd35, 4294967295;
ld.local.u64 %rd37, [%rd3];
shl.b64 %rd38, %rd36, 2;
add.s64 %rd39, %rd37, %rd38;
ld.f32 %f1, [%rd39];
mul.wide.u32 %rd40, %r20, 4;
add.s64 %rd41, %rd6, %rd40;
st.global.f32 [%rd41], %f1;
mov.u32 %r22, %nctaid.x;
mad.lo.s32 %r24, %r22, %r13, %r24;
setp.lt.u32	%p7, %r24, %r11;
@%p7 bra BB120_4;

BB120_10:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot121[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .f32 %f<2>;
.reg .b32 %r<40>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot121;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r19, [_Z25THCudaTensor_gatherKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r20, [_Z25THCudaTensor_gatherKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r37, 0;
mov.pred %p1, 0;
@%p1 bra BB121_2;

BB121_1:
mul.wide.s32 %rd10, %r37, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r37, %r37, 1;
setp.lt.u32	%p2, %r37, 27;
@%p2 bra BB121_1;

BB121_2:
mov.u32 %r22, %ntid.x;
mov.u32 %r23, %ctaid.x;
mov.u32 %r24, %tid.x;
mad.lo.s32 %r38, %r22, %r23, %r24;
setp.ge.u32	%p3, %r38, %r20;
@%p3 bra BB121_12;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r25, %r26}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB121_4:
rem.u32 %r11, %r38, %r26;
setp.eq.s32	%p4, %r19, 1;
mov.u32 %r39, 0;
@%p4 bra BB121_6;

ld.local.u32 %r28, [%rd3+112];
mul.lo.s32 %r39, %r28, %r11;

BB121_6:
div.u32 %r29, %r38, %r26;
rem.u32 %r14, %r29, %r25;
setp.eq.s32	%p5, %r19, 0;
@%p5 bra BB121_8;

ld.local.u32 %r30, [%rd3+108];
mad.lo.s32 %r39, %r30, %r14, %r39;

BB121_8:
mul.lo.s32 %r31, %r9, %r11;
mul.lo.s32 %r32, %r5, %r11;
mad.lo.s32 %r33, %r8, %r14, %r31;
mad.lo.s32 %r17, %r4, %r14, %r32;
mul.wide.u32 %rd16, %r33, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB121_10;

mul.wide.s32 %rd18, %r19, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p7, %rd8, %rd20;
@%p7 bra BB121_11;

BB121_10:
mov.u64 %rd21, $str;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T2146;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r34, 97;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r34;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB121_11:
mul.wide.s32 %rd28, %r19, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r39;
add.s64 %rd33, %rd31, %rd32;
and.b64 %rd34, %rd33, 4294967295;
ld.local.u64 %rd35, [%rd3];
shl.b64 %rd36, %rd34, 2;
add.s64 %rd37, %rd35, %rd36;
ld.f32 %f1, [%rd37];
mul.wide.u32 %rd38, %r17, 4;
add.s64 %rd39, %rd6, %rd38;
st.global.f32 [%rd39], %f1;
mov.u32 %r36, %nctaid.x;
mad.lo.s32 %r38, %r36, %r22, %r38;
setp.lt.u32	%p8, %r38, %r20;
@%p8 bra BB121_4;

BB121_12:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot122[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .f32 %f<2>;
.reg .b32 %r<54>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot122;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r26, [_Z25THCudaTensor_gatherKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r27, [_Z25THCudaTensor_gatherKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r51, 0;
mov.pred %p1, 0;
@%p1 bra BB122_2;

BB122_1:
mul.wide.s32 %rd10, %r51, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p2, %r51, 27;
@%p2 bra BB122_1;

BB122_2:
mov.u32 %r29, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r52, %r29, %r30, %r31;
setp.ge.u32	%p3, %r52, %r27;
@%p3 bra BB122_14;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r32, %r33}, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r34, %r35}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r36, %r37}, [%rd2+112];

BB122_4:
rem.u32 %r14, %r52, %r9;
setp.eq.s32	%p4, %r26, 2;
mov.u32 %r53, 0;
@%p4 bra BB122_6;

ld.local.u32 %r39, [%rd3+116];
mul.lo.s32 %r53, %r39, %r14;

BB122_6:
div.u32 %r17, %r52, %r9;
rem.u32 %r18, %r17, %r35;
setp.eq.s32	%p5, %r26, 1;
@%p5 bra BB122_8;

ld.local.u32 %r40, [%rd3+112];
mad.lo.s32 %r53, %r40, %r18, %r53;

BB122_8:
div.u32 %r41, %r17, %r35;
rem.u32 %r21, %r41, %r34;
setp.eq.s32	%p6, %r26, 0;
@%p6 bra BB122_10;

ld.local.u32 %r42, [%rd3+108];
mad.lo.s32 %r53, %r42, %r21, %r53;

BB122_10:
mul.lo.s32 %r43, %r37, %r14;
mul.lo.s32 %r44, %r33, %r14;
mad.lo.s32 %r45, %r36, %r18, %r43;
mad.lo.s32 %r46, %r32, %r18, %r44;
mad.lo.s32 %r47, %r10, %r21, %r45;
mad.lo.s32 %r24, %r4, %r21, %r46;
mul.wide.u32 %rd16, %r47, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB122_12;

mul.wide.s32 %rd18, %r26, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p8, %rd8, %rd20;
@%p8 bra BB122_13;

BB122_12:
mov.u64 %rd21, $str;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T2147;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r48, 97;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r48;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB122_13:
mul.wide.s32 %rd28, %r26, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r53;
add.s64 %rd33, %rd31, %rd32;
and.b64 %rd34, %rd33, 4294967295;
ld.local.u64 %rd35, [%rd3];
shl.b64 %rd36, %rd34, 2;
add.s64 %rd37, %rd35, %rd36;
ld.f32 %f1, [%rd37];
mul.wide.u32 %rd38, %r24, 4;
add.s64 %rd39, %rd6, %rd38;
st.global.f32 [%rd39], %f1;
mov.u32 %r50, %nctaid.x;
mad.lo.s32 %r52, %r50, %r29, %r52;
setp.lt.u32	%p9, %r52, %r27;
@%p9 bra BB122_4;

BB122_14:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot123[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .f32 %f<2>;
.reg .b32 %r<63>;
.reg .b64 %rd<70>;


mov.u64 %rd69, __local_depot123;
cvta.local.u64 %SP, %rd69;
ld.param.u32 %r28, [_Z25THCudaTensor_gatherKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r29, [_Z25THCudaTensor_gatherKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z25THCudaTensor_gatherKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd20, %SP, 216;
cvta.to.local.u64 %rd3, %rd20;
add.u64 %rd21, %SP, 432;
cvta.to.local.u64 %rd4, %rd21;
add.u64 %rd22, %SP, 0;
cvta.to.local.u64 %rd5, %rd22;
mov.u32 %r47, 0;
mov.pred %p1, 0;
@%p1 bra BB123_2;

BB123_1:
mul.wide.s32 %rd23, %r47, 8;
add.s64 %rd24, %rd6, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r47, %r47, 1;
setp.lt.u32	%p2, %r47, 27;
@%p2 bra BB123_1;

BB123_2:
mov.u32 %r48, 0;
@%p1 bra BB123_4;

BB123_3:
mul.wide.s32 %rd27, %r48, 8;
add.s64 %rd28, %rd1, %rd27;
ld.param.u64 %rd29, [%rd28];
add.s64 %rd30, %rd4, %rd27;
st.local.u64 [%rd30], %rd29;
add.s32 %r48, %r48, 1;
setp.lt.u32	%p4, %r48, 27;
@%p4 bra BB123_3;

BB123_4:
mov.u32 %r49, 0;
@%p1 bra BB123_6;

BB123_5:
mul.wide.s32 %rd31, %r49, 8;
add.s64 %rd32, %rd2, %rd31;
ld.param.u64 %rd33, [%rd32];
add.s64 %rd34, %rd5, %rd31;
st.local.u64 [%rd34], %rd33;
add.s32 %r49, %r49, 1;
setp.lt.u32	%p6, %r49, 27;
@%p6 bra BB123_5;

BB123_6:
mov.u32 %r33, %ntid.x;
mov.u32 %r34, %ctaid.x;
mov.u32 %r35, %tid.x;
mad.lo.s32 %r54, %r33, %r34, %r35;
setp.ge.u32	%p7, %r54, %r29;
@%p7 bra BB123_17;

ld.local.u32 %r8, [%rd5+208];

BB123_8:
mov.u32 %r52, %r54;
mov.u32 %r9, %r52;
mul.wide.s32 %rd66, %r8, 4;
add.s32 %r40, %r8, -1;
sub.s32 %r50, %r40, %r28;
mov.u64 %rd68, 0;
mov.u32 %r60, 0;
mov.u64 %rd67, %rd68;
mov.u32 %r56, %r60;
mov.u32 %r61, %r60;
mov.u32 %r55, %r60;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r51, %r8;
mov.u32 %r53, %r9;
@%p8 bra BB123_13;

BB123_9:
mov.u32 %r57, %r61;
mov.u32 %r62, %r57;
mov.u32 %r13, %r53;
mov.u32 %r12, %r51;
add.s64 %rd37, %rd3, %rd66;
add.s32 %r17, %r12, -1;
add.s64 %rd38, %rd5, %rd66;
ld.local.u32 %r18, [%rd38+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r41, [%rd38+104];
mad.lo.s32 %r55, %r41, %r19, %r55;
ld.local.u32 %r42, [%rd37+104];
mad.lo.s32 %r56, %r42, %r19, %r56;
setp.eq.s32	%p9, %r50, 0;
@%p9 bra BB123_11;

add.s64 %rd39, %rd4, %rd66;
ld.local.u32 %r43, [%rd39+104];
mad.lo.s32 %r62, %r43, %r19, %r62;

BB123_11:
mov.u32 %r61, %r62;
div.u32 %r24, %r13, %r18;
add.s32 %r50, %r50, -1;
add.s64 %rd66, %rd66, -4;
setp.gt.s32	%p10, %r17, 0;
mov.u32 %r51, %r17;
mov.u32 %r53, %r24;
@%p10 bra BB123_9;

cvt.u64.u32	%rd67, %r55;
cvt.u64.u32	%rd68, %r56;
mov.u32 %r60, %r61;

BB123_13:
ld.local.u64 %rd40, [%rd5];
shl.b64 %rd41, %rd67, 3;
add.s64 %rd42, %rd40, %rd41;
ld.u64 %rd19, [%rd42];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB123_15;

mul.wide.s32 %rd43, %r28, 4;
add.s64 %rd44, %rd4, %rd43;
ld.local.u32 %rd45, [%rd44+8];
setp.lt.s64	%p12, %rd19, %rd45;
@%p12 bra BB123_16;

BB123_15:
mov.u64 %rd46, $str;
cvta.global.u64 %rd47, %rd46;
mov.u64 %rd48, $str1;
cvta.global.u64 %rd49, %rd48;
mov.u64 %rd50, __T2148;
cvta.global.u64 %rd51, %rd50;
mov.u32 %r44, 97;
mov.u64 %rd52, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd47;
.param .b64 param1;
st.param.b64	[param1+0], %rd49;
.param .b32 param2;
st.param.b32	[param2+0], %r44;
.param .b64 param3;
st.param.b64	[param3+0], %rd51;
.param .b64 param4;
st.param.b64	[param4+0], %rd52;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB123_16:
mul.wide.s32 %rd53, %r28, 4;
add.s64 %rd54, %rd4, %rd53;
ld.local.u32 %rd55, [%rd54+108];
mul.lo.s64 %rd56, %rd55, %rd19;
cvt.u64.u32	%rd57, %r60;
add.s64 %rd58, %rd56, %rd57;
ld.local.u64 %rd59, [%rd4];
shl.b64 %rd60, %rd58, 2;
and.b64 %rd61, %rd60, 17179869180;
add.s64 %rd62, %rd59, %rd61;
ld.f32 %f1, [%rd62];
ld.local.u64 %rd63, [%rd3];
shl.b64 %rd64, %rd68, 2;
add.s64 %rd65, %rd63, %rd64;
st.f32 [%rd65], %f1;
mov.u32 %r46, %nctaid.x;
mad.lo.s32 %r54, %r46, %r33, %r9;
setp.lt.u32	%p13, %r54, %r29;
@%p13 bra BB123_8;

BB123_17:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[416],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[416],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[416],
.param .u32 _Z25THCudaTensor_gatherKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u64 _Z25THCudaTensor_gatherKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot124[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<16>;
.reg .f32 %f<2>;
.reg .b32 %r<37>;
.reg .b64 %rd<117>;


mov.u64 %rd116, __local_depot124;
cvta.local.u64 %SP, %rd116;
ld.param.u32 %r13, [_Z25THCudaTensor_gatherKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u64 %rd38, [_Z25THCudaTensor_gatherKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z25THCudaTensor_gatherKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd39, %SP, 416;
cvta.to.local.u64 %rd3, %rd39;
add.u64 %rd40, %SP, 832;
cvta.to.local.u64 %rd4, %rd40;
add.u64 %rd41, %SP, 0;
cvta.to.local.u64 %rd5, %rd41;
mov.u32 %r32, 0;
mov.pred %p1, 0;
@%p1 bra BB124_2;

BB124_1:
mul.wide.s32 %rd42, %r32, 8;
add.s64 %rd43, %rd6, %rd42;
ld.param.u64 %rd44, [%rd43];
add.s64 %rd45, %rd3, %rd42;
st.local.u64 [%rd45], %rd44;
add.s32 %r32, %r32, 1;
setp.lt.u32	%p2, %r32, 52;
@%p2 bra BB124_1;

BB124_2:
mov.u32 %r33, 0;
@%p1 bra BB124_4;

BB124_3:
mul.wide.s32 %rd46, %r33, 8;
add.s64 %rd47, %rd1, %rd46;
ld.param.u64 %rd48, [%rd47];
add.s64 %rd49, %rd4, %rd46;
st.local.u64 [%rd49], %rd48;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p4, %r33, 52;
@%p4 bra BB124_3;

BB124_4:
mov.u32 %r34, 0;
@%p1 bra BB124_6;

BB124_5:
mul.wide.s32 %rd50, %r34, 8;
add.s64 %rd51, %rd2, %rd50;
ld.param.u64 %rd52, [%rd51];
add.s64 %rd53, %rd5, %rd50;
st.local.u64 [%rd53], %rd52;
add.s32 %r34, %r34, 1;
setp.lt.u32	%p6, %r34, 52;
@%p6 bra BB124_5;

BB124_6:
mov.u32 %r17, %ntid.x;
mov.u32 %r18, %ctaid.x;
mov.u32 %r19, %tid.x;
mad.lo.s32 %r20, %r17, %r18, %r19;
cvt.u64.u32	%rd102, %r20;
setp.ge.u64	%p7, %rd102, %rd38;
@%p7 bra BB124_22;

ld.local.u32 %r7, [%rd5+408];

BB124_8:
mov.u64 %rd98, %rd102;
mov.u64 %rd13, %rd98;
mul.wide.s32 %rd97, %r7, 8;
add.s32 %r21, %r7, -1;
sub.s32 %r35, %r21, %r13;
mov.u64 %rd114, 0;
mov.u64 %rd110, %rd114;
mov.u64 %rd105, %rd114;
mov.u64 %rd115, %rd114;
mov.u64 %rd111, %rd114;
mov.u64 %rd106, %rd114;
setp.lt.s32	%p8, %r7, 1;
mov.u32 %r36, %r7;
mov.u64 %rd100, %rd13;
@%p8 bra BB124_18;

BB124_9:
mov.u64 %rd112, %rd111;
mov.u64 %rd16, %rd100;
mov.u32 %r10, %r36;
add.s32 %r11, %r10, -1;
add.s64 %rd20, %rd5, %rd97;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd60, %rd16, %rd21;
and.b64 %rd61, %rd60, -4294967296;
setp.eq.s64	%p9, %rd61, 0;
@%p9 bra BB124_11;
bra.uni BB124_10;

BB124_11:
cvt.u32.u64	%r22, %rd21;
cvt.u32.u64	%r23, %rd16;
rem.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd103, %r24;
bra.uni BB124_12;

BB124_10:
rem.u64 %rd103, %rd16, %rd21;

BB124_12:
add.s64 %rd62, %rd3, %rd97;
ld.local.u64 %rd63, [%rd20+200];
mul.lo.s64 %rd64, %rd63, %rd103;
add.s64 %rd106, %rd64, %rd106;
ld.local.u64 %rd65, [%rd62+200];
mul.lo.s64 %rd66, %rd65, %rd103;
add.s64 %rd115, %rd66, %rd115;
setp.eq.s32	%p10, %r35, 0;
@%p10 bra BB124_14;

add.s64 %rd67, %rd4, %rd97;
ld.local.u64 %rd68, [%rd67+200];
mul.lo.s64 %rd69, %rd68, %rd103;
add.s64 %rd112, %rd69, %rd112;

BB124_14:
mov.u64 %rd111, %rd112;
@%p9 bra BB124_16;
bra.uni BB124_15;

BB124_16:
cvt.u32.u64	%r25, %rd21;
cvt.u32.u64	%r26, %rd16;
div.u32 %r27, %r26, %r25;
cvt.u64.u32	%rd101, %r27;
bra.uni BB124_17;

BB124_15:
div.u64 %rd101, %rd16, %rd21;

BB124_17:
mov.u64 %rd31, %rd101;
add.s32 %r35, %r35, -1;
add.s64 %rd97, %rd97, -8;
setp.gt.s32	%p12, %r11, 0;
mov.u32 %r36, %r11;
mov.u64 %rd100, %rd31;
mov.u64 %rd105, %rd106;
mov.u64 %rd110, %rd111;
mov.u64 %rd114, %rd115;
@%p12 bra BB124_9;

BB124_18:
ld.local.u64 %rd72, [%rd5];
shl.b64 %rd73, %rd105, 3;
add.s64 %rd74, %rd72, %rd73;
ld.u64 %rd36, [%rd74];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB124_20;

mul.wide.s32 %rd75, %r13, 8;
add.s64 %rd76, %rd4, %rd75;
ld.local.u64 %rd77, [%rd76+8];
setp.lt.u64	%p14, %rd36, %rd77;
@%p14 bra BB124_21;

BB124_20:
mov.u64 %rd78, $str;
cvta.global.u64 %rd79, %rd78;
mov.u64 %rd80, $str1;
cvta.global.u64 %rd81, %rd80;
mov.u64 %rd82, __T2150;
cvta.global.u64 %rd83, %rd82;
mov.u32 %r28, 97;
mov.u64 %rd84, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd79;
.param .b64 param1;
st.param.b64	[param1+0], %rd81;
.param .b32 param2;
st.param.b32	[param2+0], %r28;
.param .b64 param3;
st.param.b64	[param3+0], %rd83;
.param .b64 param4;
st.param.b64	[param4+0], %rd84;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB124_21:
mul.wide.s32 %rd85, %r13, 8;
add.s64 %rd86, %rd4, %rd85;
ld.local.u64 %rd87, [%rd86+208];
mul.lo.s64 %rd88, %rd87, %rd36;
add.s64 %rd89, %rd88, %rd110;
ld.local.u64 %rd90, [%rd4];
shl.b64 %rd91, %rd89, 2;
add.s64 %rd92, %rd90, %rd91;
ld.f32 %f1, [%rd92];
ld.local.u64 %rd93, [%rd3];
shl.b64 %rd94, %rd114, 2;
add.s64 %rd95, %rd93, %rd94;
st.f32 [%rd95], %f1;
mov.u32 %r30, %nctaid.x;
mul.lo.s32 %r31, %r30, %r17;
cvt.u64.u32	%rd96, %r31;
add.s64 %rd102, %rd96, %rd13;
setp.lt.u64	%p15, %rd102, %rd38;
@%p15 bra BB124_8;

BB124_22:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot125[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .f32 %f<2>;
.reg .b32 %r<25>;
.reg .b64 %rd<44>;


mov.u64 %rd43, __local_depot125;
cvta.local.u64 %SP, %rd43;
ld.param.u32 %r10, [_Z26THCudaTensor_scatterKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r11, [_Z26THCudaTensor_scatterKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd3, %rd11;
mov.u32 %r23, 0;
mov.pred %p1, 0;
@%p1 bra BB125_2;

BB125_1:
mul.wide.s32 %rd12, %r23, 8;
add.s64 %rd13, %rd4, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd3, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r23, %r23, 1;
setp.lt.u32	%p2, %r23, 27;
@%p2 bra BB125_1;

BB125_2:
mov.u32 %r13, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r24, %r13, %r14, %r15;
setp.ge.u32	%p3, %r24, %r11;
@%p3 bra BB125_10;

ld.param.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd6, %rd16;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd17, [%rd2];
cvta.to.global.u64 %rd7, %rd17;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB125_4:
rem.u32 %r8, %r24, %r5;
setp.eq.s32	%p4, %r10, 0;
mov.u64 %rd42, 0;
@%p4 bra BB125_6;

ld.local.u32 %r16, [%rd3+108];
mul.lo.s32 %r17, %r16, %r8;
cvt.u64.u32	%rd42, %r17;

BB125_6:
mul.lo.s32 %r18, %r6, %r8;
mul.wide.u32 %rd19, %r18, 8;
add.s64 %rd20, %rd7, %rd19;
ld.global.u64 %rd10, [%rd20];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB125_8;

mul.wide.s32 %rd21, %r10, 4;
add.s64 %rd22, %rd3, %rd21;
ld.local.u32 %rd23, [%rd22+8];
setp.lt.s64	%p6, %rd10, %rd23;
@%p6 bra BB125_9;

BB125_8:
mov.u64 %rd24, $str2;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, $str1;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, __T2151;
cvta.global.u64 %rd29, %rd28;
mov.u32 %r19, 124;
mov.u64 %rd30, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd25;
.param .b64 param1;
st.param.b64	[param1+0], %rd27;
.param .b32 param2;
st.param.b32	[param2+0], %r19;
.param .b64 param3;
st.param.b64	[param3+0], %rd29;
.param .b64 param4;
st.param.b64	[param4+0], %rd30;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB125_9:
mul.lo.s32 %r20, %r4, %r8;
mul.wide.s32 %rd31, %r10, 4;
add.s64 %rd32, %rd3, %rd31;
ld.local.u32 %rd33, [%rd32+108];
mul.lo.s64 %rd34, %rd33, %rd10;
add.s64 %rd35, %rd34, %rd42;
mul.wide.u32 %rd36, %r20, 4;
add.s64 %rd37, %rd6, %rd36;
ld.global.f32 %f1, [%rd37];
ld.local.u64 %rd38, [%rd3];
shl.b64 %rd39, %rd35, 2;
and.b64 %rd40, %rd39, 17179869180;
add.s64 %rd41, %rd38, %rd40;
st.f32 [%rd41], %f1;
mov.u32 %r22, %nctaid.x;
mad.lo.s32 %r24, %r22, %r13, %r24;
setp.lt.u32	%p7, %r24, %r11;
@%p7 bra BB125_4;

BB125_10:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot126[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .f32 %f<2>;
.reg .b32 %r<40>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot126;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r19, [_Z26THCudaTensor_scatterKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r20, [_Z26THCudaTensor_scatterKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r37, 0;
mov.pred %p1, 0;
@%p1 bra BB126_2;

BB126_1:
mul.wide.s32 %rd10, %r37, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r37, %r37, 1;
setp.lt.u32	%p2, %r37, 27;
@%p2 bra BB126_1;

BB126_2:
mov.u32 %r22, %ntid.x;
mov.u32 %r23, %ctaid.x;
mov.u32 %r24, %tid.x;
mad.lo.s32 %r38, %r22, %r23, %r24;
setp.ge.u32	%p3, %r38, %r20;
@%p3 bra BB126_12;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r25, %r26}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB126_4:
rem.u32 %r11, %r38, %r26;
setp.eq.s32	%p4, %r19, 1;
mov.u32 %r39, 0;
@%p4 bra BB126_6;

ld.local.u32 %r28, [%rd3+112];
mul.lo.s32 %r39, %r28, %r11;

BB126_6:
div.u32 %r29, %r38, %r26;
rem.u32 %r14, %r29, %r25;
setp.eq.s32	%p5, %r19, 0;
@%p5 bra BB126_8;

ld.local.u32 %r30, [%rd3+108];
mad.lo.s32 %r39, %r30, %r14, %r39;

BB126_8:
mul.lo.s32 %r31, %r9, %r11;
mul.lo.s32 %r32, %r5, %r11;
mad.lo.s32 %r33, %r8, %r14, %r31;
mad.lo.s32 %r17, %r4, %r14, %r32;
mul.wide.u32 %rd16, %r33, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB126_10;

mul.wide.s32 %rd18, %r19, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p7, %rd8, %rd20;
@%p7 bra BB126_11;

BB126_10:
mov.u64 %rd21, $str2;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T2152;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r34, 124;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r34;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB126_11:
mul.wide.s32 %rd28, %r19, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r39;
add.s64 %rd33, %rd31, %rd32;
mul.wide.u32 %rd34, %r17, 4;
add.s64 %rd35, %rd6, %rd34;
ld.global.f32 %f1, [%rd35];
ld.local.u64 %rd36, [%rd3];
shl.b64 %rd37, %rd33, 2;
and.b64 %rd38, %rd37, 17179869180;
add.s64 %rd39, %rd36, %rd38;
st.f32 [%rd39], %f1;
mov.u32 %r36, %nctaid.x;
mad.lo.s32 %r38, %r36, %r22, %r38;
setp.lt.u32	%p8, %r38, %r20;
@%p8 bra BB126_4;

BB126_12:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot127[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .f32 %f<2>;
.reg .b32 %r<54>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot127;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r26, [_Z26THCudaTensor_scatterKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r27, [_Z26THCudaTensor_scatterKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r51, 0;
mov.pred %p1, 0;
@%p1 bra BB127_2;

BB127_1:
mul.wide.s32 %rd10, %r51, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p2, %r51, 27;
@%p2 bra BB127_1;

BB127_2:
mov.u32 %r29, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r52, %r29, %r30, %r31;
setp.ge.u32	%p3, %r52, %r27;
@%p3 bra BB127_14;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r32, %r33}, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r34, %r35}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r36, %r37}, [%rd2+112];

BB127_4:
rem.u32 %r14, %r52, %r9;
setp.eq.s32	%p4, %r26, 2;
mov.u32 %r53, 0;
@%p4 bra BB127_6;

ld.local.u32 %r39, [%rd3+116];
mul.lo.s32 %r53, %r39, %r14;

BB127_6:
div.u32 %r17, %r52, %r9;
rem.u32 %r18, %r17, %r35;
setp.eq.s32	%p5, %r26, 1;
@%p5 bra BB127_8;

ld.local.u32 %r40, [%rd3+112];
mad.lo.s32 %r53, %r40, %r18, %r53;

BB127_8:
div.u32 %r41, %r17, %r35;
rem.u32 %r21, %r41, %r34;
setp.eq.s32	%p6, %r26, 0;
@%p6 bra BB127_10;

ld.local.u32 %r42, [%rd3+108];
mad.lo.s32 %r53, %r42, %r21, %r53;

BB127_10:
mul.lo.s32 %r43, %r37, %r14;
mul.lo.s32 %r44, %r33, %r14;
mad.lo.s32 %r45, %r36, %r18, %r43;
mad.lo.s32 %r46, %r32, %r18, %r44;
mad.lo.s32 %r47, %r10, %r21, %r45;
mad.lo.s32 %r24, %r4, %r21, %r46;
mul.wide.u32 %rd16, %r47, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB127_12;

mul.wide.s32 %rd18, %r26, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p8, %rd8, %rd20;
@%p8 bra BB127_13;

BB127_12:
mov.u64 %rd21, $str2;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T2153;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r48, 124;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r48;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB127_13:
mul.wide.s32 %rd28, %r26, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r53;
add.s64 %rd33, %rd31, %rd32;
mul.wide.u32 %rd34, %r24, 4;
add.s64 %rd35, %rd6, %rd34;
ld.global.f32 %f1, [%rd35];
ld.local.u64 %rd36, [%rd3];
shl.b64 %rd37, %rd33, 2;
and.b64 %rd38, %rd37, 17179869180;
add.s64 %rd39, %rd36, %rd38;
st.f32 [%rd39], %f1;
mov.u32 %r50, %nctaid.x;
mad.lo.s32 %r52, %r50, %r29, %r52;
setp.lt.u32	%p9, %r52, %r27;
@%p9 bra BB127_4;

BB127_14:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot128[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .f32 %f<2>;
.reg .b32 %r<63>;
.reg .b64 %rd<70>;


mov.u64 %rd69, __local_depot128;
cvta.local.u64 %SP, %rd69;
ld.param.u32 %r28, [_Z26THCudaTensor_scatterKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r29, [_Z26THCudaTensor_scatterKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z26THCudaTensor_scatterKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd20, %SP, 216;
cvta.to.local.u64 %rd3, %rd20;
add.u64 %rd21, %SP, 432;
cvta.to.local.u64 %rd4, %rd21;
add.u64 %rd22, %SP, 0;
cvta.to.local.u64 %rd5, %rd22;
mov.u32 %r47, 0;
mov.pred %p1, 0;
@%p1 bra BB128_2;

BB128_1:
mul.wide.s32 %rd23, %r47, 8;
add.s64 %rd24, %rd6, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r47, %r47, 1;
setp.lt.u32	%p2, %r47, 27;
@%p2 bra BB128_1;

BB128_2:
mov.u32 %r48, 0;
@%p1 bra BB128_4;

BB128_3:
mul.wide.s32 %rd27, %r48, 8;
add.s64 %rd28, %rd1, %rd27;
ld.param.u64 %rd29, [%rd28];
add.s64 %rd30, %rd4, %rd27;
st.local.u64 [%rd30], %rd29;
add.s32 %r48, %r48, 1;
setp.lt.u32	%p4, %r48, 27;
@%p4 bra BB128_3;

BB128_4:
mov.u32 %r49, 0;
@%p1 bra BB128_6;

BB128_5:
mul.wide.s32 %rd31, %r49, 8;
add.s64 %rd32, %rd2, %rd31;
ld.param.u64 %rd33, [%rd32];
add.s64 %rd34, %rd5, %rd31;
st.local.u64 [%rd34], %rd33;
add.s32 %r49, %r49, 1;
setp.lt.u32	%p6, %r49, 27;
@%p6 bra BB128_5;

BB128_6:
mov.u32 %r33, %ntid.x;
mov.u32 %r34, %ctaid.x;
mov.u32 %r35, %tid.x;
mad.lo.s32 %r54, %r33, %r34, %r35;
setp.ge.u32	%p7, %r54, %r29;
@%p7 bra BB128_17;

ld.local.u32 %r8, [%rd5+208];

BB128_8:
mov.u32 %r52, %r54;
mov.u32 %r9, %r52;
mul.wide.s32 %rd66, %r8, 4;
add.s32 %r40, %r8, -1;
sub.s32 %r50, %r40, %r28;
mov.u32 %r60, 0;
mov.u64 %rd68, 0;
mov.u64 %rd67, %rd68;
mov.u32 %r61, %r60;
mov.u32 %r56, %r60;
mov.u32 %r55, %r60;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r51, %r8;
mov.u32 %r53, %r9;
@%p8 bra BB128_13;

BB128_9:
mov.u32 %r57, %r61;
mov.u32 %r62, %r57;
mov.u32 %r13, %r53;
mov.u32 %r12, %r51;
add.s64 %rd37, %rd4, %rd66;
add.s32 %r17, %r12, -1;
add.s64 %rd38, %rd5, %rd66;
ld.local.u32 %r18, [%rd38+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r41, [%rd38+104];
mad.lo.s32 %r55, %r41, %r19, %r55;
ld.local.u32 %r42, [%rd37+104];
mad.lo.s32 %r56, %r42, %r19, %r56;
setp.eq.s32	%p9, %r50, 0;
@%p9 bra BB128_11;

add.s64 %rd39, %rd3, %rd66;
ld.local.u32 %r43, [%rd39+104];
mad.lo.s32 %r62, %r43, %r19, %r62;

BB128_11:
mov.u32 %r61, %r62;
div.u32 %r24, %r13, %r18;
add.s32 %r50, %r50, -1;
add.s64 %rd66, %rd66, -4;
setp.gt.s32	%p10, %r17, 0;
mov.u32 %r51, %r17;
mov.u32 %r53, %r24;
@%p10 bra BB128_9;

cvt.u64.u32	%rd67, %r55;
cvt.u64.u32	%rd68, %r56;
mov.u32 %r60, %r61;

BB128_13:
ld.local.u64 %rd40, [%rd5];
shl.b64 %rd41, %rd67, 3;
add.s64 %rd42, %rd40, %rd41;
ld.u64 %rd19, [%rd42];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB128_15;

mul.wide.s32 %rd43, %r28, 4;
add.s64 %rd44, %rd3, %rd43;
ld.local.u32 %rd45, [%rd44+8];
setp.lt.s64	%p12, %rd19, %rd45;
@%p12 bra BB128_16;

BB128_15:
mov.u64 %rd46, $str2;
cvta.global.u64 %rd47, %rd46;
mov.u64 %rd48, $str1;
cvta.global.u64 %rd49, %rd48;
mov.u64 %rd50, __T2154;
cvta.global.u64 %rd51, %rd50;
mov.u32 %r44, 124;
mov.u64 %rd52, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd47;
.param .b64 param1;
st.param.b64	[param1+0], %rd49;
.param .b32 param2;
st.param.b32	[param2+0], %r44;
.param .b64 param3;
st.param.b64	[param3+0], %rd51;
.param .b64 param4;
st.param.b64	[param4+0], %rd52;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB128_16:
mul.wide.s32 %rd53, %r28, 4;
add.s64 %rd54, %rd3, %rd53;
ld.local.u32 %rd55, [%rd54+108];
mul.lo.s64 %rd56, %rd55, %rd19;
cvt.u64.u32	%rd57, %r60;
add.s64 %rd58, %rd56, %rd57;
ld.local.u64 %rd59, [%rd4];
shl.b64 %rd60, %rd68, 2;
add.s64 %rd61, %rd59, %rd60;
ld.f32 %f1, [%rd61];
ld.local.u64 %rd62, [%rd3];
shl.b64 %rd63, %rd58, 2;
and.b64 %rd64, %rd63, 17179869180;
add.s64 %rd65, %rd62, %rd64;
st.f32 [%rd65], %f1;
mov.u32 %r46, %nctaid.x;
mad.lo.s32 %r54, %r46, %r33, %r9;
setp.lt.u32	%p13, %r54, %r29;
@%p13 bra BB128_8;

BB128_17:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[416],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[416],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[416],
.param .u32 _Z26THCudaTensor_scatterKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u64 _Z26THCudaTensor_scatterKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot129[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<16>;
.reg .f32 %f<2>;
.reg .b32 %r<37>;
.reg .b64 %rd<117>;


mov.u64 %rd116, __local_depot129;
cvta.local.u64 %SP, %rd116;
ld.param.u32 %r13, [_Z26THCudaTensor_scatterKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u64 %rd38, [_Z26THCudaTensor_scatterKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z26THCudaTensor_scatterKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd39, %SP, 416;
cvta.to.local.u64 %rd3, %rd39;
add.u64 %rd40, %SP, 832;
cvta.to.local.u64 %rd4, %rd40;
add.u64 %rd41, %SP, 0;
cvta.to.local.u64 %rd5, %rd41;
mov.u32 %r32, 0;
mov.pred %p1, 0;
@%p1 bra BB129_2;

BB129_1:
mul.wide.s32 %rd42, %r32, 8;
add.s64 %rd43, %rd6, %rd42;
ld.param.u64 %rd44, [%rd43];
add.s64 %rd45, %rd3, %rd42;
st.local.u64 [%rd45], %rd44;
add.s32 %r32, %r32, 1;
setp.lt.u32	%p2, %r32, 52;
@%p2 bra BB129_1;

BB129_2:
mov.u32 %r33, 0;
@%p1 bra BB129_4;

BB129_3:
mul.wide.s32 %rd46, %r33, 8;
add.s64 %rd47, %rd1, %rd46;
ld.param.u64 %rd48, [%rd47];
add.s64 %rd49, %rd4, %rd46;
st.local.u64 [%rd49], %rd48;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p4, %r33, 52;
@%p4 bra BB129_3;

BB129_4:
mov.u32 %r34, 0;
@%p1 bra BB129_6;

BB129_5:
mul.wide.s32 %rd50, %r34, 8;
add.s64 %rd51, %rd2, %rd50;
ld.param.u64 %rd52, [%rd51];
add.s64 %rd53, %rd5, %rd50;
st.local.u64 [%rd53], %rd52;
add.s32 %r34, %r34, 1;
setp.lt.u32	%p6, %r34, 52;
@%p6 bra BB129_5;

BB129_6:
mov.u32 %r17, %ntid.x;
mov.u32 %r18, %ctaid.x;
mov.u32 %r19, %tid.x;
mad.lo.s32 %r20, %r17, %r18, %r19;
cvt.u64.u32	%rd102, %r20;
setp.ge.u64	%p7, %rd102, %rd38;
@%p7 bra BB129_22;

ld.local.u32 %r7, [%rd5+408];

BB129_8:
mov.u64 %rd98, %rd102;
mov.u64 %rd13, %rd98;
mul.wide.s32 %rd97, %r7, 8;
add.s32 %r21, %r7, -1;
sub.s32 %r35, %r21, %r13;
mov.u64 %rd113, 0;
mov.u64 %rd108, %rd113;
mov.u64 %rd105, %rd113;
mov.u64 %rd114, %rd113;
mov.u64 %rd109, %rd113;
mov.u64 %rd106, %rd113;
setp.lt.s32	%p8, %r7, 1;
mov.u32 %r36, %r7;
mov.u64 %rd100, %rd13;
@%p8 bra BB129_18;

BB129_9:
mov.u64 %rd115, %rd114;
mov.u64 %rd16, %rd100;
mov.u32 %r10, %r36;
add.s32 %r11, %r10, -1;
add.s64 %rd20, %rd5, %rd97;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd60, %rd16, %rd21;
and.b64 %rd61, %rd60, -4294967296;
setp.eq.s64	%p9, %rd61, 0;
@%p9 bra BB129_11;
bra.uni BB129_10;

BB129_11:
cvt.u32.u64	%r22, %rd21;
cvt.u32.u64	%r23, %rd16;
rem.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd103, %r24;
bra.uni BB129_12;

BB129_10:
rem.u64 %rd103, %rd16, %rd21;

BB129_12:
add.s64 %rd62, %rd4, %rd97;
ld.local.u64 %rd63, [%rd20+200];
mul.lo.s64 %rd64, %rd63, %rd103;
add.s64 %rd106, %rd64, %rd106;
ld.local.u64 %rd65, [%rd62+200];
mul.lo.s64 %rd66, %rd65, %rd103;
add.s64 %rd109, %rd66, %rd109;
setp.eq.s32	%p10, %r35, 0;
@%p10 bra BB129_14;

add.s64 %rd67, %rd3, %rd97;
ld.local.u64 %rd68, [%rd67+200];
mul.lo.s64 %rd69, %rd68, %rd103;
add.s64 %rd115, %rd69, %rd115;

BB129_14:
mov.u64 %rd114, %rd115;
@%p9 bra BB129_16;
bra.uni BB129_15;

BB129_16:
cvt.u32.u64	%r25, %rd21;
cvt.u32.u64	%r26, %rd16;
div.u32 %r27, %r26, %r25;
cvt.u64.u32	%rd101, %r27;
bra.uni BB129_17;

BB129_15:
div.u64 %rd101, %rd16, %rd21;

BB129_17:
mov.u64 %rd31, %rd101;
add.s32 %r35, %r35, -1;
add.s64 %rd97, %rd97, -8;
setp.gt.s32	%p12, %r11, 0;
mov.u32 %r36, %r11;
mov.u64 %rd100, %rd31;
mov.u64 %rd105, %rd106;
mov.u64 %rd108, %rd109;
mov.u64 %rd113, %rd114;
@%p12 bra BB129_9;

BB129_18:
ld.local.u64 %rd72, [%rd5];
shl.b64 %rd73, %rd105, 3;
add.s64 %rd74, %rd72, %rd73;
ld.u64 %rd36, [%rd74];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB129_20;

mul.wide.s32 %rd75, %r13, 8;
add.s64 %rd76, %rd3, %rd75;
ld.local.u64 %rd77, [%rd76+8];
setp.lt.u64	%p14, %rd36, %rd77;
@%p14 bra BB129_21;

BB129_20:
mov.u64 %rd78, $str2;
cvta.global.u64 %rd79, %rd78;
mov.u64 %rd80, $str1;
cvta.global.u64 %rd81, %rd80;
mov.u64 %rd82, __T2155;
cvta.global.u64 %rd83, %rd82;
mov.u32 %r28, 124;
mov.u64 %rd84, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd79;
.param .b64 param1;
st.param.b64	[param1+0], %rd81;
.param .b32 param2;
st.param.b32	[param2+0], %r28;
.param .b64 param3;
st.param.b64	[param3+0], %rd83;
.param .b64 param4;
st.param.b64	[param4+0], %rd84;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB129_21:
mul.wide.s32 %rd85, %r13, 8;
add.s64 %rd86, %rd3, %rd85;
ld.local.u64 %rd87, [%rd86+208];
mul.lo.s64 %rd88, %rd87, %rd36;
add.s64 %rd89, %rd88, %rd113;
ld.local.u64 %rd90, [%rd4];
shl.b64 %rd91, %rd108, 2;
add.s64 %rd92, %rd90, %rd91;
ld.f32 %f1, [%rd92];
ld.local.u64 %rd93, [%rd3];
shl.b64 %rd94, %rd89, 2;
add.s64 %rd95, %rd93, %rd94;
st.f32 [%rd95], %f1;
mov.u32 %r30, %nctaid.x;
mul.lo.s32 %r31, %r30, %r17;
cvt.u64.u32	%rd96, %r31;
add.s64 %rd102, %rd96, %rd13;
setp.lt.u64	%p15, %rd102, %rd38;
@%p15 bra BB129_8;

BB129_22:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot130[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .f32 %f<3>;
.reg .b32 %r<25>;
.reg .b64 %rd<44>;


mov.u64 %rd43, __local_depot130;
cvta.local.u64 %SP, %rd43;
ld.param.u32 %r10, [_Z29THCudaTensor_scatterAddKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r11, [_Z29THCudaTensor_scatterAddKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjfLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd3, %rd11;
mov.u32 %r23, 0;
mov.pred %p1, 0;
@%p1 bra BB130_2;

BB130_1:
mul.wide.s32 %rd12, %r23, 8;
add.s64 %rd13, %rd4, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd3, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r23, %r23, 1;
setp.lt.u32	%p2, %r23, 27;
@%p2 bra BB130_1;

BB130_2:
mov.u32 %r13, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r24, %r13, %r14, %r15;
setp.ge.u32	%p3, %r24, %r11;
@%p3 bra BB130_10;

ld.param.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd6, %rd16;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd17, [%rd2];
cvta.to.global.u64 %rd7, %rd17;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB130_4:
rem.u32 %r8, %r24, %r5;
setp.eq.s32	%p4, %r10, 0;
mov.u64 %rd42, 0;
@%p4 bra BB130_6;

ld.local.u32 %r16, [%rd3+108];
mul.lo.s32 %r17, %r16, %r8;
cvt.u64.u32	%rd42, %r17;

BB130_6:
mul.lo.s32 %r18, %r6, %r8;
mul.wide.u32 %rd19, %r18, 8;
add.s64 %rd20, %rd7, %rd19;
ld.global.u64 %rd10, [%rd20];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB130_8;

mul.wide.s32 %rd21, %r10, 4;
add.s64 %rd22, %rd3, %rd21;
ld.local.u32 %rd23, [%rd22+8];
setp.lt.s64	%p6, %rd10, %rd23;
@%p6 bra BB130_9;

BB130_8:
mov.u64 %rd24, $str2;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, $str1;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, __T2156;
cvta.global.u64 %rd29, %rd28;
mov.u32 %r19, 151;
mov.u64 %rd30, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd25;
.param .b64 param1;
st.param.b64	[param1+0], %rd27;
.param .b32 param2;
st.param.b32	[param2+0], %r19;
.param .b64 param3;
st.param.b64	[param3+0], %rd29;
.param .b64 param4;
st.param.b64	[param4+0], %rd30;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB130_9:
mul.lo.s32 %r20, %r4, %r8;
mul.wide.s32 %rd31, %r10, 4;
add.s64 %rd32, %rd3, %rd31;
ld.local.u32 %rd33, [%rd32+108];
mul.lo.s64 %rd34, %rd33, %rd10;
add.s64 %rd35, %rd34, %rd42;
and.b64 %rd36, %rd35, 4294967295;
ld.local.u64 %rd37, [%rd3];
shl.b64 %rd38, %rd36, 2;
add.s64 %rd39, %rd37, %rd38;
mul.wide.u32 %rd40, %r20, 4;
add.s64 %rd41, %rd6, %rd40;
ld.global.f32 %f1, [%rd41];
atom.add.f32 %f2, [%rd39], %f1;
mov.u32 %r22, %nctaid.x;
mad.lo.s32 %r24, %r22, %r13, %r24;
setp.lt.u32	%p7, %r24, %r11;
@%p7 bra BB130_4;

BB130_10:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot131[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .f32 %f<3>;
.reg .b32 %r<40>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot131;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r19, [_Z29THCudaTensor_scatterAddKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r20, [_Z29THCudaTensor_scatterAddKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjfLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r37, 0;
mov.pred %p1, 0;
@%p1 bra BB131_2;

BB131_1:
mul.wide.s32 %rd10, %r37, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r37, %r37, 1;
setp.lt.u32	%p2, %r37, 27;
@%p2 bra BB131_1;

BB131_2:
mov.u32 %r22, %ntid.x;
mov.u32 %r23, %ctaid.x;
mov.u32 %r24, %tid.x;
mad.lo.s32 %r38, %r22, %r23, %r24;
setp.ge.u32	%p3, %r38, %r20;
@%p3 bra BB131_12;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r25, %r26}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB131_4:
rem.u32 %r11, %r38, %r26;
setp.eq.s32	%p4, %r19, 1;
mov.u32 %r39, 0;
@%p4 bra BB131_6;

ld.local.u32 %r28, [%rd3+112];
mul.lo.s32 %r39, %r28, %r11;

BB131_6:
div.u32 %r29, %r38, %r26;
rem.u32 %r14, %r29, %r25;
setp.eq.s32	%p5, %r19, 0;
@%p5 bra BB131_8;

ld.local.u32 %r30, [%rd3+108];
mad.lo.s32 %r39, %r30, %r14, %r39;

BB131_8:
mul.lo.s32 %r31, %r9, %r11;
mul.lo.s32 %r32, %r5, %r11;
mad.lo.s32 %r33, %r8, %r14, %r31;
mad.lo.s32 %r17, %r4, %r14, %r32;
mul.wide.u32 %rd16, %r33, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB131_10;

mul.wide.s32 %rd18, %r19, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p7, %rd8, %rd20;
@%p7 bra BB131_11;

BB131_10:
mov.u64 %rd21, $str2;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T2157;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r34, 151;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r34;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB131_11:
mul.wide.s32 %rd28, %r19, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r39;
add.s64 %rd33, %rd31, %rd32;
and.b64 %rd34, %rd33, 4294967295;
ld.local.u64 %rd35, [%rd3];
shl.b64 %rd36, %rd34, 2;
add.s64 %rd37, %rd35, %rd36;
mul.wide.u32 %rd38, %r17, 4;
add.s64 %rd39, %rd6, %rd38;
ld.global.f32 %f1, [%rd39];
atom.add.f32 %f2, [%rd37], %f1;
mov.u32 %r36, %nctaid.x;
mad.lo.s32 %r38, %r36, %r22, %r38;
setp.lt.u32	%p8, %r38, %r20;
@%p8 bra BB131_4;

BB131_12:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot132[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .f32 %f<3>;
.reg .b32 %r<54>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot132;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r26, [_Z29THCudaTensor_scatterAddKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r27, [_Z29THCudaTensor_scatterAddKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjfLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r51, 0;
mov.pred %p1, 0;
@%p1 bra BB132_2;

BB132_1:
mul.wide.s32 %rd10, %r51, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p2, %r51, 27;
@%p2 bra BB132_1;

BB132_2:
mov.u32 %r29, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r52, %r29, %r30, %r31;
setp.ge.u32	%p3, %r52, %r27;
@%p3 bra BB132_14;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r32, %r33}, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r34, %r35}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r36, %r37}, [%rd2+112];

BB132_4:
rem.u32 %r14, %r52, %r9;
setp.eq.s32	%p4, %r26, 2;
mov.u32 %r53, 0;
@%p4 bra BB132_6;

ld.local.u32 %r39, [%rd3+116];
mul.lo.s32 %r53, %r39, %r14;

BB132_6:
div.u32 %r17, %r52, %r9;
rem.u32 %r18, %r17, %r35;
setp.eq.s32	%p5, %r26, 1;
@%p5 bra BB132_8;

ld.local.u32 %r40, [%rd3+112];
mad.lo.s32 %r53, %r40, %r18, %r53;

BB132_8:
div.u32 %r41, %r17, %r35;
rem.u32 %r21, %r41, %r34;
setp.eq.s32	%p6, %r26, 0;
@%p6 bra BB132_10;

ld.local.u32 %r42, [%rd3+108];
mad.lo.s32 %r53, %r42, %r21, %r53;

BB132_10:
mul.lo.s32 %r43, %r37, %r14;
mul.lo.s32 %r44, %r33, %r14;
mad.lo.s32 %r45, %r36, %r18, %r43;
mad.lo.s32 %r46, %r32, %r18, %r44;
mad.lo.s32 %r47, %r10, %r21, %r45;
mad.lo.s32 %r24, %r4, %r21, %r46;
mul.wide.u32 %rd16, %r47, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB132_12;

mul.wide.s32 %rd18, %r26, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p8, %rd8, %rd20;
@%p8 bra BB132_13;

BB132_12:
mov.u64 %rd21, $str2;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T2158;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r48, 151;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r48;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB132_13:
mul.wide.s32 %rd28, %r26, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r53;
add.s64 %rd33, %rd31, %rd32;
and.b64 %rd34, %rd33, 4294967295;
ld.local.u64 %rd35, [%rd3];
shl.b64 %rd36, %rd34, 2;
add.s64 %rd37, %rd35, %rd36;
mul.wide.u32 %rd38, %r24, 4;
add.s64 %rd39, %rd6, %rd38;
ld.global.f32 %f1, [%rd39];
atom.add.f32 %f2, [%rd37], %f1;
mov.u32 %r50, %nctaid.x;
mad.lo.s32 %r52, %r50, %r29, %r52;
setp.lt.u32	%p9, %r52, %r27;
@%p9 bra BB132_4;

BB132_14:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot133[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .f32 %f<3>;
.reg .b32 %r<63>;
.reg .b64 %rd<70>;


mov.u64 %rd69, __local_depot133;
cvta.local.u64 %SP, %rd69;
ld.param.u32 %r28, [_Z29THCudaTensor_scatterAddKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r29, [_Z29THCudaTensor_scatterAddKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z29THCudaTensor_scatterAddKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd20, %SP, 216;
cvta.to.local.u64 %rd3, %rd20;
add.u64 %rd21, %SP, 432;
cvta.to.local.u64 %rd4, %rd21;
add.u64 %rd22, %SP, 0;
cvta.to.local.u64 %rd5, %rd22;
mov.u32 %r47, 0;
mov.pred %p1, 0;
@%p1 bra BB133_2;

BB133_1:
mul.wide.s32 %rd23, %r47, 8;
add.s64 %rd24, %rd6, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r47, %r47, 1;
setp.lt.u32	%p2, %r47, 27;
@%p2 bra BB133_1;

BB133_2:
mov.u32 %r48, 0;
@%p1 bra BB133_4;

BB133_3:
mul.wide.s32 %rd27, %r48, 8;
add.s64 %rd28, %rd1, %rd27;
ld.param.u64 %rd29, [%rd28];
add.s64 %rd30, %rd4, %rd27;
st.local.u64 [%rd30], %rd29;
add.s32 %r48, %r48, 1;
setp.lt.u32	%p4, %r48, 27;
@%p4 bra BB133_3;

BB133_4:
mov.u32 %r49, 0;
@%p1 bra BB133_6;

BB133_5:
mul.wide.s32 %rd31, %r49, 8;
add.s64 %rd32, %rd2, %rd31;
ld.param.u64 %rd33, [%rd32];
add.s64 %rd34, %rd5, %rd31;
st.local.u64 [%rd34], %rd33;
add.s32 %r49, %r49, 1;
setp.lt.u32	%p6, %r49, 27;
@%p6 bra BB133_5;

BB133_6:
mov.u32 %r33, %ntid.x;
mov.u32 %r34, %ctaid.x;
mov.u32 %r35, %tid.x;
mad.lo.s32 %r54, %r33, %r34, %r35;
setp.ge.u32	%p7, %r54, %r29;
@%p7 bra BB133_17;

ld.local.u32 %r8, [%rd5+208];

BB133_8:
mov.u32 %r52, %r54;
mov.u32 %r9, %r52;
mul.wide.s32 %rd66, %r8, 4;
add.s32 %r40, %r8, -1;
sub.s32 %r50, %r40, %r28;
mov.u32 %r60, 0;
mov.u64 %rd68, 0;
mov.u64 %rd67, %rd68;
mov.u32 %r61, %r60;
mov.u32 %r56, %r60;
mov.u32 %r55, %r60;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r51, %r8;
mov.u32 %r53, %r9;
@%p8 bra BB133_13;

BB133_9:
mov.u32 %r57, %r61;
mov.u32 %r62, %r57;
mov.u32 %r13, %r53;
mov.u32 %r12, %r51;
add.s64 %rd37, %rd4, %rd66;
add.s32 %r17, %r12, -1;
add.s64 %rd38, %rd5, %rd66;
ld.local.u32 %r18, [%rd38+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r41, [%rd38+104];
mad.lo.s32 %r55, %r41, %r19, %r55;
ld.local.u32 %r42, [%rd37+104];
mad.lo.s32 %r56, %r42, %r19, %r56;
setp.eq.s32	%p9, %r50, 0;
@%p9 bra BB133_11;

add.s64 %rd39, %rd3, %rd66;
ld.local.u32 %r43, [%rd39+104];
mad.lo.s32 %r62, %r43, %r19, %r62;

BB133_11:
mov.u32 %r61, %r62;
div.u32 %r24, %r13, %r18;
add.s32 %r50, %r50, -1;
add.s64 %rd66, %rd66, -4;
setp.gt.s32	%p10, %r17, 0;
mov.u32 %r51, %r17;
mov.u32 %r53, %r24;
@%p10 bra BB133_9;

cvt.u64.u32	%rd67, %r55;
cvt.u64.u32	%rd68, %r56;
mov.u32 %r60, %r61;

BB133_13:
ld.local.u64 %rd40, [%rd5];
shl.b64 %rd41, %rd67, 3;
add.s64 %rd42, %rd40, %rd41;
ld.u64 %rd19, [%rd42];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB133_15;

mul.wide.s32 %rd43, %r28, 4;
add.s64 %rd44, %rd3, %rd43;
ld.local.u32 %rd45, [%rd44+8];
setp.lt.s64	%p12, %rd19, %rd45;
@%p12 bra BB133_16;

BB133_15:
mov.u64 %rd46, $str2;
cvta.global.u64 %rd47, %rd46;
mov.u64 %rd48, $str1;
cvta.global.u64 %rd49, %rd48;
mov.u64 %rd50, __T2159;
cvta.global.u64 %rd51, %rd50;
mov.u32 %r44, 151;
mov.u64 %rd52, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd47;
.param .b64 param1;
st.param.b64	[param1+0], %rd49;
.param .b32 param2;
st.param.b32	[param2+0], %r44;
.param .b64 param3;
st.param.b64	[param3+0], %rd51;
.param .b64 param4;
st.param.b64	[param4+0], %rd52;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB133_16:
mul.wide.s32 %rd53, %r28, 4;
add.s64 %rd54, %rd3, %rd53;
ld.local.u32 %rd55, [%rd54+108];
mul.lo.s64 %rd56, %rd55, %rd19;
cvt.u64.u32	%rd57, %r60;
add.s64 %rd58, %rd56, %rd57;
ld.local.u64 %rd59, [%rd3];
shl.b64 %rd60, %rd58, 2;
and.b64 %rd61, %rd60, 17179869180;
add.s64 %rd62, %rd59, %rd61;
ld.local.u64 %rd63, [%rd4];
shl.b64 %rd64, %rd68, 2;
add.s64 %rd65, %rd63, %rd64;
ld.f32 %f1, [%rd65];
atom.add.f32 %f2, [%rd62], %f1;
mov.u32 %r46, %nctaid.x;
mad.lo.s32 %r54, %r46, %r33, %r9;
setp.lt.u32	%p13, %r54, %r29;
@%p13 bra BB133_8;

BB133_17:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[416],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[416],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[416],
.param .u32 _Z29THCudaTensor_scatterAddKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u64 _Z29THCudaTensor_scatterAddKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot134[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<16>;
.reg .f32 %f<3>;
.reg .b32 %r<37>;
.reg .b64 %rd<117>;


mov.u64 %rd116, __local_depot134;
cvta.local.u64 %SP, %rd116;
ld.param.u32 %r13, [_Z29THCudaTensor_scatterAddKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u64 %rd38, [_Z29THCudaTensor_scatterAddKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z29THCudaTensor_scatterAddKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelImfLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd39, %SP, 416;
cvta.to.local.u64 %rd3, %rd39;
add.u64 %rd40, %SP, 832;
cvta.to.local.u64 %rd4, %rd40;
add.u64 %rd41, %SP, 0;
cvta.to.local.u64 %rd5, %rd41;
mov.u32 %r32, 0;
mov.pred %p1, 0;
@%p1 bra BB134_2;

BB134_1:
mul.wide.s32 %rd42, %r32, 8;
add.s64 %rd43, %rd6, %rd42;
ld.param.u64 %rd44, [%rd43];
add.s64 %rd45, %rd3, %rd42;
st.local.u64 [%rd45], %rd44;
add.s32 %r32, %r32, 1;
setp.lt.u32	%p2, %r32, 52;
@%p2 bra BB134_1;

BB134_2:
mov.u32 %r33, 0;
@%p1 bra BB134_4;

BB134_3:
mul.wide.s32 %rd46, %r33, 8;
add.s64 %rd47, %rd1, %rd46;
ld.param.u64 %rd48, [%rd47];
add.s64 %rd49, %rd4, %rd46;
st.local.u64 [%rd49], %rd48;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p4, %r33, 52;
@%p4 bra BB134_3;

BB134_4:
mov.u32 %r34, 0;
@%p1 bra BB134_6;

BB134_5:
mul.wide.s32 %rd50, %r34, 8;
add.s64 %rd51, %rd2, %rd50;
ld.param.u64 %rd52, [%rd51];
add.s64 %rd53, %rd5, %rd50;
st.local.u64 [%rd53], %rd52;
add.s32 %r34, %r34, 1;
setp.lt.u32	%p6, %r34, 52;
@%p6 bra BB134_5;

BB134_6:
mov.u32 %r17, %ntid.x;
mov.u32 %r18, %ctaid.x;
mov.u32 %r19, %tid.x;
mad.lo.s32 %r20, %r17, %r18, %r19;
cvt.u64.u32	%rd102, %r20;
setp.ge.u64	%p7, %rd102, %rd38;
@%p7 bra BB134_22;

ld.local.u32 %r7, [%rd5+408];

BB134_8:
mov.u64 %rd98, %rd102;
mov.u64 %rd13, %rd98;
mul.wide.s32 %rd97, %r7, 8;
add.s32 %r21, %r7, -1;
sub.s32 %r35, %r21, %r13;
mov.u64 %rd113, 0;
mov.u64 %rd108, %rd113;
mov.u64 %rd105, %rd113;
mov.u64 %rd114, %rd113;
mov.u64 %rd109, %rd113;
mov.u64 %rd106, %rd113;
setp.lt.s32	%p8, %r7, 1;
mov.u32 %r36, %r7;
mov.u64 %rd100, %rd13;
@%p8 bra BB134_18;

BB134_9:
mov.u64 %rd115, %rd114;
mov.u64 %rd16, %rd100;
mov.u32 %r10, %r36;
add.s32 %r11, %r10, -1;
add.s64 %rd20, %rd5, %rd97;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd60, %rd16, %rd21;
and.b64 %rd61, %rd60, -4294967296;
setp.eq.s64	%p9, %rd61, 0;
@%p9 bra BB134_11;
bra.uni BB134_10;

BB134_11:
cvt.u32.u64	%r22, %rd21;
cvt.u32.u64	%r23, %rd16;
rem.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd103, %r24;
bra.uni BB134_12;

BB134_10:
rem.u64 %rd103, %rd16, %rd21;

BB134_12:
add.s64 %rd62, %rd4, %rd97;
ld.local.u64 %rd63, [%rd20+200];
mul.lo.s64 %rd64, %rd63, %rd103;
add.s64 %rd106, %rd64, %rd106;
ld.local.u64 %rd65, [%rd62+200];
mul.lo.s64 %rd66, %rd65, %rd103;
add.s64 %rd109, %rd66, %rd109;
setp.eq.s32	%p10, %r35, 0;
@%p10 bra BB134_14;

add.s64 %rd67, %rd3, %rd97;
ld.local.u64 %rd68, [%rd67+200];
mul.lo.s64 %rd69, %rd68, %rd103;
add.s64 %rd115, %rd69, %rd115;

BB134_14:
mov.u64 %rd114, %rd115;
@%p9 bra BB134_16;
bra.uni BB134_15;

BB134_16:
cvt.u32.u64	%r25, %rd21;
cvt.u32.u64	%r26, %rd16;
div.u32 %r27, %r26, %r25;
cvt.u64.u32	%rd101, %r27;
bra.uni BB134_17;

BB134_15:
div.u64 %rd101, %rd16, %rd21;

BB134_17:
mov.u64 %rd31, %rd101;
add.s32 %r35, %r35, -1;
add.s64 %rd97, %rd97, -8;
setp.gt.s32	%p12, %r11, 0;
mov.u32 %r36, %r11;
mov.u64 %rd100, %rd31;
mov.u64 %rd105, %rd106;
mov.u64 %rd108, %rd109;
mov.u64 %rd113, %rd114;
@%p12 bra BB134_9;

BB134_18:
ld.local.u64 %rd72, [%rd5];
shl.b64 %rd73, %rd105, 3;
add.s64 %rd74, %rd72, %rd73;
ld.u64 %rd36, [%rd74];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB134_20;

mul.wide.s32 %rd75, %r13, 8;
add.s64 %rd76, %rd3, %rd75;
ld.local.u64 %rd77, [%rd76+8];
setp.lt.u64	%p14, %rd36, %rd77;
@%p14 bra BB134_21;

BB134_20:
mov.u64 %rd78, $str2;
cvta.global.u64 %rd79, %rd78;
mov.u64 %rd80, $str1;
cvta.global.u64 %rd81, %rd80;
mov.u64 %rd82, __T2160;
cvta.global.u64 %rd83, %rd82;
mov.u32 %r28, 151;
mov.u64 %rd84, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd79;
.param .b64 param1;
st.param.b64	[param1+0], %rd81;
.param .b32 param2;
st.param.b32	[param2+0], %r28;
.param .b64 param3;
st.param.b64	[param3+0], %rd83;
.param .b64 param4;
st.param.b64	[param4+0], %rd84;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB134_21:
mul.wide.s32 %rd85, %r13, 8;
add.s64 %rd86, %rd3, %rd85;
ld.local.u64 %rd87, [%rd86+208];
mul.lo.s64 %rd88, %rd87, %rd36;
add.s64 %rd89, %rd88, %rd113;
ld.local.u64 %rd90, [%rd3];
shl.b64 %rd91, %rd89, 2;
add.s64 %rd92, %rd90, %rd91;
ld.local.u64 %rd93, [%rd4];
shl.b64 %rd94, %rd108, 2;
add.s64 %rd95, %rd93, %rd94;
ld.f32 %f1, [%rd95];
atom.add.f32 %f2, [%rd92], %f1;
mov.u32 %r30, %nctaid.x;
mul.lo.s32 %r31, %r30, %r17;
cvt.u64.u32	%rd96, %r31;
add.s64 %rd102, %rd96, %rd13;
setp.lt.u64	%p15, %rd102, %rd38;
@%p15 bra BB134_8;

BB134_22:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjfLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjfLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjfLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .f32 _Z30THCudaTensor_scatterFillKernelIjfLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjfLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjfLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot135[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .f32 %f<2>;
.reg .b32 %r<23>;
.reg .b64 %rd<38>;


mov.u64 %rd37, __local_depot135;
cvta.local.u64 %SP, %rd37;
ld.param.f32 %f1, [_Z30THCudaTensor_scatterFillKernelIjfLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r11, [_Z30THCudaTensor_scatterFillKernelIjfLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r12, [_Z30THCudaTensor_scatterFillKernelIjfLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjfLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjfLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd2, %rd10;
mov.u32 %r21, 0;
mov.pred %p1, 0;
@%p1 bra BB135_2;

BB135_1:
mul.wide.s32 %rd11, %r21, 8;
add.s64 %rd12, %rd3, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd2, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r21, %r21, 1;
setp.lt.u32	%p2, %r21, 27;
@%p2 bra BB135_1;

BB135_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r22, %r3, %r14, %r15;
setp.ge.u32	%p3, %r22, %r12;
@%p3 bra BB135_10;

ld.param.u64 %rd15, [%rd1];
cvta.to.global.u64 %rd5, %rd15;
ld.param.u32 %r5, [%rd1+8];
ld.param.u32 %r6, [%rd1+108];
mul.wide.s32 %rd16, %r11, 4;
add.s64 %rd17, %rd2, %rd16;
add.s64 %rd6, %rd17, 8;
mov.u32 %r16, %nctaid.x;
mul.lo.s32 %r7, %r16, %r3;

BB135_4:
rem.u32 %r9, %r22, %r5;
setp.eq.s32	%p4, %r11, 0;
mov.u64 %rd36, 0;
@%p4 bra BB135_6;

ld.local.u32 %r17, [%rd2+108];
mul.lo.s32 %r18, %r17, %r9;
cvt.u64.u32	%rd36, %r18;

BB135_6:
mul.lo.s32 %r19, %r6, %r9;
mul.wide.u32 %rd19, %r19, 8;
add.s64 %rd20, %rd5, %rd19;
ld.global.u64 %rd9, [%rd20];
setp.lt.s64	%p5, %rd9, 0;
@%p5 bra BB135_8;

ld.local.u32 %rd21, [%rd6];
setp.lt.s64	%p6, %rd9, %rd21;
@%p6 bra BB135_9;

BB135_8:
mov.u64 %rd22, $str2;
cvta.global.u64 %rd23, %rd22;
mov.u64 %rd24, $str1;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, __T2161;
cvta.global.u64 %rd27, %rd26;
mov.u32 %r20, 176;
mov.u64 %rd28, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd23;
.param .b64 param1;
st.param.b64	[param1+0], %rd25;
.param .b32 param2;
st.param.b32	[param2+0], %r20;
.param .b64 param3;
st.param.b64	[param3+0], %rd27;
.param .b64 param4;
st.param.b64	[param4+0], %rd28;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB135_9:
ld.local.u32 %rd29, [%rd6+100];
mul.lo.s64 %rd30, %rd29, %rd9;
add.s64 %rd31, %rd30, %rd36;
and.b64 %rd32, %rd31, 4294967295;
ld.local.u64 %rd33, [%rd2];
shl.b64 %rd34, %rd32, 2;
add.s64 %rd35, %rd33, %rd34;
st.f32 [%rd35], %f1;
add.s32 %r22, %r7, %r22;
setp.lt.u32	%p7, %r22, %r12;
@%p7 bra BB135_4;

BB135_10:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjfLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjfLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjfLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .f32 _Z30THCudaTensor_scatterFillKernelIjfLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjfLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjfLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot136[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .f32 %f<2>;
.reg .b32 %r<36>;
.reg .b64 %rd<36>;


mov.u64 %rd35, __local_depot136;
cvta.local.u64 %SP, %rd35;
ld.param.f32 %f1, [_Z30THCudaTensor_scatterFillKernelIjfLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r16, [_Z30THCudaTensor_scatterFillKernelIjfLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r17, [_Z30THCudaTensor_scatterFillKernelIjfLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjfLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjfLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd7, %SP, 0;
cvta.to.local.u64 %rd2, %rd7;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB136_2;

BB136_1:
mul.wide.s32 %rd8, %r33, 8;
add.s64 %rd9, %rd3, %rd8;
ld.param.u64 %rd10, [%rd9];
add.s64 %rd11, %rd2, %rd8;
st.local.u64 [%rd11], %rd10;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB136_1;

BB136_2:
mov.u32 %r19, %ntid.x;
mov.u32 %r20, %ctaid.x;
mov.u32 %r21, %tid.x;
mad.lo.s32 %r34, %r19, %r20, %r21;
setp.ge.u32	%p3, %r34, %r17;
@%p3 bra BB136_12;

ld.param.u64 %rd12, [%rd1];
cvta.to.global.u64 %rd5, %rd12;
ld.param.v2.u32 {%r22, %r23}, [%rd1+8];
ld.param.u32 %r6, [%rd1+108];
ld.param.u32 %r7, [%rd1+112];

BB136_4:
rem.u32 %r9, %r34, %r23;
setp.eq.s32	%p4, %r16, 1;
mov.u32 %r35, 0;
@%p4 bra BB136_6;

ld.local.u32 %r25, [%rd2+112];
mul.lo.s32 %r35, %r25, %r9;

BB136_6:
div.u32 %r26, %r34, %r23;
rem.u32 %r12, %r26, %r22;
setp.eq.s32	%p5, %r16, 0;
@%p5 bra BB136_8;

ld.local.u32 %r27, [%rd2+108];
mad.lo.s32 %r35, %r27, %r12, %r35;

BB136_8:
mul.lo.s32 %r28, %r7, %r9;
mad.lo.s32 %r29, %r6, %r12, %r28;
mul.wide.u32 %rd13, %r29, 8;
add.s64 %rd14, %rd5, %rd13;
ld.global.u64 %rd6, [%rd14];
setp.lt.s64	%p6, %rd6, 0;
@%p6 bra BB136_10;

mul.wide.s32 %rd15, %r16, 4;
add.s64 %rd16, %rd2, %rd15;
ld.local.u32 %rd17, [%rd16+8];
setp.lt.s64	%p7, %rd6, %rd17;
@%p7 bra BB136_11;

BB136_10:
mov.u64 %rd18, $str2;
cvta.global.u64 %rd19, %rd18;
mov.u64 %rd20, $str1;
cvta.global.u64 %rd21, %rd20;
mov.u64 %rd22, __T2162;
cvta.global.u64 %rd23, %rd22;
mov.u32 %r30, 176;
mov.u64 %rd24, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd19;
.param .b64 param1;
st.param.b64	[param1+0], %rd21;
.param .b32 param2;
st.param.b32	[param2+0], %r30;
.param .b64 param3;
st.param.b64	[param3+0], %rd23;
.param .b64 param4;
st.param.b64	[param4+0], %rd24;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB136_11:
mul.wide.s32 %rd25, %r16, 4;
add.s64 %rd26, %rd2, %rd25;
ld.local.u32 %rd27, [%rd26+108];
mul.lo.s64 %rd28, %rd27, %rd6;
cvt.u64.u32	%rd29, %r35;
add.s64 %rd30, %rd28, %rd29;
and.b64 %rd31, %rd30, 4294967295;
ld.local.u64 %rd32, [%rd2];
shl.b64 %rd33, %rd31, 2;
add.s64 %rd34, %rd32, %rd33;
st.f32 [%rd34], %f1;
mov.u32 %r32, %nctaid.x;
mad.lo.s32 %r34, %r32, %r19, %r34;
setp.lt.u32	%p8, %r34, %r17;
@%p8 bra BB136_4;

BB136_12:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjfLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjfLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjfLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .f32 _Z30THCudaTensor_scatterFillKernelIjfLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjfLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjfLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot137[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .f32 %f<2>;
.reg .b32 %r<46>;
.reg .b64 %rd<36>;


mov.u64 %rd35, __local_depot137;
cvta.local.u64 %SP, %rd35;
ld.param.f32 %f1, [_Z30THCudaTensor_scatterFillKernelIjfLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r23, [_Z30THCudaTensor_scatterFillKernelIjfLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r24, [_Z30THCudaTensor_scatterFillKernelIjfLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjfLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjfLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd7, %SP, 0;
cvta.to.local.u64 %rd2, %rd7;
mov.u32 %r43, 0;
mov.pred %p1, 0;
@%p1 bra BB137_2;

BB137_1:
mul.wide.s32 %rd8, %r43, 8;
add.s64 %rd9, %rd3, %rd8;
ld.param.u64 %rd10, [%rd9];
add.s64 %rd11, %rd2, %rd8;
st.local.u64 [%rd11], %rd10;
add.s32 %r43, %r43, 1;
setp.lt.u32	%p2, %r43, 27;
@%p2 bra BB137_1;

BB137_2:
mov.u32 %r26, %ntid.x;
mov.u32 %r27, %ctaid.x;
mov.u32 %r28, %tid.x;
mad.lo.s32 %r44, %r26, %r27, %r28;
setp.ge.u32	%p3, %r44, %r24;
@%p3 bra BB137_14;

ld.param.u64 %rd12, [%rd1];
cvta.to.global.u64 %rd5, %rd12;
ld.param.v2.u32 {%r29, %r30}, [%rd1+8];
ld.param.u32 %r6, [%rd1+16];
ld.param.u32 %r7, [%rd1+108];
ld.param.v2.u32 {%r31, %r32}, [%rd1+112];

BB137_4:
rem.u32 %r11, %r44, %r6;
setp.eq.s32	%p4, %r23, 2;
mov.u32 %r45, 0;
@%p4 bra BB137_6;

ld.local.u32 %r34, [%rd2+116];
mul.lo.s32 %r45, %r34, %r11;

BB137_6:
div.u32 %r14, %r44, %r6;
rem.u32 %r15, %r14, %r30;
setp.eq.s32	%p5, %r23, 1;
@%p5 bra BB137_8;

ld.local.u32 %r35, [%rd2+112];
mad.lo.s32 %r45, %r35, %r15, %r45;

BB137_8:
mul.lo.s32 %r36, %r32, %r11;
mad.lo.s32 %r18, %r31, %r15, %r36;
div.u32 %r37, %r14, %r30;
rem.u32 %r19, %r37, %r29;
setp.eq.s32	%p6, %r23, 0;
@%p6 bra BB137_10;

ld.local.u32 %r38, [%rd2+108];
mad.lo.s32 %r45, %r38, %r19, %r45;

BB137_10:
mad.lo.s32 %r39, %r7, %r19, %r18;
mul.wide.u32 %rd13, %r39, 8;
add.s64 %rd14, %rd5, %rd13;
ld.global.u64 %rd6, [%rd14];
setp.lt.s64	%p7, %rd6, 0;
@%p7 bra BB137_12;

mul.wide.s32 %rd15, %r23, 4;
add.s64 %rd16, %rd2, %rd15;
ld.local.u32 %rd17, [%rd16+8];
setp.lt.s64	%p8, %rd6, %rd17;
@%p8 bra BB137_13;

BB137_12:
mov.u64 %rd18, $str2;
cvta.global.u64 %rd19, %rd18;
mov.u64 %rd20, $str1;
cvta.global.u64 %rd21, %rd20;
mov.u64 %rd22, __T2163;
cvta.global.u64 %rd23, %rd22;
mov.u32 %r40, 176;
mov.u64 %rd24, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd19;
.param .b64 param1;
st.param.b64	[param1+0], %rd21;
.param .b32 param2;
st.param.b32	[param2+0], %r40;
.param .b64 param3;
st.param.b64	[param3+0], %rd23;
.param .b64 param4;
st.param.b64	[param4+0], %rd24;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB137_13:
mul.wide.s32 %rd25, %r23, 4;
add.s64 %rd26, %rd2, %rd25;
ld.local.u32 %rd27, [%rd26+108];
mul.lo.s64 %rd28, %rd27, %rd6;
cvt.u64.u32	%rd29, %r45;
add.s64 %rd30, %rd28, %rd29;
and.b64 %rd31, %rd30, 4294967295;
ld.local.u64 %rd32, [%rd2];
shl.b64 %rd33, %rd31, 2;
add.s64 %rd34, %rd32, %rd33;
st.f32 [%rd34], %f1;
mov.u32 %r42, %nctaid.x;
mad.lo.s32 %r44, %r42, %r26, %r44;
setp.lt.u32	%p9, %r44, %r24;
@%p9 bra BB137_4;

BB137_14:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjfLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjfLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjfLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .f32 _Z30THCudaTensor_scatterFillKernelIjfLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjfLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjfLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot138[432];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<12>;
.reg .f32 %f<2>;
.reg .b32 %r<54>;
.reg .b64 %rd<63>;


mov.u64 %rd62, __local_depot138;
cvta.local.u64 %SP, %rd62;
ld.param.f32 %f1, [_Z30THCudaTensor_scatterFillKernelIjfLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r24, [_Z30THCudaTensor_scatterFillKernelIjfLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r25, [_Z30THCudaTensor_scatterFillKernelIjfLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd4, _Z30THCudaTensor_scatterFillKernelIjfLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjfLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd17, %SP, 216;
cvta.to.local.u64 %rd2, %rd17;
add.u64 %rd18, %SP, 0;
cvta.to.local.u64 %rd3, %rd18;
mov.u32 %r40, 0;
mov.pred %p1, 0;
@%p1 bra BB138_2;

BB138_1:
mul.wide.s32 %rd19, %r40, 8;
add.s64 %rd20, %rd4, %rd19;
ld.param.u64 %rd21, [%rd20];
add.s64 %rd22, %rd2, %rd19;
st.local.u64 [%rd22], %rd21;
add.s32 %r40, %r40, 1;
setp.lt.u32	%p2, %r40, 27;
@%p2 bra BB138_1;

BB138_2:
mov.u32 %r41, 0;
@%p1 bra BB138_4;

BB138_3:
mul.wide.s32 %rd23, %r41, 8;
add.s64 %rd24, %rd1, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r41, %r41, 1;
setp.lt.u32	%p4, %r41, 27;
@%p4 bra BB138_3;

BB138_4:
mov.u32 %r28, %ntid.x;
mov.u32 %r29, %ctaid.x;
mov.u32 %r30, %tid.x;
mad.lo.s32 %r46, %r28, %r29, %r30;
setp.ge.u32	%p5, %r46, %r25;
@%p5 bra BB138_15;

ld.local.u32 %r6, [%rd3+208];

BB138_6:
mov.u32 %r44, %r46;
mov.u32 %r7, %r44;
cvt.s64.s32	%rd28, %r6;
not.b64 %rd29, %rd28;
mov.u64 %rd30, -26;
sub.s64 %rd31, %rd30, %rd28;
add.s32 %r34, %r6, -1;
sub.s32 %r42, %r34, %r24;
neg.s64 %rd59, %rd29;
neg.s64 %rd60, %rd31;
mov.u32 %r51, 0;
mov.u64 %rd61, 0;
mov.u32 %r52, %r51;
mov.u32 %r47, %r51;
setp.lt.s32	%p6, %r6, 1;
mov.u32 %r43, %r6;
mov.u32 %r45, %r7;
@%p6 bra BB138_11;

BB138_7:
mov.u32 %r48, %r52;
mov.u32 %r53, %r48;
mov.u32 %r11, %r45;
mov.u32 %r10, %r43;
add.s32 %r14, %r10, -1;
shl.b64 %rd32, %rd59, 2;
add.s64 %rd33, %rd3, %rd32;
ld.local.u32 %r15, [%rd33];
rem.u32 %r16, %r11, %r15;
ld.local.u32 %r35, [%rd33+100];
mad.lo.s32 %r47, %r35, %r16, %r47;
setp.eq.s32	%p7, %r42, 0;
@%p7 bra BB138_9;

shl.b64 %rd34, %rd60, 2;
add.s64 %rd35, %rd2, %rd34;
ld.local.u32 %r36, [%rd35];
mad.lo.s32 %r53, %r36, %r16, %r53;

BB138_9:
mov.u32 %r52, %r53;
div.u32 %r20, %r11, %r15;
add.s32 %r42, %r42, -1;
add.s64 %rd60, %rd60, -1;
add.s64 %rd59, %rd59, -1;
setp.gt.s32	%p8, %r14, 0;
mov.u32 %r43, %r14;
mov.u32 %r45, %r20;
@%p8 bra BB138_7;

cvt.u64.u32	%rd61, %r47;
mov.u32 %r51, %r52;

BB138_11:
ld.local.u64 %rd36, [%rd3];
shl.b64 %rd37, %rd61, 3;
add.s64 %rd38, %rd36, %rd37;
ld.u64 %rd16, [%rd38];
setp.lt.s64	%p9, %rd16, 0;
@%p9 bra BB138_13;

mul.wide.s32 %rd39, %r24, 4;
add.s64 %rd40, %rd2, %rd39;
ld.local.u32 %rd41, [%rd40+8];
setp.lt.s64	%p10, %rd16, %rd41;
@%p10 bra BB138_14;

BB138_13:
mov.u64 %rd42, $str2;
cvta.global.u64 %rd43, %rd42;
mov.u64 %rd44, $str1;
cvta.global.u64 %rd45, %rd44;
mov.u64 %rd46, __T2164;
cvta.global.u64 %rd47, %rd46;
mov.u32 %r37, 176;
mov.u64 %rd48, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd43;
.param .b64 param1;
st.param.b64	[param1+0], %rd45;
.param .b32 param2;
st.param.b32	[param2+0], %r37;
.param .b64 param3;
st.param.b64	[param3+0], %rd47;
.param .b64 param4;
st.param.b64	[param4+0], %rd48;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB138_14:
mul.wide.s32 %rd49, %r24, 4;
add.s64 %rd50, %rd2, %rd49;
ld.local.u32 %rd51, [%rd50+108];
mul.lo.s64 %rd52, %rd51, %rd16;
cvt.u64.u32	%rd53, %r51;
add.s64 %rd54, %rd52, %rd53;
and.b64 %rd55, %rd54, 4294967295;
ld.local.u64 %rd56, [%rd2];
shl.b64 %rd57, %rd55, 2;
add.s64 %rd58, %rd56, %rd57;
st.f32 [%rd58], %f1;
mov.u32 %r39, %nctaid.x;
mad.lo.s32 %r46, %r39, %r28, %r7;
setp.lt.u32	%p11, %r46, %r25;
@%p11 bra BB138_6;

BB138_15:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelImfLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelImfLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[416],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelImfLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[416],
.param .f32 _Z30THCudaTensor_scatterFillKernelImfLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelImfLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u64 _Z30THCudaTensor_scatterFillKernelImfLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot139[832];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .f32 %f<2>;
.reg .b32 %r<33>;
.reg .b64 %rd<99>;


mov.u64 %rd98, __local_depot139;
cvta.local.u64 %SP, %rd98;
ld.param.f32 %f1, [_Z30THCudaTensor_scatterFillKernelImfLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r11, [_Z30THCudaTensor_scatterFillKernelImfLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u64 %rd34, [_Z30THCudaTensor_scatterFillKernelImfLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd4, _Z30THCudaTensor_scatterFillKernelImfLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelImfLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd35, %SP, 416;
cvta.to.local.u64 %rd2, %rd35;
add.u64 %rd36, %SP, 0;
cvta.to.local.u64 %rd3, %rd36;
mov.u32 %r29, 0;
mov.pred %p1, 0;
@%p1 bra BB139_2;

BB139_1:
mul.wide.s32 %rd37, %r29, 8;
add.s64 %rd38, %rd4, %rd37;
ld.param.u64 %rd39, [%rd38];
add.s64 %rd40, %rd2, %rd37;
st.local.u64 [%rd40], %rd39;
add.s32 %r29, %r29, 1;
setp.lt.u32	%p2, %r29, 52;
@%p2 bra BB139_1;

BB139_2:
mov.u32 %r30, 0;
@%p1 bra BB139_4;

BB139_3:
mul.wide.s32 %rd41, %r30, 8;
add.s64 %rd42, %rd1, %rd41;
ld.param.u64 %rd43, [%rd42];
add.s64 %rd44, %rd3, %rd41;
st.local.u64 [%rd44], %rd43;
add.s32 %r30, %r30, 1;
setp.lt.u32	%p4, %r30, 52;
@%p4 bra BB139_3;

BB139_4:
mov.u32 %r14, %ntid.x;
mov.u32 %r15, %ctaid.x;
mov.u32 %r16, %tid.x;
mad.lo.s32 %r17, %r14, %r15, %r16;
cvt.u64.u32	%rd87, %r17;
setp.ge.u64	%p5, %rd87, %rd34;
@%p5 bra BB139_20;

ld.local.u32 %r5, [%rd3+408];

BB139_6:
mov.u64 %rd83, %rd87;
mov.u64 %rd9, %rd83;
mul.wide.s32 %rd49, %r5, 8;
add.s64 %rd81, %rd3, %rd49;
add.s64 %rd50, %rd49, %rd2;
add.s64 %rd82, %rd50, 200;
add.s32 %r18, %r5, -1;
sub.s32 %r31, %r18, %r11;
mov.u64 %rd95, 0;
mov.u64 %rd90, %rd95;
mov.u64 %rd96, %rd95;
mov.u64 %rd91, %rd95;
setp.lt.s32	%p6, %r5, 1;
mov.u32 %r32, %r5;
mov.u64 %rd85, %rd9;
@%p6 bra BB139_16;

BB139_7:
mov.u64 %rd97, %rd96;
mov.u64 %rd14, %rd85;
mov.u32 %r8, %r32;
add.s32 %r9, %r8, -1;
ld.local.u64 %rd18, [%rd81];
or.b64 %rd51, %rd14, %rd18;
and.b64 %rd52, %rd51, -4294967296;
setp.eq.s64	%p7, %rd52, 0;
@%p7 bra BB139_9;
bra.uni BB139_8;

BB139_9:
cvt.u32.u64	%r19, %rd18;
cvt.u32.u64	%r20, %rd14;
rem.u32 %r21, %r20, %r19;
cvt.u64.u32	%rd88, %r21;
bra.uni BB139_10;

BB139_8:
rem.u64 %rd88, %rd14, %rd18;

BB139_10:
ld.local.u64 %rd53, [%rd81+200];
mul.lo.s64 %rd54, %rd53, %rd88;
add.s64 %rd91, %rd54, %rd91;
setp.eq.s32	%p8, %r31, 0;
@%p8 bra BB139_12;

ld.local.u64 %rd55, [%rd82];
mul.lo.s64 %rd56, %rd55, %rd88;
add.s64 %rd97, %rd56, %rd97;

BB139_12:
mov.u64 %rd96, %rd97;
@%p7 bra BB139_14;
bra.uni BB139_13;

BB139_14:
cvt.u32.u64	%r22, %rd18;
cvt.u32.u64	%r23, %rd14;
div.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd86, %r24;
bra.uni BB139_15;

BB139_13:
div.u64 %rd86, %rd14, %rd18;

BB139_15:
mov.u64 %rd27, %rd86;
add.s32 %r31, %r31, -1;
add.s64 %rd82, %rd82, -8;
add.s64 %rd81, %rd81, -8;
setp.gt.s32	%p10, %r9, 0;
mov.u32 %r32, %r9;
mov.u64 %rd85, %rd27;
mov.u64 %rd90, %rd91;
mov.u64 %rd95, %rd96;
@%p10 bra BB139_7;

BB139_16:
ld.local.u64 %rd59, [%rd3];
shl.b64 %rd60, %rd90, 3;
add.s64 %rd61, %rd59, %rd60;
ld.u64 %rd32, [%rd61];
setp.lt.s64	%p11, %rd32, 0;
@%p11 bra BB139_18;

mul.wide.s32 %rd62, %r11, 8;
add.s64 %rd63, %rd2, %rd62;
ld.local.u64 %rd64, [%rd63+8];
setp.lt.u64	%p12, %rd32, %rd64;
@%p12 bra BB139_19;

BB139_18:
mov.u64 %rd65, $str2;
cvta.global.u64 %rd66, %rd65;
mov.u64 %rd67, $str1;
cvta.global.u64 %rd68, %rd67;
mov.u64 %rd69, __T2165;
cvta.global.u64 %rd70, %rd69;
mov.u32 %r25, 176;
mov.u64 %rd71, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd66;
.param .b64 param1;
st.param.b64	[param1+0], %rd68;
.param .b32 param2;
st.param.b32	[param2+0], %r25;
.param .b64 param3;
st.param.b64	[param3+0], %rd70;
.param .b64 param4;
st.param.b64	[param4+0], %rd71;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB139_19:
mul.wide.s32 %rd72, %r11, 8;
add.s64 %rd73, %rd2, %rd72;
ld.local.u64 %rd74, [%rd73+208];
mul.lo.s64 %rd75, %rd74, %rd32;
add.s64 %rd76, %rd75, %rd95;
ld.local.u64 %rd77, [%rd2];
shl.b64 %rd78, %rd76, 2;
add.s64 %rd79, %rd77, %rd78;
st.f32 [%rd79], %f1;
mov.u32 %r27, %nctaid.x;
mul.lo.s32 %r28, %r27, %r14;
cvt.u64.u32	%rd80, %r28;
add.s64 %rd87, %rd80, %rd9;
setp.lt.u64	%p13, %rd87, %rd34;
@%p13 bra BB139_6;

BB139_20:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot140[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b32 %r<25>;
.reg .f64 %fd<2>;
.reg .b64 %rd<44>;


mov.u64 %rd43, __local_depot140;
cvta.local.u64 %SP, %rd43;
ld.param.u32 %r10, [_Z25THCudaTensor_gatherKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r11, [_Z25THCudaTensor_gatherKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd3, %rd11;
mov.u32 %r23, 0;
mov.pred %p1, 0;
@%p1 bra BB140_2;

BB140_1:
mul.wide.s32 %rd12, %r23, 8;
add.s64 %rd13, %rd4, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd3, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r23, %r23, 1;
setp.lt.u32	%p2, %r23, 27;
@%p2 bra BB140_1;

BB140_2:
mov.u32 %r13, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r24, %r13, %r14, %r15;
setp.ge.u32	%p3, %r24, %r11;
@%p3 bra BB140_10;

ld.param.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd6, %rd16;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd17, [%rd2];
cvta.to.global.u64 %rd7, %rd17;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB140_4:
rem.u32 %r8, %r24, %r5;
setp.eq.s32	%p4, %r10, 0;
mov.u64 %rd42, 0;
@%p4 bra BB140_6;

ld.local.u32 %r16, [%rd3+108];
mul.lo.s32 %r17, %r16, %r8;
cvt.u64.u32	%rd42, %r17;

BB140_6:
mul.lo.s32 %r18, %r6, %r8;
mul.wide.u32 %rd19, %r18, 8;
add.s64 %rd20, %rd7, %rd19;
ld.global.u64 %rd10, [%rd20];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB140_8;

mul.wide.s32 %rd21, %r10, 4;
add.s64 %rd22, %rd3, %rd21;
ld.local.u32 %rd23, [%rd22+8];
setp.lt.s64	%p6, %rd10, %rd23;
@%p6 bra BB140_9;

BB140_8:
mov.u64 %rd24, $str;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, $str1;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, __T2168;
cvta.global.u64 %rd29, %rd28;
mov.u32 %r19, 97;
mov.u64 %rd30, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd25;
.param .b64 param1;
st.param.b64	[param1+0], %rd27;
.param .b32 param2;
st.param.b32	[param2+0], %r19;
.param .b64 param3;
st.param.b64	[param3+0], %rd29;
.param .b64 param4;
st.param.b64	[param4+0], %rd30;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB140_9:
mul.lo.s32 %r20, %r4, %r8;
mul.wide.s32 %rd31, %r10, 4;
add.s64 %rd32, %rd3, %rd31;
ld.local.u32 %rd33, [%rd32+108];
mul.lo.s64 %rd34, %rd33, %rd10;
add.s64 %rd35, %rd34, %rd42;
and.b64 %rd36, %rd35, 4294967295;
ld.local.u64 %rd37, [%rd3];
shl.b64 %rd38, %rd36, 3;
add.s64 %rd39, %rd37, %rd38;
ld.f64 %fd1, [%rd39];
mul.wide.u32 %rd40, %r20, 8;
add.s64 %rd41, %rd6, %rd40;
st.global.f64 [%rd41], %fd1;
mov.u32 %r22, %nctaid.x;
mad.lo.s32 %r24, %r22, %r13, %r24;
setp.lt.u32	%p7, %r24, %r11;
@%p7 bra BB140_4;

BB140_10:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot141[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b32 %r<40>;
.reg .f64 %fd<2>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot141;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r19, [_Z25THCudaTensor_gatherKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r20, [_Z25THCudaTensor_gatherKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r37, 0;
mov.pred %p1, 0;
@%p1 bra BB141_2;

BB141_1:
mul.wide.s32 %rd10, %r37, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r37, %r37, 1;
setp.lt.u32	%p2, %r37, 27;
@%p2 bra BB141_1;

BB141_2:
mov.u32 %r22, %ntid.x;
mov.u32 %r23, %ctaid.x;
mov.u32 %r24, %tid.x;
mad.lo.s32 %r38, %r22, %r23, %r24;
setp.ge.u32	%p3, %r38, %r20;
@%p3 bra BB141_12;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r25, %r26}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB141_4:
rem.u32 %r11, %r38, %r26;
setp.eq.s32	%p4, %r19, 1;
mov.u32 %r39, 0;
@%p4 bra BB141_6;

ld.local.u32 %r28, [%rd3+112];
mul.lo.s32 %r39, %r28, %r11;

BB141_6:
div.u32 %r29, %r38, %r26;
rem.u32 %r14, %r29, %r25;
setp.eq.s32	%p5, %r19, 0;
@%p5 bra BB141_8;

ld.local.u32 %r30, [%rd3+108];
mad.lo.s32 %r39, %r30, %r14, %r39;

BB141_8:
mul.lo.s32 %r31, %r9, %r11;
mul.lo.s32 %r32, %r5, %r11;
mad.lo.s32 %r33, %r8, %r14, %r31;
mad.lo.s32 %r17, %r4, %r14, %r32;
mul.wide.u32 %rd16, %r33, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB141_10;

mul.wide.s32 %rd18, %r19, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p7, %rd8, %rd20;
@%p7 bra BB141_11;

BB141_10:
mov.u64 %rd21, $str;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T2169;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r34, 97;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r34;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB141_11:
mul.wide.s32 %rd28, %r19, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r39;
add.s64 %rd33, %rd31, %rd32;
and.b64 %rd34, %rd33, 4294967295;
ld.local.u64 %rd35, [%rd3];
shl.b64 %rd36, %rd34, 3;
add.s64 %rd37, %rd35, %rd36;
ld.f64 %fd1, [%rd37];
mul.wide.u32 %rd38, %r17, 8;
add.s64 %rd39, %rd6, %rd38;
st.global.f64 [%rd39], %fd1;
mov.u32 %r36, %nctaid.x;
mad.lo.s32 %r38, %r36, %r22, %r38;
setp.lt.u32	%p8, %r38, %r20;
@%p8 bra BB141_4;

BB141_12:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot142[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b32 %r<54>;
.reg .f64 %fd<2>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot142;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r26, [_Z25THCudaTensor_gatherKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r27, [_Z25THCudaTensor_gatherKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd4, _Z25THCudaTensor_gatherKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r51, 0;
mov.pred %p1, 0;
@%p1 bra BB142_2;

BB142_1:
mul.wide.s32 %rd10, %r51, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p2, %r51, 27;
@%p2 bra BB142_1;

BB142_2:
mov.u32 %r29, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r52, %r29, %r30, %r31;
setp.ge.u32	%p3, %r52, %r27;
@%p3 bra BB142_14;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r32, %r33}, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r34, %r35}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r36, %r37}, [%rd2+112];

BB142_4:
rem.u32 %r14, %r52, %r9;
setp.eq.s32	%p4, %r26, 2;
mov.u32 %r53, 0;
@%p4 bra BB142_6;

ld.local.u32 %r39, [%rd3+116];
mul.lo.s32 %r53, %r39, %r14;

BB142_6:
div.u32 %r17, %r52, %r9;
rem.u32 %r18, %r17, %r35;
setp.eq.s32	%p5, %r26, 1;
@%p5 bra BB142_8;

ld.local.u32 %r40, [%rd3+112];
mad.lo.s32 %r53, %r40, %r18, %r53;

BB142_8:
div.u32 %r41, %r17, %r35;
rem.u32 %r21, %r41, %r34;
setp.eq.s32	%p6, %r26, 0;
@%p6 bra BB142_10;

ld.local.u32 %r42, [%rd3+108];
mad.lo.s32 %r53, %r42, %r21, %r53;

BB142_10:
mul.lo.s32 %r43, %r37, %r14;
mul.lo.s32 %r44, %r33, %r14;
mad.lo.s32 %r45, %r36, %r18, %r43;
mad.lo.s32 %r46, %r32, %r18, %r44;
mad.lo.s32 %r47, %r10, %r21, %r45;
mad.lo.s32 %r24, %r4, %r21, %r46;
mul.wide.u32 %rd16, %r47, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB142_12;

mul.wide.s32 %rd18, %r26, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p8, %rd8, %rd20;
@%p8 bra BB142_13;

BB142_12:
mov.u64 %rd21, $str;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T2170;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r48, 97;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r48;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB142_13:
mul.wide.s32 %rd28, %r26, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r53;
add.s64 %rd33, %rd31, %rd32;
and.b64 %rd34, %rd33, 4294967295;
ld.local.u64 %rd35, [%rd3];
shl.b64 %rd36, %rd34, 3;
add.s64 %rd37, %rd35, %rd36;
ld.f64 %fd1, [%rd37];
mul.wide.u32 %rd38, %r24, 8;
add.s64 %rd39, %rd6, %rd38;
st.global.f64 [%rd39], %fd1;
mov.u32 %r50, %nctaid.x;
mad.lo.s32 %r52, %r50, %r29, %r52;
setp.lt.u32	%p9, %r52, %r27;
@%p9 bra BB142_4;

BB142_14:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z25THCudaTensor_gatherKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z25THCudaTensor_gatherKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot143[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b32 %r<63>;
.reg .f64 %fd<2>;
.reg .b64 %rd<70>;


mov.u64 %rd69, __local_depot143;
cvta.local.u64 %SP, %rd69;
ld.param.u32 %r28, [_Z25THCudaTensor_gatherKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r29, [_Z25THCudaTensor_gatherKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z25THCudaTensor_gatherKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd20, %SP, 216;
cvta.to.local.u64 %rd3, %rd20;
add.u64 %rd21, %SP, 432;
cvta.to.local.u64 %rd4, %rd21;
add.u64 %rd22, %SP, 0;
cvta.to.local.u64 %rd5, %rd22;
mov.u32 %r47, 0;
mov.pred %p1, 0;
@%p1 bra BB143_2;

BB143_1:
mul.wide.s32 %rd23, %r47, 8;
add.s64 %rd24, %rd6, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r47, %r47, 1;
setp.lt.u32	%p2, %r47, 27;
@%p2 bra BB143_1;

BB143_2:
mov.u32 %r48, 0;
@%p1 bra BB143_4;

BB143_3:
mul.wide.s32 %rd27, %r48, 8;
add.s64 %rd28, %rd1, %rd27;
ld.param.u64 %rd29, [%rd28];
add.s64 %rd30, %rd4, %rd27;
st.local.u64 [%rd30], %rd29;
add.s32 %r48, %r48, 1;
setp.lt.u32	%p4, %r48, 27;
@%p4 bra BB143_3;

BB143_4:
mov.u32 %r49, 0;
@%p1 bra BB143_6;

BB143_5:
mul.wide.s32 %rd31, %r49, 8;
add.s64 %rd32, %rd2, %rd31;
ld.param.u64 %rd33, [%rd32];
add.s64 %rd34, %rd5, %rd31;
st.local.u64 [%rd34], %rd33;
add.s32 %r49, %r49, 1;
setp.lt.u32	%p6, %r49, 27;
@%p6 bra BB143_5;

BB143_6:
mov.u32 %r33, %ntid.x;
mov.u32 %r34, %ctaid.x;
mov.u32 %r35, %tid.x;
mad.lo.s32 %r54, %r33, %r34, %r35;
setp.ge.u32	%p7, %r54, %r29;
@%p7 bra BB143_17;

ld.local.u32 %r8, [%rd5+208];

BB143_8:
mov.u32 %r52, %r54;
mov.u32 %r9, %r52;
mul.wide.s32 %rd66, %r8, 4;
add.s32 %r40, %r8, -1;
sub.s32 %r50, %r40, %r28;
mov.u64 %rd68, 0;
mov.u32 %r60, 0;
mov.u64 %rd67, %rd68;
mov.u32 %r56, %r60;
mov.u32 %r61, %r60;
mov.u32 %r55, %r60;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r51, %r8;
mov.u32 %r53, %r9;
@%p8 bra BB143_13;

BB143_9:
mov.u32 %r57, %r61;
mov.u32 %r62, %r57;
mov.u32 %r13, %r53;
mov.u32 %r12, %r51;
add.s64 %rd37, %rd3, %rd66;
add.s32 %r17, %r12, -1;
add.s64 %rd38, %rd5, %rd66;
ld.local.u32 %r18, [%rd38+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r41, [%rd38+104];
mad.lo.s32 %r55, %r41, %r19, %r55;
ld.local.u32 %r42, [%rd37+104];
mad.lo.s32 %r56, %r42, %r19, %r56;
setp.eq.s32	%p9, %r50, 0;
@%p9 bra BB143_11;

add.s64 %rd39, %rd4, %rd66;
ld.local.u32 %r43, [%rd39+104];
mad.lo.s32 %r62, %r43, %r19, %r62;

BB143_11:
mov.u32 %r61, %r62;
div.u32 %r24, %r13, %r18;
add.s32 %r50, %r50, -1;
add.s64 %rd66, %rd66, -4;
setp.gt.s32	%p10, %r17, 0;
mov.u32 %r51, %r17;
mov.u32 %r53, %r24;
@%p10 bra BB143_9;

cvt.u64.u32	%rd67, %r55;
cvt.u64.u32	%rd68, %r56;
mov.u32 %r60, %r61;

BB143_13:
ld.local.u64 %rd40, [%rd5];
shl.b64 %rd41, %rd67, 3;
add.s64 %rd42, %rd40, %rd41;
ld.u64 %rd19, [%rd42];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB143_15;

mul.wide.s32 %rd43, %r28, 4;
add.s64 %rd44, %rd4, %rd43;
ld.local.u32 %rd45, [%rd44+8];
setp.lt.s64	%p12, %rd19, %rd45;
@%p12 bra BB143_16;

BB143_15:
mov.u64 %rd46, $str;
cvta.global.u64 %rd47, %rd46;
mov.u64 %rd48, $str1;
cvta.global.u64 %rd49, %rd48;
mov.u64 %rd50, __T2171;
cvta.global.u64 %rd51, %rd50;
mov.u32 %r44, 97;
mov.u64 %rd52, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd47;
.param .b64 param1;
st.param.b64	[param1+0], %rd49;
.param .b32 param2;
st.param.b32	[param2+0], %r44;
.param .b64 param3;
st.param.b64	[param3+0], %rd51;
.param .b64 param4;
st.param.b64	[param4+0], %rd52;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB143_16:
mul.wide.s32 %rd53, %r28, 4;
add.s64 %rd54, %rd4, %rd53;
ld.local.u32 %rd55, [%rd54+108];
mul.lo.s64 %rd56, %rd55, %rd19;
cvt.u64.u32	%rd57, %r60;
add.s64 %rd58, %rd56, %rd57;
ld.local.u64 %rd59, [%rd4];
shl.b64 %rd60, %rd58, 3;
and.b64 %rd61, %rd60, 34359738360;
add.s64 %rd62, %rd59, %rd61;
ld.f64 %fd1, [%rd62];
ld.local.u64 %rd63, [%rd3];
shl.b64 %rd64, %rd68, 3;
add.s64 %rd65, %rd63, %rd64;
st.f64 [%rd65], %fd1;
mov.u32 %r46, %nctaid.x;
mad.lo.s32 %r54, %r46, %r33, %r9;
setp.lt.u32	%p13, %r54, %r29;
@%p13 bra BB143_8;

BB143_17:
ret;
}


.visible .entry _Z25THCudaTensor_gatherKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[416],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[416],
.param .align 8 .b8 _Z25THCudaTensor_gatherKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[416],
.param .u32 _Z25THCudaTensor_gatherKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u64 _Z25THCudaTensor_gatherKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot144[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<16>;
.reg .b32 %r<37>;
.reg .f64 %fd<2>;
.reg .b64 %rd<117>;


mov.u64 %rd116, __local_depot144;
cvta.local.u64 %SP, %rd116;
ld.param.u32 %r13, [_Z25THCudaTensor_gatherKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u64 %rd38, [_Z25THCudaTensor_gatherKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z25THCudaTensor_gatherKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z25THCudaTensor_gatherKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z25THCudaTensor_gatherKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd39, %SP, 416;
cvta.to.local.u64 %rd3, %rd39;
add.u64 %rd40, %SP, 832;
cvta.to.local.u64 %rd4, %rd40;
add.u64 %rd41, %SP, 0;
cvta.to.local.u64 %rd5, %rd41;
mov.u32 %r32, 0;
mov.pred %p1, 0;
@%p1 bra BB144_2;

BB144_1:
mul.wide.s32 %rd42, %r32, 8;
add.s64 %rd43, %rd6, %rd42;
ld.param.u64 %rd44, [%rd43];
add.s64 %rd45, %rd3, %rd42;
st.local.u64 [%rd45], %rd44;
add.s32 %r32, %r32, 1;
setp.lt.u32	%p2, %r32, 52;
@%p2 bra BB144_1;

BB144_2:
mov.u32 %r33, 0;
@%p1 bra BB144_4;

BB144_3:
mul.wide.s32 %rd46, %r33, 8;
add.s64 %rd47, %rd1, %rd46;
ld.param.u64 %rd48, [%rd47];
add.s64 %rd49, %rd4, %rd46;
st.local.u64 [%rd49], %rd48;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p4, %r33, 52;
@%p4 bra BB144_3;

BB144_4:
mov.u32 %r34, 0;
@%p1 bra BB144_6;

BB144_5:
mul.wide.s32 %rd50, %r34, 8;
add.s64 %rd51, %rd2, %rd50;
ld.param.u64 %rd52, [%rd51];
add.s64 %rd53, %rd5, %rd50;
st.local.u64 [%rd53], %rd52;
add.s32 %r34, %r34, 1;
setp.lt.u32	%p6, %r34, 52;
@%p6 bra BB144_5;

BB144_6:
mov.u32 %r17, %ntid.x;
mov.u32 %r18, %ctaid.x;
mov.u32 %r19, %tid.x;
mad.lo.s32 %r20, %r17, %r18, %r19;
cvt.u64.u32	%rd102, %r20;
setp.ge.u64	%p7, %rd102, %rd38;
@%p7 bra BB144_22;

ld.local.u32 %r7, [%rd5+408];

BB144_8:
mov.u64 %rd98, %rd102;
mov.u64 %rd13, %rd98;
mul.wide.s32 %rd97, %r7, 8;
add.s32 %r21, %r7, -1;
sub.s32 %r35, %r21, %r13;
mov.u64 %rd114, 0;
mov.u64 %rd110, %rd114;
mov.u64 %rd105, %rd114;
mov.u64 %rd115, %rd114;
mov.u64 %rd111, %rd114;
mov.u64 %rd106, %rd114;
setp.lt.s32	%p8, %r7, 1;
mov.u32 %r36, %r7;
mov.u64 %rd100, %rd13;
@%p8 bra BB144_18;

BB144_9:
mov.u64 %rd112, %rd111;
mov.u64 %rd16, %rd100;
mov.u32 %r10, %r36;
add.s32 %r11, %r10, -1;
add.s64 %rd20, %rd5, %rd97;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd60, %rd16, %rd21;
and.b64 %rd61, %rd60, -4294967296;
setp.eq.s64	%p9, %rd61, 0;
@%p9 bra BB144_11;
bra.uni BB144_10;

BB144_11:
cvt.u32.u64	%r22, %rd21;
cvt.u32.u64	%r23, %rd16;
rem.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd103, %r24;
bra.uni BB144_12;

BB144_10:
rem.u64 %rd103, %rd16, %rd21;

BB144_12:
add.s64 %rd62, %rd3, %rd97;
ld.local.u64 %rd63, [%rd20+200];
mul.lo.s64 %rd64, %rd63, %rd103;
add.s64 %rd106, %rd64, %rd106;
ld.local.u64 %rd65, [%rd62+200];
mul.lo.s64 %rd66, %rd65, %rd103;
add.s64 %rd115, %rd66, %rd115;
setp.eq.s32	%p10, %r35, 0;
@%p10 bra BB144_14;

add.s64 %rd67, %rd4, %rd97;
ld.local.u64 %rd68, [%rd67+200];
mul.lo.s64 %rd69, %rd68, %rd103;
add.s64 %rd112, %rd69, %rd112;

BB144_14:
mov.u64 %rd111, %rd112;
@%p9 bra BB144_16;
bra.uni BB144_15;

BB144_16:
cvt.u32.u64	%r25, %rd21;
cvt.u32.u64	%r26, %rd16;
div.u32 %r27, %r26, %r25;
cvt.u64.u32	%rd101, %r27;
bra.uni BB144_17;

BB144_15:
div.u64 %rd101, %rd16, %rd21;

BB144_17:
mov.u64 %rd31, %rd101;
add.s32 %r35, %r35, -1;
add.s64 %rd97, %rd97, -8;
setp.gt.s32	%p12, %r11, 0;
mov.u32 %r36, %r11;
mov.u64 %rd100, %rd31;
mov.u64 %rd105, %rd106;
mov.u64 %rd110, %rd111;
mov.u64 %rd114, %rd115;
@%p12 bra BB144_9;

BB144_18:
ld.local.u64 %rd72, [%rd5];
shl.b64 %rd73, %rd105, 3;
add.s64 %rd74, %rd72, %rd73;
ld.u64 %rd36, [%rd74];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB144_20;

mul.wide.s32 %rd75, %r13, 8;
add.s64 %rd76, %rd4, %rd75;
ld.local.u64 %rd77, [%rd76+8];
setp.lt.u64	%p14, %rd36, %rd77;
@%p14 bra BB144_21;

BB144_20:
mov.u64 %rd78, $str;
cvta.global.u64 %rd79, %rd78;
mov.u64 %rd80, $str1;
cvta.global.u64 %rd81, %rd80;
mov.u64 %rd82, __T2173;
cvta.global.u64 %rd83, %rd82;
mov.u32 %r28, 97;
mov.u64 %rd84, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd79;
.param .b64 param1;
st.param.b64	[param1+0], %rd81;
.param .b32 param2;
st.param.b32	[param2+0], %r28;
.param .b64 param3;
st.param.b64	[param3+0], %rd83;
.param .b64 param4;
st.param.b64	[param4+0], %rd84;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB144_21:
mul.wide.s32 %rd85, %r13, 8;
add.s64 %rd86, %rd4, %rd85;
ld.local.u64 %rd87, [%rd86+208];
mul.lo.s64 %rd88, %rd87, %rd36;
add.s64 %rd89, %rd88, %rd110;
ld.local.u64 %rd90, [%rd4];
shl.b64 %rd91, %rd89, 3;
add.s64 %rd92, %rd90, %rd91;
ld.f64 %fd1, [%rd92];
ld.local.u64 %rd93, [%rd3];
shl.b64 %rd94, %rd114, 3;
add.s64 %rd95, %rd93, %rd94;
st.f64 [%rd95], %fd1;
mov.u32 %r30, %nctaid.x;
mul.lo.s32 %r31, %r30, %r17;
cvt.u64.u32	%rd96, %r31;
add.s64 %rd102, %rd96, %rd13;
setp.lt.u64	%p15, %rd102, %rd38;
@%p15 bra BB144_8;

BB144_22:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot145[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b32 %r<25>;
.reg .f64 %fd<2>;
.reg .b64 %rd<44>;


mov.u64 %rd43, __local_depot145;
cvta.local.u64 %SP, %rd43;
ld.param.u32 %r10, [_Z26THCudaTensor_scatterKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r11, [_Z26THCudaTensor_scatterKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd3, %rd11;
mov.u32 %r23, 0;
mov.pred %p1, 0;
@%p1 bra BB145_2;

BB145_1:
mul.wide.s32 %rd12, %r23, 8;
add.s64 %rd13, %rd4, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd3, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r23, %r23, 1;
setp.lt.u32	%p2, %r23, 27;
@%p2 bra BB145_1;

BB145_2:
mov.u32 %r13, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r24, %r13, %r14, %r15;
setp.ge.u32	%p3, %r24, %r11;
@%p3 bra BB145_10;

ld.param.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd6, %rd16;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd17, [%rd2];
cvta.to.global.u64 %rd7, %rd17;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB145_4:
rem.u32 %r8, %r24, %r5;
setp.eq.s32	%p4, %r10, 0;
mov.u64 %rd42, 0;
@%p4 bra BB145_6;

ld.local.u32 %r16, [%rd3+108];
mul.lo.s32 %r17, %r16, %r8;
cvt.u64.u32	%rd42, %r17;

BB145_6:
mul.lo.s32 %r18, %r6, %r8;
mul.wide.u32 %rd19, %r18, 8;
add.s64 %rd20, %rd7, %rd19;
ld.global.u64 %rd10, [%rd20];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB145_8;

mul.wide.s32 %rd21, %r10, 4;
add.s64 %rd22, %rd3, %rd21;
ld.local.u32 %rd23, [%rd22+8];
setp.lt.s64	%p6, %rd10, %rd23;
@%p6 bra BB145_9;

BB145_8:
mov.u64 %rd24, $str2;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, $str1;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, __T2174;
cvta.global.u64 %rd29, %rd28;
mov.u32 %r19, 124;
mov.u64 %rd30, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd25;
.param .b64 param1;
st.param.b64	[param1+0], %rd27;
.param .b32 param2;
st.param.b32	[param2+0], %r19;
.param .b64 param3;
st.param.b64	[param3+0], %rd29;
.param .b64 param4;
st.param.b64	[param4+0], %rd30;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB145_9:
mul.lo.s32 %r20, %r4, %r8;
mul.wide.s32 %rd31, %r10, 4;
add.s64 %rd32, %rd3, %rd31;
ld.local.u32 %rd33, [%rd32+108];
mul.lo.s64 %rd34, %rd33, %rd10;
add.s64 %rd35, %rd34, %rd42;
mul.wide.u32 %rd36, %r20, 8;
add.s64 %rd37, %rd6, %rd36;
ld.global.f64 %fd1, [%rd37];
ld.local.u64 %rd38, [%rd3];
shl.b64 %rd39, %rd35, 3;
and.b64 %rd40, %rd39, 34359738360;
add.s64 %rd41, %rd38, %rd40;
st.f64 [%rd41], %fd1;
mov.u32 %r22, %nctaid.x;
mad.lo.s32 %r24, %r22, %r13, %r24;
setp.lt.u32	%p7, %r24, %r11;
@%p7 bra BB145_4;

BB145_10:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot146[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b32 %r<40>;
.reg .f64 %fd<2>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot146;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r19, [_Z26THCudaTensor_scatterKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r20, [_Z26THCudaTensor_scatterKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r37, 0;
mov.pred %p1, 0;
@%p1 bra BB146_2;

BB146_1:
mul.wide.s32 %rd10, %r37, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r37, %r37, 1;
setp.lt.u32	%p2, %r37, 27;
@%p2 bra BB146_1;

BB146_2:
mov.u32 %r22, %ntid.x;
mov.u32 %r23, %ctaid.x;
mov.u32 %r24, %tid.x;
mad.lo.s32 %r38, %r22, %r23, %r24;
setp.ge.u32	%p3, %r38, %r20;
@%p3 bra BB146_12;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r25, %r26}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB146_4:
rem.u32 %r11, %r38, %r26;
setp.eq.s32	%p4, %r19, 1;
mov.u32 %r39, 0;
@%p4 bra BB146_6;

ld.local.u32 %r28, [%rd3+112];
mul.lo.s32 %r39, %r28, %r11;

BB146_6:
div.u32 %r29, %r38, %r26;
rem.u32 %r14, %r29, %r25;
setp.eq.s32	%p5, %r19, 0;
@%p5 bra BB146_8;

ld.local.u32 %r30, [%rd3+108];
mad.lo.s32 %r39, %r30, %r14, %r39;

BB146_8:
mul.lo.s32 %r31, %r9, %r11;
mul.lo.s32 %r32, %r5, %r11;
mad.lo.s32 %r33, %r8, %r14, %r31;
mad.lo.s32 %r17, %r4, %r14, %r32;
mul.wide.u32 %rd16, %r33, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB146_10;

mul.wide.s32 %rd18, %r19, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p7, %rd8, %rd20;
@%p7 bra BB146_11;

BB146_10:
mov.u64 %rd21, $str2;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T2175;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r34, 124;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r34;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB146_11:
mul.wide.s32 %rd28, %r19, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r39;
add.s64 %rd33, %rd31, %rd32;
mul.wide.u32 %rd34, %r17, 8;
add.s64 %rd35, %rd6, %rd34;
ld.global.f64 %fd1, [%rd35];
ld.local.u64 %rd36, [%rd3];
shl.b64 %rd37, %rd33, 3;
and.b64 %rd38, %rd37, 34359738360;
add.s64 %rd39, %rd36, %rd38;
st.f64 [%rd39], %fd1;
mov.u32 %r36, %nctaid.x;
mad.lo.s32 %r38, %r36, %r22, %r38;
setp.lt.u32	%p8, %r38, %r20;
@%p8 bra BB146_4;

BB146_12:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot147[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b32 %r<54>;
.reg .f64 %fd<2>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot147;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r26, [_Z26THCudaTensor_scatterKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r27, [_Z26THCudaTensor_scatterKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z26THCudaTensor_scatterKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r51, 0;
mov.pred %p1, 0;
@%p1 bra BB147_2;

BB147_1:
mul.wide.s32 %rd10, %r51, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p2, %r51, 27;
@%p2 bra BB147_1;

BB147_2:
mov.u32 %r29, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r52, %r29, %r30, %r31;
setp.ge.u32	%p3, %r52, %r27;
@%p3 bra BB147_14;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r32, %r33}, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r34, %r35}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r36, %r37}, [%rd2+112];

BB147_4:
rem.u32 %r14, %r52, %r9;
setp.eq.s32	%p4, %r26, 2;
mov.u32 %r53, 0;
@%p4 bra BB147_6;

ld.local.u32 %r39, [%rd3+116];
mul.lo.s32 %r53, %r39, %r14;

BB147_6:
div.u32 %r17, %r52, %r9;
rem.u32 %r18, %r17, %r35;
setp.eq.s32	%p5, %r26, 1;
@%p5 bra BB147_8;

ld.local.u32 %r40, [%rd3+112];
mad.lo.s32 %r53, %r40, %r18, %r53;

BB147_8:
div.u32 %r41, %r17, %r35;
rem.u32 %r21, %r41, %r34;
setp.eq.s32	%p6, %r26, 0;
@%p6 bra BB147_10;

ld.local.u32 %r42, [%rd3+108];
mad.lo.s32 %r53, %r42, %r21, %r53;

BB147_10:
mul.lo.s32 %r43, %r37, %r14;
mul.lo.s32 %r44, %r33, %r14;
mad.lo.s32 %r45, %r36, %r18, %r43;
mad.lo.s32 %r46, %r32, %r18, %r44;
mad.lo.s32 %r47, %r10, %r21, %r45;
mad.lo.s32 %r24, %r4, %r21, %r46;
mul.wide.u32 %rd16, %r47, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB147_12;

mul.wide.s32 %rd18, %r26, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p8, %rd8, %rd20;
@%p8 bra BB147_13;

BB147_12:
mov.u64 %rd21, $str2;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T2176;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r48, 124;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r48;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB147_13:
mul.wide.s32 %rd28, %r26, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r53;
add.s64 %rd33, %rd31, %rd32;
mul.wide.u32 %rd34, %r24, 8;
add.s64 %rd35, %rd6, %rd34;
ld.global.f64 %fd1, [%rd35];
ld.local.u64 %rd36, [%rd3];
shl.b64 %rd37, %rd33, 3;
and.b64 %rd38, %rd37, 34359738360;
add.s64 %rd39, %rd36, %rd38;
st.f64 [%rd39], %fd1;
mov.u32 %r50, %nctaid.x;
mad.lo.s32 %r52, %r50, %r29, %r52;
setp.lt.u32	%p9, %r52, %r27;
@%p9 bra BB147_4;

BB147_14:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z26THCudaTensor_scatterKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z26THCudaTensor_scatterKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot148[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b32 %r<63>;
.reg .f64 %fd<2>;
.reg .b64 %rd<70>;


mov.u64 %rd69, __local_depot148;
cvta.local.u64 %SP, %rd69;
ld.param.u32 %r28, [_Z26THCudaTensor_scatterKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r29, [_Z26THCudaTensor_scatterKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z26THCudaTensor_scatterKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd20, %SP, 216;
cvta.to.local.u64 %rd3, %rd20;
add.u64 %rd21, %SP, 432;
cvta.to.local.u64 %rd4, %rd21;
add.u64 %rd22, %SP, 0;
cvta.to.local.u64 %rd5, %rd22;
mov.u32 %r47, 0;
mov.pred %p1, 0;
@%p1 bra BB148_2;

BB148_1:
mul.wide.s32 %rd23, %r47, 8;
add.s64 %rd24, %rd6, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r47, %r47, 1;
setp.lt.u32	%p2, %r47, 27;
@%p2 bra BB148_1;

BB148_2:
mov.u32 %r48, 0;
@%p1 bra BB148_4;

BB148_3:
mul.wide.s32 %rd27, %r48, 8;
add.s64 %rd28, %rd1, %rd27;
ld.param.u64 %rd29, [%rd28];
add.s64 %rd30, %rd4, %rd27;
st.local.u64 [%rd30], %rd29;
add.s32 %r48, %r48, 1;
setp.lt.u32	%p4, %r48, 27;
@%p4 bra BB148_3;

BB148_4:
mov.u32 %r49, 0;
@%p1 bra BB148_6;

BB148_5:
mul.wide.s32 %rd31, %r49, 8;
add.s64 %rd32, %rd2, %rd31;
ld.param.u64 %rd33, [%rd32];
add.s64 %rd34, %rd5, %rd31;
st.local.u64 [%rd34], %rd33;
add.s32 %r49, %r49, 1;
setp.lt.u32	%p6, %r49, 27;
@%p6 bra BB148_5;

BB148_6:
mov.u32 %r33, %ntid.x;
mov.u32 %r34, %ctaid.x;
mov.u32 %r35, %tid.x;
mad.lo.s32 %r54, %r33, %r34, %r35;
setp.ge.u32	%p7, %r54, %r29;
@%p7 bra BB148_17;

ld.local.u32 %r8, [%rd5+208];

BB148_8:
mov.u32 %r52, %r54;
mov.u32 %r9, %r52;
mul.wide.s32 %rd66, %r8, 4;
add.s32 %r40, %r8, -1;
sub.s32 %r50, %r40, %r28;
mov.u32 %r60, 0;
mov.u64 %rd68, 0;
mov.u64 %rd67, %rd68;
mov.u32 %r61, %r60;
mov.u32 %r56, %r60;
mov.u32 %r55, %r60;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r51, %r8;
mov.u32 %r53, %r9;
@%p8 bra BB148_13;

BB148_9:
mov.u32 %r57, %r61;
mov.u32 %r62, %r57;
mov.u32 %r13, %r53;
mov.u32 %r12, %r51;
add.s64 %rd37, %rd4, %rd66;
add.s32 %r17, %r12, -1;
add.s64 %rd38, %rd5, %rd66;
ld.local.u32 %r18, [%rd38+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r41, [%rd38+104];
mad.lo.s32 %r55, %r41, %r19, %r55;
ld.local.u32 %r42, [%rd37+104];
mad.lo.s32 %r56, %r42, %r19, %r56;
setp.eq.s32	%p9, %r50, 0;
@%p9 bra BB148_11;

add.s64 %rd39, %rd3, %rd66;
ld.local.u32 %r43, [%rd39+104];
mad.lo.s32 %r62, %r43, %r19, %r62;

BB148_11:
mov.u32 %r61, %r62;
div.u32 %r24, %r13, %r18;
add.s32 %r50, %r50, -1;
add.s64 %rd66, %rd66, -4;
setp.gt.s32	%p10, %r17, 0;
mov.u32 %r51, %r17;
mov.u32 %r53, %r24;
@%p10 bra BB148_9;

cvt.u64.u32	%rd67, %r55;
cvt.u64.u32	%rd68, %r56;
mov.u32 %r60, %r61;

BB148_13:
ld.local.u64 %rd40, [%rd5];
shl.b64 %rd41, %rd67, 3;
add.s64 %rd42, %rd40, %rd41;
ld.u64 %rd19, [%rd42];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB148_15;

mul.wide.s32 %rd43, %r28, 4;
add.s64 %rd44, %rd3, %rd43;
ld.local.u32 %rd45, [%rd44+8];
setp.lt.s64	%p12, %rd19, %rd45;
@%p12 bra BB148_16;

BB148_15:
mov.u64 %rd46, $str2;
cvta.global.u64 %rd47, %rd46;
mov.u64 %rd48, $str1;
cvta.global.u64 %rd49, %rd48;
mov.u64 %rd50, __T2177;
cvta.global.u64 %rd51, %rd50;
mov.u32 %r44, 124;
mov.u64 %rd52, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd47;
.param .b64 param1;
st.param.b64	[param1+0], %rd49;
.param .b32 param2;
st.param.b32	[param2+0], %r44;
.param .b64 param3;
st.param.b64	[param3+0], %rd51;
.param .b64 param4;
st.param.b64	[param4+0], %rd52;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB148_16:
mul.wide.s32 %rd53, %r28, 4;
add.s64 %rd54, %rd3, %rd53;
ld.local.u32 %rd55, [%rd54+108];
mul.lo.s64 %rd56, %rd55, %rd19;
cvt.u64.u32	%rd57, %r60;
add.s64 %rd58, %rd56, %rd57;
ld.local.u64 %rd59, [%rd4];
shl.b64 %rd60, %rd68, 3;
add.s64 %rd61, %rd59, %rd60;
ld.f64 %fd1, [%rd61];
ld.local.u64 %rd62, [%rd3];
shl.b64 %rd63, %rd58, 3;
and.b64 %rd64, %rd63, 34359738360;
add.s64 %rd65, %rd62, %rd64;
st.f64 [%rd65], %fd1;
mov.u32 %r46, %nctaid.x;
mad.lo.s32 %r54, %r46, %r33, %r9;
setp.lt.u32	%p13, %r54, %r29;
@%p13 bra BB148_8;

BB148_17:
ret;
}


.visible .entry _Z26THCudaTensor_scatterKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[416],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[416],
.param .align 8 .b8 _Z26THCudaTensor_scatterKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[416],
.param .u32 _Z26THCudaTensor_scatterKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u64 _Z26THCudaTensor_scatterKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot149[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<16>;
.reg .b32 %r<37>;
.reg .f64 %fd<2>;
.reg .b64 %rd<117>;


mov.u64 %rd116, __local_depot149;
cvta.local.u64 %SP, %rd116;
ld.param.u32 %r13, [_Z26THCudaTensor_scatterKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u64 %rd38, [_Z26THCudaTensor_scatterKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z26THCudaTensor_scatterKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z26THCudaTensor_scatterKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z26THCudaTensor_scatterKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd39, %SP, 416;
cvta.to.local.u64 %rd3, %rd39;
add.u64 %rd40, %SP, 832;
cvta.to.local.u64 %rd4, %rd40;
add.u64 %rd41, %SP, 0;
cvta.to.local.u64 %rd5, %rd41;
mov.u32 %r32, 0;
mov.pred %p1, 0;
@%p1 bra BB149_2;

BB149_1:
mul.wide.s32 %rd42, %r32, 8;
add.s64 %rd43, %rd6, %rd42;
ld.param.u64 %rd44, [%rd43];
add.s64 %rd45, %rd3, %rd42;
st.local.u64 [%rd45], %rd44;
add.s32 %r32, %r32, 1;
setp.lt.u32	%p2, %r32, 52;
@%p2 bra BB149_1;

BB149_2:
mov.u32 %r33, 0;
@%p1 bra BB149_4;

BB149_3:
mul.wide.s32 %rd46, %r33, 8;
add.s64 %rd47, %rd1, %rd46;
ld.param.u64 %rd48, [%rd47];
add.s64 %rd49, %rd4, %rd46;
st.local.u64 [%rd49], %rd48;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p4, %r33, 52;
@%p4 bra BB149_3;

BB149_4:
mov.u32 %r34, 0;
@%p1 bra BB149_6;

BB149_5:
mul.wide.s32 %rd50, %r34, 8;
add.s64 %rd51, %rd2, %rd50;
ld.param.u64 %rd52, [%rd51];
add.s64 %rd53, %rd5, %rd50;
st.local.u64 [%rd53], %rd52;
add.s32 %r34, %r34, 1;
setp.lt.u32	%p6, %r34, 52;
@%p6 bra BB149_5;

BB149_6:
mov.u32 %r17, %ntid.x;
mov.u32 %r18, %ctaid.x;
mov.u32 %r19, %tid.x;
mad.lo.s32 %r20, %r17, %r18, %r19;
cvt.u64.u32	%rd102, %r20;
setp.ge.u64	%p7, %rd102, %rd38;
@%p7 bra BB149_22;

ld.local.u32 %r7, [%rd5+408];

BB149_8:
mov.u64 %rd98, %rd102;
mov.u64 %rd13, %rd98;
mul.wide.s32 %rd97, %r7, 8;
add.s32 %r21, %r7, -1;
sub.s32 %r35, %r21, %r13;
mov.u64 %rd113, 0;
mov.u64 %rd108, %rd113;
mov.u64 %rd105, %rd113;
mov.u64 %rd114, %rd113;
mov.u64 %rd109, %rd113;
mov.u64 %rd106, %rd113;
setp.lt.s32	%p8, %r7, 1;
mov.u32 %r36, %r7;
mov.u64 %rd100, %rd13;
@%p8 bra BB149_18;

BB149_9:
mov.u64 %rd115, %rd114;
mov.u64 %rd16, %rd100;
mov.u32 %r10, %r36;
add.s32 %r11, %r10, -1;
add.s64 %rd20, %rd5, %rd97;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd60, %rd16, %rd21;
and.b64 %rd61, %rd60, -4294967296;
setp.eq.s64	%p9, %rd61, 0;
@%p9 bra BB149_11;
bra.uni BB149_10;

BB149_11:
cvt.u32.u64	%r22, %rd21;
cvt.u32.u64	%r23, %rd16;
rem.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd103, %r24;
bra.uni BB149_12;

BB149_10:
rem.u64 %rd103, %rd16, %rd21;

BB149_12:
add.s64 %rd62, %rd4, %rd97;
ld.local.u64 %rd63, [%rd20+200];
mul.lo.s64 %rd64, %rd63, %rd103;
add.s64 %rd106, %rd64, %rd106;
ld.local.u64 %rd65, [%rd62+200];
mul.lo.s64 %rd66, %rd65, %rd103;
add.s64 %rd109, %rd66, %rd109;
setp.eq.s32	%p10, %r35, 0;
@%p10 bra BB149_14;

add.s64 %rd67, %rd3, %rd97;
ld.local.u64 %rd68, [%rd67+200];
mul.lo.s64 %rd69, %rd68, %rd103;
add.s64 %rd115, %rd69, %rd115;

BB149_14:
mov.u64 %rd114, %rd115;
@%p9 bra BB149_16;
bra.uni BB149_15;

BB149_16:
cvt.u32.u64	%r25, %rd21;
cvt.u32.u64	%r26, %rd16;
div.u32 %r27, %r26, %r25;
cvt.u64.u32	%rd101, %r27;
bra.uni BB149_17;

BB149_15:
div.u64 %rd101, %rd16, %rd21;

BB149_17:
mov.u64 %rd31, %rd101;
add.s32 %r35, %r35, -1;
add.s64 %rd97, %rd97, -8;
setp.gt.s32	%p12, %r11, 0;
mov.u32 %r36, %r11;
mov.u64 %rd100, %rd31;
mov.u64 %rd105, %rd106;
mov.u64 %rd108, %rd109;
mov.u64 %rd113, %rd114;
@%p12 bra BB149_9;

BB149_18:
ld.local.u64 %rd72, [%rd5];
shl.b64 %rd73, %rd105, 3;
add.s64 %rd74, %rd72, %rd73;
ld.u64 %rd36, [%rd74];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB149_20;

mul.wide.s32 %rd75, %r13, 8;
add.s64 %rd76, %rd3, %rd75;
ld.local.u64 %rd77, [%rd76+8];
setp.lt.u64	%p14, %rd36, %rd77;
@%p14 bra BB149_21;

BB149_20:
mov.u64 %rd78, $str2;
cvta.global.u64 %rd79, %rd78;
mov.u64 %rd80, $str1;
cvta.global.u64 %rd81, %rd80;
mov.u64 %rd82, __T2178;
cvta.global.u64 %rd83, %rd82;
mov.u32 %r28, 124;
mov.u64 %rd84, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd79;
.param .b64 param1;
st.param.b64	[param1+0], %rd81;
.param .b32 param2;
st.param.b32	[param2+0], %r28;
.param .b64 param3;
st.param.b64	[param3+0], %rd83;
.param .b64 param4;
st.param.b64	[param4+0], %rd84;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB149_21:
mul.wide.s32 %rd85, %r13, 8;
add.s64 %rd86, %rd3, %rd85;
ld.local.u64 %rd87, [%rd86+208];
mul.lo.s64 %rd88, %rd87, %rd36;
add.s64 %rd89, %rd88, %rd113;
ld.local.u64 %rd90, [%rd4];
shl.b64 %rd91, %rd108, 3;
add.s64 %rd92, %rd90, %rd91;
ld.f64 %fd1, [%rd92];
ld.local.u64 %rd93, [%rd3];
shl.b64 %rd94, %rd89, 3;
add.s64 %rd95, %rd93, %rd94;
st.f64 [%rd95], %fd1;
mov.u32 %r30, %nctaid.x;
mul.lo.s32 %r31, %r30, %r17;
cvt.u64.u32	%rd96, %r31;
add.s64 %rd102, %rd96, %rd13;
setp.lt.u64	%p15, %rd102, %rd38;
@%p15 bra BB149_8;

BB149_22:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot150[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b32 %r<25>;
.reg .f64 %fd<3>;
.reg .b64 %rd<44>;


mov.u64 %rd43, __local_depot150;
cvta.local.u64 %SP, %rd43;
ld.param.u32 %r10, [_Z29THCudaTensor_scatterAddKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r11, [_Z29THCudaTensor_scatterAddKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjdLi1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd3, %rd11;
mov.u32 %r23, 0;
mov.pred %p1, 0;
@%p1 bra BB150_2;

BB150_1:
mul.wide.s32 %rd12, %r23, 8;
add.s64 %rd13, %rd4, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd3, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r23, %r23, 1;
setp.lt.u32	%p2, %r23, 27;
@%p2 bra BB150_1;

BB150_2:
mov.u32 %r13, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r24, %r13, %r14, %r15;
setp.ge.u32	%p3, %r24, %r11;
@%p3 bra BB150_10;

ld.param.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd6, %rd16;
ld.param.u32 %r4, [%rd1+108];
ld.param.u64 %rd17, [%rd2];
cvta.to.global.u64 %rd7, %rd17;
ld.param.u32 %r5, [%rd2+8];
ld.param.u32 %r6, [%rd2+108];

BB150_4:
rem.u32 %r8, %r24, %r5;
setp.eq.s32	%p4, %r10, 0;
mov.u64 %rd42, 0;
@%p4 bra BB150_6;

ld.local.u32 %r16, [%rd3+108];
mul.lo.s32 %r17, %r16, %r8;
cvt.u64.u32	%rd42, %r17;

BB150_6:
mul.lo.s32 %r18, %r6, %r8;
mul.wide.u32 %rd19, %r18, 8;
add.s64 %rd20, %rd7, %rd19;
ld.global.u64 %rd10, [%rd20];
setp.lt.s64	%p5, %rd10, 0;
@%p5 bra BB150_8;

mul.wide.s32 %rd21, %r10, 4;
add.s64 %rd22, %rd3, %rd21;
ld.local.u32 %rd23, [%rd22+8];
setp.lt.s64	%p6, %rd10, %rd23;
@%p6 bra BB150_9;

BB150_8:
mov.u64 %rd24, $str2;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, $str1;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, __T2179;
cvta.global.u64 %rd29, %rd28;
mov.u32 %r19, 151;
mov.u64 %rd30, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd25;
.param .b64 param1;
st.param.b64	[param1+0], %rd27;
.param .b32 param2;
st.param.b32	[param2+0], %r19;
.param .b64 param3;
st.param.b64	[param3+0], %rd29;
.param .b64 param4;
st.param.b64	[param4+0], %rd30;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB150_9:
mul.lo.s32 %r20, %r4, %r8;
mul.wide.s32 %rd31, %r10, 4;
add.s64 %rd32, %rd3, %rd31;
ld.local.u32 %rd33, [%rd32+108];
mul.lo.s64 %rd34, %rd33, %rd10;
add.s64 %rd35, %rd34, %rd42;
and.b64 %rd36, %rd35, 4294967295;
ld.local.u64 %rd37, [%rd3];
shl.b64 %rd38, %rd36, 3;
add.s64 %rd39, %rd37, %rd38;
mul.wide.u32 %rd40, %r20, 8;
add.s64 %rd41, %rd6, %rd40;
ld.global.f64 %fd1, [%rd41];
atom.add.f64 %fd2, [%rd39], %fd1;
mov.u32 %r22, %nctaid.x;
mad.lo.s32 %r24, %r22, %r13, %r24;
setp.lt.u32	%p7, %r24, %r11;
@%p7 bra BB150_4;

BB150_10:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot151[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b32 %r<40>;
.reg .f64 %fd<3>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot151;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r19, [_Z29THCudaTensor_scatterAddKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r20, [_Z29THCudaTensor_scatterAddKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjdLi2EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r37, 0;
mov.pred %p1, 0;
@%p1 bra BB151_2;

BB151_1:
mul.wide.s32 %rd10, %r37, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r37, %r37, 1;
setp.lt.u32	%p2, %r37, 27;
@%p2 bra BB151_1;

BB151_2:
mov.u32 %r22, %ntid.x;
mov.u32 %r23, %ctaid.x;
mov.u32 %r24, %tid.x;
mad.lo.s32 %r38, %r22, %r23, %r24;
setp.ge.u32	%p3, %r38, %r20;
@%p3 bra BB151_12;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.u32 %r5, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r25, %r26}, [%rd2+8];
ld.param.u32 %r8, [%rd2+108];
ld.param.u32 %r9, [%rd2+112];

BB151_4:
rem.u32 %r11, %r38, %r26;
setp.eq.s32	%p4, %r19, 1;
mov.u32 %r39, 0;
@%p4 bra BB151_6;

ld.local.u32 %r28, [%rd3+112];
mul.lo.s32 %r39, %r28, %r11;

BB151_6:
div.u32 %r29, %r38, %r26;
rem.u32 %r14, %r29, %r25;
setp.eq.s32	%p5, %r19, 0;
@%p5 bra BB151_8;

ld.local.u32 %r30, [%rd3+108];
mad.lo.s32 %r39, %r30, %r14, %r39;

BB151_8:
mul.lo.s32 %r31, %r9, %r11;
mul.lo.s32 %r32, %r5, %r11;
mad.lo.s32 %r33, %r8, %r14, %r31;
mad.lo.s32 %r17, %r4, %r14, %r32;
mul.wide.u32 %rd16, %r33, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p6, %rd8, 0;
@%p6 bra BB151_10;

mul.wide.s32 %rd18, %r19, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p7, %rd8, %rd20;
@%p7 bra BB151_11;

BB151_10:
mov.u64 %rd21, $str2;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T2180;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r34, 151;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r34;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB151_11:
mul.wide.s32 %rd28, %r19, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r39;
add.s64 %rd33, %rd31, %rd32;
and.b64 %rd34, %rd33, 4294967295;
ld.local.u64 %rd35, [%rd3];
shl.b64 %rd36, %rd34, 3;
add.s64 %rd37, %rd35, %rd36;
mul.wide.u32 %rd38, %r17, 8;
add.s64 %rd39, %rd6, %rd38;
ld.global.f64 %fd1, [%rd39];
atom.add.f64 %fd2, [%rd37], %fd1;
mov.u32 %r36, %nctaid.x;
mad.lo.s32 %r38, %r36, %r22, %r38;
setp.lt.u32	%p8, %r38, %r20;
@%p8 bra BB151_4;

BB151_12:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot152[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b32 %r<54>;
.reg .f64 %fd<3>;
.reg .b64 %rd<41>;


mov.u64 %rd40, __local_depot152;
cvta.local.u64 %SP, %rd40;
ld.param.u32 %r26, [_Z29THCudaTensor_scatterAddKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r27, [_Z29THCudaTensor_scatterAddKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd4, _Z29THCudaTensor_scatterAddKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjdLi3EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd9, %SP, 0;
cvta.to.local.u64 %rd3, %rd9;
mov.u32 %r51, 0;
mov.pred %p1, 0;
@%p1 bra BB152_2;

BB152_1:
mul.wide.s32 %rd10, %r51, 8;
add.s64 %rd11, %rd4, %rd10;
ld.param.u64 %rd12, [%rd11];
add.s64 %rd13, %rd3, %rd10;
st.local.u64 [%rd13], %rd12;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p2, %r51, 27;
@%p2 bra BB152_1;

BB152_2:
mov.u32 %r29, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r52, %r29, %r30, %r31;
setp.ge.u32	%p3, %r52, %r27;
@%p3 bra BB152_14;

ld.param.u64 %rd14, [%rd1];
cvta.to.global.u64 %rd6, %rd14;
ld.param.u32 %r4, [%rd1+108];
ld.param.v2.u32 {%r32, %r33}, [%rd1+112];
ld.param.u64 %rd15, [%rd2];
cvta.to.global.u64 %rd7, %rd15;
ld.param.v2.u32 {%r34, %r35}, [%rd2+8];
ld.param.u32 %r9, [%rd2+16];
ld.param.u32 %r10, [%rd2+108];
ld.param.v2.u32 {%r36, %r37}, [%rd2+112];

BB152_4:
rem.u32 %r14, %r52, %r9;
setp.eq.s32	%p4, %r26, 2;
mov.u32 %r53, 0;
@%p4 bra BB152_6;

ld.local.u32 %r39, [%rd3+116];
mul.lo.s32 %r53, %r39, %r14;

BB152_6:
div.u32 %r17, %r52, %r9;
rem.u32 %r18, %r17, %r35;
setp.eq.s32	%p5, %r26, 1;
@%p5 bra BB152_8;

ld.local.u32 %r40, [%rd3+112];
mad.lo.s32 %r53, %r40, %r18, %r53;

BB152_8:
div.u32 %r41, %r17, %r35;
rem.u32 %r21, %r41, %r34;
setp.eq.s32	%p6, %r26, 0;
@%p6 bra BB152_10;

ld.local.u32 %r42, [%rd3+108];
mad.lo.s32 %r53, %r42, %r21, %r53;

BB152_10:
mul.lo.s32 %r43, %r37, %r14;
mul.lo.s32 %r44, %r33, %r14;
mad.lo.s32 %r45, %r36, %r18, %r43;
mad.lo.s32 %r46, %r32, %r18, %r44;
mad.lo.s32 %r47, %r10, %r21, %r45;
mad.lo.s32 %r24, %r4, %r21, %r46;
mul.wide.u32 %rd16, %r47, 8;
add.s64 %rd17, %rd7, %rd16;
ld.global.u64 %rd8, [%rd17];
setp.lt.s64	%p7, %rd8, 0;
@%p7 bra BB152_12;

mul.wide.s32 %rd18, %r26, 4;
add.s64 %rd19, %rd3, %rd18;
ld.local.u32 %rd20, [%rd19+8];
setp.lt.s64	%p8, %rd8, %rd20;
@%p8 bra BB152_13;

BB152_12:
mov.u64 %rd21, $str2;
cvta.global.u64 %rd22, %rd21;
mov.u64 %rd23, $str1;
cvta.global.u64 %rd24, %rd23;
mov.u64 %rd25, __T2181;
cvta.global.u64 %rd26, %rd25;
mov.u32 %r48, 151;
mov.u64 %rd27, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd22;
.param .b64 param1;
st.param.b64	[param1+0], %rd24;
.param .b32 param2;
st.param.b32	[param2+0], %r48;
.param .b64 param3;
st.param.b64	[param3+0], %rd26;
.param .b64 param4;
st.param.b64	[param4+0], %rd27;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB152_13:
mul.wide.s32 %rd28, %r26, 4;
add.s64 %rd29, %rd3, %rd28;
ld.local.u32 %rd30, [%rd29+108];
mul.lo.s64 %rd31, %rd30, %rd8;
cvt.u64.u32	%rd32, %r53;
add.s64 %rd33, %rd31, %rd32;
and.b64 %rd34, %rd33, 4294967295;
ld.local.u64 %rd35, [%rd3];
shl.b64 %rd36, %rd34, 3;
add.s64 %rd37, %rd35, %rd36;
mul.wide.u32 %rd38, %r24, 8;
add.s64 %rd39, %rd6, %rd38;
ld.global.f64 %fd1, [%rd39];
atom.add.f64 %fd2, [%rd37], %fd1;
mov.u32 %r50, %nctaid.x;
mad.lo.s32 %r52, %r50, %r29, %r52;
setp.lt.u32	%p9, %r52, %r27;
@%p9 bra BB152_4;

BB152_14:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[216],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[216],
.param .u32 _Z29THCudaTensor_scatterAddKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u32 _Z29THCudaTensor_scatterAddKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot153[648];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b32 %r<63>;
.reg .f64 %fd<3>;
.reg .b64 %rd<70>;


mov.u64 %rd69, __local_depot153;
cvta.local.u64 %SP, %rd69;
ld.param.u32 %r28, [_Z29THCudaTensor_scatterAddKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u32 %r29, [_Z29THCudaTensor_scatterAddKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z29THCudaTensor_scatterAddKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelIjdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd20, %SP, 216;
cvta.to.local.u64 %rd3, %rd20;
add.u64 %rd21, %SP, 432;
cvta.to.local.u64 %rd4, %rd21;
add.u64 %rd22, %SP, 0;
cvta.to.local.u64 %rd5, %rd22;
mov.u32 %r47, 0;
mov.pred %p1, 0;
@%p1 bra BB153_2;

BB153_1:
mul.wide.s32 %rd23, %r47, 8;
add.s64 %rd24, %rd6, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r47, %r47, 1;
setp.lt.u32	%p2, %r47, 27;
@%p2 bra BB153_1;

BB153_2:
mov.u32 %r48, 0;
@%p1 bra BB153_4;

BB153_3:
mul.wide.s32 %rd27, %r48, 8;
add.s64 %rd28, %rd1, %rd27;
ld.param.u64 %rd29, [%rd28];
add.s64 %rd30, %rd4, %rd27;
st.local.u64 [%rd30], %rd29;
add.s32 %r48, %r48, 1;
setp.lt.u32	%p4, %r48, 27;
@%p4 bra BB153_3;

BB153_4:
mov.u32 %r49, 0;
@%p1 bra BB153_6;

BB153_5:
mul.wide.s32 %rd31, %r49, 8;
add.s64 %rd32, %rd2, %rd31;
ld.param.u64 %rd33, [%rd32];
add.s64 %rd34, %rd5, %rd31;
st.local.u64 [%rd34], %rd33;
add.s32 %r49, %r49, 1;
setp.lt.u32	%p6, %r49, 27;
@%p6 bra BB153_5;

BB153_6:
mov.u32 %r33, %ntid.x;
mov.u32 %r34, %ctaid.x;
mov.u32 %r35, %tid.x;
mad.lo.s32 %r54, %r33, %r34, %r35;
setp.ge.u32	%p7, %r54, %r29;
@%p7 bra BB153_17;

ld.local.u32 %r8, [%rd5+208];

BB153_8:
mov.u32 %r52, %r54;
mov.u32 %r9, %r52;
mul.wide.s32 %rd66, %r8, 4;
add.s32 %r40, %r8, -1;
sub.s32 %r50, %r40, %r28;
mov.u32 %r60, 0;
mov.u64 %rd68, 0;
mov.u64 %rd67, %rd68;
mov.u32 %r61, %r60;
mov.u32 %r56, %r60;
mov.u32 %r55, %r60;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r51, %r8;
mov.u32 %r53, %r9;
@%p8 bra BB153_13;

BB153_9:
mov.u32 %r57, %r61;
mov.u32 %r62, %r57;
mov.u32 %r13, %r53;
mov.u32 %r12, %r51;
add.s64 %rd37, %rd4, %rd66;
add.s32 %r17, %r12, -1;
add.s64 %rd38, %rd5, %rd66;
ld.local.u32 %r18, [%rd38+4];
rem.u32 %r19, %r13, %r18;
ld.local.u32 %r41, [%rd38+104];
mad.lo.s32 %r55, %r41, %r19, %r55;
ld.local.u32 %r42, [%rd37+104];
mad.lo.s32 %r56, %r42, %r19, %r56;
setp.eq.s32	%p9, %r50, 0;
@%p9 bra BB153_11;

add.s64 %rd39, %rd3, %rd66;
ld.local.u32 %r43, [%rd39+104];
mad.lo.s32 %r62, %r43, %r19, %r62;

BB153_11:
mov.u32 %r61, %r62;
div.u32 %r24, %r13, %r18;
add.s32 %r50, %r50, -1;
add.s64 %rd66, %rd66, -4;
setp.gt.s32	%p10, %r17, 0;
mov.u32 %r51, %r17;
mov.u32 %r53, %r24;
@%p10 bra BB153_9;

cvt.u64.u32	%rd67, %r55;
cvt.u64.u32	%rd68, %r56;
mov.u32 %r60, %r61;

BB153_13:
ld.local.u64 %rd40, [%rd5];
shl.b64 %rd41, %rd67, 3;
add.s64 %rd42, %rd40, %rd41;
ld.u64 %rd19, [%rd42];
setp.lt.s64	%p11, %rd19, 0;
@%p11 bra BB153_15;

mul.wide.s32 %rd43, %r28, 4;
add.s64 %rd44, %rd3, %rd43;
ld.local.u32 %rd45, [%rd44+8];
setp.lt.s64	%p12, %rd19, %rd45;
@%p12 bra BB153_16;

BB153_15:
mov.u64 %rd46, $str2;
cvta.global.u64 %rd47, %rd46;
mov.u64 %rd48, $str1;
cvta.global.u64 %rd49, %rd48;
mov.u64 %rd50, __T2182;
cvta.global.u64 %rd51, %rd50;
mov.u32 %r44, 151;
mov.u64 %rd52, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd47;
.param .b64 param1;
st.param.b64	[param1+0], %rd49;
.param .b32 param2;
st.param.b32	[param2+0], %r44;
.param .b64 param3;
st.param.b64	[param3+0], %rd51;
.param .b64 param4;
st.param.b64	[param4+0], %rd52;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB153_16:
mul.wide.s32 %rd53, %r28, 4;
add.s64 %rd54, %rd3, %rd53;
ld.local.u32 %rd55, [%rd54+108];
mul.lo.s64 %rd56, %rd55, %rd19;
cvt.u64.u32	%rd57, %r60;
add.s64 %rd58, %rd56, %rd57;
ld.local.u64 %rd59, [%rd3];
shl.b64 %rd60, %rd58, 3;
and.b64 %rd61, %rd60, 34359738360;
add.s64 %rd62, %rd59, %rd61;
ld.local.u64 %rd63, [%rd4];
shl.b64 %rd64, %rd68, 3;
add.s64 %rd65, %rd63, %rd64;
ld.f64 %fd1, [%rd65];
atom.add.f64 %fd2, [%rd62], %fd1;
mov.u32 %r46, %nctaid.x;
mad.lo.s32 %r54, %r46, %r33, %r9;
setp.lt.u32	%p13, %r54, %r29;
@%p13 bra BB153_8;

BB153_17:
ret;
}


.visible .entry _Z29THCudaTensor_scatterAddKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2_(
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0[416],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1[416],
.param .align 8 .b8 _Z29THCudaTensor_scatterAddKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2[416],
.param .u32 _Z29THCudaTensor_scatterAddKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3,
.param .u64 _Z29THCudaTensor_scatterAddKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4
)
{
.local .align 8 .b8 __local_depot154[1248];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<16>;
.reg .b32 %r<37>;
.reg .f64 %fd<3>;
.reg .b64 %rd<117>;


mov.u64 %rd116, __local_depot154;
cvta.local.u64 %SP, %rd116;
ld.param.u32 %r13, [_Z29THCudaTensor_scatterAddKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_3];
ld.param.u64 %rd38, [_Z29THCudaTensor_scatterAddKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_4];
mov.u64 %rd6, _Z29THCudaTensor_scatterAddKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_0;
mov.u64 %rd1, _Z29THCudaTensor_scatterAddKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_1;
mov.u64 %rd2, _Z29THCudaTensor_scatterAddKernelImdLin1EEv10TensorInfoIT0_T_ES3_S0_IlS2_EiS2__param_2;
add.u64 %rd39, %SP, 416;
cvta.to.local.u64 %rd3, %rd39;
add.u64 %rd40, %SP, 832;
cvta.to.local.u64 %rd4, %rd40;
add.u64 %rd41, %SP, 0;
cvta.to.local.u64 %rd5, %rd41;
mov.u32 %r32, 0;
mov.pred %p1, 0;
@%p1 bra BB154_2;

BB154_1:
mul.wide.s32 %rd42, %r32, 8;
add.s64 %rd43, %rd6, %rd42;
ld.param.u64 %rd44, [%rd43];
add.s64 %rd45, %rd3, %rd42;
st.local.u64 [%rd45], %rd44;
add.s32 %r32, %r32, 1;
setp.lt.u32	%p2, %r32, 52;
@%p2 bra BB154_1;

BB154_2:
mov.u32 %r33, 0;
@%p1 bra BB154_4;

BB154_3:
mul.wide.s32 %rd46, %r33, 8;
add.s64 %rd47, %rd1, %rd46;
ld.param.u64 %rd48, [%rd47];
add.s64 %rd49, %rd4, %rd46;
st.local.u64 [%rd49], %rd48;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p4, %r33, 52;
@%p4 bra BB154_3;

BB154_4:
mov.u32 %r34, 0;
@%p1 bra BB154_6;

BB154_5:
mul.wide.s32 %rd50, %r34, 8;
add.s64 %rd51, %rd2, %rd50;
ld.param.u64 %rd52, [%rd51];
add.s64 %rd53, %rd5, %rd50;
st.local.u64 [%rd53], %rd52;
add.s32 %r34, %r34, 1;
setp.lt.u32	%p6, %r34, 52;
@%p6 bra BB154_5;

BB154_6:
mov.u32 %r17, %ntid.x;
mov.u32 %r18, %ctaid.x;
mov.u32 %r19, %tid.x;
mad.lo.s32 %r20, %r17, %r18, %r19;
cvt.u64.u32	%rd102, %r20;
setp.ge.u64	%p7, %rd102, %rd38;
@%p7 bra BB154_22;

ld.local.u32 %r7, [%rd5+408];

BB154_8:
mov.u64 %rd98, %rd102;
mov.u64 %rd13, %rd98;
mul.wide.s32 %rd97, %r7, 8;
add.s32 %r21, %r7, -1;
sub.s32 %r35, %r21, %r13;
mov.u64 %rd113, 0;
mov.u64 %rd108, %rd113;
mov.u64 %rd105, %rd113;
mov.u64 %rd114, %rd113;
mov.u64 %rd109, %rd113;
mov.u64 %rd106, %rd113;
setp.lt.s32	%p8, %r7, 1;
mov.u32 %r36, %r7;
mov.u64 %rd100, %rd13;
@%p8 bra BB154_18;

BB154_9:
mov.u64 %rd115, %rd114;
mov.u64 %rd16, %rd100;
mov.u32 %r10, %r36;
add.s32 %r11, %r10, -1;
add.s64 %rd20, %rd5, %rd97;
ld.local.u64 %rd21, [%rd20];
or.b64 %rd60, %rd16, %rd21;
and.b64 %rd61, %rd60, -4294967296;
setp.eq.s64	%p9, %rd61, 0;
@%p9 bra BB154_11;
bra.uni BB154_10;

BB154_11:
cvt.u32.u64	%r22, %rd21;
cvt.u32.u64	%r23, %rd16;
rem.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd103, %r24;
bra.uni BB154_12;

BB154_10:
rem.u64 %rd103, %rd16, %rd21;

BB154_12:
add.s64 %rd62, %rd4, %rd97;
ld.local.u64 %rd63, [%rd20+200];
mul.lo.s64 %rd64, %rd63, %rd103;
add.s64 %rd106, %rd64, %rd106;
ld.local.u64 %rd65, [%rd62+200];
mul.lo.s64 %rd66, %rd65, %rd103;
add.s64 %rd109, %rd66, %rd109;
setp.eq.s32	%p10, %r35, 0;
@%p10 bra BB154_14;

add.s64 %rd67, %rd3, %rd97;
ld.local.u64 %rd68, [%rd67+200];
mul.lo.s64 %rd69, %rd68, %rd103;
add.s64 %rd115, %rd69, %rd115;

BB154_14:
mov.u64 %rd114, %rd115;
@%p9 bra BB154_16;
bra.uni BB154_15;

BB154_16:
cvt.u32.u64	%r25, %rd21;
cvt.u32.u64	%r26, %rd16;
div.u32 %r27, %r26, %r25;
cvt.u64.u32	%rd101, %r27;
bra.uni BB154_17;

BB154_15:
div.u64 %rd101, %rd16, %rd21;

BB154_17:
mov.u64 %rd31, %rd101;
add.s32 %r35, %r35, -1;
add.s64 %rd97, %rd97, -8;
setp.gt.s32	%p12, %r11, 0;
mov.u32 %r36, %r11;
mov.u64 %rd100, %rd31;
mov.u64 %rd105, %rd106;
mov.u64 %rd108, %rd109;
mov.u64 %rd113, %rd114;
@%p12 bra BB154_9;

BB154_18:
ld.local.u64 %rd72, [%rd5];
shl.b64 %rd73, %rd105, 3;
add.s64 %rd74, %rd72, %rd73;
ld.u64 %rd36, [%rd74];
setp.lt.s64	%p13, %rd36, 0;
@%p13 bra BB154_20;

mul.wide.s32 %rd75, %r13, 8;
add.s64 %rd76, %rd3, %rd75;
ld.local.u64 %rd77, [%rd76+8];
setp.lt.u64	%p14, %rd36, %rd77;
@%p14 bra BB154_21;

BB154_20:
mov.u64 %rd78, $str2;
cvta.global.u64 %rd79, %rd78;
mov.u64 %rd80, $str1;
cvta.global.u64 %rd81, %rd80;
mov.u64 %rd82, __T2183;
cvta.global.u64 %rd83, %rd82;
mov.u32 %r28, 151;
mov.u64 %rd84, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd79;
.param .b64 param1;
st.param.b64	[param1+0], %rd81;
.param .b32 param2;
st.param.b32	[param2+0], %r28;
.param .b64 param3;
st.param.b64	[param3+0], %rd83;
.param .b64 param4;
st.param.b64	[param4+0], %rd84;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB154_21:
mul.wide.s32 %rd85, %r13, 8;
add.s64 %rd86, %rd3, %rd85;
ld.local.u64 %rd87, [%rd86+208];
mul.lo.s64 %rd88, %rd87, %rd36;
add.s64 %rd89, %rd88, %rd113;
ld.local.u64 %rd90, [%rd3];
shl.b64 %rd91, %rd89, 3;
add.s64 %rd92, %rd90, %rd91;
ld.local.u64 %rd93, [%rd4];
shl.b64 %rd94, %rd108, 3;
add.s64 %rd95, %rd93, %rd94;
ld.f64 %fd1, [%rd95];
atom.add.f64 %fd2, [%rd92], %fd1;
mov.u32 %r30, %nctaid.x;
mul.lo.s32 %r31, %r30, %r17;
cvt.u64.u32	%rd96, %r31;
add.s64 %rd102, %rd96, %rd13;
setp.lt.u64	%p15, %rd102, %rd38;
@%p15 bra BB154_8;

BB154_22:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjdLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjdLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjdLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .f64 _Z30THCudaTensor_scatterFillKernelIjdLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjdLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjdLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot155[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b32 %r<23>;
.reg .f64 %fd<2>;
.reg .b64 %rd<38>;


mov.u64 %rd37, __local_depot155;
cvta.local.u64 %SP, %rd37;
ld.param.f64 %fd1, [_Z30THCudaTensor_scatterFillKernelIjdLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r11, [_Z30THCudaTensor_scatterFillKernelIjdLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r12, [_Z30THCudaTensor_scatterFillKernelIjdLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjdLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjdLi1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd2, %rd10;
mov.u32 %r21, 0;
mov.pred %p1, 0;
@%p1 bra BB155_2;

BB155_1:
mul.wide.s32 %rd11, %r21, 8;
add.s64 %rd12, %rd3, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd2, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r21, %r21, 1;
setp.lt.u32	%p2, %r21, 27;
@%p2 bra BB155_1;

BB155_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r14, %ctaid.x;
mov.u32 %r15, %tid.x;
mad.lo.s32 %r22, %r3, %r14, %r15;
setp.ge.u32	%p3, %r22, %r12;
@%p3 bra BB155_10;

ld.param.u64 %rd15, [%rd1];
cvta.to.global.u64 %rd5, %rd15;
ld.param.u32 %r5, [%rd1+8];
ld.param.u32 %r6, [%rd1+108];
mul.wide.s32 %rd16, %r11, 4;
add.s64 %rd17, %rd2, %rd16;
add.s64 %rd6, %rd17, 8;
mov.u32 %r16, %nctaid.x;
mul.lo.s32 %r7, %r16, %r3;

BB155_4:
rem.u32 %r9, %r22, %r5;
setp.eq.s32	%p4, %r11, 0;
mov.u64 %rd36, 0;
@%p4 bra BB155_6;

ld.local.u32 %r17, [%rd2+108];
mul.lo.s32 %r18, %r17, %r9;
cvt.u64.u32	%rd36, %r18;

BB155_6:
mul.lo.s32 %r19, %r6, %r9;
mul.wide.u32 %rd19, %r19, 8;
add.s64 %rd20, %rd5, %rd19;
ld.global.u64 %rd9, [%rd20];
setp.lt.s64	%p5, %rd9, 0;
@%p5 bra BB155_8;

ld.local.u32 %rd21, [%rd6];
setp.lt.s64	%p6, %rd9, %rd21;
@%p6 bra BB155_9;

BB155_8:
mov.u64 %rd22, $str2;
cvta.global.u64 %rd23, %rd22;
mov.u64 %rd24, $str1;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, __T2184;
cvta.global.u64 %rd27, %rd26;
mov.u32 %r20, 176;
mov.u64 %rd28, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd23;
.param .b64 param1;
st.param.b64	[param1+0], %rd25;
.param .b32 param2;
st.param.b32	[param2+0], %r20;
.param .b64 param3;
st.param.b64	[param3+0], %rd27;
.param .b64 param4;
st.param.b64	[param4+0], %rd28;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB155_9:
ld.local.u32 %rd29, [%rd6+100];
mul.lo.s64 %rd30, %rd29, %rd9;
add.s64 %rd31, %rd30, %rd36;
and.b64 %rd32, %rd31, 4294967295;
ld.local.u64 %rd33, [%rd2];
shl.b64 %rd34, %rd32, 3;
add.s64 %rd35, %rd33, %rd34;
st.f64 [%rd35], %fd1;
add.s32 %r22, %r7, %r22;
setp.lt.u32	%p7, %r22, %r12;
@%p7 bra BB155_4;

BB155_10:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjdLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjdLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjdLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .f64 _Z30THCudaTensor_scatterFillKernelIjdLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjdLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjdLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot156[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b32 %r<36>;
.reg .f64 %fd<2>;
.reg .b64 %rd<36>;


mov.u64 %rd35, __local_depot156;
cvta.local.u64 %SP, %rd35;
ld.param.f64 %fd1, [_Z30THCudaTensor_scatterFillKernelIjdLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r16, [_Z30THCudaTensor_scatterFillKernelIjdLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r17, [_Z30THCudaTensor_scatterFillKernelIjdLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjdLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjdLi2EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd7, %SP, 0;
cvta.to.local.u64 %rd2, %rd7;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB156_2;

BB156_1:
mul.wide.s32 %rd8, %r33, 8;
add.s64 %rd9, %rd3, %rd8;
ld.param.u64 %rd10, [%rd9];
add.s64 %rd11, %rd2, %rd8;
st.local.u64 [%rd11], %rd10;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB156_1;

BB156_2:
mov.u32 %r19, %ntid.x;
mov.u32 %r20, %ctaid.x;
mov.u32 %r21, %tid.x;
mad.lo.s32 %r34, %r19, %r20, %r21;
setp.ge.u32	%p3, %r34, %r17;
@%p3 bra BB156_12;

ld.param.u64 %rd12, [%rd1];
cvta.to.global.u64 %rd5, %rd12;
ld.param.v2.u32 {%r22, %r23}, [%rd1+8];
ld.param.u32 %r6, [%rd1+108];
ld.param.u32 %r7, [%rd1+112];

BB156_4:
rem.u32 %r9, %r34, %r23;
setp.eq.s32	%p4, %r16, 1;
mov.u32 %r35, 0;
@%p4 bra BB156_6;

ld.local.u32 %r25, [%rd2+112];
mul.lo.s32 %r35, %r25, %r9;

BB156_6:
div.u32 %r26, %r34, %r23;
rem.u32 %r12, %r26, %r22;
setp.eq.s32	%p5, %r16, 0;
@%p5 bra BB156_8;

ld.local.u32 %r27, [%rd2+108];
mad.lo.s32 %r35, %r27, %r12, %r35;

BB156_8:
mul.lo.s32 %r28, %r7, %r9;
mad.lo.s32 %r29, %r6, %r12, %r28;
mul.wide.u32 %rd13, %r29, 8;
add.s64 %rd14, %rd5, %rd13;
ld.global.u64 %rd6, [%rd14];
setp.lt.s64	%p6, %rd6, 0;
@%p6 bra BB156_10;

mul.wide.s32 %rd15, %r16, 4;
add.s64 %rd16, %rd2, %rd15;
ld.local.u32 %rd17, [%rd16+8];
setp.lt.s64	%p7, %rd6, %rd17;
@%p7 bra BB156_11;

BB156_10:
mov.u64 %rd18, $str2;
cvta.global.u64 %rd19, %rd18;
mov.u64 %rd20, $str1;
cvta.global.u64 %rd21, %rd20;
mov.u64 %rd22, __T2185;
cvta.global.u64 %rd23, %rd22;
mov.u32 %r30, 176;
mov.u64 %rd24, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd19;
.param .b64 param1;
st.param.b64	[param1+0], %rd21;
.param .b32 param2;
st.param.b32	[param2+0], %r30;
.param .b64 param3;
st.param.b64	[param3+0], %rd23;
.param .b64 param4;
st.param.b64	[param4+0], %rd24;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB156_11:
mul.wide.s32 %rd25, %r16, 4;
add.s64 %rd26, %rd2, %rd25;
ld.local.u32 %rd27, [%rd26+108];
mul.lo.s64 %rd28, %rd27, %rd6;
cvt.u64.u32	%rd29, %r35;
add.s64 %rd30, %rd28, %rd29;
and.b64 %rd31, %rd30, 4294967295;
ld.local.u64 %rd32, [%rd2];
shl.b64 %rd33, %rd31, 3;
add.s64 %rd34, %rd32, %rd33;
st.f64 [%rd34], %fd1;
mov.u32 %r32, %nctaid.x;
mad.lo.s32 %r34, %r32, %r19, %r34;
setp.lt.u32	%p8, %r34, %r17;
@%p8 bra BB156_4;

BB156_12:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjdLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjdLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjdLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .f64 _Z30THCudaTensor_scatterFillKernelIjdLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjdLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjdLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot157[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .f64 %fd<2>;
.reg .b64 %rd<36>;


mov.u64 %rd35, __local_depot157;
cvta.local.u64 %SP, %rd35;
ld.param.f64 %fd1, [_Z30THCudaTensor_scatterFillKernelIjdLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r23, [_Z30THCudaTensor_scatterFillKernelIjdLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r24, [_Z30THCudaTensor_scatterFillKernelIjdLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd3, _Z30THCudaTensor_scatterFillKernelIjdLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjdLi3EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd7, %SP, 0;
cvta.to.local.u64 %rd2, %rd7;
mov.u32 %r43, 0;
mov.pred %p1, 0;
@%p1 bra BB157_2;

BB157_1:
mul.wide.s32 %rd8, %r43, 8;
add.s64 %rd9, %rd3, %rd8;
ld.param.u64 %rd10, [%rd9];
add.s64 %rd11, %rd2, %rd8;
st.local.u64 [%rd11], %rd10;
add.s32 %r43, %r43, 1;
setp.lt.u32	%p2, %r43, 27;
@%p2 bra BB157_1;

BB157_2:
mov.u32 %r26, %ntid.x;
mov.u32 %r27, %ctaid.x;
mov.u32 %r28, %tid.x;
mad.lo.s32 %r44, %r26, %r27, %r28;
setp.ge.u32	%p3, %r44, %r24;
@%p3 bra BB157_14;

ld.param.u64 %rd12, [%rd1];
cvta.to.global.u64 %rd5, %rd12;
ld.param.v2.u32 {%r29, %r30}, [%rd1+8];
ld.param.u32 %r6, [%rd1+16];
ld.param.u32 %r7, [%rd1+108];
ld.param.v2.u32 {%r31, %r32}, [%rd1+112];

BB157_4:
rem.u32 %r11, %r44, %r6;
setp.eq.s32	%p4, %r23, 2;
mov.u32 %r45, 0;
@%p4 bra BB157_6;

ld.local.u32 %r34, [%rd2+116];
mul.lo.s32 %r45, %r34, %r11;

BB157_6:
div.u32 %r14, %r44, %r6;
rem.u32 %r15, %r14, %r30;
setp.eq.s32	%p5, %r23, 1;
@%p5 bra BB157_8;

ld.local.u32 %r35, [%rd2+112];
mad.lo.s32 %r45, %r35, %r15, %r45;

BB157_8:
mul.lo.s32 %r36, %r32, %r11;
mad.lo.s32 %r18, %r31, %r15, %r36;
div.u32 %r37, %r14, %r30;
rem.u32 %r19, %r37, %r29;
setp.eq.s32	%p6, %r23, 0;
@%p6 bra BB157_10;

ld.local.u32 %r38, [%rd2+108];
mad.lo.s32 %r45, %r38, %r19, %r45;

BB157_10:
mad.lo.s32 %r39, %r7, %r19, %r18;
mul.wide.u32 %rd13, %r39, 8;
add.s64 %rd14, %rd5, %rd13;
ld.global.u64 %rd6, [%rd14];
setp.lt.s64	%p7, %rd6, 0;
@%p7 bra BB157_12;

mul.wide.s32 %rd15, %r23, 4;
add.s64 %rd16, %rd2, %rd15;
ld.local.u32 %rd17, [%rd16+8];
setp.lt.s64	%p8, %rd6, %rd17;
@%p8 bra BB157_13;

BB157_12:
mov.u64 %rd18, $str2;
cvta.global.u64 %rd19, %rd18;
mov.u64 %rd20, $str1;
cvta.global.u64 %rd21, %rd20;
mov.u64 %rd22, __T2186;
cvta.global.u64 %rd23, %rd22;
mov.u32 %r40, 176;
mov.u64 %rd24, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd19;
.param .b64 param1;
st.param.b64	[param1+0], %rd21;
.param .b32 param2;
st.param.b32	[param2+0], %r40;
.param .b64 param3;
st.param.b64	[param3+0], %rd23;
.param .b64 param4;
st.param.b64	[param4+0], %rd24;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB157_13:
mul.wide.s32 %rd25, %r23, 4;
add.s64 %rd26, %rd2, %rd25;
ld.local.u32 %rd27, [%rd26+108];
mul.lo.s64 %rd28, %rd27, %rd6;
cvt.u64.u32	%rd29, %r45;
add.s64 %rd30, %rd28, %rd29;
and.b64 %rd31, %rd30, 4294967295;
ld.local.u64 %rd32, [%rd2];
shl.b64 %rd33, %rd31, 3;
add.s64 %rd34, %rd32, %rd33;
st.f64 [%rd34], %fd1;
mov.u32 %r42, %nctaid.x;
mad.lo.s32 %r44, %r42, %r26, %r44;
setp.lt.u32	%p9, %r44, %r24;
@%p9 bra BB157_4;

BB157_14:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelIjdLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjdLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[216],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelIjdLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[216],
.param .f64 _Z30THCudaTensor_scatterFillKernelIjdLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjdLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u32 _Z30THCudaTensor_scatterFillKernelIjdLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot158[432];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<12>;
.reg .b32 %r<54>;
.reg .f64 %fd<2>;
.reg .b64 %rd<63>;


mov.u64 %rd62, __local_depot158;
cvta.local.u64 %SP, %rd62;
ld.param.f64 %fd1, [_Z30THCudaTensor_scatterFillKernelIjdLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r24, [_Z30THCudaTensor_scatterFillKernelIjdLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u32 %r25, [_Z30THCudaTensor_scatterFillKernelIjdLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd4, _Z30THCudaTensor_scatterFillKernelIjdLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelIjdLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd17, %SP, 216;
cvta.to.local.u64 %rd2, %rd17;
add.u64 %rd18, %SP, 0;
cvta.to.local.u64 %rd3, %rd18;
mov.u32 %r40, 0;
mov.pred %p1, 0;
@%p1 bra BB158_2;

BB158_1:
mul.wide.s32 %rd19, %r40, 8;
add.s64 %rd20, %rd4, %rd19;
ld.param.u64 %rd21, [%rd20];
add.s64 %rd22, %rd2, %rd19;
st.local.u64 [%rd22], %rd21;
add.s32 %r40, %r40, 1;
setp.lt.u32	%p2, %r40, 27;
@%p2 bra BB158_1;

BB158_2:
mov.u32 %r41, 0;
@%p1 bra BB158_4;

BB158_3:
mul.wide.s32 %rd23, %r41, 8;
add.s64 %rd24, %rd1, %rd23;
ld.param.u64 %rd25, [%rd24];
add.s64 %rd26, %rd3, %rd23;
st.local.u64 [%rd26], %rd25;
add.s32 %r41, %r41, 1;
setp.lt.u32	%p4, %r41, 27;
@%p4 bra BB158_3;

BB158_4:
mov.u32 %r28, %ntid.x;
mov.u32 %r29, %ctaid.x;
mov.u32 %r30, %tid.x;
mad.lo.s32 %r46, %r28, %r29, %r30;
setp.ge.u32	%p5, %r46, %r25;
@%p5 bra BB158_15;

ld.local.u32 %r6, [%rd3+208];

BB158_6:
mov.u32 %r44, %r46;
mov.u32 %r7, %r44;
cvt.s64.s32	%rd28, %r6;
not.b64 %rd29, %rd28;
mov.u64 %rd30, -26;
sub.s64 %rd31, %rd30, %rd28;
add.s32 %r34, %r6, -1;
sub.s32 %r42, %r34, %r24;
neg.s64 %rd59, %rd29;
neg.s64 %rd60, %rd31;
mov.u32 %r51, 0;
mov.u64 %rd61, 0;
mov.u32 %r52, %r51;
mov.u32 %r47, %r51;
setp.lt.s32	%p6, %r6, 1;
mov.u32 %r43, %r6;
mov.u32 %r45, %r7;
@%p6 bra BB158_11;

BB158_7:
mov.u32 %r48, %r52;
mov.u32 %r53, %r48;
mov.u32 %r11, %r45;
mov.u32 %r10, %r43;
add.s32 %r14, %r10, -1;
shl.b64 %rd32, %rd59, 2;
add.s64 %rd33, %rd3, %rd32;
ld.local.u32 %r15, [%rd33];
rem.u32 %r16, %r11, %r15;
ld.local.u32 %r35, [%rd33+100];
mad.lo.s32 %r47, %r35, %r16, %r47;
setp.eq.s32	%p7, %r42, 0;
@%p7 bra BB158_9;

shl.b64 %rd34, %rd60, 2;
add.s64 %rd35, %rd2, %rd34;
ld.local.u32 %r36, [%rd35];
mad.lo.s32 %r53, %r36, %r16, %r53;

BB158_9:
mov.u32 %r52, %r53;
div.u32 %r20, %r11, %r15;
add.s32 %r42, %r42, -1;
add.s64 %rd60, %rd60, -1;
add.s64 %rd59, %rd59, -1;
setp.gt.s32	%p8, %r14, 0;
mov.u32 %r43, %r14;
mov.u32 %r45, %r20;
@%p8 bra BB158_7;

cvt.u64.u32	%rd61, %r47;
mov.u32 %r51, %r52;

BB158_11:
ld.local.u64 %rd36, [%rd3];
shl.b64 %rd37, %rd61, 3;
add.s64 %rd38, %rd36, %rd37;
ld.u64 %rd16, [%rd38];
setp.lt.s64	%p9, %rd16, 0;
@%p9 bra BB158_13;

mul.wide.s32 %rd39, %r24, 4;
add.s64 %rd40, %rd2, %rd39;
ld.local.u32 %rd41, [%rd40+8];
setp.lt.s64	%p10, %rd16, %rd41;
@%p10 bra BB158_14;

BB158_13:
mov.u64 %rd42, $str2;
cvta.global.u64 %rd43, %rd42;
mov.u64 %rd44, $str1;
cvta.global.u64 %rd45, %rd44;
mov.u64 %rd46, __T2187;
cvta.global.u64 %rd47, %rd46;
mov.u32 %r37, 176;
mov.u64 %rd48, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd43;
.param .b64 param1;
st.param.b64	[param1+0], %rd45;
.param .b32 param2;
st.param.b32	[param2+0], %r37;
.param .b64 param3;
st.param.b64	[param3+0], %rd47;
.param .b64 param4;
st.param.b64	[param4+0], %rd48;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB158_14:
mul.wide.s32 %rd49, %r24, 4;
add.s64 %rd50, %rd2, %rd49;
ld.local.u32 %rd51, [%rd50+108];
mul.lo.s64 %rd52, %rd51, %rd16;
cvt.u64.u32	%rd53, %r51;
add.s64 %rd54, %rd52, %rd53;
and.b64 %rd55, %rd54, 4294967295;
ld.local.u64 %rd56, [%rd2];
shl.b64 %rd57, %rd55, 3;
add.s64 %rd58, %rd56, %rd57;
st.f64 [%rd58], %fd1;
mov.u32 %r39, %nctaid.x;
mad.lo.s32 %r46, %r39, %r28, %r7;
setp.lt.u32	%p11, %r46, %r25;
@%p11 bra BB158_6;

BB158_15:
ret;
}


.visible .entry _Z30THCudaTensor_scatterFillKernelImdLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2_(
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelImdLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0[416],
.param .align 8 .b8 _Z30THCudaTensor_scatterFillKernelImdLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1[416],
.param .f64 _Z30THCudaTensor_scatterFillKernelImdLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2,
.param .u32 _Z30THCudaTensor_scatterFillKernelImdLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3,
.param .u64 _Z30THCudaTensor_scatterFillKernelImdLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4
)
{
.local .align 8 .b8 __local_depot159[832];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b32 %r<33>;
.reg .f64 %fd<2>;
.reg .b64 %rd<99>;


mov.u64 %rd98, __local_depot159;
cvta.local.u64 %SP, %rd98;
ld.param.f64 %fd1, [_Z30THCudaTensor_scatterFillKernelImdLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_2];
ld.param.u32 %r11, [_Z30THCudaTensor_scatterFillKernelImdLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_3];
ld.param.u64 %rd34, [_Z30THCudaTensor_scatterFillKernelImdLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_4];
mov.u64 %rd4, _Z30THCudaTensor_scatterFillKernelImdLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_0;
mov.u64 %rd1, _Z30THCudaTensor_scatterFillKernelImdLin1EEv10TensorInfoIT0_T_ES0_IlS2_ES1_iS2__param_1;
add.u64 %rd35, %SP, 416;
cvta.to.local.u64 %rd2, %rd35;
add.u64 %rd36, %SP, 0;
cvta.to.local.u64 %rd3, %rd36;
mov.u32 %r29, 0;
mov.pred %p1, 0;
@%p1 bra BB159_2;

BB159_1:
mul.wide.s32 %rd37, %r29, 8;
add.s64 %rd38, %rd4, %rd37;
ld.param.u64 %rd39, [%rd38];
add.s64 %rd40, %rd2, %rd37;
st.local.u64 [%rd40], %rd39;
add.s32 %r29, %r29, 1;
setp.lt.u32	%p2, %r29, 52;
@%p2 bra BB159_1;

BB159_2:
mov.u32 %r30, 0;
@%p1 bra BB159_4;

BB159_3:
mul.wide.s32 %rd41, %r30, 8;
add.s64 %rd42, %rd1, %rd41;
ld.param.u64 %rd43, [%rd42];
add.s64 %rd44, %rd3, %rd41;
st.local.u64 [%rd44], %rd43;
add.s32 %r30, %r30, 1;
setp.lt.u32	%p4, %r30, 52;
@%p4 bra BB159_3;

BB159_4:
mov.u32 %r14, %ntid.x;
mov.u32 %r15, %ctaid.x;
mov.u32 %r16, %tid.x;
mad.lo.s32 %r17, %r14, %r15, %r16;
cvt.u64.u32	%rd87, %r17;
setp.ge.u64	%p5, %rd87, %rd34;
@%p5 bra BB159_20;

ld.local.u32 %r5, [%rd3+408];

BB159_6:
mov.u64 %rd83, %rd87;
mov.u64 %rd9, %rd83;
mul.wide.s32 %rd49, %r5, 8;
add.s64 %rd81, %rd3, %rd49;
add.s64 %rd50, %rd49, %rd2;
add.s64 %rd82, %rd50, 200;
add.s32 %r18, %r5, -1;
sub.s32 %r31, %r18, %r11;
mov.u64 %rd95, 0;
mov.u64 %rd90, %rd95;
mov.u64 %rd96, %rd95;
mov.u64 %rd91, %rd95;
setp.lt.s32	%p6, %r5, 1;
mov.u32 %r32, %r5;
mov.u64 %rd85, %rd9;
@%p6 bra BB159_16;

BB159_7:
mov.u64 %rd97, %rd96;
mov.u64 %rd14, %rd85;
mov.u32 %r8, %r32;
add.s32 %r9, %r8, -1;
ld.local.u64 %rd18, [%rd81];
or.b64 %rd51, %rd14, %rd18;
and.b64 %rd52, %rd51, -4294967296;
setp.eq.s64	%p7, %rd52, 0;
@%p7 bra BB159_9;
bra.uni BB159_8;

BB159_9:
cvt.u32.u64	%r19, %rd18;
cvt.u32.u64	%r20, %rd14;
rem.u32 %r21, %r20, %r19;
cvt.u64.u32	%rd88, %r21;
bra.uni BB159_10;

BB159_8:
rem.u64 %rd88, %rd14, %rd18;

BB159_10:
ld.local.u64 %rd53, [%rd81+200];
mul.lo.s64 %rd54, %rd53, %rd88;
add.s64 %rd91, %rd54, %rd91;
setp.eq.s32	%p8, %r31, 0;
@%p8 bra BB159_12;

ld.local.u64 %rd55, [%rd82];
mul.lo.s64 %rd56, %rd55, %rd88;
add.s64 %rd97, %rd56, %rd97;

BB159_12:
mov.u64 %rd96, %rd97;
@%p7 bra BB159_14;
bra.uni BB159_13;

BB159_14:
cvt.u32.u64	%r22, %rd18;
cvt.u32.u64	%r23, %rd14;
div.u32 %r24, %r23, %r22;
cvt.u64.u32	%rd86, %r24;
bra.uni BB159_15;

BB159_13:
div.u64 %rd86, %rd14, %rd18;

BB159_15:
mov.u64 %rd27, %rd86;
add.s32 %r31, %r31, -1;
add.s64 %rd82, %rd82, -8;
add.s64 %rd81, %rd81, -8;
setp.gt.s32	%p10, %r9, 0;
mov.u32 %r32, %r9;
mov.u64 %rd85, %rd27;
mov.u64 %rd90, %rd91;
mov.u64 %rd95, %rd96;
@%p10 bra BB159_7;

BB159_16:
ld.local.u64 %rd59, [%rd3];
shl.b64 %rd60, %rd90, 3;
add.s64 %rd61, %rd59, %rd60;
ld.u64 %rd32, [%rd61];
setp.lt.s64	%p11, %rd32, 0;
@%p11 bra BB159_18;

mul.wide.s32 %rd62, %r11, 8;
add.s64 %rd63, %rd2, %rd62;
ld.local.u64 %rd64, [%rd63+8];
setp.lt.u64	%p12, %rd32, %rd64;
@%p12 bra BB159_19;

BB159_18:
mov.u64 %rd65, $str2;
cvta.global.u64 %rd66, %rd65;
mov.u64 %rd67, $str1;
cvta.global.u64 %rd68, %rd67;
mov.u64 %rd69, __T2188;
cvta.global.u64 %rd70, %rd69;
mov.u32 %r25, 176;
mov.u64 %rd71, 1;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.b64	[param0+0], %rd66;
.param .b64 param1;
st.param.b64	[param1+0], %rd68;
.param .b32 param2;
st.param.b32	[param2+0], %r25;
.param .b64 param3;
st.param.b64	[param3+0], %rd70;
.param .b64 param4;
st.param.b64	[param4+0], %rd71;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);


	}

BB159_19:
mul.wide.s32 %rd72, %r11, 8;
add.s64 %rd73, %rd2, %rd72;
ld.local.u64 %rd74, [%rd73+208];
mul.lo.s64 %rd75, %rd74, %rd32;
add.s64 %rd76, %rd75, %rd95;
ld.local.u64 %rd77, [%rd2];
shl.b64 %rd78, %rd76, 3;
add.s64 %rd79, %rd77, %rd78;
st.f64 [%rd79], %fd1;
mov.u32 %r27, %nctaid.x;
mul.lo.s32 %r28, %r27, %r14;
cvt.u64.u32	%rd80, %r28;
add.s64 %rd87, %rd80, %rd9;
setp.lt.u64	%p13, %rd87, %rd34;
@%p13 bra BB159_6;

BB159_20:
ret;
}


