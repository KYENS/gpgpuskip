







.version 5.0
.target sm_61
.address_size 64


.global .align 8 .b8 _ZTVSt9basic_iosIcSt11char_traitsIcEE[32];
.global .align 8 .b8 _ZTTSo[8];
.global .align 8 .b8 _ZTVSt15basic_streambufIcSt11char_traitsIcEE[128];
.global .align 8 .b8 _ZTVNSt7__cxx1115basic_stringbufIcSt11char_traitsIcESaIcEEE[128];
.global .align 8 .b8 _ZTTNSt7__cxx1119basic_ostringstreamIcSt11char_traitsIcESaIcEEE[8];
.global .align 8 .b8 _ZTVN10__cxxabiv117__class_type_infoE[8];
.global .align 8 .b8 _ZTVN10__cxxabiv120__si_class_type_infoE[8];
.global .align 8 .b8 _ZTVN3c105ErrorE[40];
.global .align 1 .b8 __T21[38] = {84, 32, 112, 111, 119, 105, 40, 84, 44, 32, 84, 41, 32, 91, 119, 105, 116, 104, 32, 84, 32, 61, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 93, 0};
.global .align 1 .b8 __T22[36] = {84, 32, 112, 111, 119, 105, 40, 84, 44, 32, 84, 41, 32, 91, 119, 105, 116, 104, 32, 84, 32, 61, 32, 115, 105, 103, 110, 101, 100, 32, 99, 104, 97, 114, 93, 0};
.global .align 1 .b8 __T23[30] = {84, 32, 112, 111, 119, 105, 40, 84, 44, 32, 84, 41, 32, 91, 119, 105, 116, 104, 32, 84, 32, 61, 32, 115, 104, 111, 114, 116, 93, 0};
.global .align 1 .b8 __T24[28] = {84, 32, 112, 111, 119, 105, 40, 84, 44, 32, 84, 41, 32, 91, 119, 105, 116, 104, 32, 84, 32, 61, 32, 105, 110, 116, 93, 0};
.global .align 1 .b8 __T25[29] = {84, 32, 112, 111, 119, 105, 40, 84, 44, 32, 84, 41, 32, 91, 119, 105, 116, 104, 32, 84, 32, 61, 32, 108, 111, 110, 103, 93, 0};

.visible .entry _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<18>;
.reg .f32 %f<4>;
.reg .b32 %r<17>;
.reg .b64 %rd<9>;


ld.param.u32 %r8, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r9, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r10, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r11, %ctaid.x;
mov.u32 %r12, %tid.x;
mad.lo.s32 %r16, %r1, %r11, %r12;
setp.ge.u32	%p1, %r16, %r10;
@%p1 bra BB0_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;
mov.u32 %r13, %nctaid.x;
mul.lo.s32 %r5, %r13, %r1;

BB0_2:
mul.lo.s32 %r14, %r16, %r8;
cvt.u64.u32	%rd5, %r14;
add.s64 %rd6, %rd1, %rd5;
mul.lo.s32 %r15, %r16, %r9;
mul.wide.u32 %rd7, %r15, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.lt.f32	%p2, %f3, %f2;
selp.u16	%rs17, 1, 0, %p2;
st.global.u8 [%rd6], %rs17;
add.s32 %r16, %r5, %r16;
setp.lt.u32	%p3, %r16, %r10;
@%p3 bra BB0_2;

BB0_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.u32 %r12, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r3, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r3, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB1_3;

cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r3;
cvta.to.global.u64 %rd2, %rd4;

BB1_2:
mul.lo.s32 %r33, %r41, %r12;
cvt.u64.u32	%rd5, %r33;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r34, %r41, %r24;
add.s32 %r35, %r34, %r41;
shr.u32 %r36, %r35, %r25;
mul.lo.s32 %r37, %r36, %r27;
sub.s32 %r38, %r41, %r37;
mul.lo.s32 %r39, %r38, %r23;
mad.lo.s32 %r40, %r22, %r36, %r39;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.lt.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
st.global.u8 [%rd6], %rs9;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB1_2;

BB1_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot2[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot2;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB2_2;

BB2_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB2_1;

BB2_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB2_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB2_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB2_6;

BB2_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB2_5;

BB2_6:
mul.lo.s32 %r30, %r8, %r18;
cvt.u64.u32	%rd16, %r30;
add.s64 %rd17, %rd4, %rd16;
ld.local.u32 %r31, [%rd1+108];
mad.lo.s32 %r32, %r31, %r38, %r42;
ld.local.u64 %rd18, [%rd1];
cvta.to.global.u64 %rd19, %rd18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd19, %rd20;
ld.global.f32 %f3, [%rd21];
setp.lt.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
st.global.u8 [%rd17], %rs9;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB2_4;

BB2_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r20, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r1, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB3_3;

cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r1;
cvta.to.global.u64 %rd2, %rd3;

BB3_2:
mul.hi.u32 %r33, %r41, %r24;
add.s32 %r34, %r33, %r41;
shr.u32 %r35, %r34, %r25;
mul.lo.s32 %r36, %r35, %r27;
sub.s32 %r37, %r41, %r36;
mul.lo.s32 %r38, %r37, %r23;
mad.lo.s32 %r39, %r22, %r35, %r38;
cvt.u64.u32	%rd5, %r39;
add.s64 %rd6, %rd2, %rd5;
mul.lo.s32 %r40, %r41, %r20;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd1, %rd7;
ld.global.f32 %f3, [%rd8];
setp.lt.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
st.global.u8 [%rd6], %rs9;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB3_2;

BB3_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<67>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r39, %r40}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r41, %r42}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r43, %r44}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r47, %ntid.x;
mov.u32 %r48, %ctaid.x;
mov.u32 %r49, %tid.x;
mad.lo.s32 %r66, %r47, %r48, %r49;
setp.ge.u32	%p1, %r66, %r30;
@%p1 bra BB4_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;

BB4_2:
mul.hi.u32 %r50, %r66, %r33;
add.s32 %r51, %r50, %r66;
shr.u32 %r52, %r51, %r34;
mul.lo.s32 %r53, %r52, %r36;
sub.s32 %r54, %r66, %r53;
mul.lo.s32 %r55, %r54, %r32;
mad.lo.s32 %r56, %r31, %r52, %r55;
cvt.u64.u32	%rd5, %r56;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r57, %r66, %r41;
add.s32 %r58, %r57, %r66;
shr.u32 %r59, %r58, %r42;
mul.lo.s32 %r60, %r59, %r44;
sub.s32 %r61, %r66, %r60;
mul.lo.s32 %r62, %r61, %r40;
mad.lo.s32 %r63, %r39, %r59, %r62;
mul.wide.u32 %rd7, %r63, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.lt.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
st.global.u8 [%rd6], %rs1;
mov.u32 %r65, %nctaid.x;
mad.lo.s32 %r66, %r65, %r47, %r66;
setp.lt.u32	%p3, %r66, %r30;
@%p3 bra BB4_2;

BB4_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot5[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot5;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r32, %r33}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r34, %r35}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r36, %r37}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB5_2;

BB5_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB5_1;

BB5_2:
mov.u32 %r40, %ntid.x;
mov.u32 %r41, %ctaid.x;
mov.u32 %r42, %tid.x;
mad.lo.s32 %r65, %r40, %r41, %r42;
setp.ge.u32	%p3, %r65, %r30;
@%p3 bra BB5_7;

cvta.to.global.u64 %rd4, %rd10;
ld.local.u32 %r43, [%rd1+208];
add.s32 %r9, %r43, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd5, %rd16;
mul.wide.s32 %rd17, %r43, 4;
add.s64 %rd6, %rd1, %rd17;

BB5_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mul.hi.u32 %r12, %r11, %r34;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB5_6;

BB5_5:
mov.u32 %r14, %r64;
mov.u32 %r13, %r59;
ld.local.u32 %r46, [%rd22+4];
rem.u32 %r47, %r14, %r46;
ld.local.u32 %r48, [%rd22+104];
mad.lo.s32 %r68, %r48, %r47, %r68;
div.u32 %r17, %r14, %r46;
add.s64 %rd22, %rd22, -4;
add.s32 %r18, %r13, -1;
setp.gt.s32	%p5, %r18, 0;
mov.u32 %r59, %r18;
mov.u32 %r63, %r17;
mov.u32 %r64, %r17;
mov.u32 %r67, %r68;
@%p5 bra BB5_5;

BB5_6:
add.s32 %r49, %r12, %r11;
shr.u32 %r50, %r49, %r35;
mul.lo.s32 %r51, %r50, %r37;
sub.s32 %r52, %r11, %r51;
mul.lo.s32 %r53, %r52, %r33;
mad.lo.s32 %r54, %r32, %r50, %r53;
cvt.u64.u32	%rd18, %r54;
add.s64 %rd19, %rd4, %rd18;
mad.lo.s32 %r55, %r10, %r63, %r67;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.lt.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
st.global.u8 [%rd19], %rs1;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r40, %r11;
setp.lt.u32	%p7, %r65, %r30;
@%p7 bra BB5_4;

BB5_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot6[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot6;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB6_2;

BB6_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB6_1;

BB6_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB6_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB6_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB6_6;

BB6_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB6_5;

BB6_6:
ld.local.u32 %r30, [%rd1+108];
mad.lo.s32 %r31, %r30, %r38, %r42;
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd17, %rd16;
cvt.u64.u32	%rd18, %r31;
add.s64 %rd19, %rd17, %rd18;
mul.lo.s32 %r32, %r8, %r18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd4, %rd20;
ld.global.f32 %f3, [%rd21];
setp.lt.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
st.global.u8 [%rd19], %rs9;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB6_4;

BB6_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot7[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot7;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB7_2;

BB7_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB7_1;

BB7_2:
mov.u32 %r39, %ntid.x;
mov.u32 %r40, %ctaid.x;
mov.u32 %r41, %tid.x;
mad.lo.s32 %r65, %r39, %r40, %r41;
setp.ge.u32	%p3, %r65, %r29;
@%p3 bra BB7_7;

ld.local.u32 %r42, [%rd1+208];
add.s32 %r9, %r42, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd4, %rd16;
cvta.to.global.u64 %rd5, %rd10;
mul.wide.s32 %rd17, %r42, 4;
add.s64 %rd6, %rd1, %rd17;

BB7_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB7_6;

BB7_5:
mov.u32 %r13, %r64;
mov.u32 %r12, %r59;
ld.local.u32 %r45, [%rd22+4];
rem.u32 %r46, %r13, %r45;
ld.local.u32 %r47, [%rd22+104];
mad.lo.s32 %r68, %r47, %r46, %r68;
div.u32 %r16, %r13, %r45;
add.s64 %rd22, %rd22, -4;
add.s32 %r17, %r12, -1;
setp.gt.s32	%p5, %r17, 0;
mov.u32 %r59, %r17;
mov.u32 %r63, %r16;
mov.u32 %r64, %r16;
mov.u32 %r67, %r68;
@%p5 bra BB7_5;

BB7_6:
mad.lo.s32 %r48, %r10, %r63, %r67;
cvt.u64.u32	%rd18, %r48;
add.s64 %rd19, %rd4, %rd18;
mul.hi.u32 %r49, %r11, %r33;
add.s32 %r50, %r49, %r11;
shr.u32 %r51, %r50, %r34;
mul.lo.s32 %r52, %r51, %r36;
sub.s32 %r53, %r11, %r52;
mul.lo.s32 %r54, %r53, %r32;
mad.lo.s32 %r55, %r31, %r51, %r54;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.lt.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
st.global.u8 [%rd19], %rs1;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r39, %r11;
setp.lt.u32	%p7, %r65, %r29;
@%p7 bra BB7_4;

BB7_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot8[432];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<12>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<72>;
.reg .b64 %rd<39>;


mov.u64 %rd38, __local_depot8;
cvta.local.u64 %SP, %rd38;
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd18, %SP, 216;
cvta.to.local.u64 %rd2, %rd18;
add.u64 %rd19, %SP, 0;
cvta.to.local.u64 %rd3, %rd19;
mov.u32 %r50, 0;
mov.pred %p1, 0;
@%p1 bra BB8_2;

BB8_1:
mul.wide.s32 %rd20, %r50, 8;
add.s64 %rd21, %rd4, %rd20;
ld.param.u64 %rd22, [%rd21];
add.s64 %rd23, %rd2, %rd20;
st.local.u64 [%rd23], %rd22;
add.s32 %r50, %r50, 1;
setp.lt.u32	%p2, %r50, 27;
@%p2 bra BB8_1;

BB8_2:
mov.u32 %r51, 0;
@%p1 bra BB8_4;

BB8_3:
mul.wide.s32 %rd24, %r51, 8;
add.s64 %rd25, %rd1, %rd24;
ld.param.u64 %rd26, [%rd25];
add.s64 %rd27, %rd3, %rd24;
st.local.u64 [%rd27], %rd26;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p4, %r51, 27;
@%p4 bra BB8_3;

BB8_4:
mov.u32 %r32, %ntid.x;
mov.u32 %r33, %ctaid.x;
mov.u32 %r34, %tid.x;
mad.lo.s32 %r64, %r32, %r33, %r34;
setp.ge.u32	%p5, %r64, %r29;
@%p5 bra BB8_11;

ld.local.u32 %r35, [%rd2+208];
add.s32 %r6, %r35, -1;
ld.local.u32 %r7, [%rd2+108];
ld.local.u64 %rd28, [%rd2];
cvta.to.global.u64 %rd8, %rd28;
ld.local.u32 %r36, [%rd3+208];
add.s32 %r8, %r36, -1;
ld.local.u32 %r9, [%rd3+108];
ld.local.u64 %rd29, [%rd3];
cvta.to.global.u64 %rd9, %rd29;
mul.wide.s32 %rd30, %r35, 4;
add.s64 %rd10, %rd2, %rd30;
mul.wide.s32 %rd31, %r36, 4;
add.s64 %rd11, %rd3, %rd31;

BB8_6:
mov.u32 %r54, %r64;
mov.u32 %r10, %r54;
mov.u64 %rd36, %rd10;
mov.u32 %r38, 0;
mov.u32 %r71, %r38;
setp.lt.s32	%p6, %r6, 1;
mov.u32 %r52, %r6;
mov.u32 %r62, %r10;
mov.u32 %r63, %r10;
mov.u32 %r70, %r38;
@%p6 bra BB8_8;

BB8_7:
mov.u32 %r12, %r63;
mov.u32 %r11, %r52;
ld.local.u32 %r39, [%rd36+4];
rem.u32 %r40, %r12, %r39;
ld.local.u32 %r41, [%rd36+104];
mad.lo.s32 %r71, %r41, %r40, %r71;
div.u32 %r15, %r12, %r39;
add.s64 %rd36, %rd36, -4;
add.s32 %r16, %r11, -1;
setp.gt.s32	%p7, %r16, 0;
mov.u32 %r52, %r16;
mov.u32 %r62, %r15;
mov.u32 %r63, %r15;
mov.u32 %r65, %r71;
mov.u32 %r70, %r65;
@%p7 bra BB8_7;

BB8_8:
mov.u32 %r18, %r70;
mov.u64 %rd37, %rd11;
mad.lo.s32 %r19, %r7, %r62, %r18;
mov.u32 %r69, %r38;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r53, %r8;
mov.u32 %r61, %r10;
mov.u32 %r60, %r10;
mov.u32 %r68, %r38;
@%p8 bra BB8_10;

BB8_9:
mov.u32 %r20, %r53;
ld.local.u32 %r44, [%rd37+4];
rem.u32 %r45, %r61, %r44;
ld.local.u32 %r46, [%rd37+104];
mad.lo.s32 %r69, %r46, %r45, %r69;
div.u32 %r61, %r61, %r44;
add.s64 %rd37, %rd37, -4;
add.s32 %r25, %r20, -1;
setp.gt.s32	%p9, %r25, 0;
mov.u32 %r53, %r25;
mov.u32 %r60, %r61;
mov.u32 %r68, %r69;
@%p9 bra BB8_9;

BB8_10:
cvt.u64.u32	%rd32, %r19;
add.s64 %rd33, %rd8, %rd32;
mad.lo.s32 %r47, %r9, %r60, %r68;
mul.wide.u32 %rd34, %r47, 4;
add.s64 %rd35, %rd9, %rd34;
ld.global.f32 %f3, [%rd35];
setp.lt.f32	%p10, %f3, %f2;
selp.u16	%rs1, 1, 0, %p10;
st.global.u8 [%rd33], %rs1;
mov.u32 %r49, %nctaid.x;
mad.lo.s32 %r64, %r49, %r32, %r10;
setp.lt.u32	%p11, %r64, %r29;
@%p11 bra BB8_6;

BB8_11:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u64 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<5>;
.reg .b64 %rd<24>;


ld.param.u64 %rd11, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u64 %rd13, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd12, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u64 %rd14, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %ntid.x;
cvt.u64.u32	%rd1, %r2;
mul.wide.u32 %rd15, %r2, %r1;
mov.u32 %r3, %tid.x;
cvt.u64.u32	%rd16, %r3;
add.s64 %rd23, %rd15, %rd16;
setp.ge.u64	%p1, %rd23, %rd14;
@%p1 bra BB9_3;

cvta.to.global.u64 %rd3, %rd10;
cvta.to.global.u64 %rd5, %rd12;
mov.u32 %r4, %nctaid.x;
cvt.u64.u32	%rd17, %r4;
mul.lo.s64 %rd7, %rd17, %rd1;

BB9_2:
mul.lo.s64 %rd18, %rd23, %rd11;
add.s64 %rd19, %rd3, %rd18;
mul.lo.s64 %rd20, %rd23, %rd13;
shl.b64 %rd21, %rd20, 2;
add.s64 %rd22, %rd5, %rd21;
ld.global.f32 %f3, [%rd22];
setp.lt.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
st.global.u8 [%rd19], %rs1;
add.s64 %rd23, %rd7, %rd23;
setp.lt.u64	%p3, %rd23, %rd14;
@%p3 bra BB9_2;

BB9_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[416],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[416],
.param .u64 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot10[832];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<32>;
.reg .b64 %rd<112>;


mov.u64 %rd111, __local_depot10;
cvta.local.u64 %SP, %rd111;
ld.param.u64 %rd49, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorLTValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd50, %SP, 416;
cvta.to.local.u64 %rd2, %rd50;
add.u64 %rd51, %SP, 0;
cvta.to.local.u64 %rd3, %rd51;
mov.u32 %r28, 0;
mov.pred %p1, 0;
@%p1 bra BB10_2;

BB10_1:
mul.wide.s32 %rd52, %r28, 8;
add.s64 %rd53, %rd4, %rd52;
ld.param.u64 %rd54, [%rd53];
add.s64 %rd55, %rd2, %rd52;
st.local.u64 [%rd55], %rd54;
add.s32 %r28, %r28, 1;
setp.lt.u32	%p2, %r28, 52;
@%p2 bra BB10_1;

BB10_2:
mov.u32 %r29, 0;
@%p1 bra BB10_4;

BB10_3:
mul.wide.s32 %rd56, %r29, 8;
add.s64 %rd57, %rd1, %rd56;
ld.param.u64 %rd58, [%rd57];
add.s64 %rd59, %rd3, %rd56;
st.local.u64 [%rd59], %rd58;
add.s32 %r29, %r29, 1;
setp.lt.u32	%p4, %r29, 52;
@%p4 bra BB10_3;

BB10_4:
mov.u32 %r13, %ctaid.x;
mov.u32 %r14, %ntid.x;
mul.wide.u32 %rd60, %r14, %r13;
mov.u32 %r15, %tid.x;
cvt.u64.u32	%rd61, %r15;
add.s64 %rd103, %rd60, %rd61;
setp.ge.u64	%p5, %rd103, %rd49;
@%p5 bra BB10_17;

ld.local.u32 %r16, [%rd2+408];
add.s32 %r5, %r16, -1;
ld.local.u64 %rd9, [%rd2+208];
ld.local.u64 %rd62, [%rd2];
cvta.to.global.u64 %rd10, %rd62;
ld.local.u32 %r17, [%rd3+408];
add.s32 %r6, %r17, -1;
ld.local.u64 %rd11, [%rd3+208];
ld.local.u64 %rd63, [%rd3];
cvta.to.global.u64 %rd12, %rd63;
mul.wide.s32 %rd64, %r16, 8;
add.s64 %rd13, %rd2, %rd64;
mul.wide.s32 %rd65, %r17, 8;
add.s64 %rd14, %rd3, %rd65;

BB10_6:
mov.u64 %rd89, %rd103;
mov.u64 %rd15, %rd89;
mov.u64 %rd85, %rd13;
mov.u64 %rd67, 0;
mov.u64 %rd110, %rd67;
setp.lt.s32	%p6, %r5, 1;
mov.u32 %r30, %r5;
mov.u64 %rd100, %rd15;
mov.u64 %rd101, %rd15;
mov.u64 %rd109, %rd67;
@%p6 bra BB10_11;

BB10_7:
mov.u64 %rd18, %rd101;
mov.u32 %r7, %r30;
ld.local.u64 %rd21, [%rd85];
or.b64 %rd68, %rd18, %rd21;
and.b64 %rd69, %rd68, -4294967296;
setp.eq.s64	%p7, %rd69, 0;
@%p7 bra BB10_9;
bra.uni BB10_8;

BB10_9:
cvt.u32.u64	%r18, %rd21;
cvt.u32.u64	%r19, %rd18;
div.u32 %r20, %r19, %r18;
rem.u32 %r21, %r19, %r18;
cvt.u64.u32	%rd102, %r20;
cvt.u64.u32	%rd86, %r21;
bra.uni BB10_10;

BB10_8:
div.u64 %rd102, %rd18, %rd21;
rem.u64 %rd86, %rd18, %rd21;

BB10_10:
mov.u64 %rd26, %rd102;
ld.local.u64 %rd70, [%rd85+200];
mul.lo.s64 %rd71, %rd70, %rd86;
add.s64 %rd110, %rd71, %rd110;
add.s64 %rd85, %rd85, -8;
add.s32 %r8, %r7, -1;
setp.gt.s32	%p8, %r8, 0;
mov.u32 %r30, %r8;
mov.u64 %rd100, %rd26;
mov.u64 %rd101, %rd26;
mov.u64 %rd104, %rd110;
mov.u64 %rd109, %rd104;
@%p8 bra BB10_7;

BB10_11:
mov.u64 %rd31, %rd109;
mov.u64 %rd87, %rd14;
mul.lo.s64 %rd74, %rd9, %rd100;
add.s64 %rd33, %rd74, %rd31;
mov.u64 %rd108, %rd67;
setp.lt.s32	%p9, %r6, 1;
mov.u32 %r31, %r6;
mov.u64 %rd98, %rd15;
mov.u64 %rd97, %rd15;
mov.u64 %rd107, %rd67;
@%p9 bra BB10_16;

BB10_12:
mov.u32 %r9, %r31;
ld.local.u64 %rd37, [%rd87];
or.b64 %rd75, %rd98, %rd37;
and.b64 %rd76, %rd75, -4294967296;
setp.eq.s64	%p10, %rd76, 0;
@%p10 bra BB10_14;
bra.uni BB10_13;

BB10_14:
cvt.u32.u64	%r22, %rd37;
cvt.u32.u64	%r23, %rd98;
div.u32 %r24, %r23, %r22;
rem.u32 %r25, %r23, %r22;
cvt.u64.u32	%rd99, %r24;
cvt.u64.u32	%rd88, %r25;
bra.uni BB10_15;

BB10_13:
div.u64 %rd99, %rd98, %rd37;
rem.u64 %rd88, %rd98, %rd37;

BB10_15:
mov.u64 %rd98, %rd99;
ld.local.u64 %rd77, [%rd87+200];
mul.lo.s64 %rd78, %rd77, %rd88;
add.s64 %rd108, %rd78, %rd108;
add.s64 %rd87, %rd87, -8;
add.s32 %r10, %r9, -1;
setp.gt.s32	%p11, %r10, 0;
mov.u32 %r31, %r10;
mov.u64 %rd97, %rd98;
mov.u64 %rd107, %rd108;
@%p11 bra BB10_12;

BB10_16:
add.s64 %rd79, %rd10, %rd33;
mul.lo.s64 %rd80, %rd11, %rd97;
add.s64 %rd81, %rd80, %rd107;
shl.b64 %rd82, %rd81, 2;
add.s64 %rd83, %rd12, %rd82;
ld.global.f32 %f3, [%rd83];
setp.lt.f32	%p12, %f3, %f2;
selp.u16	%rs1, 1, 0, %p12;
st.global.u8 [%rd79], %rs1;
mov.u32 %r26, %nctaid.x;
mul.wide.u32 %rd84, %r26, %r14;
add.s64 %rd103, %rd84, %rd15;
setp.lt.u64	%p13, %rd103, %rd49;
@%p13 bra BB10_6;

BB10_17:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<18>;
.reg .f32 %f<4>;
.reg .b32 %r<17>;
.reg .b64 %rd<9>;


ld.param.u32 %r8, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r9, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r10, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r11, %ctaid.x;
mov.u32 %r12, %tid.x;
mad.lo.s32 %r16, %r1, %r11, %r12;
setp.ge.u32	%p1, %r16, %r10;
@%p1 bra BB11_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;
mov.u32 %r13, %nctaid.x;
mul.lo.s32 %r5, %r13, %r1;

BB11_2:
mul.lo.s32 %r14, %r16, %r8;
cvt.u64.u32	%rd5, %r14;
add.s64 %rd6, %rd1, %rd5;
mul.lo.s32 %r15, %r16, %r9;
mul.wide.u32 %rd7, %r15, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.gt.f32	%p2, %f3, %f2;
selp.u16	%rs17, 1, 0, %p2;
st.global.u8 [%rd6], %rs17;
add.s32 %r16, %r5, %r16;
setp.lt.u32	%p3, %r16, %r10;
@%p3 bra BB11_2;

BB11_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.u32 %r12, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r3, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r3, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB12_3;

cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r3;
cvta.to.global.u64 %rd2, %rd4;

BB12_2:
mul.lo.s32 %r33, %r41, %r12;
cvt.u64.u32	%rd5, %r33;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r34, %r41, %r24;
add.s32 %r35, %r34, %r41;
shr.u32 %r36, %r35, %r25;
mul.lo.s32 %r37, %r36, %r27;
sub.s32 %r38, %r41, %r37;
mul.lo.s32 %r39, %r38, %r23;
mad.lo.s32 %r40, %r22, %r36, %r39;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.gt.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
st.global.u8 [%rd6], %rs9;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB12_2;

BB12_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot13[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot13;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB13_2;

BB13_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB13_1;

BB13_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB13_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB13_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB13_6;

BB13_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB13_5;

BB13_6:
mul.lo.s32 %r30, %r8, %r18;
cvt.u64.u32	%rd16, %r30;
add.s64 %rd17, %rd4, %rd16;
ld.local.u32 %r31, [%rd1+108];
mad.lo.s32 %r32, %r31, %r38, %r42;
ld.local.u64 %rd18, [%rd1];
cvta.to.global.u64 %rd19, %rd18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd19, %rd20;
ld.global.f32 %f3, [%rd21];
setp.gt.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
st.global.u8 [%rd17], %rs9;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB13_4;

BB13_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r20, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r1, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB14_3;

cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r1;
cvta.to.global.u64 %rd2, %rd3;

BB14_2:
mul.hi.u32 %r33, %r41, %r24;
add.s32 %r34, %r33, %r41;
shr.u32 %r35, %r34, %r25;
mul.lo.s32 %r36, %r35, %r27;
sub.s32 %r37, %r41, %r36;
mul.lo.s32 %r38, %r37, %r23;
mad.lo.s32 %r39, %r22, %r35, %r38;
cvt.u64.u32	%rd5, %r39;
add.s64 %rd6, %rd2, %rd5;
mul.lo.s32 %r40, %r41, %r20;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd1, %rd7;
ld.global.f32 %f3, [%rd8];
setp.gt.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
st.global.u8 [%rd6], %rs9;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB14_2;

BB14_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<67>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r39, %r40}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r41, %r42}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r43, %r44}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r47, %ntid.x;
mov.u32 %r48, %ctaid.x;
mov.u32 %r49, %tid.x;
mad.lo.s32 %r66, %r47, %r48, %r49;
setp.ge.u32	%p1, %r66, %r30;
@%p1 bra BB15_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;

BB15_2:
mul.hi.u32 %r50, %r66, %r33;
add.s32 %r51, %r50, %r66;
shr.u32 %r52, %r51, %r34;
mul.lo.s32 %r53, %r52, %r36;
sub.s32 %r54, %r66, %r53;
mul.lo.s32 %r55, %r54, %r32;
mad.lo.s32 %r56, %r31, %r52, %r55;
cvt.u64.u32	%rd5, %r56;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r57, %r66, %r41;
add.s32 %r58, %r57, %r66;
shr.u32 %r59, %r58, %r42;
mul.lo.s32 %r60, %r59, %r44;
sub.s32 %r61, %r66, %r60;
mul.lo.s32 %r62, %r61, %r40;
mad.lo.s32 %r63, %r39, %r59, %r62;
mul.wide.u32 %rd7, %r63, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.gt.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
st.global.u8 [%rd6], %rs1;
mov.u32 %r65, %nctaid.x;
mad.lo.s32 %r66, %r65, %r47, %r66;
setp.lt.u32	%p3, %r66, %r30;
@%p3 bra BB15_2;

BB15_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot16[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot16;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r32, %r33}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r34, %r35}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r36, %r37}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB16_2;

BB16_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB16_1;

BB16_2:
mov.u32 %r40, %ntid.x;
mov.u32 %r41, %ctaid.x;
mov.u32 %r42, %tid.x;
mad.lo.s32 %r65, %r40, %r41, %r42;
setp.ge.u32	%p3, %r65, %r30;
@%p3 bra BB16_7;

cvta.to.global.u64 %rd4, %rd10;
ld.local.u32 %r43, [%rd1+208];
add.s32 %r9, %r43, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd5, %rd16;
mul.wide.s32 %rd17, %r43, 4;
add.s64 %rd6, %rd1, %rd17;

BB16_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mul.hi.u32 %r12, %r11, %r34;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB16_6;

BB16_5:
mov.u32 %r14, %r64;
mov.u32 %r13, %r59;
ld.local.u32 %r46, [%rd22+4];
rem.u32 %r47, %r14, %r46;
ld.local.u32 %r48, [%rd22+104];
mad.lo.s32 %r68, %r48, %r47, %r68;
div.u32 %r17, %r14, %r46;
add.s64 %rd22, %rd22, -4;
add.s32 %r18, %r13, -1;
setp.gt.s32	%p5, %r18, 0;
mov.u32 %r59, %r18;
mov.u32 %r63, %r17;
mov.u32 %r64, %r17;
mov.u32 %r67, %r68;
@%p5 bra BB16_5;

BB16_6:
add.s32 %r49, %r12, %r11;
shr.u32 %r50, %r49, %r35;
mul.lo.s32 %r51, %r50, %r37;
sub.s32 %r52, %r11, %r51;
mul.lo.s32 %r53, %r52, %r33;
mad.lo.s32 %r54, %r32, %r50, %r53;
cvt.u64.u32	%rd18, %r54;
add.s64 %rd19, %rd4, %rd18;
mad.lo.s32 %r55, %r10, %r63, %r67;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.gt.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
st.global.u8 [%rd19], %rs1;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r40, %r11;
setp.lt.u32	%p7, %r65, %r30;
@%p7 bra BB16_4;

BB16_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot17[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot17;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB17_2;

BB17_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB17_1;

BB17_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB17_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB17_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB17_6;

BB17_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB17_5;

BB17_6:
ld.local.u32 %r30, [%rd1+108];
mad.lo.s32 %r31, %r30, %r38, %r42;
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd17, %rd16;
cvt.u64.u32	%rd18, %r31;
add.s64 %rd19, %rd17, %rd18;
mul.lo.s32 %r32, %r8, %r18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd4, %rd20;
ld.global.f32 %f3, [%rd21];
setp.gt.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
st.global.u8 [%rd19], %rs9;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB17_4;

BB17_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot18[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot18;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB18_2;

BB18_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB18_1;

BB18_2:
mov.u32 %r39, %ntid.x;
mov.u32 %r40, %ctaid.x;
mov.u32 %r41, %tid.x;
mad.lo.s32 %r65, %r39, %r40, %r41;
setp.ge.u32	%p3, %r65, %r29;
@%p3 bra BB18_7;

ld.local.u32 %r42, [%rd1+208];
add.s32 %r9, %r42, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd4, %rd16;
cvta.to.global.u64 %rd5, %rd10;
mul.wide.s32 %rd17, %r42, 4;
add.s64 %rd6, %rd1, %rd17;

BB18_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB18_6;

BB18_5:
mov.u32 %r13, %r64;
mov.u32 %r12, %r59;
ld.local.u32 %r45, [%rd22+4];
rem.u32 %r46, %r13, %r45;
ld.local.u32 %r47, [%rd22+104];
mad.lo.s32 %r68, %r47, %r46, %r68;
div.u32 %r16, %r13, %r45;
add.s64 %rd22, %rd22, -4;
add.s32 %r17, %r12, -1;
setp.gt.s32	%p5, %r17, 0;
mov.u32 %r59, %r17;
mov.u32 %r63, %r16;
mov.u32 %r64, %r16;
mov.u32 %r67, %r68;
@%p5 bra BB18_5;

BB18_6:
mad.lo.s32 %r48, %r10, %r63, %r67;
cvt.u64.u32	%rd18, %r48;
add.s64 %rd19, %rd4, %rd18;
mul.hi.u32 %r49, %r11, %r33;
add.s32 %r50, %r49, %r11;
shr.u32 %r51, %r50, %r34;
mul.lo.s32 %r52, %r51, %r36;
sub.s32 %r53, %r11, %r52;
mul.lo.s32 %r54, %r53, %r32;
mad.lo.s32 %r55, %r31, %r51, %r54;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.gt.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
st.global.u8 [%rd19], %rs1;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r39, %r11;
setp.lt.u32	%p7, %r65, %r29;
@%p7 bra BB18_4;

BB18_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot19[432];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<12>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<72>;
.reg .b64 %rd<39>;


mov.u64 %rd38, __local_depot19;
cvta.local.u64 %SP, %rd38;
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd18, %SP, 216;
cvta.to.local.u64 %rd2, %rd18;
add.u64 %rd19, %SP, 0;
cvta.to.local.u64 %rd3, %rd19;
mov.u32 %r50, 0;
mov.pred %p1, 0;
@%p1 bra BB19_2;

BB19_1:
mul.wide.s32 %rd20, %r50, 8;
add.s64 %rd21, %rd4, %rd20;
ld.param.u64 %rd22, [%rd21];
add.s64 %rd23, %rd2, %rd20;
st.local.u64 [%rd23], %rd22;
add.s32 %r50, %r50, 1;
setp.lt.u32	%p2, %r50, 27;
@%p2 bra BB19_1;

BB19_2:
mov.u32 %r51, 0;
@%p1 bra BB19_4;

BB19_3:
mul.wide.s32 %rd24, %r51, 8;
add.s64 %rd25, %rd1, %rd24;
ld.param.u64 %rd26, [%rd25];
add.s64 %rd27, %rd3, %rd24;
st.local.u64 [%rd27], %rd26;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p4, %r51, 27;
@%p4 bra BB19_3;

BB19_4:
mov.u32 %r32, %ntid.x;
mov.u32 %r33, %ctaid.x;
mov.u32 %r34, %tid.x;
mad.lo.s32 %r64, %r32, %r33, %r34;
setp.ge.u32	%p5, %r64, %r29;
@%p5 bra BB19_11;

ld.local.u32 %r35, [%rd2+208];
add.s32 %r6, %r35, -1;
ld.local.u32 %r7, [%rd2+108];
ld.local.u64 %rd28, [%rd2];
cvta.to.global.u64 %rd8, %rd28;
ld.local.u32 %r36, [%rd3+208];
add.s32 %r8, %r36, -1;
ld.local.u32 %r9, [%rd3+108];
ld.local.u64 %rd29, [%rd3];
cvta.to.global.u64 %rd9, %rd29;
mul.wide.s32 %rd30, %r35, 4;
add.s64 %rd10, %rd2, %rd30;
mul.wide.s32 %rd31, %r36, 4;
add.s64 %rd11, %rd3, %rd31;

BB19_6:
mov.u32 %r54, %r64;
mov.u32 %r10, %r54;
mov.u64 %rd36, %rd10;
mov.u32 %r38, 0;
mov.u32 %r71, %r38;
setp.lt.s32	%p6, %r6, 1;
mov.u32 %r52, %r6;
mov.u32 %r62, %r10;
mov.u32 %r63, %r10;
mov.u32 %r70, %r38;
@%p6 bra BB19_8;

BB19_7:
mov.u32 %r12, %r63;
mov.u32 %r11, %r52;
ld.local.u32 %r39, [%rd36+4];
rem.u32 %r40, %r12, %r39;
ld.local.u32 %r41, [%rd36+104];
mad.lo.s32 %r71, %r41, %r40, %r71;
div.u32 %r15, %r12, %r39;
add.s64 %rd36, %rd36, -4;
add.s32 %r16, %r11, -1;
setp.gt.s32	%p7, %r16, 0;
mov.u32 %r52, %r16;
mov.u32 %r62, %r15;
mov.u32 %r63, %r15;
mov.u32 %r65, %r71;
mov.u32 %r70, %r65;
@%p7 bra BB19_7;

BB19_8:
mov.u32 %r18, %r70;
mov.u64 %rd37, %rd11;
mad.lo.s32 %r19, %r7, %r62, %r18;
mov.u32 %r69, %r38;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r53, %r8;
mov.u32 %r61, %r10;
mov.u32 %r60, %r10;
mov.u32 %r68, %r38;
@%p8 bra BB19_10;

BB19_9:
mov.u32 %r20, %r53;
ld.local.u32 %r44, [%rd37+4];
rem.u32 %r45, %r61, %r44;
ld.local.u32 %r46, [%rd37+104];
mad.lo.s32 %r69, %r46, %r45, %r69;
div.u32 %r61, %r61, %r44;
add.s64 %rd37, %rd37, -4;
add.s32 %r25, %r20, -1;
setp.gt.s32	%p9, %r25, 0;
mov.u32 %r53, %r25;
mov.u32 %r60, %r61;
mov.u32 %r68, %r69;
@%p9 bra BB19_9;

BB19_10:
cvt.u64.u32	%rd32, %r19;
add.s64 %rd33, %rd8, %rd32;
mad.lo.s32 %r47, %r9, %r60, %r68;
mul.wide.u32 %rd34, %r47, 4;
add.s64 %rd35, %rd9, %rd34;
ld.global.f32 %f3, [%rd35];
setp.gt.f32	%p10, %f3, %f2;
selp.u16	%rs1, 1, 0, %p10;
st.global.u8 [%rd33], %rs1;
mov.u32 %r49, %nctaid.x;
mad.lo.s32 %r64, %r49, %r32, %r10;
setp.lt.u32	%p11, %r64, %r29;
@%p11 bra BB19_6;

BB19_11:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u64 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<5>;
.reg .b64 %rd<24>;


ld.param.u64 %rd11, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u64 %rd13, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd12, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u64 %rd14, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %ntid.x;
cvt.u64.u32	%rd1, %r2;
mul.wide.u32 %rd15, %r2, %r1;
mov.u32 %r3, %tid.x;
cvt.u64.u32	%rd16, %r3;
add.s64 %rd23, %rd15, %rd16;
setp.ge.u64	%p1, %rd23, %rd14;
@%p1 bra BB20_3;

cvta.to.global.u64 %rd3, %rd10;
cvta.to.global.u64 %rd5, %rd12;
mov.u32 %r4, %nctaid.x;
cvt.u64.u32	%rd17, %r4;
mul.lo.s64 %rd7, %rd17, %rd1;

BB20_2:
mul.lo.s64 %rd18, %rd23, %rd11;
add.s64 %rd19, %rd3, %rd18;
mul.lo.s64 %rd20, %rd23, %rd13;
shl.b64 %rd21, %rd20, 2;
add.s64 %rd22, %rd5, %rd21;
ld.global.f32 %f3, [%rd22];
setp.gt.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
st.global.u8 [%rd19], %rs1;
add.s64 %rd23, %rd7, %rd23;
setp.lt.u64	%p3, %rd23, %rd14;
@%p3 bra BB20_2;

BB20_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[416],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[416],
.param .u64 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot21[832];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<32>;
.reg .b64 %rd<112>;


mov.u64 %rd111, __local_depot21;
cvta.local.u64 %SP, %rd111;
ld.param.u64 %rd49, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorGTValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd50, %SP, 416;
cvta.to.local.u64 %rd2, %rd50;
add.u64 %rd51, %SP, 0;
cvta.to.local.u64 %rd3, %rd51;
mov.u32 %r28, 0;
mov.pred %p1, 0;
@%p1 bra BB21_2;

BB21_1:
mul.wide.s32 %rd52, %r28, 8;
add.s64 %rd53, %rd4, %rd52;
ld.param.u64 %rd54, [%rd53];
add.s64 %rd55, %rd2, %rd52;
st.local.u64 [%rd55], %rd54;
add.s32 %r28, %r28, 1;
setp.lt.u32	%p2, %r28, 52;
@%p2 bra BB21_1;

BB21_2:
mov.u32 %r29, 0;
@%p1 bra BB21_4;

BB21_3:
mul.wide.s32 %rd56, %r29, 8;
add.s64 %rd57, %rd1, %rd56;
ld.param.u64 %rd58, [%rd57];
add.s64 %rd59, %rd3, %rd56;
st.local.u64 [%rd59], %rd58;
add.s32 %r29, %r29, 1;
setp.lt.u32	%p4, %r29, 52;
@%p4 bra BB21_3;

BB21_4:
mov.u32 %r13, %ctaid.x;
mov.u32 %r14, %ntid.x;
mul.wide.u32 %rd60, %r14, %r13;
mov.u32 %r15, %tid.x;
cvt.u64.u32	%rd61, %r15;
add.s64 %rd103, %rd60, %rd61;
setp.ge.u64	%p5, %rd103, %rd49;
@%p5 bra BB21_17;

ld.local.u32 %r16, [%rd2+408];
add.s32 %r5, %r16, -1;
ld.local.u64 %rd9, [%rd2+208];
ld.local.u64 %rd62, [%rd2];
cvta.to.global.u64 %rd10, %rd62;
ld.local.u32 %r17, [%rd3+408];
add.s32 %r6, %r17, -1;
ld.local.u64 %rd11, [%rd3+208];
ld.local.u64 %rd63, [%rd3];
cvta.to.global.u64 %rd12, %rd63;
mul.wide.s32 %rd64, %r16, 8;
add.s64 %rd13, %rd2, %rd64;
mul.wide.s32 %rd65, %r17, 8;
add.s64 %rd14, %rd3, %rd65;

BB21_6:
mov.u64 %rd89, %rd103;
mov.u64 %rd15, %rd89;
mov.u64 %rd85, %rd13;
mov.u64 %rd67, 0;
mov.u64 %rd110, %rd67;
setp.lt.s32	%p6, %r5, 1;
mov.u32 %r30, %r5;
mov.u64 %rd100, %rd15;
mov.u64 %rd101, %rd15;
mov.u64 %rd109, %rd67;
@%p6 bra BB21_11;

BB21_7:
mov.u64 %rd18, %rd101;
mov.u32 %r7, %r30;
ld.local.u64 %rd21, [%rd85];
or.b64 %rd68, %rd18, %rd21;
and.b64 %rd69, %rd68, -4294967296;
setp.eq.s64	%p7, %rd69, 0;
@%p7 bra BB21_9;
bra.uni BB21_8;

BB21_9:
cvt.u32.u64	%r18, %rd21;
cvt.u32.u64	%r19, %rd18;
div.u32 %r20, %r19, %r18;
rem.u32 %r21, %r19, %r18;
cvt.u64.u32	%rd102, %r20;
cvt.u64.u32	%rd86, %r21;
bra.uni BB21_10;

BB21_8:
div.u64 %rd102, %rd18, %rd21;
rem.u64 %rd86, %rd18, %rd21;

BB21_10:
mov.u64 %rd26, %rd102;
ld.local.u64 %rd70, [%rd85+200];
mul.lo.s64 %rd71, %rd70, %rd86;
add.s64 %rd110, %rd71, %rd110;
add.s64 %rd85, %rd85, -8;
add.s32 %r8, %r7, -1;
setp.gt.s32	%p8, %r8, 0;
mov.u32 %r30, %r8;
mov.u64 %rd100, %rd26;
mov.u64 %rd101, %rd26;
mov.u64 %rd104, %rd110;
mov.u64 %rd109, %rd104;
@%p8 bra BB21_7;

BB21_11:
mov.u64 %rd31, %rd109;
mov.u64 %rd87, %rd14;
mul.lo.s64 %rd74, %rd9, %rd100;
add.s64 %rd33, %rd74, %rd31;
mov.u64 %rd108, %rd67;
setp.lt.s32	%p9, %r6, 1;
mov.u32 %r31, %r6;
mov.u64 %rd98, %rd15;
mov.u64 %rd97, %rd15;
mov.u64 %rd107, %rd67;
@%p9 bra BB21_16;

BB21_12:
mov.u32 %r9, %r31;
ld.local.u64 %rd37, [%rd87];
or.b64 %rd75, %rd98, %rd37;
and.b64 %rd76, %rd75, -4294967296;
setp.eq.s64	%p10, %rd76, 0;
@%p10 bra BB21_14;
bra.uni BB21_13;

BB21_14:
cvt.u32.u64	%r22, %rd37;
cvt.u32.u64	%r23, %rd98;
div.u32 %r24, %r23, %r22;
rem.u32 %r25, %r23, %r22;
cvt.u64.u32	%rd99, %r24;
cvt.u64.u32	%rd88, %r25;
bra.uni BB21_15;

BB21_13:
div.u64 %rd99, %rd98, %rd37;
rem.u64 %rd88, %rd98, %rd37;

BB21_15:
mov.u64 %rd98, %rd99;
ld.local.u64 %rd77, [%rd87+200];
mul.lo.s64 %rd78, %rd77, %rd88;
add.s64 %rd108, %rd78, %rd108;
add.s64 %rd87, %rd87, -8;
add.s32 %r10, %r9, -1;
setp.gt.s32	%p11, %r10, 0;
mov.u32 %r31, %r10;
mov.u64 %rd97, %rd98;
mov.u64 %rd107, %rd108;
@%p11 bra BB21_12;

BB21_16:
add.s64 %rd79, %rd10, %rd33;
mul.lo.s64 %rd80, %rd11, %rd97;
add.s64 %rd81, %rd80, %rd107;
shl.b64 %rd82, %rd81, 2;
add.s64 %rd83, %rd12, %rd82;
ld.global.f32 %f3, [%rd83];
setp.gt.f32	%p12, %f3, %f2;
selp.u16	%rs1, 1, 0, %p12;
st.global.u8 [%rd79], %rs1;
mov.u32 %r26, %nctaid.x;
mul.wide.u32 %rd84, %r26, %r14;
add.s64 %rd103, %rd84, %rd15;
setp.lt.u64	%p13, %rd103, %rd49;
@%p13 bra BB21_6;

BB21_17:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<18>;
.reg .f32 %f<4>;
.reg .b32 %r<17>;
.reg .b64 %rd<9>;


ld.param.u32 %r8, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r9, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r10, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r11, %ctaid.x;
mov.u32 %r12, %tid.x;
mad.lo.s32 %r16, %r1, %r11, %r12;
setp.ge.u32	%p1, %r16, %r10;
@%p1 bra BB22_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;
mov.u32 %r13, %nctaid.x;
mul.lo.s32 %r5, %r13, %r1;

BB22_2:
mul.lo.s32 %r14, %r16, %r8;
cvt.u64.u32	%rd5, %r14;
add.s64 %rd6, %rd1, %rd5;
mul.lo.s32 %r15, %r16, %r9;
mul.wide.u32 %rd7, %r15, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.le.f32	%p2, %f3, %f2;
selp.u16	%rs17, 1, 0, %p2;
st.global.u8 [%rd6], %rs17;
add.s32 %r16, %r5, %r16;
setp.lt.u32	%p3, %r16, %r10;
@%p3 bra BB22_2;

BB22_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.u32 %r12, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r3, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r3, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB23_3;

cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r3;
cvta.to.global.u64 %rd2, %rd4;

BB23_2:
mul.lo.s32 %r33, %r41, %r12;
cvt.u64.u32	%rd5, %r33;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r34, %r41, %r24;
add.s32 %r35, %r34, %r41;
shr.u32 %r36, %r35, %r25;
mul.lo.s32 %r37, %r36, %r27;
sub.s32 %r38, %r41, %r37;
mul.lo.s32 %r39, %r38, %r23;
mad.lo.s32 %r40, %r22, %r36, %r39;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.le.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
st.global.u8 [%rd6], %rs9;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB23_2;

BB23_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot24[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot24;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB24_2;

BB24_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB24_1;

BB24_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB24_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB24_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB24_6;

BB24_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB24_5;

BB24_6:
mul.lo.s32 %r30, %r8, %r18;
cvt.u64.u32	%rd16, %r30;
add.s64 %rd17, %rd4, %rd16;
ld.local.u32 %r31, [%rd1+108];
mad.lo.s32 %r32, %r31, %r38, %r42;
ld.local.u64 %rd18, [%rd1];
cvta.to.global.u64 %rd19, %rd18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd19, %rd20;
ld.global.f32 %f3, [%rd21];
setp.le.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
st.global.u8 [%rd17], %rs9;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB24_4;

BB24_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r20, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r1, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB25_3;

cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r1;
cvta.to.global.u64 %rd2, %rd3;

BB25_2:
mul.hi.u32 %r33, %r41, %r24;
add.s32 %r34, %r33, %r41;
shr.u32 %r35, %r34, %r25;
mul.lo.s32 %r36, %r35, %r27;
sub.s32 %r37, %r41, %r36;
mul.lo.s32 %r38, %r37, %r23;
mad.lo.s32 %r39, %r22, %r35, %r38;
cvt.u64.u32	%rd5, %r39;
add.s64 %rd6, %rd2, %rd5;
mul.lo.s32 %r40, %r41, %r20;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd1, %rd7;
ld.global.f32 %f3, [%rd8];
setp.le.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
st.global.u8 [%rd6], %rs9;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB25_2;

BB25_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<67>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r39, %r40}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r41, %r42}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r43, %r44}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r47, %ntid.x;
mov.u32 %r48, %ctaid.x;
mov.u32 %r49, %tid.x;
mad.lo.s32 %r66, %r47, %r48, %r49;
setp.ge.u32	%p1, %r66, %r30;
@%p1 bra BB26_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;

BB26_2:
mul.hi.u32 %r50, %r66, %r33;
add.s32 %r51, %r50, %r66;
shr.u32 %r52, %r51, %r34;
mul.lo.s32 %r53, %r52, %r36;
sub.s32 %r54, %r66, %r53;
mul.lo.s32 %r55, %r54, %r32;
mad.lo.s32 %r56, %r31, %r52, %r55;
cvt.u64.u32	%rd5, %r56;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r57, %r66, %r41;
add.s32 %r58, %r57, %r66;
shr.u32 %r59, %r58, %r42;
mul.lo.s32 %r60, %r59, %r44;
sub.s32 %r61, %r66, %r60;
mul.lo.s32 %r62, %r61, %r40;
mad.lo.s32 %r63, %r39, %r59, %r62;
mul.wide.u32 %rd7, %r63, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.le.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
st.global.u8 [%rd6], %rs1;
mov.u32 %r65, %nctaid.x;
mad.lo.s32 %r66, %r65, %r47, %r66;
setp.lt.u32	%p3, %r66, %r30;
@%p3 bra BB26_2;

BB26_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot27[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot27;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r32, %r33}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r34, %r35}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r36, %r37}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB27_2;

BB27_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB27_1;

BB27_2:
mov.u32 %r40, %ntid.x;
mov.u32 %r41, %ctaid.x;
mov.u32 %r42, %tid.x;
mad.lo.s32 %r65, %r40, %r41, %r42;
setp.ge.u32	%p3, %r65, %r30;
@%p3 bra BB27_7;

cvta.to.global.u64 %rd4, %rd10;
ld.local.u32 %r43, [%rd1+208];
add.s32 %r9, %r43, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd5, %rd16;
mul.wide.s32 %rd17, %r43, 4;
add.s64 %rd6, %rd1, %rd17;

BB27_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mul.hi.u32 %r12, %r11, %r34;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB27_6;

BB27_5:
mov.u32 %r14, %r64;
mov.u32 %r13, %r59;
ld.local.u32 %r46, [%rd22+4];
rem.u32 %r47, %r14, %r46;
ld.local.u32 %r48, [%rd22+104];
mad.lo.s32 %r68, %r48, %r47, %r68;
div.u32 %r17, %r14, %r46;
add.s64 %rd22, %rd22, -4;
add.s32 %r18, %r13, -1;
setp.gt.s32	%p5, %r18, 0;
mov.u32 %r59, %r18;
mov.u32 %r63, %r17;
mov.u32 %r64, %r17;
mov.u32 %r67, %r68;
@%p5 bra BB27_5;

BB27_6:
add.s32 %r49, %r12, %r11;
shr.u32 %r50, %r49, %r35;
mul.lo.s32 %r51, %r50, %r37;
sub.s32 %r52, %r11, %r51;
mul.lo.s32 %r53, %r52, %r33;
mad.lo.s32 %r54, %r32, %r50, %r53;
cvt.u64.u32	%rd18, %r54;
add.s64 %rd19, %rd4, %rd18;
mad.lo.s32 %r55, %r10, %r63, %r67;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.le.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
st.global.u8 [%rd19], %rs1;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r40, %r11;
setp.lt.u32	%p7, %r65, %r30;
@%p7 bra BB27_4;

BB27_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot28[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot28;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB28_2;

BB28_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB28_1;

BB28_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB28_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB28_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB28_6;

BB28_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB28_5;

BB28_6:
ld.local.u32 %r30, [%rd1+108];
mad.lo.s32 %r31, %r30, %r38, %r42;
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd17, %rd16;
cvt.u64.u32	%rd18, %r31;
add.s64 %rd19, %rd17, %rd18;
mul.lo.s32 %r32, %r8, %r18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd4, %rd20;
ld.global.f32 %f3, [%rd21];
setp.le.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
st.global.u8 [%rd19], %rs9;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB28_4;

BB28_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot29[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot29;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB29_2;

BB29_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB29_1;

BB29_2:
mov.u32 %r39, %ntid.x;
mov.u32 %r40, %ctaid.x;
mov.u32 %r41, %tid.x;
mad.lo.s32 %r65, %r39, %r40, %r41;
setp.ge.u32	%p3, %r65, %r29;
@%p3 bra BB29_7;

ld.local.u32 %r42, [%rd1+208];
add.s32 %r9, %r42, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd4, %rd16;
cvta.to.global.u64 %rd5, %rd10;
mul.wide.s32 %rd17, %r42, 4;
add.s64 %rd6, %rd1, %rd17;

BB29_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB29_6;

BB29_5:
mov.u32 %r13, %r64;
mov.u32 %r12, %r59;
ld.local.u32 %r45, [%rd22+4];
rem.u32 %r46, %r13, %r45;
ld.local.u32 %r47, [%rd22+104];
mad.lo.s32 %r68, %r47, %r46, %r68;
div.u32 %r16, %r13, %r45;
add.s64 %rd22, %rd22, -4;
add.s32 %r17, %r12, -1;
setp.gt.s32	%p5, %r17, 0;
mov.u32 %r59, %r17;
mov.u32 %r63, %r16;
mov.u32 %r64, %r16;
mov.u32 %r67, %r68;
@%p5 bra BB29_5;

BB29_6:
mad.lo.s32 %r48, %r10, %r63, %r67;
cvt.u64.u32	%rd18, %r48;
add.s64 %rd19, %rd4, %rd18;
mul.hi.u32 %r49, %r11, %r33;
add.s32 %r50, %r49, %r11;
shr.u32 %r51, %r50, %r34;
mul.lo.s32 %r52, %r51, %r36;
sub.s32 %r53, %r11, %r52;
mul.lo.s32 %r54, %r53, %r32;
mad.lo.s32 %r55, %r31, %r51, %r54;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.le.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
st.global.u8 [%rd19], %rs1;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r39, %r11;
setp.lt.u32	%p7, %r65, %r29;
@%p7 bra BB29_4;

BB29_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot30[432];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<12>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<72>;
.reg .b64 %rd<39>;


mov.u64 %rd38, __local_depot30;
cvta.local.u64 %SP, %rd38;
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd18, %SP, 216;
cvta.to.local.u64 %rd2, %rd18;
add.u64 %rd19, %SP, 0;
cvta.to.local.u64 %rd3, %rd19;
mov.u32 %r50, 0;
mov.pred %p1, 0;
@%p1 bra BB30_2;

BB30_1:
mul.wide.s32 %rd20, %r50, 8;
add.s64 %rd21, %rd4, %rd20;
ld.param.u64 %rd22, [%rd21];
add.s64 %rd23, %rd2, %rd20;
st.local.u64 [%rd23], %rd22;
add.s32 %r50, %r50, 1;
setp.lt.u32	%p2, %r50, 27;
@%p2 bra BB30_1;

BB30_2:
mov.u32 %r51, 0;
@%p1 bra BB30_4;

BB30_3:
mul.wide.s32 %rd24, %r51, 8;
add.s64 %rd25, %rd1, %rd24;
ld.param.u64 %rd26, [%rd25];
add.s64 %rd27, %rd3, %rd24;
st.local.u64 [%rd27], %rd26;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p4, %r51, 27;
@%p4 bra BB30_3;

BB30_4:
mov.u32 %r32, %ntid.x;
mov.u32 %r33, %ctaid.x;
mov.u32 %r34, %tid.x;
mad.lo.s32 %r64, %r32, %r33, %r34;
setp.ge.u32	%p5, %r64, %r29;
@%p5 bra BB30_11;

ld.local.u32 %r35, [%rd2+208];
add.s32 %r6, %r35, -1;
ld.local.u32 %r7, [%rd2+108];
ld.local.u64 %rd28, [%rd2];
cvta.to.global.u64 %rd8, %rd28;
ld.local.u32 %r36, [%rd3+208];
add.s32 %r8, %r36, -1;
ld.local.u32 %r9, [%rd3+108];
ld.local.u64 %rd29, [%rd3];
cvta.to.global.u64 %rd9, %rd29;
mul.wide.s32 %rd30, %r35, 4;
add.s64 %rd10, %rd2, %rd30;
mul.wide.s32 %rd31, %r36, 4;
add.s64 %rd11, %rd3, %rd31;

BB30_6:
mov.u32 %r54, %r64;
mov.u32 %r10, %r54;
mov.u64 %rd36, %rd10;
mov.u32 %r38, 0;
mov.u32 %r71, %r38;
setp.lt.s32	%p6, %r6, 1;
mov.u32 %r52, %r6;
mov.u32 %r62, %r10;
mov.u32 %r63, %r10;
mov.u32 %r70, %r38;
@%p6 bra BB30_8;

BB30_7:
mov.u32 %r12, %r63;
mov.u32 %r11, %r52;
ld.local.u32 %r39, [%rd36+4];
rem.u32 %r40, %r12, %r39;
ld.local.u32 %r41, [%rd36+104];
mad.lo.s32 %r71, %r41, %r40, %r71;
div.u32 %r15, %r12, %r39;
add.s64 %rd36, %rd36, -4;
add.s32 %r16, %r11, -1;
setp.gt.s32	%p7, %r16, 0;
mov.u32 %r52, %r16;
mov.u32 %r62, %r15;
mov.u32 %r63, %r15;
mov.u32 %r65, %r71;
mov.u32 %r70, %r65;
@%p7 bra BB30_7;

BB30_8:
mov.u32 %r18, %r70;
mov.u64 %rd37, %rd11;
mad.lo.s32 %r19, %r7, %r62, %r18;
mov.u32 %r69, %r38;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r53, %r8;
mov.u32 %r61, %r10;
mov.u32 %r60, %r10;
mov.u32 %r68, %r38;
@%p8 bra BB30_10;

BB30_9:
mov.u32 %r20, %r53;
ld.local.u32 %r44, [%rd37+4];
rem.u32 %r45, %r61, %r44;
ld.local.u32 %r46, [%rd37+104];
mad.lo.s32 %r69, %r46, %r45, %r69;
div.u32 %r61, %r61, %r44;
add.s64 %rd37, %rd37, -4;
add.s32 %r25, %r20, -1;
setp.gt.s32	%p9, %r25, 0;
mov.u32 %r53, %r25;
mov.u32 %r60, %r61;
mov.u32 %r68, %r69;
@%p9 bra BB30_9;

BB30_10:
cvt.u64.u32	%rd32, %r19;
add.s64 %rd33, %rd8, %rd32;
mad.lo.s32 %r47, %r9, %r60, %r68;
mul.wide.u32 %rd34, %r47, 4;
add.s64 %rd35, %rd9, %rd34;
ld.global.f32 %f3, [%rd35];
setp.le.f32	%p10, %f3, %f2;
selp.u16	%rs1, 1, 0, %p10;
st.global.u8 [%rd33], %rs1;
mov.u32 %r49, %nctaid.x;
mad.lo.s32 %r64, %r49, %r32, %r10;
setp.lt.u32	%p11, %r64, %r29;
@%p11 bra BB30_6;

BB30_11:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u64 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<5>;
.reg .b64 %rd<24>;


ld.param.u64 %rd11, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u64 %rd13, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd12, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u64 %rd14, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %ntid.x;
cvt.u64.u32	%rd1, %r2;
mul.wide.u32 %rd15, %r2, %r1;
mov.u32 %r3, %tid.x;
cvt.u64.u32	%rd16, %r3;
add.s64 %rd23, %rd15, %rd16;
setp.ge.u64	%p1, %rd23, %rd14;
@%p1 bra BB31_3;

cvta.to.global.u64 %rd3, %rd10;
cvta.to.global.u64 %rd5, %rd12;
mov.u32 %r4, %nctaid.x;
cvt.u64.u32	%rd17, %r4;
mul.lo.s64 %rd7, %rd17, %rd1;

BB31_2:
mul.lo.s64 %rd18, %rd23, %rd11;
add.s64 %rd19, %rd3, %rd18;
mul.lo.s64 %rd20, %rd23, %rd13;
shl.b64 %rd21, %rd20, 2;
add.s64 %rd22, %rd5, %rd21;
ld.global.f32 %f3, [%rd22];
setp.le.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
st.global.u8 [%rd19], %rs1;
add.s64 %rd23, %rd7, %rd23;
setp.lt.u64	%p3, %rd23, %rd14;
@%p3 bra BB31_2;

BB31_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[416],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[416],
.param .u64 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot32[832];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<32>;
.reg .b64 %rd<112>;


mov.u64 %rd111, __local_depot32;
cvta.local.u64 %SP, %rd111;
ld.param.u64 %rd49, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorLEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd50, %SP, 416;
cvta.to.local.u64 %rd2, %rd50;
add.u64 %rd51, %SP, 0;
cvta.to.local.u64 %rd3, %rd51;
mov.u32 %r28, 0;
mov.pred %p1, 0;
@%p1 bra BB32_2;

BB32_1:
mul.wide.s32 %rd52, %r28, 8;
add.s64 %rd53, %rd4, %rd52;
ld.param.u64 %rd54, [%rd53];
add.s64 %rd55, %rd2, %rd52;
st.local.u64 [%rd55], %rd54;
add.s32 %r28, %r28, 1;
setp.lt.u32	%p2, %r28, 52;
@%p2 bra BB32_1;

BB32_2:
mov.u32 %r29, 0;
@%p1 bra BB32_4;

BB32_3:
mul.wide.s32 %rd56, %r29, 8;
add.s64 %rd57, %rd1, %rd56;
ld.param.u64 %rd58, [%rd57];
add.s64 %rd59, %rd3, %rd56;
st.local.u64 [%rd59], %rd58;
add.s32 %r29, %r29, 1;
setp.lt.u32	%p4, %r29, 52;
@%p4 bra BB32_3;

BB32_4:
mov.u32 %r13, %ctaid.x;
mov.u32 %r14, %ntid.x;
mul.wide.u32 %rd60, %r14, %r13;
mov.u32 %r15, %tid.x;
cvt.u64.u32	%rd61, %r15;
add.s64 %rd103, %rd60, %rd61;
setp.ge.u64	%p5, %rd103, %rd49;
@%p5 bra BB32_17;

ld.local.u32 %r16, [%rd2+408];
add.s32 %r5, %r16, -1;
ld.local.u64 %rd9, [%rd2+208];
ld.local.u64 %rd62, [%rd2];
cvta.to.global.u64 %rd10, %rd62;
ld.local.u32 %r17, [%rd3+408];
add.s32 %r6, %r17, -1;
ld.local.u64 %rd11, [%rd3+208];
ld.local.u64 %rd63, [%rd3];
cvta.to.global.u64 %rd12, %rd63;
mul.wide.s32 %rd64, %r16, 8;
add.s64 %rd13, %rd2, %rd64;
mul.wide.s32 %rd65, %r17, 8;
add.s64 %rd14, %rd3, %rd65;

BB32_6:
mov.u64 %rd89, %rd103;
mov.u64 %rd15, %rd89;
mov.u64 %rd85, %rd13;
mov.u64 %rd67, 0;
mov.u64 %rd110, %rd67;
setp.lt.s32	%p6, %r5, 1;
mov.u32 %r30, %r5;
mov.u64 %rd100, %rd15;
mov.u64 %rd101, %rd15;
mov.u64 %rd109, %rd67;
@%p6 bra BB32_11;

BB32_7:
mov.u64 %rd18, %rd101;
mov.u32 %r7, %r30;
ld.local.u64 %rd21, [%rd85];
or.b64 %rd68, %rd18, %rd21;
and.b64 %rd69, %rd68, -4294967296;
setp.eq.s64	%p7, %rd69, 0;
@%p7 bra BB32_9;
bra.uni BB32_8;

BB32_9:
cvt.u32.u64	%r18, %rd21;
cvt.u32.u64	%r19, %rd18;
div.u32 %r20, %r19, %r18;
rem.u32 %r21, %r19, %r18;
cvt.u64.u32	%rd102, %r20;
cvt.u64.u32	%rd86, %r21;
bra.uni BB32_10;

BB32_8:
div.u64 %rd102, %rd18, %rd21;
rem.u64 %rd86, %rd18, %rd21;

BB32_10:
mov.u64 %rd26, %rd102;
ld.local.u64 %rd70, [%rd85+200];
mul.lo.s64 %rd71, %rd70, %rd86;
add.s64 %rd110, %rd71, %rd110;
add.s64 %rd85, %rd85, -8;
add.s32 %r8, %r7, -1;
setp.gt.s32	%p8, %r8, 0;
mov.u32 %r30, %r8;
mov.u64 %rd100, %rd26;
mov.u64 %rd101, %rd26;
mov.u64 %rd104, %rd110;
mov.u64 %rd109, %rd104;
@%p8 bra BB32_7;

BB32_11:
mov.u64 %rd31, %rd109;
mov.u64 %rd87, %rd14;
mul.lo.s64 %rd74, %rd9, %rd100;
add.s64 %rd33, %rd74, %rd31;
mov.u64 %rd108, %rd67;
setp.lt.s32	%p9, %r6, 1;
mov.u32 %r31, %r6;
mov.u64 %rd98, %rd15;
mov.u64 %rd97, %rd15;
mov.u64 %rd107, %rd67;
@%p9 bra BB32_16;

BB32_12:
mov.u32 %r9, %r31;
ld.local.u64 %rd37, [%rd87];
or.b64 %rd75, %rd98, %rd37;
and.b64 %rd76, %rd75, -4294967296;
setp.eq.s64	%p10, %rd76, 0;
@%p10 bra BB32_14;
bra.uni BB32_13;

BB32_14:
cvt.u32.u64	%r22, %rd37;
cvt.u32.u64	%r23, %rd98;
div.u32 %r24, %r23, %r22;
rem.u32 %r25, %r23, %r22;
cvt.u64.u32	%rd99, %r24;
cvt.u64.u32	%rd88, %r25;
bra.uni BB32_15;

BB32_13:
div.u64 %rd99, %rd98, %rd37;
rem.u64 %rd88, %rd98, %rd37;

BB32_15:
mov.u64 %rd98, %rd99;
ld.local.u64 %rd77, [%rd87+200];
mul.lo.s64 %rd78, %rd77, %rd88;
add.s64 %rd108, %rd78, %rd108;
add.s64 %rd87, %rd87, -8;
add.s32 %r10, %r9, -1;
setp.gt.s32	%p11, %r10, 0;
mov.u32 %r31, %r10;
mov.u64 %rd97, %rd98;
mov.u64 %rd107, %rd108;
@%p11 bra BB32_12;

BB32_16:
add.s64 %rd79, %rd10, %rd33;
mul.lo.s64 %rd80, %rd11, %rd97;
add.s64 %rd81, %rd80, %rd107;
shl.b64 %rd82, %rd81, 2;
add.s64 %rd83, %rd12, %rd82;
ld.global.f32 %f3, [%rd83];
setp.le.f32	%p12, %f3, %f2;
selp.u16	%rs1, 1, 0, %p12;
st.global.u8 [%rd79], %rs1;
mov.u32 %r26, %nctaid.x;
mul.wide.u32 %rd84, %r26, %r14;
add.s64 %rd103, %rd84, %rd15;
setp.lt.u64	%p13, %rd103, %rd49;
@%p13 bra BB32_6;

BB32_17:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<18>;
.reg .f32 %f<4>;
.reg .b32 %r<17>;
.reg .b64 %rd<9>;


ld.param.u32 %r8, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r9, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r10, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r11, %ctaid.x;
mov.u32 %r12, %tid.x;
mad.lo.s32 %r16, %r1, %r11, %r12;
setp.ge.u32	%p1, %r16, %r10;
@%p1 bra BB33_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;
mov.u32 %r13, %nctaid.x;
mul.lo.s32 %r5, %r13, %r1;

BB33_2:
mul.lo.s32 %r14, %r16, %r8;
cvt.u64.u32	%rd5, %r14;
add.s64 %rd6, %rd1, %rd5;
mul.lo.s32 %r15, %r16, %r9;
mul.wide.u32 %rd7, %r15, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.ge.f32	%p2, %f3, %f2;
selp.u16	%rs17, 1, 0, %p2;
st.global.u8 [%rd6], %rs17;
add.s32 %r16, %r5, %r16;
setp.lt.u32	%p3, %r16, %r10;
@%p3 bra BB33_2;

BB33_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.u32 %r12, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r3, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r3, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB34_3;

cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r3;
cvta.to.global.u64 %rd2, %rd4;

BB34_2:
mul.lo.s32 %r33, %r41, %r12;
cvt.u64.u32	%rd5, %r33;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r34, %r41, %r24;
add.s32 %r35, %r34, %r41;
shr.u32 %r36, %r35, %r25;
mul.lo.s32 %r37, %r36, %r27;
sub.s32 %r38, %r41, %r37;
mul.lo.s32 %r39, %r38, %r23;
mad.lo.s32 %r40, %r22, %r36, %r39;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.ge.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
st.global.u8 [%rd6], %rs9;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB34_2;

BB34_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot35[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot35;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB35_2;

BB35_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB35_1;

BB35_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB35_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB35_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB35_6;

BB35_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB35_5;

BB35_6:
mul.lo.s32 %r30, %r8, %r18;
cvt.u64.u32	%rd16, %r30;
add.s64 %rd17, %rd4, %rd16;
ld.local.u32 %r31, [%rd1+108];
mad.lo.s32 %r32, %r31, %r38, %r42;
ld.local.u64 %rd18, [%rd1];
cvta.to.global.u64 %rd19, %rd18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd19, %rd20;
ld.global.f32 %f3, [%rd21];
setp.ge.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
st.global.u8 [%rd17], %rs9;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB35_4;

BB35_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r20, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r1, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB36_3;

cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r1;
cvta.to.global.u64 %rd2, %rd3;

BB36_2:
mul.hi.u32 %r33, %r41, %r24;
add.s32 %r34, %r33, %r41;
shr.u32 %r35, %r34, %r25;
mul.lo.s32 %r36, %r35, %r27;
sub.s32 %r37, %r41, %r36;
mul.lo.s32 %r38, %r37, %r23;
mad.lo.s32 %r39, %r22, %r35, %r38;
cvt.u64.u32	%rd5, %r39;
add.s64 %rd6, %rd2, %rd5;
mul.lo.s32 %r40, %r41, %r20;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd1, %rd7;
ld.global.f32 %f3, [%rd8];
setp.ge.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
st.global.u8 [%rd6], %rs9;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB36_2;

BB36_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<67>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r39, %r40}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r41, %r42}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r43, %r44}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r47, %ntid.x;
mov.u32 %r48, %ctaid.x;
mov.u32 %r49, %tid.x;
mad.lo.s32 %r66, %r47, %r48, %r49;
setp.ge.u32	%p1, %r66, %r30;
@%p1 bra BB37_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;

BB37_2:
mul.hi.u32 %r50, %r66, %r33;
add.s32 %r51, %r50, %r66;
shr.u32 %r52, %r51, %r34;
mul.lo.s32 %r53, %r52, %r36;
sub.s32 %r54, %r66, %r53;
mul.lo.s32 %r55, %r54, %r32;
mad.lo.s32 %r56, %r31, %r52, %r55;
cvt.u64.u32	%rd5, %r56;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r57, %r66, %r41;
add.s32 %r58, %r57, %r66;
shr.u32 %r59, %r58, %r42;
mul.lo.s32 %r60, %r59, %r44;
sub.s32 %r61, %r66, %r60;
mul.lo.s32 %r62, %r61, %r40;
mad.lo.s32 %r63, %r39, %r59, %r62;
mul.wide.u32 %rd7, %r63, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.ge.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
st.global.u8 [%rd6], %rs1;
mov.u32 %r65, %nctaid.x;
mad.lo.s32 %r66, %r65, %r47, %r66;
setp.lt.u32	%p3, %r66, %r30;
@%p3 bra BB37_2;

BB37_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot38[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot38;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r32, %r33}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r34, %r35}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r36, %r37}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB38_2;

BB38_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB38_1;

BB38_2:
mov.u32 %r40, %ntid.x;
mov.u32 %r41, %ctaid.x;
mov.u32 %r42, %tid.x;
mad.lo.s32 %r65, %r40, %r41, %r42;
setp.ge.u32	%p3, %r65, %r30;
@%p3 bra BB38_7;

cvta.to.global.u64 %rd4, %rd10;
ld.local.u32 %r43, [%rd1+208];
add.s32 %r9, %r43, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd5, %rd16;
mul.wide.s32 %rd17, %r43, 4;
add.s64 %rd6, %rd1, %rd17;

BB38_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mul.hi.u32 %r12, %r11, %r34;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB38_6;

BB38_5:
mov.u32 %r14, %r64;
mov.u32 %r13, %r59;
ld.local.u32 %r46, [%rd22+4];
rem.u32 %r47, %r14, %r46;
ld.local.u32 %r48, [%rd22+104];
mad.lo.s32 %r68, %r48, %r47, %r68;
div.u32 %r17, %r14, %r46;
add.s64 %rd22, %rd22, -4;
add.s32 %r18, %r13, -1;
setp.gt.s32	%p5, %r18, 0;
mov.u32 %r59, %r18;
mov.u32 %r63, %r17;
mov.u32 %r64, %r17;
mov.u32 %r67, %r68;
@%p5 bra BB38_5;

BB38_6:
add.s32 %r49, %r12, %r11;
shr.u32 %r50, %r49, %r35;
mul.lo.s32 %r51, %r50, %r37;
sub.s32 %r52, %r11, %r51;
mul.lo.s32 %r53, %r52, %r33;
mad.lo.s32 %r54, %r32, %r50, %r53;
cvt.u64.u32	%rd18, %r54;
add.s64 %rd19, %rd4, %rd18;
mad.lo.s32 %r55, %r10, %r63, %r67;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.ge.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
st.global.u8 [%rd19], %rs1;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r40, %r11;
setp.lt.u32	%p7, %r65, %r30;
@%p7 bra BB38_4;

BB38_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot39[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot39;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB39_2;

BB39_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB39_1;

BB39_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB39_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB39_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB39_6;

BB39_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB39_5;

BB39_6:
ld.local.u32 %r30, [%rd1+108];
mad.lo.s32 %r31, %r30, %r38, %r42;
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd17, %rd16;
cvt.u64.u32	%rd18, %r31;
add.s64 %rd19, %rd17, %rd18;
mul.lo.s32 %r32, %r8, %r18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd4, %rd20;
ld.global.f32 %f3, [%rd21];
setp.ge.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
st.global.u8 [%rd19], %rs9;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB39_4;

BB39_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot40[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot40;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB40_2;

BB40_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB40_1;

BB40_2:
mov.u32 %r39, %ntid.x;
mov.u32 %r40, %ctaid.x;
mov.u32 %r41, %tid.x;
mad.lo.s32 %r65, %r39, %r40, %r41;
setp.ge.u32	%p3, %r65, %r29;
@%p3 bra BB40_7;

ld.local.u32 %r42, [%rd1+208];
add.s32 %r9, %r42, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd4, %rd16;
cvta.to.global.u64 %rd5, %rd10;
mul.wide.s32 %rd17, %r42, 4;
add.s64 %rd6, %rd1, %rd17;

BB40_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB40_6;

BB40_5:
mov.u32 %r13, %r64;
mov.u32 %r12, %r59;
ld.local.u32 %r45, [%rd22+4];
rem.u32 %r46, %r13, %r45;
ld.local.u32 %r47, [%rd22+104];
mad.lo.s32 %r68, %r47, %r46, %r68;
div.u32 %r16, %r13, %r45;
add.s64 %rd22, %rd22, -4;
add.s32 %r17, %r12, -1;
setp.gt.s32	%p5, %r17, 0;
mov.u32 %r59, %r17;
mov.u32 %r63, %r16;
mov.u32 %r64, %r16;
mov.u32 %r67, %r68;
@%p5 bra BB40_5;

BB40_6:
mad.lo.s32 %r48, %r10, %r63, %r67;
cvt.u64.u32	%rd18, %r48;
add.s64 %rd19, %rd4, %rd18;
mul.hi.u32 %r49, %r11, %r33;
add.s32 %r50, %r49, %r11;
shr.u32 %r51, %r50, %r34;
mul.lo.s32 %r52, %r51, %r36;
sub.s32 %r53, %r11, %r52;
mul.lo.s32 %r54, %r53, %r32;
mad.lo.s32 %r55, %r31, %r51, %r54;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.ge.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
st.global.u8 [%rd19], %rs1;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r39, %r11;
setp.lt.u32	%p7, %r65, %r29;
@%p7 bra BB40_4;

BB40_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot41[432];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<12>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<72>;
.reg .b64 %rd<39>;


mov.u64 %rd38, __local_depot41;
cvta.local.u64 %SP, %rd38;
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd18, %SP, 216;
cvta.to.local.u64 %rd2, %rd18;
add.u64 %rd19, %SP, 0;
cvta.to.local.u64 %rd3, %rd19;
mov.u32 %r50, 0;
mov.pred %p1, 0;
@%p1 bra BB41_2;

BB41_1:
mul.wide.s32 %rd20, %r50, 8;
add.s64 %rd21, %rd4, %rd20;
ld.param.u64 %rd22, [%rd21];
add.s64 %rd23, %rd2, %rd20;
st.local.u64 [%rd23], %rd22;
add.s32 %r50, %r50, 1;
setp.lt.u32	%p2, %r50, 27;
@%p2 bra BB41_1;

BB41_2:
mov.u32 %r51, 0;
@%p1 bra BB41_4;

BB41_3:
mul.wide.s32 %rd24, %r51, 8;
add.s64 %rd25, %rd1, %rd24;
ld.param.u64 %rd26, [%rd25];
add.s64 %rd27, %rd3, %rd24;
st.local.u64 [%rd27], %rd26;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p4, %r51, 27;
@%p4 bra BB41_3;

BB41_4:
mov.u32 %r32, %ntid.x;
mov.u32 %r33, %ctaid.x;
mov.u32 %r34, %tid.x;
mad.lo.s32 %r64, %r32, %r33, %r34;
setp.ge.u32	%p5, %r64, %r29;
@%p5 bra BB41_11;

ld.local.u32 %r35, [%rd2+208];
add.s32 %r6, %r35, -1;
ld.local.u32 %r7, [%rd2+108];
ld.local.u64 %rd28, [%rd2];
cvta.to.global.u64 %rd8, %rd28;
ld.local.u32 %r36, [%rd3+208];
add.s32 %r8, %r36, -1;
ld.local.u32 %r9, [%rd3+108];
ld.local.u64 %rd29, [%rd3];
cvta.to.global.u64 %rd9, %rd29;
mul.wide.s32 %rd30, %r35, 4;
add.s64 %rd10, %rd2, %rd30;
mul.wide.s32 %rd31, %r36, 4;
add.s64 %rd11, %rd3, %rd31;

BB41_6:
mov.u32 %r54, %r64;
mov.u32 %r10, %r54;
mov.u64 %rd36, %rd10;
mov.u32 %r38, 0;
mov.u32 %r71, %r38;
setp.lt.s32	%p6, %r6, 1;
mov.u32 %r52, %r6;
mov.u32 %r62, %r10;
mov.u32 %r63, %r10;
mov.u32 %r70, %r38;
@%p6 bra BB41_8;

BB41_7:
mov.u32 %r12, %r63;
mov.u32 %r11, %r52;
ld.local.u32 %r39, [%rd36+4];
rem.u32 %r40, %r12, %r39;
ld.local.u32 %r41, [%rd36+104];
mad.lo.s32 %r71, %r41, %r40, %r71;
div.u32 %r15, %r12, %r39;
add.s64 %rd36, %rd36, -4;
add.s32 %r16, %r11, -1;
setp.gt.s32	%p7, %r16, 0;
mov.u32 %r52, %r16;
mov.u32 %r62, %r15;
mov.u32 %r63, %r15;
mov.u32 %r65, %r71;
mov.u32 %r70, %r65;
@%p7 bra BB41_7;

BB41_8:
mov.u32 %r18, %r70;
mov.u64 %rd37, %rd11;
mad.lo.s32 %r19, %r7, %r62, %r18;
mov.u32 %r69, %r38;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r53, %r8;
mov.u32 %r61, %r10;
mov.u32 %r60, %r10;
mov.u32 %r68, %r38;
@%p8 bra BB41_10;

BB41_9:
mov.u32 %r20, %r53;
ld.local.u32 %r44, [%rd37+4];
rem.u32 %r45, %r61, %r44;
ld.local.u32 %r46, [%rd37+104];
mad.lo.s32 %r69, %r46, %r45, %r69;
div.u32 %r61, %r61, %r44;
add.s64 %rd37, %rd37, -4;
add.s32 %r25, %r20, -1;
setp.gt.s32	%p9, %r25, 0;
mov.u32 %r53, %r25;
mov.u32 %r60, %r61;
mov.u32 %r68, %r69;
@%p9 bra BB41_9;

BB41_10:
cvt.u64.u32	%rd32, %r19;
add.s64 %rd33, %rd8, %rd32;
mad.lo.s32 %r47, %r9, %r60, %r68;
mul.wide.u32 %rd34, %r47, 4;
add.s64 %rd35, %rd9, %rd34;
ld.global.f32 %f3, [%rd35];
setp.ge.f32	%p10, %f3, %f2;
selp.u16	%rs1, 1, 0, %p10;
st.global.u8 [%rd33], %rs1;
mov.u32 %r49, %nctaid.x;
mad.lo.s32 %r64, %r49, %r32, %r10;
setp.lt.u32	%p11, %r64, %r29;
@%p11 bra BB41_6;

BB41_11:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u64 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<5>;
.reg .b64 %rd<24>;


ld.param.u64 %rd11, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u64 %rd13, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd12, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u64 %rd14, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %ntid.x;
cvt.u64.u32	%rd1, %r2;
mul.wide.u32 %rd15, %r2, %r1;
mov.u32 %r3, %tid.x;
cvt.u64.u32	%rd16, %r3;
add.s64 %rd23, %rd15, %rd16;
setp.ge.u64	%p1, %rd23, %rd14;
@%p1 bra BB42_3;

cvta.to.global.u64 %rd3, %rd10;
cvta.to.global.u64 %rd5, %rd12;
mov.u32 %r4, %nctaid.x;
cvt.u64.u32	%rd17, %r4;
mul.lo.s64 %rd7, %rd17, %rd1;

BB42_2:
mul.lo.s64 %rd18, %rd23, %rd11;
add.s64 %rd19, %rd3, %rd18;
mul.lo.s64 %rd20, %rd23, %rd13;
shl.b64 %rd21, %rd20, 2;
add.s64 %rd22, %rd5, %rd21;
ld.global.f32 %f3, [%rd22];
setp.ge.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
st.global.u8 [%rd19], %rs1;
add.s64 %rd23, %rd7, %rd23;
setp.lt.u64	%p3, %rd23, %rd14;
@%p3 bra BB42_2;

BB42_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[416],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[416],
.param .u64 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot43[832];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<32>;
.reg .b64 %rd<112>;


mov.u64 %rd111, __local_depot43;
cvta.local.u64 %SP, %rd111;
ld.param.u64 %rd49, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorGEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd50, %SP, 416;
cvta.to.local.u64 %rd2, %rd50;
add.u64 %rd51, %SP, 0;
cvta.to.local.u64 %rd3, %rd51;
mov.u32 %r28, 0;
mov.pred %p1, 0;
@%p1 bra BB43_2;

BB43_1:
mul.wide.s32 %rd52, %r28, 8;
add.s64 %rd53, %rd4, %rd52;
ld.param.u64 %rd54, [%rd53];
add.s64 %rd55, %rd2, %rd52;
st.local.u64 [%rd55], %rd54;
add.s32 %r28, %r28, 1;
setp.lt.u32	%p2, %r28, 52;
@%p2 bra BB43_1;

BB43_2:
mov.u32 %r29, 0;
@%p1 bra BB43_4;

BB43_3:
mul.wide.s32 %rd56, %r29, 8;
add.s64 %rd57, %rd1, %rd56;
ld.param.u64 %rd58, [%rd57];
add.s64 %rd59, %rd3, %rd56;
st.local.u64 [%rd59], %rd58;
add.s32 %r29, %r29, 1;
setp.lt.u32	%p4, %r29, 52;
@%p4 bra BB43_3;

BB43_4:
mov.u32 %r13, %ctaid.x;
mov.u32 %r14, %ntid.x;
mul.wide.u32 %rd60, %r14, %r13;
mov.u32 %r15, %tid.x;
cvt.u64.u32	%rd61, %r15;
add.s64 %rd103, %rd60, %rd61;
setp.ge.u64	%p5, %rd103, %rd49;
@%p5 bra BB43_17;

ld.local.u32 %r16, [%rd2+408];
add.s32 %r5, %r16, -1;
ld.local.u64 %rd9, [%rd2+208];
ld.local.u64 %rd62, [%rd2];
cvta.to.global.u64 %rd10, %rd62;
ld.local.u32 %r17, [%rd3+408];
add.s32 %r6, %r17, -1;
ld.local.u64 %rd11, [%rd3+208];
ld.local.u64 %rd63, [%rd3];
cvta.to.global.u64 %rd12, %rd63;
mul.wide.s32 %rd64, %r16, 8;
add.s64 %rd13, %rd2, %rd64;
mul.wide.s32 %rd65, %r17, 8;
add.s64 %rd14, %rd3, %rd65;

BB43_6:
mov.u64 %rd89, %rd103;
mov.u64 %rd15, %rd89;
mov.u64 %rd85, %rd13;
mov.u64 %rd67, 0;
mov.u64 %rd110, %rd67;
setp.lt.s32	%p6, %r5, 1;
mov.u32 %r30, %r5;
mov.u64 %rd100, %rd15;
mov.u64 %rd101, %rd15;
mov.u64 %rd109, %rd67;
@%p6 bra BB43_11;

BB43_7:
mov.u64 %rd18, %rd101;
mov.u32 %r7, %r30;
ld.local.u64 %rd21, [%rd85];
or.b64 %rd68, %rd18, %rd21;
and.b64 %rd69, %rd68, -4294967296;
setp.eq.s64	%p7, %rd69, 0;
@%p7 bra BB43_9;
bra.uni BB43_8;

BB43_9:
cvt.u32.u64	%r18, %rd21;
cvt.u32.u64	%r19, %rd18;
div.u32 %r20, %r19, %r18;
rem.u32 %r21, %r19, %r18;
cvt.u64.u32	%rd102, %r20;
cvt.u64.u32	%rd86, %r21;
bra.uni BB43_10;

BB43_8:
div.u64 %rd102, %rd18, %rd21;
rem.u64 %rd86, %rd18, %rd21;

BB43_10:
mov.u64 %rd26, %rd102;
ld.local.u64 %rd70, [%rd85+200];
mul.lo.s64 %rd71, %rd70, %rd86;
add.s64 %rd110, %rd71, %rd110;
add.s64 %rd85, %rd85, -8;
add.s32 %r8, %r7, -1;
setp.gt.s32	%p8, %r8, 0;
mov.u32 %r30, %r8;
mov.u64 %rd100, %rd26;
mov.u64 %rd101, %rd26;
mov.u64 %rd104, %rd110;
mov.u64 %rd109, %rd104;
@%p8 bra BB43_7;

BB43_11:
mov.u64 %rd31, %rd109;
mov.u64 %rd87, %rd14;
mul.lo.s64 %rd74, %rd9, %rd100;
add.s64 %rd33, %rd74, %rd31;
mov.u64 %rd108, %rd67;
setp.lt.s32	%p9, %r6, 1;
mov.u32 %r31, %r6;
mov.u64 %rd98, %rd15;
mov.u64 %rd97, %rd15;
mov.u64 %rd107, %rd67;
@%p9 bra BB43_16;

BB43_12:
mov.u32 %r9, %r31;
ld.local.u64 %rd37, [%rd87];
or.b64 %rd75, %rd98, %rd37;
and.b64 %rd76, %rd75, -4294967296;
setp.eq.s64	%p10, %rd76, 0;
@%p10 bra BB43_14;
bra.uni BB43_13;

BB43_14:
cvt.u32.u64	%r22, %rd37;
cvt.u32.u64	%r23, %rd98;
div.u32 %r24, %r23, %r22;
rem.u32 %r25, %r23, %r22;
cvt.u64.u32	%rd99, %r24;
cvt.u64.u32	%rd88, %r25;
bra.uni BB43_15;

BB43_13:
div.u64 %rd99, %rd98, %rd37;
rem.u64 %rd88, %rd98, %rd37;

BB43_15:
mov.u64 %rd98, %rd99;
ld.local.u64 %rd77, [%rd87+200];
mul.lo.s64 %rd78, %rd77, %rd88;
add.s64 %rd108, %rd78, %rd108;
add.s64 %rd87, %rd87, -8;
add.s32 %r10, %r9, -1;
setp.gt.s32	%p11, %r10, 0;
mov.u32 %r31, %r10;
mov.u64 %rd97, %rd98;
mov.u64 %rd107, %rd108;
@%p11 bra BB43_12;

BB43_16:
add.s64 %rd79, %rd10, %rd33;
mul.lo.s64 %rd80, %rd11, %rd97;
add.s64 %rd81, %rd80, %rd107;
shl.b64 %rd82, %rd81, 2;
add.s64 %rd83, %rd12, %rd82;
ld.global.f32 %f3, [%rd83];
setp.ge.f32	%p12, %f3, %f2;
selp.u16	%rs1, 1, 0, %p12;
st.global.u8 [%rd79], %rs1;
mov.u32 %r26, %nctaid.x;
mul.wide.u32 %rd84, %r26, %r14;
add.s64 %rd103, %rd84, %rd15;
setp.lt.u64	%p13, %rd103, %rd49;
@%p13 bra BB43_6;

BB43_17:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<18>;
.reg .f32 %f<4>;
.reg .b32 %r<17>;
.reg .b64 %rd<9>;


ld.param.u32 %r8, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r9, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r10, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r11, %ctaid.x;
mov.u32 %r12, %tid.x;
mad.lo.s32 %r16, %r1, %r11, %r12;
setp.ge.u32	%p1, %r16, %r10;
@%p1 bra BB44_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;
mov.u32 %r13, %nctaid.x;
mul.lo.s32 %r5, %r13, %r1;

BB44_2:
mul.lo.s32 %r14, %r16, %r8;
cvt.u64.u32	%rd5, %r14;
add.s64 %rd6, %rd1, %rd5;
mul.lo.s32 %r15, %r16, %r9;
mul.wide.u32 %rd7, %r15, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.eq.f32	%p2, %f3, %f2;
selp.u16	%rs17, 1, 0, %p2;
st.global.u8 [%rd6], %rs17;
add.s32 %r16, %r5, %r16;
setp.lt.u32	%p3, %r16, %r10;
@%p3 bra BB44_2;

BB44_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.u32 %r12, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r3, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r3, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB45_3;

cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r3;
cvta.to.global.u64 %rd2, %rd4;

BB45_2:
mul.lo.s32 %r33, %r41, %r12;
cvt.u64.u32	%rd5, %r33;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r34, %r41, %r24;
add.s32 %r35, %r34, %r41;
shr.u32 %r36, %r35, %r25;
mul.lo.s32 %r37, %r36, %r27;
sub.s32 %r38, %r41, %r37;
mul.lo.s32 %r39, %r38, %r23;
mad.lo.s32 %r40, %r22, %r36, %r39;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.eq.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
st.global.u8 [%rd6], %rs9;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB45_2;

BB45_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot46[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot46;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB46_2;

BB46_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB46_1;

BB46_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB46_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB46_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB46_6;

BB46_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB46_5;

BB46_6:
mul.lo.s32 %r30, %r8, %r18;
cvt.u64.u32	%rd16, %r30;
add.s64 %rd17, %rd4, %rd16;
ld.local.u32 %r31, [%rd1+108];
mad.lo.s32 %r32, %r31, %r38, %r42;
ld.local.u64 %rd18, [%rd1];
cvta.to.global.u64 %rd19, %rd18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd19, %rd20;
ld.global.f32 %f3, [%rd21];
setp.eq.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
st.global.u8 [%rd17], %rs9;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB46_4;

BB46_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r20, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r1, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB47_3;

cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r1;
cvta.to.global.u64 %rd2, %rd3;

BB47_2:
mul.hi.u32 %r33, %r41, %r24;
add.s32 %r34, %r33, %r41;
shr.u32 %r35, %r34, %r25;
mul.lo.s32 %r36, %r35, %r27;
sub.s32 %r37, %r41, %r36;
mul.lo.s32 %r38, %r37, %r23;
mad.lo.s32 %r39, %r22, %r35, %r38;
cvt.u64.u32	%rd5, %r39;
add.s64 %rd6, %rd2, %rd5;
mul.lo.s32 %r40, %r41, %r20;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd1, %rd7;
ld.global.f32 %f3, [%rd8];
setp.eq.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
st.global.u8 [%rd6], %rs9;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB47_2;

BB47_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<67>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r39, %r40}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r41, %r42}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r43, %r44}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r47, %ntid.x;
mov.u32 %r48, %ctaid.x;
mov.u32 %r49, %tid.x;
mad.lo.s32 %r66, %r47, %r48, %r49;
setp.ge.u32	%p1, %r66, %r30;
@%p1 bra BB48_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;

BB48_2:
mul.hi.u32 %r50, %r66, %r33;
add.s32 %r51, %r50, %r66;
shr.u32 %r52, %r51, %r34;
mul.lo.s32 %r53, %r52, %r36;
sub.s32 %r54, %r66, %r53;
mul.lo.s32 %r55, %r54, %r32;
mad.lo.s32 %r56, %r31, %r52, %r55;
cvt.u64.u32	%rd5, %r56;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r57, %r66, %r41;
add.s32 %r58, %r57, %r66;
shr.u32 %r59, %r58, %r42;
mul.lo.s32 %r60, %r59, %r44;
sub.s32 %r61, %r66, %r60;
mul.lo.s32 %r62, %r61, %r40;
mad.lo.s32 %r63, %r39, %r59, %r62;
mul.wide.u32 %rd7, %r63, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.eq.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
st.global.u8 [%rd6], %rs1;
mov.u32 %r65, %nctaid.x;
mad.lo.s32 %r66, %r65, %r47, %r66;
setp.lt.u32	%p3, %r66, %r30;
@%p3 bra BB48_2;

BB48_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot49[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot49;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r32, %r33}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r34, %r35}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r36, %r37}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB49_2;

BB49_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB49_1;

BB49_2:
mov.u32 %r40, %ntid.x;
mov.u32 %r41, %ctaid.x;
mov.u32 %r42, %tid.x;
mad.lo.s32 %r65, %r40, %r41, %r42;
setp.ge.u32	%p3, %r65, %r30;
@%p3 bra BB49_7;

cvta.to.global.u64 %rd4, %rd10;
ld.local.u32 %r43, [%rd1+208];
add.s32 %r9, %r43, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd5, %rd16;
mul.wide.s32 %rd17, %r43, 4;
add.s64 %rd6, %rd1, %rd17;

BB49_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mul.hi.u32 %r12, %r11, %r34;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB49_6;

BB49_5:
mov.u32 %r14, %r64;
mov.u32 %r13, %r59;
ld.local.u32 %r46, [%rd22+4];
rem.u32 %r47, %r14, %r46;
ld.local.u32 %r48, [%rd22+104];
mad.lo.s32 %r68, %r48, %r47, %r68;
div.u32 %r17, %r14, %r46;
add.s64 %rd22, %rd22, -4;
add.s32 %r18, %r13, -1;
setp.gt.s32	%p5, %r18, 0;
mov.u32 %r59, %r18;
mov.u32 %r63, %r17;
mov.u32 %r64, %r17;
mov.u32 %r67, %r68;
@%p5 bra BB49_5;

BB49_6:
add.s32 %r49, %r12, %r11;
shr.u32 %r50, %r49, %r35;
mul.lo.s32 %r51, %r50, %r37;
sub.s32 %r52, %r11, %r51;
mul.lo.s32 %r53, %r52, %r33;
mad.lo.s32 %r54, %r32, %r50, %r53;
cvt.u64.u32	%rd18, %r54;
add.s64 %rd19, %rd4, %rd18;
mad.lo.s32 %r55, %r10, %r63, %r67;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.eq.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
st.global.u8 [%rd19], %rs1;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r40, %r11;
setp.lt.u32	%p7, %r65, %r30;
@%p7 bra BB49_4;

BB49_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot50[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot50;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB50_2;

BB50_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB50_1;

BB50_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB50_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB50_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB50_6;

BB50_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB50_5;

BB50_6:
ld.local.u32 %r30, [%rd1+108];
mad.lo.s32 %r31, %r30, %r38, %r42;
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd17, %rd16;
cvt.u64.u32	%rd18, %r31;
add.s64 %rd19, %rd17, %rd18;
mul.lo.s32 %r32, %r8, %r18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd4, %rd20;
ld.global.f32 %f3, [%rd21];
setp.eq.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
st.global.u8 [%rd19], %rs9;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB50_4;

BB50_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot51[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot51;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB51_2;

BB51_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB51_1;

BB51_2:
mov.u32 %r39, %ntid.x;
mov.u32 %r40, %ctaid.x;
mov.u32 %r41, %tid.x;
mad.lo.s32 %r65, %r39, %r40, %r41;
setp.ge.u32	%p3, %r65, %r29;
@%p3 bra BB51_7;

ld.local.u32 %r42, [%rd1+208];
add.s32 %r9, %r42, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd4, %rd16;
cvta.to.global.u64 %rd5, %rd10;
mul.wide.s32 %rd17, %r42, 4;
add.s64 %rd6, %rd1, %rd17;

BB51_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB51_6;

BB51_5:
mov.u32 %r13, %r64;
mov.u32 %r12, %r59;
ld.local.u32 %r45, [%rd22+4];
rem.u32 %r46, %r13, %r45;
ld.local.u32 %r47, [%rd22+104];
mad.lo.s32 %r68, %r47, %r46, %r68;
div.u32 %r16, %r13, %r45;
add.s64 %rd22, %rd22, -4;
add.s32 %r17, %r12, -1;
setp.gt.s32	%p5, %r17, 0;
mov.u32 %r59, %r17;
mov.u32 %r63, %r16;
mov.u32 %r64, %r16;
mov.u32 %r67, %r68;
@%p5 bra BB51_5;

BB51_6:
mad.lo.s32 %r48, %r10, %r63, %r67;
cvt.u64.u32	%rd18, %r48;
add.s64 %rd19, %rd4, %rd18;
mul.hi.u32 %r49, %r11, %r33;
add.s32 %r50, %r49, %r11;
shr.u32 %r51, %r50, %r34;
mul.lo.s32 %r52, %r51, %r36;
sub.s32 %r53, %r11, %r52;
mul.lo.s32 %r54, %r53, %r32;
mad.lo.s32 %r55, %r31, %r51, %r54;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.eq.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
st.global.u8 [%rd19], %rs1;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r39, %r11;
setp.lt.u32	%p7, %r65, %r29;
@%p7 bra BB51_4;

BB51_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot52[432];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<12>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<72>;
.reg .b64 %rd<39>;


mov.u64 %rd38, __local_depot52;
cvta.local.u64 %SP, %rd38;
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd18, %SP, 216;
cvta.to.local.u64 %rd2, %rd18;
add.u64 %rd19, %SP, 0;
cvta.to.local.u64 %rd3, %rd19;
mov.u32 %r50, 0;
mov.pred %p1, 0;
@%p1 bra BB52_2;

BB52_1:
mul.wide.s32 %rd20, %r50, 8;
add.s64 %rd21, %rd4, %rd20;
ld.param.u64 %rd22, [%rd21];
add.s64 %rd23, %rd2, %rd20;
st.local.u64 [%rd23], %rd22;
add.s32 %r50, %r50, 1;
setp.lt.u32	%p2, %r50, 27;
@%p2 bra BB52_1;

BB52_2:
mov.u32 %r51, 0;
@%p1 bra BB52_4;

BB52_3:
mul.wide.s32 %rd24, %r51, 8;
add.s64 %rd25, %rd1, %rd24;
ld.param.u64 %rd26, [%rd25];
add.s64 %rd27, %rd3, %rd24;
st.local.u64 [%rd27], %rd26;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p4, %r51, 27;
@%p4 bra BB52_3;

BB52_4:
mov.u32 %r32, %ntid.x;
mov.u32 %r33, %ctaid.x;
mov.u32 %r34, %tid.x;
mad.lo.s32 %r64, %r32, %r33, %r34;
setp.ge.u32	%p5, %r64, %r29;
@%p5 bra BB52_11;

ld.local.u32 %r35, [%rd2+208];
add.s32 %r6, %r35, -1;
ld.local.u32 %r7, [%rd2+108];
ld.local.u64 %rd28, [%rd2];
cvta.to.global.u64 %rd8, %rd28;
ld.local.u32 %r36, [%rd3+208];
add.s32 %r8, %r36, -1;
ld.local.u32 %r9, [%rd3+108];
ld.local.u64 %rd29, [%rd3];
cvta.to.global.u64 %rd9, %rd29;
mul.wide.s32 %rd30, %r35, 4;
add.s64 %rd10, %rd2, %rd30;
mul.wide.s32 %rd31, %r36, 4;
add.s64 %rd11, %rd3, %rd31;

BB52_6:
mov.u32 %r54, %r64;
mov.u32 %r10, %r54;
mov.u64 %rd36, %rd10;
mov.u32 %r38, 0;
mov.u32 %r71, %r38;
setp.lt.s32	%p6, %r6, 1;
mov.u32 %r52, %r6;
mov.u32 %r62, %r10;
mov.u32 %r63, %r10;
mov.u32 %r70, %r38;
@%p6 bra BB52_8;

BB52_7:
mov.u32 %r12, %r63;
mov.u32 %r11, %r52;
ld.local.u32 %r39, [%rd36+4];
rem.u32 %r40, %r12, %r39;
ld.local.u32 %r41, [%rd36+104];
mad.lo.s32 %r71, %r41, %r40, %r71;
div.u32 %r15, %r12, %r39;
add.s64 %rd36, %rd36, -4;
add.s32 %r16, %r11, -1;
setp.gt.s32	%p7, %r16, 0;
mov.u32 %r52, %r16;
mov.u32 %r62, %r15;
mov.u32 %r63, %r15;
mov.u32 %r65, %r71;
mov.u32 %r70, %r65;
@%p7 bra BB52_7;

BB52_8:
mov.u32 %r18, %r70;
mov.u64 %rd37, %rd11;
mad.lo.s32 %r19, %r7, %r62, %r18;
mov.u32 %r69, %r38;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r53, %r8;
mov.u32 %r61, %r10;
mov.u32 %r60, %r10;
mov.u32 %r68, %r38;
@%p8 bra BB52_10;

BB52_9:
mov.u32 %r20, %r53;
ld.local.u32 %r44, [%rd37+4];
rem.u32 %r45, %r61, %r44;
ld.local.u32 %r46, [%rd37+104];
mad.lo.s32 %r69, %r46, %r45, %r69;
div.u32 %r61, %r61, %r44;
add.s64 %rd37, %rd37, -4;
add.s32 %r25, %r20, -1;
setp.gt.s32	%p9, %r25, 0;
mov.u32 %r53, %r25;
mov.u32 %r60, %r61;
mov.u32 %r68, %r69;
@%p9 bra BB52_9;

BB52_10:
cvt.u64.u32	%rd32, %r19;
add.s64 %rd33, %rd8, %rd32;
mad.lo.s32 %r47, %r9, %r60, %r68;
mul.wide.u32 %rd34, %r47, 4;
add.s64 %rd35, %rd9, %rd34;
ld.global.f32 %f3, [%rd35];
setp.eq.f32	%p10, %f3, %f2;
selp.u16	%rs1, 1, 0, %p10;
st.global.u8 [%rd33], %rs1;
mov.u32 %r49, %nctaid.x;
mad.lo.s32 %r64, %r49, %r32, %r10;
setp.lt.u32	%p11, %r64, %r29;
@%p11 bra BB52_6;

BB52_11:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u64 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<5>;
.reg .b64 %rd<24>;


ld.param.u64 %rd11, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u64 %rd13, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd12, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u64 %rd14, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %ntid.x;
cvt.u64.u32	%rd1, %r2;
mul.wide.u32 %rd15, %r2, %r1;
mov.u32 %r3, %tid.x;
cvt.u64.u32	%rd16, %r3;
add.s64 %rd23, %rd15, %rd16;
setp.ge.u64	%p1, %rd23, %rd14;
@%p1 bra BB53_3;

cvta.to.global.u64 %rd3, %rd10;
cvta.to.global.u64 %rd5, %rd12;
mov.u32 %r4, %nctaid.x;
cvt.u64.u32	%rd17, %r4;
mul.lo.s64 %rd7, %rd17, %rd1;

BB53_2:
mul.lo.s64 %rd18, %rd23, %rd11;
add.s64 %rd19, %rd3, %rd18;
mul.lo.s64 %rd20, %rd23, %rd13;
shl.b64 %rd21, %rd20, 2;
add.s64 %rd22, %rd5, %rd21;
ld.global.f32 %f3, [%rd22];
setp.eq.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
st.global.u8 [%rd19], %rs1;
add.s64 %rd23, %rd7, %rd23;
setp.lt.u64	%p3, %rd23, %rd14;
@%p3 bra BB53_2;

BB53_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[416],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[416],
.param .u64 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot54[832];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<32>;
.reg .b64 %rd<112>;


mov.u64 %rd111, __local_depot54;
cvta.local.u64 %SP, %rd111;
ld.param.u64 %rd49, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorEQValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd50, %SP, 416;
cvta.to.local.u64 %rd2, %rd50;
add.u64 %rd51, %SP, 0;
cvta.to.local.u64 %rd3, %rd51;
mov.u32 %r28, 0;
mov.pred %p1, 0;
@%p1 bra BB54_2;

BB54_1:
mul.wide.s32 %rd52, %r28, 8;
add.s64 %rd53, %rd4, %rd52;
ld.param.u64 %rd54, [%rd53];
add.s64 %rd55, %rd2, %rd52;
st.local.u64 [%rd55], %rd54;
add.s32 %r28, %r28, 1;
setp.lt.u32	%p2, %r28, 52;
@%p2 bra BB54_1;

BB54_2:
mov.u32 %r29, 0;
@%p1 bra BB54_4;

BB54_3:
mul.wide.s32 %rd56, %r29, 8;
add.s64 %rd57, %rd1, %rd56;
ld.param.u64 %rd58, [%rd57];
add.s64 %rd59, %rd3, %rd56;
st.local.u64 [%rd59], %rd58;
add.s32 %r29, %r29, 1;
setp.lt.u32	%p4, %r29, 52;
@%p4 bra BB54_3;

BB54_4:
mov.u32 %r13, %ctaid.x;
mov.u32 %r14, %ntid.x;
mul.wide.u32 %rd60, %r14, %r13;
mov.u32 %r15, %tid.x;
cvt.u64.u32	%rd61, %r15;
add.s64 %rd103, %rd60, %rd61;
setp.ge.u64	%p5, %rd103, %rd49;
@%p5 bra BB54_17;

ld.local.u32 %r16, [%rd2+408];
add.s32 %r5, %r16, -1;
ld.local.u64 %rd9, [%rd2+208];
ld.local.u64 %rd62, [%rd2];
cvta.to.global.u64 %rd10, %rd62;
ld.local.u32 %r17, [%rd3+408];
add.s32 %r6, %r17, -1;
ld.local.u64 %rd11, [%rd3+208];
ld.local.u64 %rd63, [%rd3];
cvta.to.global.u64 %rd12, %rd63;
mul.wide.s32 %rd64, %r16, 8;
add.s64 %rd13, %rd2, %rd64;
mul.wide.s32 %rd65, %r17, 8;
add.s64 %rd14, %rd3, %rd65;

BB54_6:
mov.u64 %rd89, %rd103;
mov.u64 %rd15, %rd89;
mov.u64 %rd85, %rd13;
mov.u64 %rd67, 0;
mov.u64 %rd110, %rd67;
setp.lt.s32	%p6, %r5, 1;
mov.u32 %r30, %r5;
mov.u64 %rd100, %rd15;
mov.u64 %rd101, %rd15;
mov.u64 %rd109, %rd67;
@%p6 bra BB54_11;

BB54_7:
mov.u64 %rd18, %rd101;
mov.u32 %r7, %r30;
ld.local.u64 %rd21, [%rd85];
or.b64 %rd68, %rd18, %rd21;
and.b64 %rd69, %rd68, -4294967296;
setp.eq.s64	%p7, %rd69, 0;
@%p7 bra BB54_9;
bra.uni BB54_8;

BB54_9:
cvt.u32.u64	%r18, %rd21;
cvt.u32.u64	%r19, %rd18;
div.u32 %r20, %r19, %r18;
rem.u32 %r21, %r19, %r18;
cvt.u64.u32	%rd102, %r20;
cvt.u64.u32	%rd86, %r21;
bra.uni BB54_10;

BB54_8:
div.u64 %rd102, %rd18, %rd21;
rem.u64 %rd86, %rd18, %rd21;

BB54_10:
mov.u64 %rd26, %rd102;
ld.local.u64 %rd70, [%rd85+200];
mul.lo.s64 %rd71, %rd70, %rd86;
add.s64 %rd110, %rd71, %rd110;
add.s64 %rd85, %rd85, -8;
add.s32 %r8, %r7, -1;
setp.gt.s32	%p8, %r8, 0;
mov.u32 %r30, %r8;
mov.u64 %rd100, %rd26;
mov.u64 %rd101, %rd26;
mov.u64 %rd104, %rd110;
mov.u64 %rd109, %rd104;
@%p8 bra BB54_7;

BB54_11:
mov.u64 %rd31, %rd109;
mov.u64 %rd87, %rd14;
mul.lo.s64 %rd74, %rd9, %rd100;
add.s64 %rd33, %rd74, %rd31;
mov.u64 %rd108, %rd67;
setp.lt.s32	%p9, %r6, 1;
mov.u32 %r31, %r6;
mov.u64 %rd98, %rd15;
mov.u64 %rd97, %rd15;
mov.u64 %rd107, %rd67;
@%p9 bra BB54_16;

BB54_12:
mov.u32 %r9, %r31;
ld.local.u64 %rd37, [%rd87];
or.b64 %rd75, %rd98, %rd37;
and.b64 %rd76, %rd75, -4294967296;
setp.eq.s64	%p10, %rd76, 0;
@%p10 bra BB54_14;
bra.uni BB54_13;

BB54_14:
cvt.u32.u64	%r22, %rd37;
cvt.u32.u64	%r23, %rd98;
div.u32 %r24, %r23, %r22;
rem.u32 %r25, %r23, %r22;
cvt.u64.u32	%rd99, %r24;
cvt.u64.u32	%rd88, %r25;
bra.uni BB54_15;

BB54_13:
div.u64 %rd99, %rd98, %rd37;
rem.u64 %rd88, %rd98, %rd37;

BB54_15:
mov.u64 %rd98, %rd99;
ld.local.u64 %rd77, [%rd87+200];
mul.lo.s64 %rd78, %rd77, %rd88;
add.s64 %rd108, %rd78, %rd108;
add.s64 %rd87, %rd87, -8;
add.s32 %r10, %r9, -1;
setp.gt.s32	%p11, %r10, 0;
mov.u32 %r31, %r10;
mov.u64 %rd97, %rd98;
mov.u64 %rd107, %rd108;
@%p11 bra BB54_12;

BB54_16:
add.s64 %rd79, %rd10, %rd33;
mul.lo.s64 %rd80, %rd11, %rd97;
add.s64 %rd81, %rd80, %rd107;
shl.b64 %rd82, %rd81, 2;
add.s64 %rd83, %rd12, %rd82;
ld.global.f32 %f3, [%rd83];
setp.eq.f32	%p12, %f3, %f2;
selp.u16	%rs1, 1, 0, %p12;
st.global.u8 [%rd79], %rs1;
mov.u32 %r26, %nctaid.x;
mul.wide.u32 %rd84, %r26, %r14;
add.s64 %rd103, %rd84, %rd15;
setp.lt.u64	%p13, %rd103, %rd49;
@%p13 bra BB54_6;

BB54_17:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<18>;
.reg .f32 %f<4>;
.reg .b32 %r<17>;
.reg .b64 %rd<9>;


ld.param.u32 %r8, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r9, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r10, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r11, %ctaid.x;
mov.u32 %r12, %tid.x;
mad.lo.s32 %r16, %r1, %r11, %r12;
setp.ge.u32	%p1, %r16, %r10;
@%p1 bra BB55_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;
mov.u32 %r13, %nctaid.x;
mul.lo.s32 %r5, %r13, %r1;

BB55_2:
mul.lo.s32 %r14, %r16, %r8;
cvt.u64.u32	%rd5, %r14;
add.s64 %rd6, %rd1, %rd5;
mul.lo.s32 %r15, %r16, %r9;
mul.wide.u32 %rd7, %r15, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.neu.f32	%p2, %f3, %f2;
selp.u16	%rs17, 1, 0, %p2;
st.global.u8 [%rd6], %rs17;
add.s32 %r16, %r5, %r16;
setp.lt.u32	%p3, %r16, %r10;
@%p3 bra BB55_2;

BB55_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.u32 %r12, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r3, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r3, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB56_3;

cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r3;
cvta.to.global.u64 %rd2, %rd4;

BB56_2:
mul.lo.s32 %r33, %r41, %r12;
cvt.u64.u32	%rd5, %r33;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r34, %r41, %r24;
add.s32 %r35, %r34, %r41;
shr.u32 %r36, %r35, %r25;
mul.lo.s32 %r37, %r36, %r27;
sub.s32 %r38, %r41, %r37;
mul.lo.s32 %r39, %r38, %r23;
mad.lo.s32 %r40, %r22, %r36, %r39;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.neu.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
st.global.u8 [%rd6], %rs9;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB56_2;

BB56_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot57[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot57;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB57_2;

BB57_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB57_1;

BB57_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB57_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB57_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB57_6;

BB57_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB57_5;

BB57_6:
mul.lo.s32 %r30, %r8, %r18;
cvt.u64.u32	%rd16, %r30;
add.s64 %rd17, %rd4, %rd16;
ld.local.u32 %r31, [%rd1+108];
mad.lo.s32 %r32, %r31, %r38, %r42;
ld.local.u64 %rd18, [%rd1];
cvta.to.global.u64 %rd19, %rd18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd19, %rd20;
ld.global.f32 %f3, [%rd21];
setp.neu.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
st.global.u8 [%rd17], %rs9;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB57_4;

BB57_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r20, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r1, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB58_3;

cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r1;
cvta.to.global.u64 %rd2, %rd3;

BB58_2:
mul.hi.u32 %r33, %r41, %r24;
add.s32 %r34, %r33, %r41;
shr.u32 %r35, %r34, %r25;
mul.lo.s32 %r36, %r35, %r27;
sub.s32 %r37, %r41, %r36;
mul.lo.s32 %r38, %r37, %r23;
mad.lo.s32 %r39, %r22, %r35, %r38;
cvt.u64.u32	%rd5, %r39;
add.s64 %rd6, %rd2, %rd5;
mul.lo.s32 %r40, %r41, %r20;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd1, %rd7;
ld.global.f32 %f3, [%rd8];
setp.neu.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
st.global.u8 [%rd6], %rs9;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB58_2;

BB58_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<67>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r39, %r40}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r41, %r42}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r43, %r44}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r47, %ntid.x;
mov.u32 %r48, %ctaid.x;
mov.u32 %r49, %tid.x;
mad.lo.s32 %r66, %r47, %r48, %r49;
setp.ge.u32	%p1, %r66, %r30;
@%p1 bra BB59_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;

BB59_2:
mul.hi.u32 %r50, %r66, %r33;
add.s32 %r51, %r50, %r66;
shr.u32 %r52, %r51, %r34;
mul.lo.s32 %r53, %r52, %r36;
sub.s32 %r54, %r66, %r53;
mul.lo.s32 %r55, %r54, %r32;
mad.lo.s32 %r56, %r31, %r52, %r55;
cvt.u64.u32	%rd5, %r56;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r57, %r66, %r41;
add.s32 %r58, %r57, %r66;
shr.u32 %r59, %r58, %r42;
mul.lo.s32 %r60, %r59, %r44;
sub.s32 %r61, %r66, %r60;
mul.lo.s32 %r62, %r61, %r40;
mad.lo.s32 %r63, %r39, %r59, %r62;
mul.wide.u32 %rd7, %r63, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.neu.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
st.global.u8 [%rd6], %rs1;
mov.u32 %r65, %nctaid.x;
mad.lo.s32 %r66, %r65, %r47, %r66;
setp.lt.u32	%p3, %r66, %r30;
@%p3 bra BB59_2;

BB59_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot60[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot60;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r32, %r33}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r34, %r35}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r36, %r37}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB60_2;

BB60_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB60_1;

BB60_2:
mov.u32 %r40, %ntid.x;
mov.u32 %r41, %ctaid.x;
mov.u32 %r42, %tid.x;
mad.lo.s32 %r65, %r40, %r41, %r42;
setp.ge.u32	%p3, %r65, %r30;
@%p3 bra BB60_7;

cvta.to.global.u64 %rd4, %rd10;
ld.local.u32 %r43, [%rd1+208];
add.s32 %r9, %r43, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd5, %rd16;
mul.wide.s32 %rd17, %r43, 4;
add.s64 %rd6, %rd1, %rd17;

BB60_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mul.hi.u32 %r12, %r11, %r34;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB60_6;

BB60_5:
mov.u32 %r14, %r64;
mov.u32 %r13, %r59;
ld.local.u32 %r46, [%rd22+4];
rem.u32 %r47, %r14, %r46;
ld.local.u32 %r48, [%rd22+104];
mad.lo.s32 %r68, %r48, %r47, %r68;
div.u32 %r17, %r14, %r46;
add.s64 %rd22, %rd22, -4;
add.s32 %r18, %r13, -1;
setp.gt.s32	%p5, %r18, 0;
mov.u32 %r59, %r18;
mov.u32 %r63, %r17;
mov.u32 %r64, %r17;
mov.u32 %r67, %r68;
@%p5 bra BB60_5;

BB60_6:
add.s32 %r49, %r12, %r11;
shr.u32 %r50, %r49, %r35;
mul.lo.s32 %r51, %r50, %r37;
sub.s32 %r52, %r11, %r51;
mul.lo.s32 %r53, %r52, %r33;
mad.lo.s32 %r54, %r32, %r50, %r53;
cvt.u64.u32	%rd18, %r54;
add.s64 %rd19, %rd4, %rd18;
mad.lo.s32 %r55, %r10, %r63, %r67;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.neu.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
st.global.u8 [%rd19], %rs1;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r40, %r11;
setp.lt.u32	%p7, %r65, %r30;
@%p7 bra BB60_4;

BB60_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot61[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<4>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot61;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB61_2;

BB61_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB61_1;

BB61_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB61_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB61_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB61_6;

BB61_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB61_5;

BB61_6:
ld.local.u32 %r30, [%rd1+108];
mad.lo.s32 %r31, %r30, %r38, %r42;
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd17, %rd16;
cvt.u64.u32	%rd18, %r31;
add.s64 %rd19, %rd17, %rd18;
mul.lo.s32 %r32, %r8, %r18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd4, %rd20;
ld.global.f32 %f3, [%rd21];
setp.neu.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
st.global.u8 [%rd19], %rs9;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB61_4;

BB61_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot62[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot62;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB62_2;

BB62_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB62_1;

BB62_2:
mov.u32 %r39, %ntid.x;
mov.u32 %r40, %ctaid.x;
mov.u32 %r41, %tid.x;
mad.lo.s32 %r65, %r39, %r40, %r41;
setp.ge.u32	%p3, %r65, %r29;
@%p3 bra BB62_7;

ld.local.u32 %r42, [%rd1+208];
add.s32 %r9, %r42, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd4, %rd16;
cvta.to.global.u64 %rd5, %rd10;
mul.wide.s32 %rd17, %r42, 4;
add.s64 %rd6, %rd1, %rd17;

BB62_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB62_6;

BB62_5:
mov.u32 %r13, %r64;
mov.u32 %r12, %r59;
ld.local.u32 %r45, [%rd22+4];
rem.u32 %r46, %r13, %r45;
ld.local.u32 %r47, [%rd22+104];
mad.lo.s32 %r68, %r47, %r46, %r68;
div.u32 %r16, %r13, %r45;
add.s64 %rd22, %rd22, -4;
add.s32 %r17, %r12, -1;
setp.gt.s32	%p5, %r17, 0;
mov.u32 %r59, %r17;
mov.u32 %r63, %r16;
mov.u32 %r64, %r16;
mov.u32 %r67, %r68;
@%p5 bra BB62_5;

BB62_6:
mad.lo.s32 %r48, %r10, %r63, %r67;
cvt.u64.u32	%rd18, %r48;
add.s64 %rd19, %rd4, %rd18;
mul.hi.u32 %r49, %r11, %r33;
add.s32 %r50, %r49, %r11;
shr.u32 %r51, %r50, %r34;
mul.lo.s32 %r52, %r51, %r36;
sub.s32 %r53, %r11, %r52;
mul.lo.s32 %r54, %r53, %r32;
mad.lo.s32 %r55, %r31, %r51, %r54;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.neu.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
st.global.u8 [%rd19], %rs1;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r39, %r11;
setp.lt.u32	%p7, %r65, %r29;
@%p7 bra BB62_4;

BB62_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot63[432];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<12>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<72>;
.reg .b64 %rd<39>;


mov.u64 %rd38, __local_depot63;
cvta.local.u64 %SP, %rd38;
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd18, %SP, 216;
cvta.to.local.u64 %rd2, %rd18;
add.u64 %rd19, %SP, 0;
cvta.to.local.u64 %rd3, %rd19;
mov.u32 %r50, 0;
mov.pred %p1, 0;
@%p1 bra BB63_2;

BB63_1:
mul.wide.s32 %rd20, %r50, 8;
add.s64 %rd21, %rd4, %rd20;
ld.param.u64 %rd22, [%rd21];
add.s64 %rd23, %rd2, %rd20;
st.local.u64 [%rd23], %rd22;
add.s32 %r50, %r50, 1;
setp.lt.u32	%p2, %r50, 27;
@%p2 bra BB63_1;

BB63_2:
mov.u32 %r51, 0;
@%p1 bra BB63_4;

BB63_3:
mul.wide.s32 %rd24, %r51, 8;
add.s64 %rd25, %rd1, %rd24;
ld.param.u64 %rd26, [%rd25];
add.s64 %rd27, %rd3, %rd24;
st.local.u64 [%rd27], %rd26;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p4, %r51, 27;
@%p4 bra BB63_3;

BB63_4:
mov.u32 %r32, %ntid.x;
mov.u32 %r33, %ctaid.x;
mov.u32 %r34, %tid.x;
mad.lo.s32 %r64, %r32, %r33, %r34;
setp.ge.u32	%p5, %r64, %r29;
@%p5 bra BB63_11;

ld.local.u32 %r35, [%rd2+208];
add.s32 %r6, %r35, -1;
ld.local.u32 %r7, [%rd2+108];
ld.local.u64 %rd28, [%rd2];
cvta.to.global.u64 %rd8, %rd28;
ld.local.u32 %r36, [%rd3+208];
add.s32 %r8, %r36, -1;
ld.local.u32 %r9, [%rd3+108];
ld.local.u64 %rd29, [%rd3];
cvta.to.global.u64 %rd9, %rd29;
mul.wide.s32 %rd30, %r35, 4;
add.s64 %rd10, %rd2, %rd30;
mul.wide.s32 %rd31, %r36, 4;
add.s64 %rd11, %rd3, %rd31;

BB63_6:
mov.u32 %r54, %r64;
mov.u32 %r10, %r54;
mov.u64 %rd36, %rd10;
mov.u32 %r38, 0;
mov.u32 %r71, %r38;
setp.lt.s32	%p6, %r6, 1;
mov.u32 %r52, %r6;
mov.u32 %r62, %r10;
mov.u32 %r63, %r10;
mov.u32 %r70, %r38;
@%p6 bra BB63_8;

BB63_7:
mov.u32 %r12, %r63;
mov.u32 %r11, %r52;
ld.local.u32 %r39, [%rd36+4];
rem.u32 %r40, %r12, %r39;
ld.local.u32 %r41, [%rd36+104];
mad.lo.s32 %r71, %r41, %r40, %r71;
div.u32 %r15, %r12, %r39;
add.s64 %rd36, %rd36, -4;
add.s32 %r16, %r11, -1;
setp.gt.s32	%p7, %r16, 0;
mov.u32 %r52, %r16;
mov.u32 %r62, %r15;
mov.u32 %r63, %r15;
mov.u32 %r65, %r71;
mov.u32 %r70, %r65;
@%p7 bra BB63_7;

BB63_8:
mov.u32 %r18, %r70;
mov.u64 %rd37, %rd11;
mad.lo.s32 %r19, %r7, %r62, %r18;
mov.u32 %r69, %r38;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r53, %r8;
mov.u32 %r61, %r10;
mov.u32 %r60, %r10;
mov.u32 %r68, %r38;
@%p8 bra BB63_10;

BB63_9:
mov.u32 %r20, %r53;
ld.local.u32 %r44, [%rd37+4];
rem.u32 %r45, %r61, %r44;
ld.local.u32 %r46, [%rd37+104];
mad.lo.s32 %r69, %r46, %r45, %r69;
div.u32 %r61, %r61, %r44;
add.s64 %rd37, %rd37, -4;
add.s32 %r25, %r20, -1;
setp.gt.s32	%p9, %r25, 0;
mov.u32 %r53, %r25;
mov.u32 %r60, %r61;
mov.u32 %r68, %r69;
@%p9 bra BB63_9;

BB63_10:
cvt.u64.u32	%rd32, %r19;
add.s64 %rd33, %rd8, %rd32;
mad.lo.s32 %r47, %r9, %r60, %r68;
mul.wide.u32 %rd34, %r47, 4;
add.s64 %rd35, %rd9, %rd34;
ld.global.f32 %f3, [%rd35];
setp.neu.f32	%p10, %f3, %f2;
selp.u16	%rs1, 1, 0, %p10;
st.global.u8 [%rd33], %rs1;
mov.u32 %r49, %nctaid.x;
mad.lo.s32 %r64, %r49, %r32, %r10;
setp.lt.u32	%p11, %r64, %r29;
@%p11 bra BB63_6;

BB63_11:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u64 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<5>;
.reg .b64 %rd<24>;


ld.param.u64 %rd11, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u64 %rd13, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd12, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u64 %rd14, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %ntid.x;
cvt.u64.u32	%rd1, %r2;
mul.wide.u32 %rd15, %r2, %r1;
mov.u32 %r3, %tid.x;
cvt.u64.u32	%rd16, %r3;
add.s64 %rd23, %rd15, %rd16;
setp.ge.u64	%p1, %rd23, %rd14;
@%p1 bra BB64_3;

cvta.to.global.u64 %rd3, %rd10;
cvta.to.global.u64 %rd5, %rd12;
mov.u32 %r4, %nctaid.x;
cvt.u64.u32	%rd17, %r4;
mul.lo.s64 %rd7, %rd17, %rd1;

BB64_2:
mul.lo.s64 %rd18, %rd23, %rd11;
add.s64 %rd19, %rd3, %rd18;
mul.lo.s64 %rd20, %rd23, %rd13;
shl.b64 %rd21, %rd20, 2;
add.s64 %rd22, %rd5, %rd21;
ld.global.f32 %f3, [%rd22];
setp.neu.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
st.global.u8 [%rd19], %rs1;
add.s64 %rd23, %rd7, %rd23;
setp.lt.u64	%p3, %rd23, %rd14;
@%p3 bra BB64_2;

BB64_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[416],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[416],
.param .u64 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot65[832];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .f32 %f<4>;
.reg .b32 %r<32>;
.reg .b64 %rd<112>;


mov.u64 %rd111, __local_depot65;
cvta.local.u64 %SP, %rd111;
ld.param.u64 %rd49, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorNEValueOpIfhEhfmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd50, %SP, 416;
cvta.to.local.u64 %rd2, %rd50;
add.u64 %rd51, %SP, 0;
cvta.to.local.u64 %rd3, %rd51;
mov.u32 %r28, 0;
mov.pred %p1, 0;
@%p1 bra BB65_2;

BB65_1:
mul.wide.s32 %rd52, %r28, 8;
add.s64 %rd53, %rd4, %rd52;
ld.param.u64 %rd54, [%rd53];
add.s64 %rd55, %rd2, %rd52;
st.local.u64 [%rd55], %rd54;
add.s32 %r28, %r28, 1;
setp.lt.u32	%p2, %r28, 52;
@%p2 bra BB65_1;

BB65_2:
mov.u32 %r29, 0;
@%p1 bra BB65_4;

BB65_3:
mul.wide.s32 %rd56, %r29, 8;
add.s64 %rd57, %rd1, %rd56;
ld.param.u64 %rd58, [%rd57];
add.s64 %rd59, %rd3, %rd56;
st.local.u64 [%rd59], %rd58;
add.s32 %r29, %r29, 1;
setp.lt.u32	%p4, %r29, 52;
@%p4 bra BB65_3;

BB65_4:
mov.u32 %r13, %ctaid.x;
mov.u32 %r14, %ntid.x;
mul.wide.u32 %rd60, %r14, %r13;
mov.u32 %r15, %tid.x;
cvt.u64.u32	%rd61, %r15;
add.s64 %rd103, %rd60, %rd61;
setp.ge.u64	%p5, %rd103, %rd49;
@%p5 bra BB65_17;

ld.local.u32 %r16, [%rd2+408];
add.s32 %r5, %r16, -1;
ld.local.u64 %rd9, [%rd2+208];
ld.local.u64 %rd62, [%rd2];
cvta.to.global.u64 %rd10, %rd62;
ld.local.u32 %r17, [%rd3+408];
add.s32 %r6, %r17, -1;
ld.local.u64 %rd11, [%rd3+208];
ld.local.u64 %rd63, [%rd3];
cvta.to.global.u64 %rd12, %rd63;
mul.wide.s32 %rd64, %r16, 8;
add.s64 %rd13, %rd2, %rd64;
mul.wide.s32 %rd65, %r17, 8;
add.s64 %rd14, %rd3, %rd65;

BB65_6:
mov.u64 %rd89, %rd103;
mov.u64 %rd15, %rd89;
mov.u64 %rd85, %rd13;
mov.u64 %rd67, 0;
mov.u64 %rd110, %rd67;
setp.lt.s32	%p6, %r5, 1;
mov.u32 %r30, %r5;
mov.u64 %rd100, %rd15;
mov.u64 %rd101, %rd15;
mov.u64 %rd109, %rd67;
@%p6 bra BB65_11;

BB65_7:
mov.u64 %rd18, %rd101;
mov.u32 %r7, %r30;
ld.local.u64 %rd21, [%rd85];
or.b64 %rd68, %rd18, %rd21;
and.b64 %rd69, %rd68, -4294967296;
setp.eq.s64	%p7, %rd69, 0;
@%p7 bra BB65_9;
bra.uni BB65_8;

BB65_9:
cvt.u32.u64	%r18, %rd21;
cvt.u32.u64	%r19, %rd18;
div.u32 %r20, %r19, %r18;
rem.u32 %r21, %r19, %r18;
cvt.u64.u32	%rd102, %r20;
cvt.u64.u32	%rd86, %r21;
bra.uni BB65_10;

BB65_8:
div.u64 %rd102, %rd18, %rd21;
rem.u64 %rd86, %rd18, %rd21;

BB65_10:
mov.u64 %rd26, %rd102;
ld.local.u64 %rd70, [%rd85+200];
mul.lo.s64 %rd71, %rd70, %rd86;
add.s64 %rd110, %rd71, %rd110;
add.s64 %rd85, %rd85, -8;
add.s32 %r8, %r7, -1;
setp.gt.s32	%p8, %r8, 0;
mov.u32 %r30, %r8;
mov.u64 %rd100, %rd26;
mov.u64 %rd101, %rd26;
mov.u64 %rd104, %rd110;
mov.u64 %rd109, %rd104;
@%p8 bra BB65_7;

BB65_11:
mov.u64 %rd31, %rd109;
mov.u64 %rd87, %rd14;
mul.lo.s64 %rd74, %rd9, %rd100;
add.s64 %rd33, %rd74, %rd31;
mov.u64 %rd108, %rd67;
setp.lt.s32	%p9, %r6, 1;
mov.u32 %r31, %r6;
mov.u64 %rd98, %rd15;
mov.u64 %rd97, %rd15;
mov.u64 %rd107, %rd67;
@%p9 bra BB65_16;

BB65_12:
mov.u32 %r9, %r31;
ld.local.u64 %rd37, [%rd87];
or.b64 %rd75, %rd98, %rd37;
and.b64 %rd76, %rd75, -4294967296;
setp.eq.s64	%p10, %rd76, 0;
@%p10 bra BB65_14;
bra.uni BB65_13;

BB65_14:
cvt.u32.u64	%r22, %rd37;
cvt.u32.u64	%r23, %rd98;
div.u32 %r24, %r23, %r22;
rem.u32 %r25, %r23, %r22;
cvt.u64.u32	%rd99, %r24;
cvt.u64.u32	%rd88, %r25;
bra.uni BB65_15;

BB65_13:
div.u64 %rd99, %rd98, %rd37;
rem.u64 %rd88, %rd98, %rd37;

BB65_15:
mov.u64 %rd98, %rd99;
ld.local.u64 %rd77, [%rd87+200];
mul.lo.s64 %rd78, %rd77, %rd88;
add.s64 %rd108, %rd78, %rd108;
add.s64 %rd87, %rd87, -8;
add.s32 %r10, %r9, -1;
setp.gt.s32	%p11, %r10, 0;
mov.u32 %r31, %r10;
mov.u64 %rd97, %rd98;
mov.u64 %rd107, %rd108;
@%p11 bra BB65_12;

BB65_16:
add.s64 %rd79, %rd10, %rd33;
mul.lo.s64 %rd80, %rd11, %rd97;
add.s64 %rd81, %rd80, %rd107;
shl.b64 %rd82, %rd81, 2;
add.s64 %rd83, %rd12, %rd82;
ld.global.f32 %f3, [%rd83];
setp.neu.f32	%p12, %f3, %f2;
selp.u16	%rs1, 1, 0, %p12;
st.global.u8 [%rd79], %rs1;
mov.u32 %r26, %nctaid.x;
mul.wide.u32 %rd84, %r26, %r14;
add.s64 %rd103, %rd84, %rd15;
setp.lt.u64	%p13, %rd103, %rd49;
@%p13 bra BB65_6;

BB65_17:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<18>;
.reg .f32 %f<5>;
.reg .b32 %r<17>;
.reg .b64 %rd<9>;


ld.param.u32 %r8, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r9, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r10, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r11, %ctaid.x;
mov.u32 %r12, %tid.x;
mad.lo.s32 %r16, %r1, %r11, %r12;
setp.ge.u32	%p1, %r16, %r10;
@%p1 bra BB66_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;
mov.u32 %r13, %nctaid.x;
mul.lo.s32 %r5, %r13, %r1;

BB66_2:
mul.lo.s32 %r14, %r16, %r8;
mul.wide.u32 %rd5, %r14, 4;
add.s64 %rd6, %rd1, %rd5;
mul.lo.s32 %r15, %r16, %r9;
mul.wide.u32 %rd7, %r15, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.lt.f32	%p2, %f3, %f2;
selp.u16	%rs17, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs17;
st.global.f32 [%rd6], %f4;
add.s32 %r16, %r5, %r16;
setp.lt.u32	%p3, %r16, %r10;
@%p3 bra BB66_2;

BB66_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.u32 %r12, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r4, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r4, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB67_3;

cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r4;
cvta.to.global.u64 %rd2, %rd4;

BB67_2:
mul.lo.s32 %r33, %r41, %r12;
mul.wide.u32 %rd5, %r33, 4;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r34, %r41, %r24;
add.s32 %r35, %r34, %r41;
shr.u32 %r36, %r35, %r25;
mul.lo.s32 %r37, %r36, %r27;
sub.s32 %r38, %r41, %r37;
mul.lo.s32 %r39, %r38, %r23;
mad.lo.s32 %r40, %r22, %r36, %r39;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.lt.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd6], %f4;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB67_2;

BB67_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot68[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot68;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB68_2;

BB68_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB68_1;

BB68_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB68_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB68_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB68_6;

BB68_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB68_5;

BB68_6:
mul.lo.s32 %r30, %r8, %r18;
mul.wide.u32 %rd16, %r30, 4;
add.s64 %rd17, %rd4, %rd16;
ld.local.u32 %r31, [%rd1+108];
mad.lo.s32 %r32, %r31, %r38, %r42;
ld.local.u64 %rd18, [%rd1];
cvta.to.global.u64 %rd19, %rd18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd19, %rd20;
ld.global.f32 %f3, [%rd21];
setp.lt.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd17], %f4;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB68_4;

BB68_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r20, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r1, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB69_3;

cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r1;
cvta.to.global.u64 %rd2, %rd3;

BB69_2:
mul.hi.u32 %r33, %r41, %r24;
add.s32 %r34, %r33, %r41;
shr.u32 %r35, %r34, %r25;
mul.lo.s32 %r36, %r35, %r27;
sub.s32 %r37, %r41, %r36;
mul.lo.s32 %r38, %r37, %r23;
mad.lo.s32 %r39, %r22, %r35, %r38;
mul.wide.u32 %rd5, %r39, 4;
add.s64 %rd6, %rd2, %rd5;
mul.lo.s32 %r40, %r41, %r20;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd1, %rd7;
ld.global.f32 %f3, [%rd8];
setp.lt.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd6], %f4;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB69_2;

BB69_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<67>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r39, %r40}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r41, %r42}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r43, %r44}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r47, %ntid.x;
mov.u32 %r48, %ctaid.x;
mov.u32 %r49, %tid.x;
mad.lo.s32 %r66, %r47, %r48, %r49;
setp.ge.u32	%p1, %r66, %r30;
@%p1 bra BB70_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;

BB70_2:
mul.hi.u32 %r50, %r66, %r33;
add.s32 %r51, %r50, %r66;
shr.u32 %r52, %r51, %r34;
mul.lo.s32 %r53, %r52, %r36;
sub.s32 %r54, %r66, %r53;
mul.lo.s32 %r55, %r54, %r32;
mad.lo.s32 %r56, %r31, %r52, %r55;
mul.wide.u32 %rd5, %r56, 4;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r57, %r66, %r41;
add.s32 %r58, %r57, %r66;
shr.u32 %r59, %r58, %r42;
mul.lo.s32 %r60, %r59, %r44;
sub.s32 %r61, %r66, %r60;
mul.lo.s32 %r62, %r61, %r40;
mad.lo.s32 %r63, %r39, %r59, %r62;
mul.wide.u32 %rd7, %r63, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.lt.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd6], %f4;
mov.u32 %r65, %nctaid.x;
mad.lo.s32 %r66, %r65, %r47, %r66;
setp.lt.u32	%p3, %r66, %r30;
@%p3 bra BB70_2;

BB70_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot71[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot71;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r32, %r33}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r34, %r35}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r36, %r37}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB71_2;

BB71_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB71_1;

BB71_2:
mov.u32 %r40, %ntid.x;
mov.u32 %r41, %ctaid.x;
mov.u32 %r42, %tid.x;
mad.lo.s32 %r65, %r40, %r41, %r42;
setp.ge.u32	%p3, %r65, %r30;
@%p3 bra BB71_7;

cvta.to.global.u64 %rd4, %rd10;
ld.local.u32 %r43, [%rd1+208];
add.s32 %r9, %r43, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd5, %rd16;
mul.wide.s32 %rd17, %r43, 4;
add.s64 %rd6, %rd1, %rd17;

BB71_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mul.hi.u32 %r12, %r11, %r34;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB71_6;

BB71_5:
mov.u32 %r14, %r64;
mov.u32 %r13, %r59;
ld.local.u32 %r46, [%rd22+4];
rem.u32 %r47, %r14, %r46;
ld.local.u32 %r48, [%rd22+104];
mad.lo.s32 %r68, %r48, %r47, %r68;
div.u32 %r17, %r14, %r46;
add.s64 %rd22, %rd22, -4;
add.s32 %r18, %r13, -1;
setp.gt.s32	%p5, %r18, 0;
mov.u32 %r59, %r18;
mov.u32 %r63, %r17;
mov.u32 %r64, %r17;
mov.u32 %r67, %r68;
@%p5 bra BB71_5;

BB71_6:
add.s32 %r49, %r12, %r11;
shr.u32 %r50, %r49, %r35;
mul.lo.s32 %r51, %r50, %r37;
sub.s32 %r52, %r11, %r51;
mul.lo.s32 %r53, %r52, %r33;
mad.lo.s32 %r54, %r32, %r50, %r53;
mul.wide.u32 %rd18, %r54, 4;
add.s64 %rd19, %rd4, %rd18;
mad.lo.s32 %r55, %r10, %r63, %r67;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.lt.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd19], %f4;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r40, %r11;
setp.lt.u32	%p7, %r65, %r30;
@%p7 bra BB71_4;

BB71_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot72[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot72;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB72_2;

BB72_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB72_1;

BB72_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB72_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB72_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB72_6;

BB72_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB72_5;

BB72_6:
ld.local.u32 %r30, [%rd1+108];
mad.lo.s32 %r31, %r30, %r38, %r42;
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd17, %rd16;
mul.wide.u32 %rd18, %r31, 4;
add.s64 %rd19, %rd17, %rd18;
mul.lo.s32 %r32, %r8, %r18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd4, %rd20;
ld.global.f32 %f3, [%rd21];
setp.lt.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd19], %f4;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB72_4;

BB72_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot73[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot73;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB73_2;

BB73_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB73_1;

BB73_2:
mov.u32 %r39, %ntid.x;
mov.u32 %r40, %ctaid.x;
mov.u32 %r41, %tid.x;
mad.lo.s32 %r65, %r39, %r40, %r41;
setp.ge.u32	%p3, %r65, %r29;
@%p3 bra BB73_7;

ld.local.u32 %r42, [%rd1+208];
add.s32 %r9, %r42, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd4, %rd16;
cvta.to.global.u64 %rd5, %rd10;
mul.wide.s32 %rd17, %r42, 4;
add.s64 %rd6, %rd1, %rd17;

BB73_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB73_6;

BB73_5:
mov.u32 %r13, %r64;
mov.u32 %r12, %r59;
ld.local.u32 %r45, [%rd22+4];
rem.u32 %r46, %r13, %r45;
ld.local.u32 %r47, [%rd22+104];
mad.lo.s32 %r68, %r47, %r46, %r68;
div.u32 %r16, %r13, %r45;
add.s64 %rd22, %rd22, -4;
add.s32 %r17, %r12, -1;
setp.gt.s32	%p5, %r17, 0;
mov.u32 %r59, %r17;
mov.u32 %r63, %r16;
mov.u32 %r64, %r16;
mov.u32 %r67, %r68;
@%p5 bra BB73_5;

BB73_6:
mad.lo.s32 %r48, %r10, %r63, %r67;
mul.wide.u32 %rd18, %r48, 4;
add.s64 %rd19, %rd4, %rd18;
mul.hi.u32 %r49, %r11, %r33;
add.s32 %r50, %r49, %r11;
shr.u32 %r51, %r50, %r34;
mul.lo.s32 %r52, %r51, %r36;
sub.s32 %r53, %r11, %r52;
mul.lo.s32 %r54, %r53, %r32;
mad.lo.s32 %r55, %r31, %r51, %r54;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.lt.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd19], %f4;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r39, %r11;
setp.lt.u32	%p7, %r65, %r29;
@%p7 bra BB73_4;

BB73_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot74[432];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<12>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<72>;
.reg .b64 %rd<39>;


mov.u64 %rd38, __local_depot74;
cvta.local.u64 %SP, %rd38;
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd18, %SP, 216;
cvta.to.local.u64 %rd2, %rd18;
add.u64 %rd19, %SP, 0;
cvta.to.local.u64 %rd3, %rd19;
mov.u32 %r50, 0;
mov.pred %p1, 0;
@%p1 bra BB74_2;

BB74_1:
mul.wide.s32 %rd20, %r50, 8;
add.s64 %rd21, %rd4, %rd20;
ld.param.u64 %rd22, [%rd21];
add.s64 %rd23, %rd2, %rd20;
st.local.u64 [%rd23], %rd22;
add.s32 %r50, %r50, 1;
setp.lt.u32	%p2, %r50, 27;
@%p2 bra BB74_1;

BB74_2:
mov.u32 %r51, 0;
@%p1 bra BB74_4;

BB74_3:
mul.wide.s32 %rd24, %r51, 8;
add.s64 %rd25, %rd1, %rd24;
ld.param.u64 %rd26, [%rd25];
add.s64 %rd27, %rd3, %rd24;
st.local.u64 [%rd27], %rd26;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p4, %r51, 27;
@%p4 bra BB74_3;

BB74_4:
mov.u32 %r32, %ntid.x;
mov.u32 %r33, %ctaid.x;
mov.u32 %r34, %tid.x;
mad.lo.s32 %r64, %r32, %r33, %r34;
setp.ge.u32	%p5, %r64, %r29;
@%p5 bra BB74_11;

ld.local.u32 %r35, [%rd2+208];
add.s32 %r6, %r35, -1;
ld.local.u32 %r7, [%rd2+108];
ld.local.u64 %rd28, [%rd2];
cvta.to.global.u64 %rd8, %rd28;
ld.local.u32 %r36, [%rd3+208];
add.s32 %r8, %r36, -1;
ld.local.u32 %r9, [%rd3+108];
ld.local.u64 %rd29, [%rd3];
cvta.to.global.u64 %rd9, %rd29;
mul.wide.s32 %rd30, %r35, 4;
add.s64 %rd10, %rd2, %rd30;
mul.wide.s32 %rd31, %r36, 4;
add.s64 %rd11, %rd3, %rd31;

BB74_6:
mov.u32 %r54, %r64;
mov.u32 %r10, %r54;
mov.u64 %rd36, %rd10;
mov.u32 %r38, 0;
mov.u32 %r71, %r38;
setp.lt.s32	%p6, %r6, 1;
mov.u32 %r52, %r6;
mov.u32 %r62, %r10;
mov.u32 %r63, %r10;
mov.u32 %r70, %r38;
@%p6 bra BB74_8;

BB74_7:
mov.u32 %r12, %r63;
mov.u32 %r11, %r52;
ld.local.u32 %r39, [%rd36+4];
rem.u32 %r40, %r12, %r39;
ld.local.u32 %r41, [%rd36+104];
mad.lo.s32 %r71, %r41, %r40, %r71;
div.u32 %r15, %r12, %r39;
add.s64 %rd36, %rd36, -4;
add.s32 %r16, %r11, -1;
setp.gt.s32	%p7, %r16, 0;
mov.u32 %r52, %r16;
mov.u32 %r62, %r15;
mov.u32 %r63, %r15;
mov.u32 %r65, %r71;
mov.u32 %r70, %r65;
@%p7 bra BB74_7;

BB74_8:
mov.u32 %r18, %r70;
mov.u64 %rd37, %rd11;
mad.lo.s32 %r19, %r7, %r62, %r18;
mov.u32 %r69, %r38;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r53, %r8;
mov.u32 %r61, %r10;
mov.u32 %r60, %r10;
mov.u32 %r68, %r38;
@%p8 bra BB74_10;

BB74_9:
mov.u32 %r20, %r53;
ld.local.u32 %r44, [%rd37+4];
rem.u32 %r45, %r61, %r44;
ld.local.u32 %r46, [%rd37+104];
mad.lo.s32 %r69, %r46, %r45, %r69;
div.u32 %r61, %r61, %r44;
add.s64 %rd37, %rd37, -4;
add.s32 %r25, %r20, -1;
setp.gt.s32	%p9, %r25, 0;
mov.u32 %r53, %r25;
mov.u32 %r60, %r61;
mov.u32 %r68, %r69;
@%p9 bra BB74_9;

BB74_10:
mul.wide.u32 %rd32, %r19, 4;
add.s64 %rd33, %rd8, %rd32;
mad.lo.s32 %r47, %r9, %r60, %r68;
mul.wide.u32 %rd34, %r47, 4;
add.s64 %rd35, %rd9, %rd34;
ld.global.f32 %f3, [%rd35];
setp.lt.f32	%p10, %f3, %f2;
selp.u16	%rs1, 1, 0, %p10;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd33], %f4;
mov.u32 %r49, %nctaid.x;
mad.lo.s32 %r64, %r49, %r32, %r10;
setp.lt.u32	%p11, %r64, %r29;
@%p11 bra BB74_6;

BB74_11:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u64 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<5>;
.reg .b64 %rd<25>;


ld.param.u64 %rd11, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u64 %rd13, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd12, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u64 %rd14, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %ntid.x;
cvt.u64.u32	%rd1, %r2;
mul.wide.u32 %rd15, %r2, %r1;
mov.u32 %r3, %tid.x;
cvt.u64.u32	%rd16, %r3;
add.s64 %rd24, %rd15, %rd16;
setp.ge.u64	%p1, %rd24, %rd14;
@%p1 bra BB75_3;

cvta.to.global.u64 %rd3, %rd10;
cvta.to.global.u64 %rd5, %rd12;
mov.u32 %r4, %nctaid.x;
cvt.u64.u32	%rd17, %r4;
mul.lo.s64 %rd7, %rd17, %rd1;

BB75_2:
mul.lo.s64 %rd18, %rd24, %rd11;
shl.b64 %rd19, %rd18, 2;
add.s64 %rd20, %rd3, %rd19;
mul.lo.s64 %rd21, %rd24, %rd13;
shl.b64 %rd22, %rd21, 2;
add.s64 %rd23, %rd5, %rd22;
ld.global.f32 %f3, [%rd23];
setp.lt.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd20], %f4;
add.s64 %rd24, %rd7, %rd24;
setp.lt.u64	%p3, %rd24, %rd14;
@%p3 bra BB75_2;

BB75_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[416],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[416],
.param .u64 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot76[832];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<32>;
.reg .b64 %rd<113>;


mov.u64 %rd112, __local_depot76;
cvta.local.u64 %SP, %rd112;
ld.param.u64 %rd49, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLTValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorLTValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd50, %SP, 416;
cvta.to.local.u64 %rd2, %rd50;
add.u64 %rd51, %SP, 0;
cvta.to.local.u64 %rd3, %rd51;
mov.u32 %r28, 0;
mov.pred %p1, 0;
@%p1 bra BB76_2;

BB76_1:
mul.wide.s32 %rd52, %r28, 8;
add.s64 %rd53, %rd4, %rd52;
ld.param.u64 %rd54, [%rd53];
add.s64 %rd55, %rd2, %rd52;
st.local.u64 [%rd55], %rd54;
add.s32 %r28, %r28, 1;
setp.lt.u32	%p2, %r28, 52;
@%p2 bra BB76_1;

BB76_2:
mov.u32 %r29, 0;
@%p1 bra BB76_4;

BB76_3:
mul.wide.s32 %rd56, %r29, 8;
add.s64 %rd57, %rd1, %rd56;
ld.param.u64 %rd58, [%rd57];
add.s64 %rd59, %rd3, %rd56;
st.local.u64 [%rd59], %rd58;
add.s32 %r29, %r29, 1;
setp.lt.u32	%p4, %r29, 52;
@%p4 bra BB76_3;

BB76_4:
mov.u32 %r13, %ctaid.x;
mov.u32 %r14, %ntid.x;
mul.wide.u32 %rd60, %r14, %r13;
mov.u32 %r15, %tid.x;
cvt.u64.u32	%rd61, %r15;
add.s64 %rd104, %rd60, %rd61;
setp.ge.u64	%p5, %rd104, %rd49;
@%p5 bra BB76_17;

ld.local.u32 %r16, [%rd2+408];
add.s32 %r5, %r16, -1;
ld.local.u64 %rd9, [%rd2+208];
ld.local.u64 %rd62, [%rd2];
cvta.to.global.u64 %rd10, %rd62;
ld.local.u32 %r17, [%rd3+408];
add.s32 %r6, %r17, -1;
ld.local.u64 %rd11, [%rd3+208];
ld.local.u64 %rd63, [%rd3];
cvta.to.global.u64 %rd12, %rd63;
mul.wide.s32 %rd64, %r16, 8;
add.s64 %rd13, %rd2, %rd64;
mul.wide.s32 %rd65, %r17, 8;
add.s64 %rd14, %rd3, %rd65;

BB76_6:
mov.u64 %rd90, %rd104;
mov.u64 %rd15, %rd90;
mov.u64 %rd86, %rd13;
mov.u64 %rd67, 0;
mov.u64 %rd111, %rd67;
setp.lt.s32	%p6, %r5, 1;
mov.u32 %r30, %r5;
mov.u64 %rd101, %rd15;
mov.u64 %rd102, %rd15;
mov.u64 %rd110, %rd67;
@%p6 bra BB76_11;

BB76_7:
mov.u64 %rd18, %rd102;
mov.u32 %r7, %r30;
ld.local.u64 %rd21, [%rd86];
or.b64 %rd68, %rd18, %rd21;
and.b64 %rd69, %rd68, -4294967296;
setp.eq.s64	%p7, %rd69, 0;
@%p7 bra BB76_9;
bra.uni BB76_8;

BB76_9:
cvt.u32.u64	%r18, %rd21;
cvt.u32.u64	%r19, %rd18;
div.u32 %r20, %r19, %r18;
rem.u32 %r21, %r19, %r18;
cvt.u64.u32	%rd103, %r20;
cvt.u64.u32	%rd87, %r21;
bra.uni BB76_10;

BB76_8:
div.u64 %rd103, %rd18, %rd21;
rem.u64 %rd87, %rd18, %rd21;

BB76_10:
mov.u64 %rd26, %rd103;
ld.local.u64 %rd70, [%rd86+200];
mul.lo.s64 %rd71, %rd70, %rd87;
add.s64 %rd111, %rd71, %rd111;
add.s64 %rd86, %rd86, -8;
add.s32 %r8, %r7, -1;
setp.gt.s32	%p8, %r8, 0;
mov.u32 %r30, %r8;
mov.u64 %rd101, %rd26;
mov.u64 %rd102, %rd26;
mov.u64 %rd105, %rd111;
mov.u64 %rd110, %rd105;
@%p8 bra BB76_7;

BB76_11:
mov.u64 %rd31, %rd110;
mov.u64 %rd88, %rd14;
mul.lo.s64 %rd74, %rd9, %rd101;
add.s64 %rd33, %rd74, %rd31;
mov.u64 %rd109, %rd67;
setp.lt.s32	%p9, %r6, 1;
mov.u32 %r31, %r6;
mov.u64 %rd99, %rd15;
mov.u64 %rd98, %rd15;
mov.u64 %rd108, %rd67;
@%p9 bra BB76_16;

BB76_12:
mov.u32 %r9, %r31;
ld.local.u64 %rd37, [%rd88];
or.b64 %rd75, %rd99, %rd37;
and.b64 %rd76, %rd75, -4294967296;
setp.eq.s64	%p10, %rd76, 0;
@%p10 bra BB76_14;
bra.uni BB76_13;

BB76_14:
cvt.u32.u64	%r22, %rd37;
cvt.u32.u64	%r23, %rd99;
div.u32 %r24, %r23, %r22;
rem.u32 %r25, %r23, %r22;
cvt.u64.u32	%rd100, %r24;
cvt.u64.u32	%rd89, %r25;
bra.uni BB76_15;

BB76_13:
div.u64 %rd100, %rd99, %rd37;
rem.u64 %rd89, %rd99, %rd37;

BB76_15:
mov.u64 %rd99, %rd100;
ld.local.u64 %rd77, [%rd88+200];
mul.lo.s64 %rd78, %rd77, %rd89;
add.s64 %rd109, %rd78, %rd109;
add.s64 %rd88, %rd88, -8;
add.s32 %r10, %r9, -1;
setp.gt.s32	%p11, %r10, 0;
mov.u32 %r31, %r10;
mov.u64 %rd98, %rd99;
mov.u64 %rd108, %rd109;
@%p11 bra BB76_12;

BB76_16:
shl.b64 %rd79, %rd33, 2;
add.s64 %rd80, %rd10, %rd79;
mul.lo.s64 %rd81, %rd11, %rd98;
add.s64 %rd82, %rd81, %rd108;
shl.b64 %rd83, %rd82, 2;
add.s64 %rd84, %rd12, %rd83;
ld.global.f32 %f3, [%rd84];
setp.lt.f32	%p12, %f3, %f2;
selp.u16	%rs1, 1, 0, %p12;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd80], %f4;
mov.u32 %r26, %nctaid.x;
mul.wide.u32 %rd85, %r26, %r14;
add.s64 %rd104, %rd85, %rd15;
setp.lt.u64	%p13, %rd104, %rd49;
@%p13 bra BB76_6;

BB76_17:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<18>;
.reg .f32 %f<5>;
.reg .b32 %r<17>;
.reg .b64 %rd<9>;


ld.param.u32 %r8, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r9, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r10, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r11, %ctaid.x;
mov.u32 %r12, %tid.x;
mad.lo.s32 %r16, %r1, %r11, %r12;
setp.ge.u32	%p1, %r16, %r10;
@%p1 bra BB77_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;
mov.u32 %r13, %nctaid.x;
mul.lo.s32 %r5, %r13, %r1;

BB77_2:
mul.lo.s32 %r14, %r16, %r8;
mul.wide.u32 %rd5, %r14, 4;
add.s64 %rd6, %rd1, %rd5;
mul.lo.s32 %r15, %r16, %r9;
mul.wide.u32 %rd7, %r15, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.gt.f32	%p2, %f3, %f2;
selp.u16	%rs17, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs17;
st.global.f32 [%rd6], %f4;
add.s32 %r16, %r5, %r16;
setp.lt.u32	%p3, %r16, %r10;
@%p3 bra BB77_2;

BB77_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.u32 %r12, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r4, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r4, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB78_3;

cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r4;
cvta.to.global.u64 %rd2, %rd4;

BB78_2:
mul.lo.s32 %r33, %r41, %r12;
mul.wide.u32 %rd5, %r33, 4;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r34, %r41, %r24;
add.s32 %r35, %r34, %r41;
shr.u32 %r36, %r35, %r25;
mul.lo.s32 %r37, %r36, %r27;
sub.s32 %r38, %r41, %r37;
mul.lo.s32 %r39, %r38, %r23;
mad.lo.s32 %r40, %r22, %r36, %r39;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.gt.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd6], %f4;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB78_2;

BB78_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot79[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot79;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB79_2;

BB79_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB79_1;

BB79_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB79_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB79_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB79_6;

BB79_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB79_5;

BB79_6:
mul.lo.s32 %r30, %r8, %r18;
mul.wide.u32 %rd16, %r30, 4;
add.s64 %rd17, %rd4, %rd16;
ld.local.u32 %r31, [%rd1+108];
mad.lo.s32 %r32, %r31, %r38, %r42;
ld.local.u64 %rd18, [%rd1];
cvta.to.global.u64 %rd19, %rd18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd19, %rd20;
ld.global.f32 %f3, [%rd21];
setp.gt.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd17], %f4;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB79_4;

BB79_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r20, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r1, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB80_3;

cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r1;
cvta.to.global.u64 %rd2, %rd3;

BB80_2:
mul.hi.u32 %r33, %r41, %r24;
add.s32 %r34, %r33, %r41;
shr.u32 %r35, %r34, %r25;
mul.lo.s32 %r36, %r35, %r27;
sub.s32 %r37, %r41, %r36;
mul.lo.s32 %r38, %r37, %r23;
mad.lo.s32 %r39, %r22, %r35, %r38;
mul.wide.u32 %rd5, %r39, 4;
add.s64 %rd6, %rd2, %rd5;
mul.lo.s32 %r40, %r41, %r20;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd1, %rd7;
ld.global.f32 %f3, [%rd8];
setp.gt.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd6], %f4;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB80_2;

BB80_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<67>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r39, %r40}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r41, %r42}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r43, %r44}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r47, %ntid.x;
mov.u32 %r48, %ctaid.x;
mov.u32 %r49, %tid.x;
mad.lo.s32 %r66, %r47, %r48, %r49;
setp.ge.u32	%p1, %r66, %r30;
@%p1 bra BB81_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;

BB81_2:
mul.hi.u32 %r50, %r66, %r33;
add.s32 %r51, %r50, %r66;
shr.u32 %r52, %r51, %r34;
mul.lo.s32 %r53, %r52, %r36;
sub.s32 %r54, %r66, %r53;
mul.lo.s32 %r55, %r54, %r32;
mad.lo.s32 %r56, %r31, %r52, %r55;
mul.wide.u32 %rd5, %r56, 4;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r57, %r66, %r41;
add.s32 %r58, %r57, %r66;
shr.u32 %r59, %r58, %r42;
mul.lo.s32 %r60, %r59, %r44;
sub.s32 %r61, %r66, %r60;
mul.lo.s32 %r62, %r61, %r40;
mad.lo.s32 %r63, %r39, %r59, %r62;
mul.wide.u32 %rd7, %r63, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.gt.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd6], %f4;
mov.u32 %r65, %nctaid.x;
mad.lo.s32 %r66, %r65, %r47, %r66;
setp.lt.u32	%p3, %r66, %r30;
@%p3 bra BB81_2;

BB81_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot82[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot82;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r32, %r33}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r34, %r35}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r36, %r37}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB82_2;

BB82_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB82_1;

BB82_2:
mov.u32 %r40, %ntid.x;
mov.u32 %r41, %ctaid.x;
mov.u32 %r42, %tid.x;
mad.lo.s32 %r65, %r40, %r41, %r42;
setp.ge.u32	%p3, %r65, %r30;
@%p3 bra BB82_7;

cvta.to.global.u64 %rd4, %rd10;
ld.local.u32 %r43, [%rd1+208];
add.s32 %r9, %r43, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd5, %rd16;
mul.wide.s32 %rd17, %r43, 4;
add.s64 %rd6, %rd1, %rd17;

BB82_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mul.hi.u32 %r12, %r11, %r34;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB82_6;

BB82_5:
mov.u32 %r14, %r64;
mov.u32 %r13, %r59;
ld.local.u32 %r46, [%rd22+4];
rem.u32 %r47, %r14, %r46;
ld.local.u32 %r48, [%rd22+104];
mad.lo.s32 %r68, %r48, %r47, %r68;
div.u32 %r17, %r14, %r46;
add.s64 %rd22, %rd22, -4;
add.s32 %r18, %r13, -1;
setp.gt.s32	%p5, %r18, 0;
mov.u32 %r59, %r18;
mov.u32 %r63, %r17;
mov.u32 %r64, %r17;
mov.u32 %r67, %r68;
@%p5 bra BB82_5;

BB82_6:
add.s32 %r49, %r12, %r11;
shr.u32 %r50, %r49, %r35;
mul.lo.s32 %r51, %r50, %r37;
sub.s32 %r52, %r11, %r51;
mul.lo.s32 %r53, %r52, %r33;
mad.lo.s32 %r54, %r32, %r50, %r53;
mul.wide.u32 %rd18, %r54, 4;
add.s64 %rd19, %rd4, %rd18;
mad.lo.s32 %r55, %r10, %r63, %r67;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.gt.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd19], %f4;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r40, %r11;
setp.lt.u32	%p7, %r65, %r30;
@%p7 bra BB82_4;

BB82_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot83[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot83;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB83_2;

BB83_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB83_1;

BB83_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB83_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB83_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB83_6;

BB83_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB83_5;

BB83_6:
ld.local.u32 %r30, [%rd1+108];
mad.lo.s32 %r31, %r30, %r38, %r42;
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd17, %rd16;
mul.wide.u32 %rd18, %r31, 4;
add.s64 %rd19, %rd17, %rd18;
mul.lo.s32 %r32, %r8, %r18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd4, %rd20;
ld.global.f32 %f3, [%rd21];
setp.gt.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd19], %f4;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB83_4;

BB83_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot84[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot84;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB84_2;

BB84_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB84_1;

BB84_2:
mov.u32 %r39, %ntid.x;
mov.u32 %r40, %ctaid.x;
mov.u32 %r41, %tid.x;
mad.lo.s32 %r65, %r39, %r40, %r41;
setp.ge.u32	%p3, %r65, %r29;
@%p3 bra BB84_7;

ld.local.u32 %r42, [%rd1+208];
add.s32 %r9, %r42, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd4, %rd16;
cvta.to.global.u64 %rd5, %rd10;
mul.wide.s32 %rd17, %r42, 4;
add.s64 %rd6, %rd1, %rd17;

BB84_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB84_6;

BB84_5:
mov.u32 %r13, %r64;
mov.u32 %r12, %r59;
ld.local.u32 %r45, [%rd22+4];
rem.u32 %r46, %r13, %r45;
ld.local.u32 %r47, [%rd22+104];
mad.lo.s32 %r68, %r47, %r46, %r68;
div.u32 %r16, %r13, %r45;
add.s64 %rd22, %rd22, -4;
add.s32 %r17, %r12, -1;
setp.gt.s32	%p5, %r17, 0;
mov.u32 %r59, %r17;
mov.u32 %r63, %r16;
mov.u32 %r64, %r16;
mov.u32 %r67, %r68;
@%p5 bra BB84_5;

BB84_6:
mad.lo.s32 %r48, %r10, %r63, %r67;
mul.wide.u32 %rd18, %r48, 4;
add.s64 %rd19, %rd4, %rd18;
mul.hi.u32 %r49, %r11, %r33;
add.s32 %r50, %r49, %r11;
shr.u32 %r51, %r50, %r34;
mul.lo.s32 %r52, %r51, %r36;
sub.s32 %r53, %r11, %r52;
mul.lo.s32 %r54, %r53, %r32;
mad.lo.s32 %r55, %r31, %r51, %r54;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.gt.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd19], %f4;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r39, %r11;
setp.lt.u32	%p7, %r65, %r29;
@%p7 bra BB84_4;

BB84_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot85[432];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<12>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<72>;
.reg .b64 %rd<39>;


mov.u64 %rd38, __local_depot85;
cvta.local.u64 %SP, %rd38;
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd18, %SP, 216;
cvta.to.local.u64 %rd2, %rd18;
add.u64 %rd19, %SP, 0;
cvta.to.local.u64 %rd3, %rd19;
mov.u32 %r50, 0;
mov.pred %p1, 0;
@%p1 bra BB85_2;

BB85_1:
mul.wide.s32 %rd20, %r50, 8;
add.s64 %rd21, %rd4, %rd20;
ld.param.u64 %rd22, [%rd21];
add.s64 %rd23, %rd2, %rd20;
st.local.u64 [%rd23], %rd22;
add.s32 %r50, %r50, 1;
setp.lt.u32	%p2, %r50, 27;
@%p2 bra BB85_1;

BB85_2:
mov.u32 %r51, 0;
@%p1 bra BB85_4;

BB85_3:
mul.wide.s32 %rd24, %r51, 8;
add.s64 %rd25, %rd1, %rd24;
ld.param.u64 %rd26, [%rd25];
add.s64 %rd27, %rd3, %rd24;
st.local.u64 [%rd27], %rd26;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p4, %r51, 27;
@%p4 bra BB85_3;

BB85_4:
mov.u32 %r32, %ntid.x;
mov.u32 %r33, %ctaid.x;
mov.u32 %r34, %tid.x;
mad.lo.s32 %r64, %r32, %r33, %r34;
setp.ge.u32	%p5, %r64, %r29;
@%p5 bra BB85_11;

ld.local.u32 %r35, [%rd2+208];
add.s32 %r6, %r35, -1;
ld.local.u32 %r7, [%rd2+108];
ld.local.u64 %rd28, [%rd2];
cvta.to.global.u64 %rd8, %rd28;
ld.local.u32 %r36, [%rd3+208];
add.s32 %r8, %r36, -1;
ld.local.u32 %r9, [%rd3+108];
ld.local.u64 %rd29, [%rd3];
cvta.to.global.u64 %rd9, %rd29;
mul.wide.s32 %rd30, %r35, 4;
add.s64 %rd10, %rd2, %rd30;
mul.wide.s32 %rd31, %r36, 4;
add.s64 %rd11, %rd3, %rd31;

BB85_6:
mov.u32 %r54, %r64;
mov.u32 %r10, %r54;
mov.u64 %rd36, %rd10;
mov.u32 %r38, 0;
mov.u32 %r71, %r38;
setp.lt.s32	%p6, %r6, 1;
mov.u32 %r52, %r6;
mov.u32 %r62, %r10;
mov.u32 %r63, %r10;
mov.u32 %r70, %r38;
@%p6 bra BB85_8;

BB85_7:
mov.u32 %r12, %r63;
mov.u32 %r11, %r52;
ld.local.u32 %r39, [%rd36+4];
rem.u32 %r40, %r12, %r39;
ld.local.u32 %r41, [%rd36+104];
mad.lo.s32 %r71, %r41, %r40, %r71;
div.u32 %r15, %r12, %r39;
add.s64 %rd36, %rd36, -4;
add.s32 %r16, %r11, -1;
setp.gt.s32	%p7, %r16, 0;
mov.u32 %r52, %r16;
mov.u32 %r62, %r15;
mov.u32 %r63, %r15;
mov.u32 %r65, %r71;
mov.u32 %r70, %r65;
@%p7 bra BB85_7;

BB85_8:
mov.u32 %r18, %r70;
mov.u64 %rd37, %rd11;
mad.lo.s32 %r19, %r7, %r62, %r18;
mov.u32 %r69, %r38;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r53, %r8;
mov.u32 %r61, %r10;
mov.u32 %r60, %r10;
mov.u32 %r68, %r38;
@%p8 bra BB85_10;

BB85_9:
mov.u32 %r20, %r53;
ld.local.u32 %r44, [%rd37+4];
rem.u32 %r45, %r61, %r44;
ld.local.u32 %r46, [%rd37+104];
mad.lo.s32 %r69, %r46, %r45, %r69;
div.u32 %r61, %r61, %r44;
add.s64 %rd37, %rd37, -4;
add.s32 %r25, %r20, -1;
setp.gt.s32	%p9, %r25, 0;
mov.u32 %r53, %r25;
mov.u32 %r60, %r61;
mov.u32 %r68, %r69;
@%p9 bra BB85_9;

BB85_10:
mul.wide.u32 %rd32, %r19, 4;
add.s64 %rd33, %rd8, %rd32;
mad.lo.s32 %r47, %r9, %r60, %r68;
mul.wide.u32 %rd34, %r47, 4;
add.s64 %rd35, %rd9, %rd34;
ld.global.f32 %f3, [%rd35];
setp.gt.f32	%p10, %f3, %f2;
selp.u16	%rs1, 1, 0, %p10;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd33], %f4;
mov.u32 %r49, %nctaid.x;
mad.lo.s32 %r64, %r49, %r32, %r10;
setp.lt.u32	%p11, %r64, %r29;
@%p11 bra BB85_6;

BB85_11:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u64 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<5>;
.reg .b64 %rd<25>;


ld.param.u64 %rd11, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u64 %rd13, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd12, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u64 %rd14, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %ntid.x;
cvt.u64.u32	%rd1, %r2;
mul.wide.u32 %rd15, %r2, %r1;
mov.u32 %r3, %tid.x;
cvt.u64.u32	%rd16, %r3;
add.s64 %rd24, %rd15, %rd16;
setp.ge.u64	%p1, %rd24, %rd14;
@%p1 bra BB86_3;

cvta.to.global.u64 %rd3, %rd10;
cvta.to.global.u64 %rd5, %rd12;
mov.u32 %r4, %nctaid.x;
cvt.u64.u32	%rd17, %r4;
mul.lo.s64 %rd7, %rd17, %rd1;

BB86_2:
mul.lo.s64 %rd18, %rd24, %rd11;
shl.b64 %rd19, %rd18, 2;
add.s64 %rd20, %rd3, %rd19;
mul.lo.s64 %rd21, %rd24, %rd13;
shl.b64 %rd22, %rd21, 2;
add.s64 %rd23, %rd5, %rd22;
ld.global.f32 %f3, [%rd23];
setp.gt.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd20], %f4;
add.s64 %rd24, %rd7, %rd24;
setp.lt.u64	%p3, %rd24, %rd14;
@%p3 bra BB86_2;

BB86_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[416],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[416],
.param .u64 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot87[832];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<32>;
.reg .b64 %rd<113>;


mov.u64 %rd112, __local_depot87;
cvta.local.u64 %SP, %rd112;
ld.param.u64 %rd49, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGTValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorGTValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd50, %SP, 416;
cvta.to.local.u64 %rd2, %rd50;
add.u64 %rd51, %SP, 0;
cvta.to.local.u64 %rd3, %rd51;
mov.u32 %r28, 0;
mov.pred %p1, 0;
@%p1 bra BB87_2;

BB87_1:
mul.wide.s32 %rd52, %r28, 8;
add.s64 %rd53, %rd4, %rd52;
ld.param.u64 %rd54, [%rd53];
add.s64 %rd55, %rd2, %rd52;
st.local.u64 [%rd55], %rd54;
add.s32 %r28, %r28, 1;
setp.lt.u32	%p2, %r28, 52;
@%p2 bra BB87_1;

BB87_2:
mov.u32 %r29, 0;
@%p1 bra BB87_4;

BB87_3:
mul.wide.s32 %rd56, %r29, 8;
add.s64 %rd57, %rd1, %rd56;
ld.param.u64 %rd58, [%rd57];
add.s64 %rd59, %rd3, %rd56;
st.local.u64 [%rd59], %rd58;
add.s32 %r29, %r29, 1;
setp.lt.u32	%p4, %r29, 52;
@%p4 bra BB87_3;

BB87_4:
mov.u32 %r13, %ctaid.x;
mov.u32 %r14, %ntid.x;
mul.wide.u32 %rd60, %r14, %r13;
mov.u32 %r15, %tid.x;
cvt.u64.u32	%rd61, %r15;
add.s64 %rd104, %rd60, %rd61;
setp.ge.u64	%p5, %rd104, %rd49;
@%p5 bra BB87_17;

ld.local.u32 %r16, [%rd2+408];
add.s32 %r5, %r16, -1;
ld.local.u64 %rd9, [%rd2+208];
ld.local.u64 %rd62, [%rd2];
cvta.to.global.u64 %rd10, %rd62;
ld.local.u32 %r17, [%rd3+408];
add.s32 %r6, %r17, -1;
ld.local.u64 %rd11, [%rd3+208];
ld.local.u64 %rd63, [%rd3];
cvta.to.global.u64 %rd12, %rd63;
mul.wide.s32 %rd64, %r16, 8;
add.s64 %rd13, %rd2, %rd64;
mul.wide.s32 %rd65, %r17, 8;
add.s64 %rd14, %rd3, %rd65;

BB87_6:
mov.u64 %rd90, %rd104;
mov.u64 %rd15, %rd90;
mov.u64 %rd86, %rd13;
mov.u64 %rd67, 0;
mov.u64 %rd111, %rd67;
setp.lt.s32	%p6, %r5, 1;
mov.u32 %r30, %r5;
mov.u64 %rd101, %rd15;
mov.u64 %rd102, %rd15;
mov.u64 %rd110, %rd67;
@%p6 bra BB87_11;

BB87_7:
mov.u64 %rd18, %rd102;
mov.u32 %r7, %r30;
ld.local.u64 %rd21, [%rd86];
or.b64 %rd68, %rd18, %rd21;
and.b64 %rd69, %rd68, -4294967296;
setp.eq.s64	%p7, %rd69, 0;
@%p7 bra BB87_9;
bra.uni BB87_8;

BB87_9:
cvt.u32.u64	%r18, %rd21;
cvt.u32.u64	%r19, %rd18;
div.u32 %r20, %r19, %r18;
rem.u32 %r21, %r19, %r18;
cvt.u64.u32	%rd103, %r20;
cvt.u64.u32	%rd87, %r21;
bra.uni BB87_10;

BB87_8:
div.u64 %rd103, %rd18, %rd21;
rem.u64 %rd87, %rd18, %rd21;

BB87_10:
mov.u64 %rd26, %rd103;
ld.local.u64 %rd70, [%rd86+200];
mul.lo.s64 %rd71, %rd70, %rd87;
add.s64 %rd111, %rd71, %rd111;
add.s64 %rd86, %rd86, -8;
add.s32 %r8, %r7, -1;
setp.gt.s32	%p8, %r8, 0;
mov.u32 %r30, %r8;
mov.u64 %rd101, %rd26;
mov.u64 %rd102, %rd26;
mov.u64 %rd105, %rd111;
mov.u64 %rd110, %rd105;
@%p8 bra BB87_7;

BB87_11:
mov.u64 %rd31, %rd110;
mov.u64 %rd88, %rd14;
mul.lo.s64 %rd74, %rd9, %rd101;
add.s64 %rd33, %rd74, %rd31;
mov.u64 %rd109, %rd67;
setp.lt.s32	%p9, %r6, 1;
mov.u32 %r31, %r6;
mov.u64 %rd99, %rd15;
mov.u64 %rd98, %rd15;
mov.u64 %rd108, %rd67;
@%p9 bra BB87_16;

BB87_12:
mov.u32 %r9, %r31;
ld.local.u64 %rd37, [%rd88];
or.b64 %rd75, %rd99, %rd37;
and.b64 %rd76, %rd75, -4294967296;
setp.eq.s64	%p10, %rd76, 0;
@%p10 bra BB87_14;
bra.uni BB87_13;

BB87_14:
cvt.u32.u64	%r22, %rd37;
cvt.u32.u64	%r23, %rd99;
div.u32 %r24, %r23, %r22;
rem.u32 %r25, %r23, %r22;
cvt.u64.u32	%rd100, %r24;
cvt.u64.u32	%rd89, %r25;
bra.uni BB87_15;

BB87_13:
div.u64 %rd100, %rd99, %rd37;
rem.u64 %rd89, %rd99, %rd37;

BB87_15:
mov.u64 %rd99, %rd100;
ld.local.u64 %rd77, [%rd88+200];
mul.lo.s64 %rd78, %rd77, %rd89;
add.s64 %rd109, %rd78, %rd109;
add.s64 %rd88, %rd88, -8;
add.s32 %r10, %r9, -1;
setp.gt.s32	%p11, %r10, 0;
mov.u32 %r31, %r10;
mov.u64 %rd98, %rd99;
mov.u64 %rd108, %rd109;
@%p11 bra BB87_12;

BB87_16:
shl.b64 %rd79, %rd33, 2;
add.s64 %rd80, %rd10, %rd79;
mul.lo.s64 %rd81, %rd11, %rd98;
add.s64 %rd82, %rd81, %rd108;
shl.b64 %rd83, %rd82, 2;
add.s64 %rd84, %rd12, %rd83;
ld.global.f32 %f3, [%rd84];
setp.gt.f32	%p12, %f3, %f2;
selp.u16	%rs1, 1, 0, %p12;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd80], %f4;
mov.u32 %r26, %nctaid.x;
mul.wide.u32 %rd85, %r26, %r14;
add.s64 %rd104, %rd85, %rd15;
setp.lt.u64	%p13, %rd104, %rd49;
@%p13 bra BB87_6;

BB87_17:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<18>;
.reg .f32 %f<5>;
.reg .b32 %r<17>;
.reg .b64 %rd<9>;


ld.param.u32 %r8, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r9, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r10, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r11, %ctaid.x;
mov.u32 %r12, %tid.x;
mad.lo.s32 %r16, %r1, %r11, %r12;
setp.ge.u32	%p1, %r16, %r10;
@%p1 bra BB88_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;
mov.u32 %r13, %nctaid.x;
mul.lo.s32 %r5, %r13, %r1;

BB88_2:
mul.lo.s32 %r14, %r16, %r8;
mul.wide.u32 %rd5, %r14, 4;
add.s64 %rd6, %rd1, %rd5;
mul.lo.s32 %r15, %r16, %r9;
mul.wide.u32 %rd7, %r15, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.le.f32	%p2, %f3, %f2;
selp.u16	%rs17, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs17;
st.global.f32 [%rd6], %f4;
add.s32 %r16, %r5, %r16;
setp.lt.u32	%p3, %r16, %r10;
@%p3 bra BB88_2;

BB88_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.u32 %r12, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r4, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r4, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB89_3;

cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r4;
cvta.to.global.u64 %rd2, %rd4;

BB89_2:
mul.lo.s32 %r33, %r41, %r12;
mul.wide.u32 %rd5, %r33, 4;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r34, %r41, %r24;
add.s32 %r35, %r34, %r41;
shr.u32 %r36, %r35, %r25;
mul.lo.s32 %r37, %r36, %r27;
sub.s32 %r38, %r41, %r37;
mul.lo.s32 %r39, %r38, %r23;
mad.lo.s32 %r40, %r22, %r36, %r39;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.le.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd6], %f4;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB89_2;

BB89_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot90[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot90;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB90_2;

BB90_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB90_1;

BB90_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB90_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB90_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB90_6;

BB90_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB90_5;

BB90_6:
mul.lo.s32 %r30, %r8, %r18;
mul.wide.u32 %rd16, %r30, 4;
add.s64 %rd17, %rd4, %rd16;
ld.local.u32 %r31, [%rd1+108];
mad.lo.s32 %r32, %r31, %r38, %r42;
ld.local.u64 %rd18, [%rd1];
cvta.to.global.u64 %rd19, %rd18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd19, %rd20;
ld.global.f32 %f3, [%rd21];
setp.le.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd17], %f4;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB90_4;

BB90_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r20, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r1, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB91_3;

cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r1;
cvta.to.global.u64 %rd2, %rd3;

BB91_2:
mul.hi.u32 %r33, %r41, %r24;
add.s32 %r34, %r33, %r41;
shr.u32 %r35, %r34, %r25;
mul.lo.s32 %r36, %r35, %r27;
sub.s32 %r37, %r41, %r36;
mul.lo.s32 %r38, %r37, %r23;
mad.lo.s32 %r39, %r22, %r35, %r38;
mul.wide.u32 %rd5, %r39, 4;
add.s64 %rd6, %rd2, %rd5;
mul.lo.s32 %r40, %r41, %r20;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd1, %rd7;
ld.global.f32 %f3, [%rd8];
setp.le.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd6], %f4;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB91_2;

BB91_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<67>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r39, %r40}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r41, %r42}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r43, %r44}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r47, %ntid.x;
mov.u32 %r48, %ctaid.x;
mov.u32 %r49, %tid.x;
mad.lo.s32 %r66, %r47, %r48, %r49;
setp.ge.u32	%p1, %r66, %r30;
@%p1 bra BB92_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;

BB92_2:
mul.hi.u32 %r50, %r66, %r33;
add.s32 %r51, %r50, %r66;
shr.u32 %r52, %r51, %r34;
mul.lo.s32 %r53, %r52, %r36;
sub.s32 %r54, %r66, %r53;
mul.lo.s32 %r55, %r54, %r32;
mad.lo.s32 %r56, %r31, %r52, %r55;
mul.wide.u32 %rd5, %r56, 4;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r57, %r66, %r41;
add.s32 %r58, %r57, %r66;
shr.u32 %r59, %r58, %r42;
mul.lo.s32 %r60, %r59, %r44;
sub.s32 %r61, %r66, %r60;
mul.lo.s32 %r62, %r61, %r40;
mad.lo.s32 %r63, %r39, %r59, %r62;
mul.wide.u32 %rd7, %r63, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.le.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd6], %f4;
mov.u32 %r65, %nctaid.x;
mad.lo.s32 %r66, %r65, %r47, %r66;
setp.lt.u32	%p3, %r66, %r30;
@%p3 bra BB92_2;

BB92_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot93[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot93;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r32, %r33}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r34, %r35}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r36, %r37}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB93_2;

BB93_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB93_1;

BB93_2:
mov.u32 %r40, %ntid.x;
mov.u32 %r41, %ctaid.x;
mov.u32 %r42, %tid.x;
mad.lo.s32 %r65, %r40, %r41, %r42;
setp.ge.u32	%p3, %r65, %r30;
@%p3 bra BB93_7;

cvta.to.global.u64 %rd4, %rd10;
ld.local.u32 %r43, [%rd1+208];
add.s32 %r9, %r43, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd5, %rd16;
mul.wide.s32 %rd17, %r43, 4;
add.s64 %rd6, %rd1, %rd17;

BB93_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mul.hi.u32 %r12, %r11, %r34;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB93_6;

BB93_5:
mov.u32 %r14, %r64;
mov.u32 %r13, %r59;
ld.local.u32 %r46, [%rd22+4];
rem.u32 %r47, %r14, %r46;
ld.local.u32 %r48, [%rd22+104];
mad.lo.s32 %r68, %r48, %r47, %r68;
div.u32 %r17, %r14, %r46;
add.s64 %rd22, %rd22, -4;
add.s32 %r18, %r13, -1;
setp.gt.s32	%p5, %r18, 0;
mov.u32 %r59, %r18;
mov.u32 %r63, %r17;
mov.u32 %r64, %r17;
mov.u32 %r67, %r68;
@%p5 bra BB93_5;

BB93_6:
add.s32 %r49, %r12, %r11;
shr.u32 %r50, %r49, %r35;
mul.lo.s32 %r51, %r50, %r37;
sub.s32 %r52, %r11, %r51;
mul.lo.s32 %r53, %r52, %r33;
mad.lo.s32 %r54, %r32, %r50, %r53;
mul.wide.u32 %rd18, %r54, 4;
add.s64 %rd19, %rd4, %rd18;
mad.lo.s32 %r55, %r10, %r63, %r67;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.le.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd19], %f4;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r40, %r11;
setp.lt.u32	%p7, %r65, %r30;
@%p7 bra BB93_4;

BB93_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot94[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot94;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB94_2;

BB94_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB94_1;

BB94_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB94_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB94_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB94_6;

BB94_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB94_5;

BB94_6:
ld.local.u32 %r30, [%rd1+108];
mad.lo.s32 %r31, %r30, %r38, %r42;
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd17, %rd16;
mul.wide.u32 %rd18, %r31, 4;
add.s64 %rd19, %rd17, %rd18;
mul.lo.s32 %r32, %r8, %r18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd4, %rd20;
ld.global.f32 %f3, [%rd21];
setp.le.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd19], %f4;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB94_4;

BB94_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot95[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot95;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB95_2;

BB95_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB95_1;

BB95_2:
mov.u32 %r39, %ntid.x;
mov.u32 %r40, %ctaid.x;
mov.u32 %r41, %tid.x;
mad.lo.s32 %r65, %r39, %r40, %r41;
setp.ge.u32	%p3, %r65, %r29;
@%p3 bra BB95_7;

ld.local.u32 %r42, [%rd1+208];
add.s32 %r9, %r42, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd4, %rd16;
cvta.to.global.u64 %rd5, %rd10;
mul.wide.s32 %rd17, %r42, 4;
add.s64 %rd6, %rd1, %rd17;

BB95_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB95_6;

BB95_5:
mov.u32 %r13, %r64;
mov.u32 %r12, %r59;
ld.local.u32 %r45, [%rd22+4];
rem.u32 %r46, %r13, %r45;
ld.local.u32 %r47, [%rd22+104];
mad.lo.s32 %r68, %r47, %r46, %r68;
div.u32 %r16, %r13, %r45;
add.s64 %rd22, %rd22, -4;
add.s32 %r17, %r12, -1;
setp.gt.s32	%p5, %r17, 0;
mov.u32 %r59, %r17;
mov.u32 %r63, %r16;
mov.u32 %r64, %r16;
mov.u32 %r67, %r68;
@%p5 bra BB95_5;

BB95_6:
mad.lo.s32 %r48, %r10, %r63, %r67;
mul.wide.u32 %rd18, %r48, 4;
add.s64 %rd19, %rd4, %rd18;
mul.hi.u32 %r49, %r11, %r33;
add.s32 %r50, %r49, %r11;
shr.u32 %r51, %r50, %r34;
mul.lo.s32 %r52, %r51, %r36;
sub.s32 %r53, %r11, %r52;
mul.lo.s32 %r54, %r53, %r32;
mad.lo.s32 %r55, %r31, %r51, %r54;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.le.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd19], %f4;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r39, %r11;
setp.lt.u32	%p7, %r65, %r29;
@%p7 bra BB95_4;

BB95_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot96[432];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<12>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<72>;
.reg .b64 %rd<39>;


mov.u64 %rd38, __local_depot96;
cvta.local.u64 %SP, %rd38;
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd18, %SP, 216;
cvta.to.local.u64 %rd2, %rd18;
add.u64 %rd19, %SP, 0;
cvta.to.local.u64 %rd3, %rd19;
mov.u32 %r50, 0;
mov.pred %p1, 0;
@%p1 bra BB96_2;

BB96_1:
mul.wide.s32 %rd20, %r50, 8;
add.s64 %rd21, %rd4, %rd20;
ld.param.u64 %rd22, [%rd21];
add.s64 %rd23, %rd2, %rd20;
st.local.u64 [%rd23], %rd22;
add.s32 %r50, %r50, 1;
setp.lt.u32	%p2, %r50, 27;
@%p2 bra BB96_1;

BB96_2:
mov.u32 %r51, 0;
@%p1 bra BB96_4;

BB96_3:
mul.wide.s32 %rd24, %r51, 8;
add.s64 %rd25, %rd1, %rd24;
ld.param.u64 %rd26, [%rd25];
add.s64 %rd27, %rd3, %rd24;
st.local.u64 [%rd27], %rd26;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p4, %r51, 27;
@%p4 bra BB96_3;

BB96_4:
mov.u32 %r32, %ntid.x;
mov.u32 %r33, %ctaid.x;
mov.u32 %r34, %tid.x;
mad.lo.s32 %r64, %r32, %r33, %r34;
setp.ge.u32	%p5, %r64, %r29;
@%p5 bra BB96_11;

ld.local.u32 %r35, [%rd2+208];
add.s32 %r6, %r35, -1;
ld.local.u32 %r7, [%rd2+108];
ld.local.u64 %rd28, [%rd2];
cvta.to.global.u64 %rd8, %rd28;
ld.local.u32 %r36, [%rd3+208];
add.s32 %r8, %r36, -1;
ld.local.u32 %r9, [%rd3+108];
ld.local.u64 %rd29, [%rd3];
cvta.to.global.u64 %rd9, %rd29;
mul.wide.s32 %rd30, %r35, 4;
add.s64 %rd10, %rd2, %rd30;
mul.wide.s32 %rd31, %r36, 4;
add.s64 %rd11, %rd3, %rd31;

BB96_6:
mov.u32 %r54, %r64;
mov.u32 %r10, %r54;
mov.u64 %rd36, %rd10;
mov.u32 %r38, 0;
mov.u32 %r71, %r38;
setp.lt.s32	%p6, %r6, 1;
mov.u32 %r52, %r6;
mov.u32 %r62, %r10;
mov.u32 %r63, %r10;
mov.u32 %r70, %r38;
@%p6 bra BB96_8;

BB96_7:
mov.u32 %r12, %r63;
mov.u32 %r11, %r52;
ld.local.u32 %r39, [%rd36+4];
rem.u32 %r40, %r12, %r39;
ld.local.u32 %r41, [%rd36+104];
mad.lo.s32 %r71, %r41, %r40, %r71;
div.u32 %r15, %r12, %r39;
add.s64 %rd36, %rd36, -4;
add.s32 %r16, %r11, -1;
setp.gt.s32	%p7, %r16, 0;
mov.u32 %r52, %r16;
mov.u32 %r62, %r15;
mov.u32 %r63, %r15;
mov.u32 %r65, %r71;
mov.u32 %r70, %r65;
@%p7 bra BB96_7;

BB96_8:
mov.u32 %r18, %r70;
mov.u64 %rd37, %rd11;
mad.lo.s32 %r19, %r7, %r62, %r18;
mov.u32 %r69, %r38;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r53, %r8;
mov.u32 %r61, %r10;
mov.u32 %r60, %r10;
mov.u32 %r68, %r38;
@%p8 bra BB96_10;

BB96_9:
mov.u32 %r20, %r53;
ld.local.u32 %r44, [%rd37+4];
rem.u32 %r45, %r61, %r44;
ld.local.u32 %r46, [%rd37+104];
mad.lo.s32 %r69, %r46, %r45, %r69;
div.u32 %r61, %r61, %r44;
add.s64 %rd37, %rd37, -4;
add.s32 %r25, %r20, -1;
setp.gt.s32	%p9, %r25, 0;
mov.u32 %r53, %r25;
mov.u32 %r60, %r61;
mov.u32 %r68, %r69;
@%p9 bra BB96_9;

BB96_10:
mul.wide.u32 %rd32, %r19, 4;
add.s64 %rd33, %rd8, %rd32;
mad.lo.s32 %r47, %r9, %r60, %r68;
mul.wide.u32 %rd34, %r47, 4;
add.s64 %rd35, %rd9, %rd34;
ld.global.f32 %f3, [%rd35];
setp.le.f32	%p10, %f3, %f2;
selp.u16	%rs1, 1, 0, %p10;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd33], %f4;
mov.u32 %r49, %nctaid.x;
mad.lo.s32 %r64, %r49, %r32, %r10;
setp.lt.u32	%p11, %r64, %r29;
@%p11 bra BB96_6;

BB96_11:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u64 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<5>;
.reg .b64 %rd<25>;


ld.param.u64 %rd11, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u64 %rd13, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd12, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u64 %rd14, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %ntid.x;
cvt.u64.u32	%rd1, %r2;
mul.wide.u32 %rd15, %r2, %r1;
mov.u32 %r3, %tid.x;
cvt.u64.u32	%rd16, %r3;
add.s64 %rd24, %rd15, %rd16;
setp.ge.u64	%p1, %rd24, %rd14;
@%p1 bra BB97_3;

cvta.to.global.u64 %rd3, %rd10;
cvta.to.global.u64 %rd5, %rd12;
mov.u32 %r4, %nctaid.x;
cvt.u64.u32	%rd17, %r4;
mul.lo.s64 %rd7, %rd17, %rd1;

BB97_2:
mul.lo.s64 %rd18, %rd24, %rd11;
shl.b64 %rd19, %rd18, 2;
add.s64 %rd20, %rd3, %rd19;
mul.lo.s64 %rd21, %rd24, %rd13;
shl.b64 %rd22, %rd21, 2;
add.s64 %rd23, %rd5, %rd22;
ld.global.f32 %f3, [%rd23];
setp.le.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd20], %f4;
add.s64 %rd24, %rd7, %rd24;
setp.lt.u64	%p3, %rd24, %rd14;
@%p3 bra BB97_2;

BB97_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[416],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[416],
.param .u64 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot98[832];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<32>;
.reg .b64 %rd<113>;


mov.u64 %rd112, __local_depot98;
cvta.local.u64 %SP, %rd112;
ld.param.u64 %rd49, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorLEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorLEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd50, %SP, 416;
cvta.to.local.u64 %rd2, %rd50;
add.u64 %rd51, %SP, 0;
cvta.to.local.u64 %rd3, %rd51;
mov.u32 %r28, 0;
mov.pred %p1, 0;
@%p1 bra BB98_2;

BB98_1:
mul.wide.s32 %rd52, %r28, 8;
add.s64 %rd53, %rd4, %rd52;
ld.param.u64 %rd54, [%rd53];
add.s64 %rd55, %rd2, %rd52;
st.local.u64 [%rd55], %rd54;
add.s32 %r28, %r28, 1;
setp.lt.u32	%p2, %r28, 52;
@%p2 bra BB98_1;

BB98_2:
mov.u32 %r29, 0;
@%p1 bra BB98_4;

BB98_3:
mul.wide.s32 %rd56, %r29, 8;
add.s64 %rd57, %rd1, %rd56;
ld.param.u64 %rd58, [%rd57];
add.s64 %rd59, %rd3, %rd56;
st.local.u64 [%rd59], %rd58;
add.s32 %r29, %r29, 1;
setp.lt.u32	%p4, %r29, 52;
@%p4 bra BB98_3;

BB98_4:
mov.u32 %r13, %ctaid.x;
mov.u32 %r14, %ntid.x;
mul.wide.u32 %rd60, %r14, %r13;
mov.u32 %r15, %tid.x;
cvt.u64.u32	%rd61, %r15;
add.s64 %rd104, %rd60, %rd61;
setp.ge.u64	%p5, %rd104, %rd49;
@%p5 bra BB98_17;

ld.local.u32 %r16, [%rd2+408];
add.s32 %r5, %r16, -1;
ld.local.u64 %rd9, [%rd2+208];
ld.local.u64 %rd62, [%rd2];
cvta.to.global.u64 %rd10, %rd62;
ld.local.u32 %r17, [%rd3+408];
add.s32 %r6, %r17, -1;
ld.local.u64 %rd11, [%rd3+208];
ld.local.u64 %rd63, [%rd3];
cvta.to.global.u64 %rd12, %rd63;
mul.wide.s32 %rd64, %r16, 8;
add.s64 %rd13, %rd2, %rd64;
mul.wide.s32 %rd65, %r17, 8;
add.s64 %rd14, %rd3, %rd65;

BB98_6:
mov.u64 %rd90, %rd104;
mov.u64 %rd15, %rd90;
mov.u64 %rd86, %rd13;
mov.u64 %rd67, 0;
mov.u64 %rd111, %rd67;
setp.lt.s32	%p6, %r5, 1;
mov.u32 %r30, %r5;
mov.u64 %rd101, %rd15;
mov.u64 %rd102, %rd15;
mov.u64 %rd110, %rd67;
@%p6 bra BB98_11;

BB98_7:
mov.u64 %rd18, %rd102;
mov.u32 %r7, %r30;
ld.local.u64 %rd21, [%rd86];
or.b64 %rd68, %rd18, %rd21;
and.b64 %rd69, %rd68, -4294967296;
setp.eq.s64	%p7, %rd69, 0;
@%p7 bra BB98_9;
bra.uni BB98_8;

BB98_9:
cvt.u32.u64	%r18, %rd21;
cvt.u32.u64	%r19, %rd18;
div.u32 %r20, %r19, %r18;
rem.u32 %r21, %r19, %r18;
cvt.u64.u32	%rd103, %r20;
cvt.u64.u32	%rd87, %r21;
bra.uni BB98_10;

BB98_8:
div.u64 %rd103, %rd18, %rd21;
rem.u64 %rd87, %rd18, %rd21;

BB98_10:
mov.u64 %rd26, %rd103;
ld.local.u64 %rd70, [%rd86+200];
mul.lo.s64 %rd71, %rd70, %rd87;
add.s64 %rd111, %rd71, %rd111;
add.s64 %rd86, %rd86, -8;
add.s32 %r8, %r7, -1;
setp.gt.s32	%p8, %r8, 0;
mov.u32 %r30, %r8;
mov.u64 %rd101, %rd26;
mov.u64 %rd102, %rd26;
mov.u64 %rd105, %rd111;
mov.u64 %rd110, %rd105;
@%p8 bra BB98_7;

BB98_11:
mov.u64 %rd31, %rd110;
mov.u64 %rd88, %rd14;
mul.lo.s64 %rd74, %rd9, %rd101;
add.s64 %rd33, %rd74, %rd31;
mov.u64 %rd109, %rd67;
setp.lt.s32	%p9, %r6, 1;
mov.u32 %r31, %r6;
mov.u64 %rd99, %rd15;
mov.u64 %rd98, %rd15;
mov.u64 %rd108, %rd67;
@%p9 bra BB98_16;

BB98_12:
mov.u32 %r9, %r31;
ld.local.u64 %rd37, [%rd88];
or.b64 %rd75, %rd99, %rd37;
and.b64 %rd76, %rd75, -4294967296;
setp.eq.s64	%p10, %rd76, 0;
@%p10 bra BB98_14;
bra.uni BB98_13;

BB98_14:
cvt.u32.u64	%r22, %rd37;
cvt.u32.u64	%r23, %rd99;
div.u32 %r24, %r23, %r22;
rem.u32 %r25, %r23, %r22;
cvt.u64.u32	%rd100, %r24;
cvt.u64.u32	%rd89, %r25;
bra.uni BB98_15;

BB98_13:
div.u64 %rd100, %rd99, %rd37;
rem.u64 %rd89, %rd99, %rd37;

BB98_15:
mov.u64 %rd99, %rd100;
ld.local.u64 %rd77, [%rd88+200];
mul.lo.s64 %rd78, %rd77, %rd89;
add.s64 %rd109, %rd78, %rd109;
add.s64 %rd88, %rd88, -8;
add.s32 %r10, %r9, -1;
setp.gt.s32	%p11, %r10, 0;
mov.u32 %r31, %r10;
mov.u64 %rd98, %rd99;
mov.u64 %rd108, %rd109;
@%p11 bra BB98_12;

BB98_16:
shl.b64 %rd79, %rd33, 2;
add.s64 %rd80, %rd10, %rd79;
mul.lo.s64 %rd81, %rd11, %rd98;
add.s64 %rd82, %rd81, %rd108;
shl.b64 %rd83, %rd82, 2;
add.s64 %rd84, %rd12, %rd83;
ld.global.f32 %f3, [%rd84];
setp.le.f32	%p12, %f3, %f2;
selp.u16	%rs1, 1, 0, %p12;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd80], %f4;
mov.u32 %r26, %nctaid.x;
mul.wide.u32 %rd85, %r26, %r14;
add.s64 %rd104, %rd85, %rd15;
setp.lt.u64	%p13, %rd104, %rd49;
@%p13 bra BB98_6;

BB98_17:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<18>;
.reg .f32 %f<5>;
.reg .b32 %r<17>;
.reg .b64 %rd<9>;


ld.param.u32 %r8, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r9, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r10, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r11, %ctaid.x;
mov.u32 %r12, %tid.x;
mad.lo.s32 %r16, %r1, %r11, %r12;
setp.ge.u32	%p1, %r16, %r10;
@%p1 bra BB99_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;
mov.u32 %r13, %nctaid.x;
mul.lo.s32 %r5, %r13, %r1;

BB99_2:
mul.lo.s32 %r14, %r16, %r8;
mul.wide.u32 %rd5, %r14, 4;
add.s64 %rd6, %rd1, %rd5;
mul.lo.s32 %r15, %r16, %r9;
mul.wide.u32 %rd7, %r15, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.ge.f32	%p2, %f3, %f2;
selp.u16	%rs17, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs17;
st.global.f32 [%rd6], %f4;
add.s32 %r16, %r5, %r16;
setp.lt.u32	%p3, %r16, %r10;
@%p3 bra BB99_2;

BB99_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.u32 %r12, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r4, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r4, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB100_3;

cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r4;
cvta.to.global.u64 %rd2, %rd4;

BB100_2:
mul.lo.s32 %r33, %r41, %r12;
mul.wide.u32 %rd5, %r33, 4;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r34, %r41, %r24;
add.s32 %r35, %r34, %r41;
shr.u32 %r36, %r35, %r25;
mul.lo.s32 %r37, %r36, %r27;
sub.s32 %r38, %r41, %r37;
mul.lo.s32 %r39, %r38, %r23;
mad.lo.s32 %r40, %r22, %r36, %r39;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.ge.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd6], %f4;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB100_2;

BB100_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot101[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot101;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB101_2;

BB101_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB101_1;

BB101_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB101_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB101_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB101_6;

BB101_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB101_5;

BB101_6:
mul.lo.s32 %r30, %r8, %r18;
mul.wide.u32 %rd16, %r30, 4;
add.s64 %rd17, %rd4, %rd16;
ld.local.u32 %r31, [%rd1+108];
mad.lo.s32 %r32, %r31, %r38, %r42;
ld.local.u64 %rd18, [%rd1];
cvta.to.global.u64 %rd19, %rd18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd19, %rd20;
ld.global.f32 %f3, [%rd21];
setp.ge.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd17], %f4;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB101_4;

BB101_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r20, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r1, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB102_3;

cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r1;
cvta.to.global.u64 %rd2, %rd3;

BB102_2:
mul.hi.u32 %r33, %r41, %r24;
add.s32 %r34, %r33, %r41;
shr.u32 %r35, %r34, %r25;
mul.lo.s32 %r36, %r35, %r27;
sub.s32 %r37, %r41, %r36;
mul.lo.s32 %r38, %r37, %r23;
mad.lo.s32 %r39, %r22, %r35, %r38;
mul.wide.u32 %rd5, %r39, 4;
add.s64 %rd6, %rd2, %rd5;
mul.lo.s32 %r40, %r41, %r20;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd1, %rd7;
ld.global.f32 %f3, [%rd8];
setp.ge.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd6], %f4;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB102_2;

BB102_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<67>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r39, %r40}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r41, %r42}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r43, %r44}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r47, %ntid.x;
mov.u32 %r48, %ctaid.x;
mov.u32 %r49, %tid.x;
mad.lo.s32 %r66, %r47, %r48, %r49;
setp.ge.u32	%p1, %r66, %r30;
@%p1 bra BB103_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;

BB103_2:
mul.hi.u32 %r50, %r66, %r33;
add.s32 %r51, %r50, %r66;
shr.u32 %r52, %r51, %r34;
mul.lo.s32 %r53, %r52, %r36;
sub.s32 %r54, %r66, %r53;
mul.lo.s32 %r55, %r54, %r32;
mad.lo.s32 %r56, %r31, %r52, %r55;
mul.wide.u32 %rd5, %r56, 4;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r57, %r66, %r41;
add.s32 %r58, %r57, %r66;
shr.u32 %r59, %r58, %r42;
mul.lo.s32 %r60, %r59, %r44;
sub.s32 %r61, %r66, %r60;
mul.lo.s32 %r62, %r61, %r40;
mad.lo.s32 %r63, %r39, %r59, %r62;
mul.wide.u32 %rd7, %r63, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.ge.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd6], %f4;
mov.u32 %r65, %nctaid.x;
mad.lo.s32 %r66, %r65, %r47, %r66;
setp.lt.u32	%p3, %r66, %r30;
@%p3 bra BB103_2;

BB103_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot104[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot104;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r32, %r33}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r34, %r35}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r36, %r37}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB104_2;

BB104_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB104_1;

BB104_2:
mov.u32 %r40, %ntid.x;
mov.u32 %r41, %ctaid.x;
mov.u32 %r42, %tid.x;
mad.lo.s32 %r65, %r40, %r41, %r42;
setp.ge.u32	%p3, %r65, %r30;
@%p3 bra BB104_7;

cvta.to.global.u64 %rd4, %rd10;
ld.local.u32 %r43, [%rd1+208];
add.s32 %r9, %r43, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd5, %rd16;
mul.wide.s32 %rd17, %r43, 4;
add.s64 %rd6, %rd1, %rd17;

BB104_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mul.hi.u32 %r12, %r11, %r34;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB104_6;

BB104_5:
mov.u32 %r14, %r64;
mov.u32 %r13, %r59;
ld.local.u32 %r46, [%rd22+4];
rem.u32 %r47, %r14, %r46;
ld.local.u32 %r48, [%rd22+104];
mad.lo.s32 %r68, %r48, %r47, %r68;
div.u32 %r17, %r14, %r46;
add.s64 %rd22, %rd22, -4;
add.s32 %r18, %r13, -1;
setp.gt.s32	%p5, %r18, 0;
mov.u32 %r59, %r18;
mov.u32 %r63, %r17;
mov.u32 %r64, %r17;
mov.u32 %r67, %r68;
@%p5 bra BB104_5;

BB104_6:
add.s32 %r49, %r12, %r11;
shr.u32 %r50, %r49, %r35;
mul.lo.s32 %r51, %r50, %r37;
sub.s32 %r52, %r11, %r51;
mul.lo.s32 %r53, %r52, %r33;
mad.lo.s32 %r54, %r32, %r50, %r53;
mul.wide.u32 %rd18, %r54, 4;
add.s64 %rd19, %rd4, %rd18;
mad.lo.s32 %r55, %r10, %r63, %r67;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.ge.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd19], %f4;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r40, %r11;
setp.lt.u32	%p7, %r65, %r30;
@%p7 bra BB104_4;

BB104_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot105[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot105;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB105_2;

BB105_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB105_1;

BB105_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB105_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB105_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB105_6;

BB105_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB105_5;

BB105_6:
ld.local.u32 %r30, [%rd1+108];
mad.lo.s32 %r31, %r30, %r38, %r42;
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd17, %rd16;
mul.wide.u32 %rd18, %r31, 4;
add.s64 %rd19, %rd17, %rd18;
mul.lo.s32 %r32, %r8, %r18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd4, %rd20;
ld.global.f32 %f3, [%rd21];
setp.ge.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd19], %f4;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB105_4;

BB105_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot106[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot106;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB106_2;

BB106_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB106_1;

BB106_2:
mov.u32 %r39, %ntid.x;
mov.u32 %r40, %ctaid.x;
mov.u32 %r41, %tid.x;
mad.lo.s32 %r65, %r39, %r40, %r41;
setp.ge.u32	%p3, %r65, %r29;
@%p3 bra BB106_7;

ld.local.u32 %r42, [%rd1+208];
add.s32 %r9, %r42, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd4, %rd16;
cvta.to.global.u64 %rd5, %rd10;
mul.wide.s32 %rd17, %r42, 4;
add.s64 %rd6, %rd1, %rd17;

BB106_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB106_6;

BB106_5:
mov.u32 %r13, %r64;
mov.u32 %r12, %r59;
ld.local.u32 %r45, [%rd22+4];
rem.u32 %r46, %r13, %r45;
ld.local.u32 %r47, [%rd22+104];
mad.lo.s32 %r68, %r47, %r46, %r68;
div.u32 %r16, %r13, %r45;
add.s64 %rd22, %rd22, -4;
add.s32 %r17, %r12, -1;
setp.gt.s32	%p5, %r17, 0;
mov.u32 %r59, %r17;
mov.u32 %r63, %r16;
mov.u32 %r64, %r16;
mov.u32 %r67, %r68;
@%p5 bra BB106_5;

BB106_6:
mad.lo.s32 %r48, %r10, %r63, %r67;
mul.wide.u32 %rd18, %r48, 4;
add.s64 %rd19, %rd4, %rd18;
mul.hi.u32 %r49, %r11, %r33;
add.s32 %r50, %r49, %r11;
shr.u32 %r51, %r50, %r34;
mul.lo.s32 %r52, %r51, %r36;
sub.s32 %r53, %r11, %r52;
mul.lo.s32 %r54, %r53, %r32;
mad.lo.s32 %r55, %r31, %r51, %r54;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.ge.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd19], %f4;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r39, %r11;
setp.lt.u32	%p7, %r65, %r29;
@%p7 bra BB106_4;

BB106_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot107[432];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<12>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<72>;
.reg .b64 %rd<39>;


mov.u64 %rd38, __local_depot107;
cvta.local.u64 %SP, %rd38;
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd18, %SP, 216;
cvta.to.local.u64 %rd2, %rd18;
add.u64 %rd19, %SP, 0;
cvta.to.local.u64 %rd3, %rd19;
mov.u32 %r50, 0;
mov.pred %p1, 0;
@%p1 bra BB107_2;

BB107_1:
mul.wide.s32 %rd20, %r50, 8;
add.s64 %rd21, %rd4, %rd20;
ld.param.u64 %rd22, [%rd21];
add.s64 %rd23, %rd2, %rd20;
st.local.u64 [%rd23], %rd22;
add.s32 %r50, %r50, 1;
setp.lt.u32	%p2, %r50, 27;
@%p2 bra BB107_1;

BB107_2:
mov.u32 %r51, 0;
@%p1 bra BB107_4;

BB107_3:
mul.wide.s32 %rd24, %r51, 8;
add.s64 %rd25, %rd1, %rd24;
ld.param.u64 %rd26, [%rd25];
add.s64 %rd27, %rd3, %rd24;
st.local.u64 [%rd27], %rd26;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p4, %r51, 27;
@%p4 bra BB107_3;

BB107_4:
mov.u32 %r32, %ntid.x;
mov.u32 %r33, %ctaid.x;
mov.u32 %r34, %tid.x;
mad.lo.s32 %r64, %r32, %r33, %r34;
setp.ge.u32	%p5, %r64, %r29;
@%p5 bra BB107_11;

ld.local.u32 %r35, [%rd2+208];
add.s32 %r6, %r35, -1;
ld.local.u32 %r7, [%rd2+108];
ld.local.u64 %rd28, [%rd2];
cvta.to.global.u64 %rd8, %rd28;
ld.local.u32 %r36, [%rd3+208];
add.s32 %r8, %r36, -1;
ld.local.u32 %r9, [%rd3+108];
ld.local.u64 %rd29, [%rd3];
cvta.to.global.u64 %rd9, %rd29;
mul.wide.s32 %rd30, %r35, 4;
add.s64 %rd10, %rd2, %rd30;
mul.wide.s32 %rd31, %r36, 4;
add.s64 %rd11, %rd3, %rd31;

BB107_6:
mov.u32 %r54, %r64;
mov.u32 %r10, %r54;
mov.u64 %rd36, %rd10;
mov.u32 %r38, 0;
mov.u32 %r71, %r38;
setp.lt.s32	%p6, %r6, 1;
mov.u32 %r52, %r6;
mov.u32 %r62, %r10;
mov.u32 %r63, %r10;
mov.u32 %r70, %r38;
@%p6 bra BB107_8;

BB107_7:
mov.u32 %r12, %r63;
mov.u32 %r11, %r52;
ld.local.u32 %r39, [%rd36+4];
rem.u32 %r40, %r12, %r39;
ld.local.u32 %r41, [%rd36+104];
mad.lo.s32 %r71, %r41, %r40, %r71;
div.u32 %r15, %r12, %r39;
add.s64 %rd36, %rd36, -4;
add.s32 %r16, %r11, -1;
setp.gt.s32	%p7, %r16, 0;
mov.u32 %r52, %r16;
mov.u32 %r62, %r15;
mov.u32 %r63, %r15;
mov.u32 %r65, %r71;
mov.u32 %r70, %r65;
@%p7 bra BB107_7;

BB107_8:
mov.u32 %r18, %r70;
mov.u64 %rd37, %rd11;
mad.lo.s32 %r19, %r7, %r62, %r18;
mov.u32 %r69, %r38;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r53, %r8;
mov.u32 %r61, %r10;
mov.u32 %r60, %r10;
mov.u32 %r68, %r38;
@%p8 bra BB107_10;

BB107_9:
mov.u32 %r20, %r53;
ld.local.u32 %r44, [%rd37+4];
rem.u32 %r45, %r61, %r44;
ld.local.u32 %r46, [%rd37+104];
mad.lo.s32 %r69, %r46, %r45, %r69;
div.u32 %r61, %r61, %r44;
add.s64 %rd37, %rd37, -4;
add.s32 %r25, %r20, -1;
setp.gt.s32	%p9, %r25, 0;
mov.u32 %r53, %r25;
mov.u32 %r60, %r61;
mov.u32 %r68, %r69;
@%p9 bra BB107_9;

BB107_10:
mul.wide.u32 %rd32, %r19, 4;
add.s64 %rd33, %rd8, %rd32;
mad.lo.s32 %r47, %r9, %r60, %r68;
mul.wide.u32 %rd34, %r47, 4;
add.s64 %rd35, %rd9, %rd34;
ld.global.f32 %f3, [%rd35];
setp.ge.f32	%p10, %f3, %f2;
selp.u16	%rs1, 1, 0, %p10;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd33], %f4;
mov.u32 %r49, %nctaid.x;
mad.lo.s32 %r64, %r49, %r32, %r10;
setp.lt.u32	%p11, %r64, %r29;
@%p11 bra BB107_6;

BB107_11:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u64 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<5>;
.reg .b64 %rd<25>;


ld.param.u64 %rd11, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u64 %rd13, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd12, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u64 %rd14, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %ntid.x;
cvt.u64.u32	%rd1, %r2;
mul.wide.u32 %rd15, %r2, %r1;
mov.u32 %r3, %tid.x;
cvt.u64.u32	%rd16, %r3;
add.s64 %rd24, %rd15, %rd16;
setp.ge.u64	%p1, %rd24, %rd14;
@%p1 bra BB108_3;

cvta.to.global.u64 %rd3, %rd10;
cvta.to.global.u64 %rd5, %rd12;
mov.u32 %r4, %nctaid.x;
cvt.u64.u32	%rd17, %r4;
mul.lo.s64 %rd7, %rd17, %rd1;

BB108_2:
mul.lo.s64 %rd18, %rd24, %rd11;
shl.b64 %rd19, %rd18, 2;
add.s64 %rd20, %rd3, %rd19;
mul.lo.s64 %rd21, %rd24, %rd13;
shl.b64 %rd22, %rd21, 2;
add.s64 %rd23, %rd5, %rd22;
ld.global.f32 %f3, [%rd23];
setp.ge.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd20], %f4;
add.s64 %rd24, %rd7, %rd24;
setp.lt.u64	%p3, %rd24, %rd14;
@%p3 bra BB108_2;

BB108_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[416],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[416],
.param .u64 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot109[832];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<32>;
.reg .b64 %rd<113>;


mov.u64 %rd112, __local_depot109;
cvta.local.u64 %SP, %rd112;
ld.param.u64 %rd49, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorGEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorGEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd50, %SP, 416;
cvta.to.local.u64 %rd2, %rd50;
add.u64 %rd51, %SP, 0;
cvta.to.local.u64 %rd3, %rd51;
mov.u32 %r28, 0;
mov.pred %p1, 0;
@%p1 bra BB109_2;

BB109_1:
mul.wide.s32 %rd52, %r28, 8;
add.s64 %rd53, %rd4, %rd52;
ld.param.u64 %rd54, [%rd53];
add.s64 %rd55, %rd2, %rd52;
st.local.u64 [%rd55], %rd54;
add.s32 %r28, %r28, 1;
setp.lt.u32	%p2, %r28, 52;
@%p2 bra BB109_1;

BB109_2:
mov.u32 %r29, 0;
@%p1 bra BB109_4;

BB109_3:
mul.wide.s32 %rd56, %r29, 8;
add.s64 %rd57, %rd1, %rd56;
ld.param.u64 %rd58, [%rd57];
add.s64 %rd59, %rd3, %rd56;
st.local.u64 [%rd59], %rd58;
add.s32 %r29, %r29, 1;
setp.lt.u32	%p4, %r29, 52;
@%p4 bra BB109_3;

BB109_4:
mov.u32 %r13, %ctaid.x;
mov.u32 %r14, %ntid.x;
mul.wide.u32 %rd60, %r14, %r13;
mov.u32 %r15, %tid.x;
cvt.u64.u32	%rd61, %r15;
add.s64 %rd104, %rd60, %rd61;
setp.ge.u64	%p5, %rd104, %rd49;
@%p5 bra BB109_17;

ld.local.u32 %r16, [%rd2+408];
add.s32 %r5, %r16, -1;
ld.local.u64 %rd9, [%rd2+208];
ld.local.u64 %rd62, [%rd2];
cvta.to.global.u64 %rd10, %rd62;
ld.local.u32 %r17, [%rd3+408];
add.s32 %r6, %r17, -1;
ld.local.u64 %rd11, [%rd3+208];
ld.local.u64 %rd63, [%rd3];
cvta.to.global.u64 %rd12, %rd63;
mul.wide.s32 %rd64, %r16, 8;
add.s64 %rd13, %rd2, %rd64;
mul.wide.s32 %rd65, %r17, 8;
add.s64 %rd14, %rd3, %rd65;

BB109_6:
mov.u64 %rd90, %rd104;
mov.u64 %rd15, %rd90;
mov.u64 %rd86, %rd13;
mov.u64 %rd67, 0;
mov.u64 %rd111, %rd67;
setp.lt.s32	%p6, %r5, 1;
mov.u32 %r30, %r5;
mov.u64 %rd101, %rd15;
mov.u64 %rd102, %rd15;
mov.u64 %rd110, %rd67;
@%p6 bra BB109_11;

BB109_7:
mov.u64 %rd18, %rd102;
mov.u32 %r7, %r30;
ld.local.u64 %rd21, [%rd86];
or.b64 %rd68, %rd18, %rd21;
and.b64 %rd69, %rd68, -4294967296;
setp.eq.s64	%p7, %rd69, 0;
@%p7 bra BB109_9;
bra.uni BB109_8;

BB109_9:
cvt.u32.u64	%r18, %rd21;
cvt.u32.u64	%r19, %rd18;
div.u32 %r20, %r19, %r18;
rem.u32 %r21, %r19, %r18;
cvt.u64.u32	%rd103, %r20;
cvt.u64.u32	%rd87, %r21;
bra.uni BB109_10;

BB109_8:
div.u64 %rd103, %rd18, %rd21;
rem.u64 %rd87, %rd18, %rd21;

BB109_10:
mov.u64 %rd26, %rd103;
ld.local.u64 %rd70, [%rd86+200];
mul.lo.s64 %rd71, %rd70, %rd87;
add.s64 %rd111, %rd71, %rd111;
add.s64 %rd86, %rd86, -8;
add.s32 %r8, %r7, -1;
setp.gt.s32	%p8, %r8, 0;
mov.u32 %r30, %r8;
mov.u64 %rd101, %rd26;
mov.u64 %rd102, %rd26;
mov.u64 %rd105, %rd111;
mov.u64 %rd110, %rd105;
@%p8 bra BB109_7;

BB109_11:
mov.u64 %rd31, %rd110;
mov.u64 %rd88, %rd14;
mul.lo.s64 %rd74, %rd9, %rd101;
add.s64 %rd33, %rd74, %rd31;
mov.u64 %rd109, %rd67;
setp.lt.s32	%p9, %r6, 1;
mov.u32 %r31, %r6;
mov.u64 %rd99, %rd15;
mov.u64 %rd98, %rd15;
mov.u64 %rd108, %rd67;
@%p9 bra BB109_16;

BB109_12:
mov.u32 %r9, %r31;
ld.local.u64 %rd37, [%rd88];
or.b64 %rd75, %rd99, %rd37;
and.b64 %rd76, %rd75, -4294967296;
setp.eq.s64	%p10, %rd76, 0;
@%p10 bra BB109_14;
bra.uni BB109_13;

BB109_14:
cvt.u32.u64	%r22, %rd37;
cvt.u32.u64	%r23, %rd99;
div.u32 %r24, %r23, %r22;
rem.u32 %r25, %r23, %r22;
cvt.u64.u32	%rd100, %r24;
cvt.u64.u32	%rd89, %r25;
bra.uni BB109_15;

BB109_13:
div.u64 %rd100, %rd99, %rd37;
rem.u64 %rd89, %rd99, %rd37;

BB109_15:
mov.u64 %rd99, %rd100;
ld.local.u64 %rd77, [%rd88+200];
mul.lo.s64 %rd78, %rd77, %rd89;
add.s64 %rd109, %rd78, %rd109;
add.s64 %rd88, %rd88, -8;
add.s32 %r10, %r9, -1;
setp.gt.s32	%p11, %r10, 0;
mov.u32 %r31, %r10;
mov.u64 %rd98, %rd99;
mov.u64 %rd108, %rd109;
@%p11 bra BB109_12;

BB109_16:
shl.b64 %rd79, %rd33, 2;
add.s64 %rd80, %rd10, %rd79;
mul.lo.s64 %rd81, %rd11, %rd98;
add.s64 %rd82, %rd81, %rd108;
shl.b64 %rd83, %rd82, 2;
add.s64 %rd84, %rd12, %rd83;
ld.global.f32 %f3, [%rd84];
setp.ge.f32	%p12, %f3, %f2;
selp.u16	%rs1, 1, 0, %p12;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd80], %f4;
mov.u32 %r26, %nctaid.x;
mul.wide.u32 %rd85, %r26, %r14;
add.s64 %rd104, %rd85, %rd15;
setp.lt.u64	%p13, %rd104, %rd49;
@%p13 bra BB109_6;

BB109_17:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<18>;
.reg .f32 %f<5>;
.reg .b32 %r<17>;
.reg .b64 %rd<9>;


ld.param.u32 %r8, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r9, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r10, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r11, %ctaid.x;
mov.u32 %r12, %tid.x;
mad.lo.s32 %r16, %r1, %r11, %r12;
setp.ge.u32	%p1, %r16, %r10;
@%p1 bra BB110_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;
mov.u32 %r13, %nctaid.x;
mul.lo.s32 %r5, %r13, %r1;

BB110_2:
mul.lo.s32 %r14, %r16, %r8;
mul.wide.u32 %rd5, %r14, 4;
add.s64 %rd6, %rd1, %rd5;
mul.lo.s32 %r15, %r16, %r9;
mul.wide.u32 %rd7, %r15, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.eq.f32	%p2, %f3, %f2;
selp.u16	%rs17, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs17;
st.global.f32 [%rd6], %f4;
add.s32 %r16, %r5, %r16;
setp.lt.u32	%p3, %r16, %r10;
@%p3 bra BB110_2;

BB110_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.u32 %r12, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r4, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r4, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB111_3;

cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r4;
cvta.to.global.u64 %rd2, %rd4;

BB111_2:
mul.lo.s32 %r33, %r41, %r12;
mul.wide.u32 %rd5, %r33, 4;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r34, %r41, %r24;
add.s32 %r35, %r34, %r41;
shr.u32 %r36, %r35, %r25;
mul.lo.s32 %r37, %r36, %r27;
sub.s32 %r38, %r41, %r37;
mul.lo.s32 %r39, %r38, %r23;
mad.lo.s32 %r40, %r22, %r36, %r39;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.eq.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd6], %f4;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB111_2;

BB111_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot112[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot112;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB112_2;

BB112_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB112_1;

BB112_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB112_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB112_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB112_6;

BB112_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB112_5;

BB112_6:
mul.lo.s32 %r30, %r8, %r18;
mul.wide.u32 %rd16, %r30, 4;
add.s64 %rd17, %rd4, %rd16;
ld.local.u32 %r31, [%rd1+108];
mad.lo.s32 %r32, %r31, %r38, %r42;
ld.local.u64 %rd18, [%rd1];
cvta.to.global.u64 %rd19, %rd18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd19, %rd20;
ld.global.f32 %f3, [%rd21];
setp.eq.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd17], %f4;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB112_4;

BB112_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r20, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r1, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB113_3;

cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r1;
cvta.to.global.u64 %rd2, %rd3;

BB113_2:
mul.hi.u32 %r33, %r41, %r24;
add.s32 %r34, %r33, %r41;
shr.u32 %r35, %r34, %r25;
mul.lo.s32 %r36, %r35, %r27;
sub.s32 %r37, %r41, %r36;
mul.lo.s32 %r38, %r37, %r23;
mad.lo.s32 %r39, %r22, %r35, %r38;
mul.wide.u32 %rd5, %r39, 4;
add.s64 %rd6, %rd2, %rd5;
mul.lo.s32 %r40, %r41, %r20;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd1, %rd7;
ld.global.f32 %f3, [%rd8];
setp.eq.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd6], %f4;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB113_2;

BB113_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<67>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r39, %r40}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r41, %r42}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r43, %r44}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r47, %ntid.x;
mov.u32 %r48, %ctaid.x;
mov.u32 %r49, %tid.x;
mad.lo.s32 %r66, %r47, %r48, %r49;
setp.ge.u32	%p1, %r66, %r30;
@%p1 bra BB114_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;

BB114_2:
mul.hi.u32 %r50, %r66, %r33;
add.s32 %r51, %r50, %r66;
shr.u32 %r52, %r51, %r34;
mul.lo.s32 %r53, %r52, %r36;
sub.s32 %r54, %r66, %r53;
mul.lo.s32 %r55, %r54, %r32;
mad.lo.s32 %r56, %r31, %r52, %r55;
mul.wide.u32 %rd5, %r56, 4;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r57, %r66, %r41;
add.s32 %r58, %r57, %r66;
shr.u32 %r59, %r58, %r42;
mul.lo.s32 %r60, %r59, %r44;
sub.s32 %r61, %r66, %r60;
mul.lo.s32 %r62, %r61, %r40;
mad.lo.s32 %r63, %r39, %r59, %r62;
mul.wide.u32 %rd7, %r63, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.eq.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd6], %f4;
mov.u32 %r65, %nctaid.x;
mad.lo.s32 %r66, %r65, %r47, %r66;
setp.lt.u32	%p3, %r66, %r30;
@%p3 bra BB114_2;

BB114_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot115[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot115;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r32, %r33}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r34, %r35}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r36, %r37}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB115_2;

BB115_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB115_1;

BB115_2:
mov.u32 %r40, %ntid.x;
mov.u32 %r41, %ctaid.x;
mov.u32 %r42, %tid.x;
mad.lo.s32 %r65, %r40, %r41, %r42;
setp.ge.u32	%p3, %r65, %r30;
@%p3 bra BB115_7;

cvta.to.global.u64 %rd4, %rd10;
ld.local.u32 %r43, [%rd1+208];
add.s32 %r9, %r43, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd5, %rd16;
mul.wide.s32 %rd17, %r43, 4;
add.s64 %rd6, %rd1, %rd17;

BB115_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mul.hi.u32 %r12, %r11, %r34;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB115_6;

BB115_5:
mov.u32 %r14, %r64;
mov.u32 %r13, %r59;
ld.local.u32 %r46, [%rd22+4];
rem.u32 %r47, %r14, %r46;
ld.local.u32 %r48, [%rd22+104];
mad.lo.s32 %r68, %r48, %r47, %r68;
div.u32 %r17, %r14, %r46;
add.s64 %rd22, %rd22, -4;
add.s32 %r18, %r13, -1;
setp.gt.s32	%p5, %r18, 0;
mov.u32 %r59, %r18;
mov.u32 %r63, %r17;
mov.u32 %r64, %r17;
mov.u32 %r67, %r68;
@%p5 bra BB115_5;

BB115_6:
add.s32 %r49, %r12, %r11;
shr.u32 %r50, %r49, %r35;
mul.lo.s32 %r51, %r50, %r37;
sub.s32 %r52, %r11, %r51;
mul.lo.s32 %r53, %r52, %r33;
mad.lo.s32 %r54, %r32, %r50, %r53;
mul.wide.u32 %rd18, %r54, 4;
add.s64 %rd19, %rd4, %rd18;
mad.lo.s32 %r55, %r10, %r63, %r67;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.eq.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd19], %f4;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r40, %r11;
setp.lt.u32	%p7, %r65, %r30;
@%p7 bra BB115_4;

BB115_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot116[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot116;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB116_2;

BB116_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB116_1;

BB116_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB116_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB116_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB116_6;

BB116_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB116_5;

BB116_6:
ld.local.u32 %r30, [%rd1+108];
mad.lo.s32 %r31, %r30, %r38, %r42;
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd17, %rd16;
mul.wide.u32 %rd18, %r31, 4;
add.s64 %rd19, %rd17, %rd18;
mul.lo.s32 %r32, %r8, %r18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd4, %rd20;
ld.global.f32 %f3, [%rd21];
setp.eq.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd19], %f4;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB116_4;

BB116_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot117[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot117;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB117_2;

BB117_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB117_1;

BB117_2:
mov.u32 %r39, %ntid.x;
mov.u32 %r40, %ctaid.x;
mov.u32 %r41, %tid.x;
mad.lo.s32 %r65, %r39, %r40, %r41;
setp.ge.u32	%p3, %r65, %r29;
@%p3 bra BB117_7;

ld.local.u32 %r42, [%rd1+208];
add.s32 %r9, %r42, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd4, %rd16;
cvta.to.global.u64 %rd5, %rd10;
mul.wide.s32 %rd17, %r42, 4;
add.s64 %rd6, %rd1, %rd17;

BB117_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB117_6;

BB117_5:
mov.u32 %r13, %r64;
mov.u32 %r12, %r59;
ld.local.u32 %r45, [%rd22+4];
rem.u32 %r46, %r13, %r45;
ld.local.u32 %r47, [%rd22+104];
mad.lo.s32 %r68, %r47, %r46, %r68;
div.u32 %r16, %r13, %r45;
add.s64 %rd22, %rd22, -4;
add.s32 %r17, %r12, -1;
setp.gt.s32	%p5, %r17, 0;
mov.u32 %r59, %r17;
mov.u32 %r63, %r16;
mov.u32 %r64, %r16;
mov.u32 %r67, %r68;
@%p5 bra BB117_5;

BB117_6:
mad.lo.s32 %r48, %r10, %r63, %r67;
mul.wide.u32 %rd18, %r48, 4;
add.s64 %rd19, %rd4, %rd18;
mul.hi.u32 %r49, %r11, %r33;
add.s32 %r50, %r49, %r11;
shr.u32 %r51, %r50, %r34;
mul.lo.s32 %r52, %r51, %r36;
sub.s32 %r53, %r11, %r52;
mul.lo.s32 %r54, %r53, %r32;
mad.lo.s32 %r55, %r31, %r51, %r54;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.eq.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd19], %f4;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r39, %r11;
setp.lt.u32	%p7, %r65, %r29;
@%p7 bra BB117_4;

BB117_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot118[432];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<12>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<72>;
.reg .b64 %rd<39>;


mov.u64 %rd38, __local_depot118;
cvta.local.u64 %SP, %rd38;
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd18, %SP, 216;
cvta.to.local.u64 %rd2, %rd18;
add.u64 %rd19, %SP, 0;
cvta.to.local.u64 %rd3, %rd19;
mov.u32 %r50, 0;
mov.pred %p1, 0;
@%p1 bra BB118_2;

BB118_1:
mul.wide.s32 %rd20, %r50, 8;
add.s64 %rd21, %rd4, %rd20;
ld.param.u64 %rd22, [%rd21];
add.s64 %rd23, %rd2, %rd20;
st.local.u64 [%rd23], %rd22;
add.s32 %r50, %r50, 1;
setp.lt.u32	%p2, %r50, 27;
@%p2 bra BB118_1;

BB118_2:
mov.u32 %r51, 0;
@%p1 bra BB118_4;

BB118_3:
mul.wide.s32 %rd24, %r51, 8;
add.s64 %rd25, %rd1, %rd24;
ld.param.u64 %rd26, [%rd25];
add.s64 %rd27, %rd3, %rd24;
st.local.u64 [%rd27], %rd26;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p4, %r51, 27;
@%p4 bra BB118_3;

BB118_4:
mov.u32 %r32, %ntid.x;
mov.u32 %r33, %ctaid.x;
mov.u32 %r34, %tid.x;
mad.lo.s32 %r64, %r32, %r33, %r34;
setp.ge.u32	%p5, %r64, %r29;
@%p5 bra BB118_11;

ld.local.u32 %r35, [%rd2+208];
add.s32 %r6, %r35, -1;
ld.local.u32 %r7, [%rd2+108];
ld.local.u64 %rd28, [%rd2];
cvta.to.global.u64 %rd8, %rd28;
ld.local.u32 %r36, [%rd3+208];
add.s32 %r8, %r36, -1;
ld.local.u32 %r9, [%rd3+108];
ld.local.u64 %rd29, [%rd3];
cvta.to.global.u64 %rd9, %rd29;
mul.wide.s32 %rd30, %r35, 4;
add.s64 %rd10, %rd2, %rd30;
mul.wide.s32 %rd31, %r36, 4;
add.s64 %rd11, %rd3, %rd31;

BB118_6:
mov.u32 %r54, %r64;
mov.u32 %r10, %r54;
mov.u64 %rd36, %rd10;
mov.u32 %r38, 0;
mov.u32 %r71, %r38;
setp.lt.s32	%p6, %r6, 1;
mov.u32 %r52, %r6;
mov.u32 %r62, %r10;
mov.u32 %r63, %r10;
mov.u32 %r70, %r38;
@%p6 bra BB118_8;

BB118_7:
mov.u32 %r12, %r63;
mov.u32 %r11, %r52;
ld.local.u32 %r39, [%rd36+4];
rem.u32 %r40, %r12, %r39;
ld.local.u32 %r41, [%rd36+104];
mad.lo.s32 %r71, %r41, %r40, %r71;
div.u32 %r15, %r12, %r39;
add.s64 %rd36, %rd36, -4;
add.s32 %r16, %r11, -1;
setp.gt.s32	%p7, %r16, 0;
mov.u32 %r52, %r16;
mov.u32 %r62, %r15;
mov.u32 %r63, %r15;
mov.u32 %r65, %r71;
mov.u32 %r70, %r65;
@%p7 bra BB118_7;

BB118_8:
mov.u32 %r18, %r70;
mov.u64 %rd37, %rd11;
mad.lo.s32 %r19, %r7, %r62, %r18;
mov.u32 %r69, %r38;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r53, %r8;
mov.u32 %r61, %r10;
mov.u32 %r60, %r10;
mov.u32 %r68, %r38;
@%p8 bra BB118_10;

BB118_9:
mov.u32 %r20, %r53;
ld.local.u32 %r44, [%rd37+4];
rem.u32 %r45, %r61, %r44;
ld.local.u32 %r46, [%rd37+104];
mad.lo.s32 %r69, %r46, %r45, %r69;
div.u32 %r61, %r61, %r44;
add.s64 %rd37, %rd37, -4;
add.s32 %r25, %r20, -1;
setp.gt.s32	%p9, %r25, 0;
mov.u32 %r53, %r25;
mov.u32 %r60, %r61;
mov.u32 %r68, %r69;
@%p9 bra BB118_9;

BB118_10:
mul.wide.u32 %rd32, %r19, 4;
add.s64 %rd33, %rd8, %rd32;
mad.lo.s32 %r47, %r9, %r60, %r68;
mul.wide.u32 %rd34, %r47, 4;
add.s64 %rd35, %rd9, %rd34;
ld.global.f32 %f3, [%rd35];
setp.eq.f32	%p10, %f3, %f2;
selp.u16	%rs1, 1, 0, %p10;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd33], %f4;
mov.u32 %r49, %nctaid.x;
mad.lo.s32 %r64, %r49, %r32, %r10;
setp.lt.u32	%p11, %r64, %r29;
@%p11 bra BB118_6;

BB118_11:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u64 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<5>;
.reg .b64 %rd<25>;


ld.param.u64 %rd11, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u64 %rd13, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd12, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u64 %rd14, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %ntid.x;
cvt.u64.u32	%rd1, %r2;
mul.wide.u32 %rd15, %r2, %r1;
mov.u32 %r3, %tid.x;
cvt.u64.u32	%rd16, %r3;
add.s64 %rd24, %rd15, %rd16;
setp.ge.u64	%p1, %rd24, %rd14;
@%p1 bra BB119_3;

cvta.to.global.u64 %rd3, %rd10;
cvta.to.global.u64 %rd5, %rd12;
mov.u32 %r4, %nctaid.x;
cvt.u64.u32	%rd17, %r4;
mul.lo.s64 %rd7, %rd17, %rd1;

BB119_2:
mul.lo.s64 %rd18, %rd24, %rd11;
shl.b64 %rd19, %rd18, 2;
add.s64 %rd20, %rd3, %rd19;
mul.lo.s64 %rd21, %rd24, %rd13;
shl.b64 %rd22, %rd21, 2;
add.s64 %rd23, %rd5, %rd22;
ld.global.f32 %f3, [%rd23];
setp.eq.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd20], %f4;
add.s64 %rd24, %rd7, %rd24;
setp.lt.u64	%p3, %rd24, %rd14;
@%p3 bra BB119_2;

BB119_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[416],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[416],
.param .u64 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot120[832];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<32>;
.reg .b64 %rd<113>;


mov.u64 %rd112, __local_depot120;
cvta.local.u64 %SP, %rd112;
ld.param.u64 %rd49, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorEQValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorEQValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd50, %SP, 416;
cvta.to.local.u64 %rd2, %rd50;
add.u64 %rd51, %SP, 0;
cvta.to.local.u64 %rd3, %rd51;
mov.u32 %r28, 0;
mov.pred %p1, 0;
@%p1 bra BB120_2;

BB120_1:
mul.wide.s32 %rd52, %r28, 8;
add.s64 %rd53, %rd4, %rd52;
ld.param.u64 %rd54, [%rd53];
add.s64 %rd55, %rd2, %rd52;
st.local.u64 [%rd55], %rd54;
add.s32 %r28, %r28, 1;
setp.lt.u32	%p2, %r28, 52;
@%p2 bra BB120_1;

BB120_2:
mov.u32 %r29, 0;
@%p1 bra BB120_4;

BB120_3:
mul.wide.s32 %rd56, %r29, 8;
add.s64 %rd57, %rd1, %rd56;
ld.param.u64 %rd58, [%rd57];
add.s64 %rd59, %rd3, %rd56;
st.local.u64 [%rd59], %rd58;
add.s32 %r29, %r29, 1;
setp.lt.u32	%p4, %r29, 52;
@%p4 bra BB120_3;

BB120_4:
mov.u32 %r13, %ctaid.x;
mov.u32 %r14, %ntid.x;
mul.wide.u32 %rd60, %r14, %r13;
mov.u32 %r15, %tid.x;
cvt.u64.u32	%rd61, %r15;
add.s64 %rd104, %rd60, %rd61;
setp.ge.u64	%p5, %rd104, %rd49;
@%p5 bra BB120_17;

ld.local.u32 %r16, [%rd2+408];
add.s32 %r5, %r16, -1;
ld.local.u64 %rd9, [%rd2+208];
ld.local.u64 %rd62, [%rd2];
cvta.to.global.u64 %rd10, %rd62;
ld.local.u32 %r17, [%rd3+408];
add.s32 %r6, %r17, -1;
ld.local.u64 %rd11, [%rd3+208];
ld.local.u64 %rd63, [%rd3];
cvta.to.global.u64 %rd12, %rd63;
mul.wide.s32 %rd64, %r16, 8;
add.s64 %rd13, %rd2, %rd64;
mul.wide.s32 %rd65, %r17, 8;
add.s64 %rd14, %rd3, %rd65;

BB120_6:
mov.u64 %rd90, %rd104;
mov.u64 %rd15, %rd90;
mov.u64 %rd86, %rd13;
mov.u64 %rd67, 0;
mov.u64 %rd111, %rd67;
setp.lt.s32	%p6, %r5, 1;
mov.u32 %r30, %r5;
mov.u64 %rd101, %rd15;
mov.u64 %rd102, %rd15;
mov.u64 %rd110, %rd67;
@%p6 bra BB120_11;

BB120_7:
mov.u64 %rd18, %rd102;
mov.u32 %r7, %r30;
ld.local.u64 %rd21, [%rd86];
or.b64 %rd68, %rd18, %rd21;
and.b64 %rd69, %rd68, -4294967296;
setp.eq.s64	%p7, %rd69, 0;
@%p7 bra BB120_9;
bra.uni BB120_8;

BB120_9:
cvt.u32.u64	%r18, %rd21;
cvt.u32.u64	%r19, %rd18;
div.u32 %r20, %r19, %r18;
rem.u32 %r21, %r19, %r18;
cvt.u64.u32	%rd103, %r20;
cvt.u64.u32	%rd87, %r21;
bra.uni BB120_10;

BB120_8:
div.u64 %rd103, %rd18, %rd21;
rem.u64 %rd87, %rd18, %rd21;

BB120_10:
mov.u64 %rd26, %rd103;
ld.local.u64 %rd70, [%rd86+200];
mul.lo.s64 %rd71, %rd70, %rd87;
add.s64 %rd111, %rd71, %rd111;
add.s64 %rd86, %rd86, -8;
add.s32 %r8, %r7, -1;
setp.gt.s32	%p8, %r8, 0;
mov.u32 %r30, %r8;
mov.u64 %rd101, %rd26;
mov.u64 %rd102, %rd26;
mov.u64 %rd105, %rd111;
mov.u64 %rd110, %rd105;
@%p8 bra BB120_7;

BB120_11:
mov.u64 %rd31, %rd110;
mov.u64 %rd88, %rd14;
mul.lo.s64 %rd74, %rd9, %rd101;
add.s64 %rd33, %rd74, %rd31;
mov.u64 %rd109, %rd67;
setp.lt.s32	%p9, %r6, 1;
mov.u32 %r31, %r6;
mov.u64 %rd99, %rd15;
mov.u64 %rd98, %rd15;
mov.u64 %rd108, %rd67;
@%p9 bra BB120_16;

BB120_12:
mov.u32 %r9, %r31;
ld.local.u64 %rd37, [%rd88];
or.b64 %rd75, %rd99, %rd37;
and.b64 %rd76, %rd75, -4294967296;
setp.eq.s64	%p10, %rd76, 0;
@%p10 bra BB120_14;
bra.uni BB120_13;

BB120_14:
cvt.u32.u64	%r22, %rd37;
cvt.u32.u64	%r23, %rd99;
div.u32 %r24, %r23, %r22;
rem.u32 %r25, %r23, %r22;
cvt.u64.u32	%rd100, %r24;
cvt.u64.u32	%rd89, %r25;
bra.uni BB120_15;

BB120_13:
div.u64 %rd100, %rd99, %rd37;
rem.u64 %rd89, %rd99, %rd37;

BB120_15:
mov.u64 %rd99, %rd100;
ld.local.u64 %rd77, [%rd88+200];
mul.lo.s64 %rd78, %rd77, %rd89;
add.s64 %rd109, %rd78, %rd109;
add.s64 %rd88, %rd88, -8;
add.s32 %r10, %r9, -1;
setp.gt.s32	%p11, %r10, 0;
mov.u32 %r31, %r10;
mov.u64 %rd98, %rd99;
mov.u64 %rd108, %rd109;
@%p11 bra BB120_12;

BB120_16:
shl.b64 %rd79, %rd33, 2;
add.s64 %rd80, %rd10, %rd79;
mul.lo.s64 %rd81, %rd11, %rd98;
add.s64 %rd82, %rd81, %rd108;
shl.b64 %rd83, %rd82, 2;
add.s64 %rd84, %rd12, %rd83;
ld.global.f32 %f3, [%rd84];
setp.eq.f32	%p12, %f3, %f2;
selp.u16	%rs1, 1, 0, %p12;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd80], %f4;
mov.u32 %r26, %nctaid.x;
mul.wide.u32 %rd85, %r26, %r14;
add.s64 %rd104, %rd85, %rd15;
setp.lt.u64	%p13, %rd104, %rd49;
@%p13 bra BB120_6;

BB120_17:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<18>;
.reg .f32 %f<5>;
.reg .b32 %r<17>;
.reg .b64 %rd<9>;


ld.param.u32 %r8, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r9, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r10, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r11, %ctaid.x;
mov.u32 %r12, %tid.x;
mad.lo.s32 %r16, %r1, %r11, %r12;
setp.ge.u32	%p1, %r16, %r10;
@%p1 bra BB121_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;
mov.u32 %r13, %nctaid.x;
mul.lo.s32 %r5, %r13, %r1;

BB121_2:
mul.lo.s32 %r14, %r16, %r8;
mul.wide.u32 %rd5, %r14, 4;
add.s64 %rd6, %rd1, %rd5;
mul.lo.s32 %r15, %r16, %r9;
mul.wide.u32 %rd7, %r15, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.neu.f32	%p2, %f3, %f2;
selp.u16	%rs17, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs17;
st.global.f32 [%rd6], %f4;
add.s32 %r16, %r5, %r16;
setp.lt.u32	%p3, %r16, %r10;
@%p3 bra BB121_2;

BB121_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.u32 %r12, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r4, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r4, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB122_3;

cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r4;
cvta.to.global.u64 %rd2, %rd4;

BB122_2:
mul.lo.s32 %r33, %r41, %r12;
mul.wide.u32 %rd5, %r33, 4;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r34, %r41, %r24;
add.s32 %r35, %r34, %r41;
shr.u32 %r36, %r35, %r25;
mul.lo.s32 %r37, %r36, %r27;
sub.s32 %r38, %r41, %r37;
mul.lo.s32 %r39, %r38, %r23;
mad.lo.s32 %r40, %r22, %r36, %r39;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.neu.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd6], %f4;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB122_2;

BB122_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot123[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot123;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB123_2;

BB123_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB123_1;

BB123_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB123_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB123_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB123_6;

BB123_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB123_5;

BB123_6:
mul.lo.s32 %r30, %r8, %r18;
mul.wide.u32 %rd16, %r30, 4;
add.s64 %rd17, %rd4, %rd16;
ld.local.u32 %r31, [%rd1+108];
mad.lo.s32 %r32, %r31, %r38, %r42;
ld.local.u64 %rd18, [%rd1];
cvta.to.global.u64 %rd19, %rd18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd19, %rd20;
ld.global.f32 %f3, [%rd21];
setp.neu.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd17], %f4;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB123_4;

BB123_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<42>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r22, %r23}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r24, %r25}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r26, %r27}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r20, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r21, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ntid.x;
mov.u32 %r30, %ctaid.x;
mov.u32 %r31, %tid.x;
mad.lo.s32 %r41, %r1, %r30, %r31;
setp.ge.u32	%p1, %r41, %r21;
@%p1 bra BB124_3;

cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r32, %nctaid.x;
mul.lo.s32 %r9, %r32, %r1;
cvta.to.global.u64 %rd2, %rd3;

BB124_2:
mul.hi.u32 %r33, %r41, %r24;
add.s32 %r34, %r33, %r41;
shr.u32 %r35, %r34, %r25;
mul.lo.s32 %r36, %r35, %r27;
sub.s32 %r37, %r41, %r36;
mul.lo.s32 %r38, %r37, %r23;
mad.lo.s32 %r39, %r22, %r35, %r38;
mul.wide.u32 %rd5, %r39, 4;
add.s64 %rd6, %rd2, %rd5;
mul.lo.s32 %r40, %r41, %r20;
mul.wide.u32 %rd7, %r40, 4;
add.s64 %rd8, %rd1, %rd7;
ld.global.f32 %f3, [%rd8];
setp.neu.f32	%p2, %f3, %f2;
selp.u16	%rs9, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd6], %f4;
add.s32 %r41, %r9, %r41;
setp.lt.u32	%p3, %r41, %r21;
@%p3 bra BB124_2;

BB124_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<67>;
.reg .b64 %rd<9>;


ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd3, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.v2.u32 {%r39, %r40}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r41, %r42}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r43, %r44}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd4, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r47, %ntid.x;
mov.u32 %r48, %ctaid.x;
mov.u32 %r49, %tid.x;
mad.lo.s32 %r66, %r47, %r48, %r49;
setp.ge.u32	%p1, %r66, %r30;
@%p1 bra BB125_3;

cvta.to.global.u64 %rd1, %rd3;
cvta.to.global.u64 %rd2, %rd4;

BB125_2:
mul.hi.u32 %r50, %r66, %r33;
add.s32 %r51, %r50, %r66;
shr.u32 %r52, %r51, %r34;
mul.lo.s32 %r53, %r52, %r36;
sub.s32 %r54, %r66, %r53;
mul.lo.s32 %r55, %r54, %r32;
mad.lo.s32 %r56, %r31, %r52, %r55;
mul.wide.u32 %rd5, %r56, 4;
add.s64 %rd6, %rd1, %rd5;
mul.hi.u32 %r57, %r66, %r41;
add.s32 %r58, %r57, %r66;
shr.u32 %r59, %r58, %r42;
mul.lo.s32 %r60, %r59, %r44;
sub.s32 %r61, %r66, %r60;
mul.lo.s32 %r62, %r61, %r40;
mad.lo.s32 %r63, %r39, %r59, %r62;
mul.wide.u32 %rd7, %r63, 4;
add.s64 %rd8, %rd2, %rd7;
ld.global.f32 %f3, [%rd8];
setp.neu.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd6], %f4;
mov.u32 %r65, %nctaid.x;
mad.lo.s32 %r66, %r65, %r47, %r66;
setp.lt.u32	%p3, %r66, %r30;
@%p3 bra BB125_2;

BB125_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[40],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot126[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot126;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r32, %r33}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+32];
ld.param.v2.u32 {%r34, %r35}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+24];
ld.param.v2.u32 {%r36, %r37}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u32 %r30, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLi2ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB126_2;

BB126_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB126_1;

BB126_2:
mov.u32 %r40, %ntid.x;
mov.u32 %r41, %ctaid.x;
mov.u32 %r42, %tid.x;
mad.lo.s32 %r65, %r40, %r41, %r42;
setp.ge.u32	%p3, %r65, %r30;
@%p3 bra BB126_7;

cvta.to.global.u64 %rd4, %rd10;
ld.local.u32 %r43, [%rd1+208];
add.s32 %r9, %r43, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd5, %rd16;
mul.wide.s32 %rd17, %r43, 4;
add.s64 %rd6, %rd1, %rd17;

BB126_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mul.hi.u32 %r12, %r11, %r34;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB126_6;

BB126_5:
mov.u32 %r14, %r64;
mov.u32 %r13, %r59;
ld.local.u32 %r46, [%rd22+4];
rem.u32 %r47, %r14, %r46;
ld.local.u32 %r48, [%rd22+104];
mad.lo.s32 %r68, %r48, %r47, %r68;
div.u32 %r17, %r14, %r46;
add.s64 %rd22, %rd22, -4;
add.s32 %r18, %r13, -1;
setp.gt.s32	%p5, %r18, 0;
mov.u32 %r59, %r18;
mov.u32 %r63, %r17;
mov.u32 %r64, %r17;
mov.u32 %r67, %r68;
@%p5 bra BB126_5;

BB126_6:
add.s32 %r49, %r12, %r11;
shr.u32 %r50, %r49, %r35;
mul.lo.s32 %r51, %r50, %r37;
sub.s32 %r52, %r11, %r51;
mul.lo.s32 %r53, %r52, %r33;
mad.lo.s32 %r54, %r32, %r50, %r53;
mul.wide.u32 %rd18, %r54, 4;
add.s64 %rd19, %rd4, %rd18;
mad.lo.s32 %r55, %r10, %r63, %r67;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.neu.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd19], %f4;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r40, %r11;
setp.lt.u32	%p7, %r65, %r30;
@%p7 bra BB126_4;

BB126_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u32 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot127[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<10>;
.reg .f32 %f<5>;
.reg .b32 %r<44>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot127;
cvta.local.u64 %SP, %rd23;
ld.param.u32 %r18, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd9, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r19, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd10, %SP, 0;
cvta.to.local.u64 %rd1, %rd10;
mov.u32 %r33, 0;
mov.pred %p1, 0;
@%p1 bra BB127_2;

BB127_1:
mul.wide.s32 %rd11, %r33, 8;
add.s64 %rd12, %rd2, %rd11;
ld.param.u64 %rd13, [%rd12];
add.s64 %rd14, %rd1, %rd11;
st.local.u64 [%rd14], %rd13;
add.s32 %r33, %r33, 1;
setp.lt.u32	%p2, %r33, 27;
@%p2 bra BB127_1;

BB127_2:
mov.u32 %r3, %ntid.x;
mov.u32 %r21, %ctaid.x;
mov.u32 %r22, %tid.x;
mad.lo.s32 %r40, %r3, %r21, %r22;
setp.ge.u32	%p3, %r40, %r19;
@%p3 bra BB127_7;

cvta.to.global.u64 %rd4, %rd9;
mov.u32 %r23, %nctaid.x;
mul.lo.s32 %r6, %r23, %r3;
ld.local.u32 %r24, [%rd1+208];
add.s32 %r7, %r24, -1;
mul.wide.s32 %rd15, %r24, 4;
add.s64 %rd5, %rd1, %rd15;

BB127_4:
mov.u32 %r35, %r40;
mov.u32 %r8, %r35;
mov.u64 %rd22, %rd5;
mov.u32 %r42, 0;
mov.u32 %r43, %r42;
setp.lt.s32	%p4, %r7, 1;
mov.u32 %r34, %r7;
mov.u32 %r38, %r8;
mov.u32 %r39, %r8;
@%p4 bra BB127_6;

BB127_5:
mov.u32 %r10, %r39;
mov.u32 %r9, %r34;
ld.local.u32 %r27, [%rd22+4];
rem.u32 %r28, %r10, %r27;
ld.local.u32 %r29, [%rd22+104];
mad.lo.s32 %r43, %r29, %r28, %r43;
div.u32 %r13, %r10, %r27;
add.s64 %rd22, %rd22, -4;
add.s32 %r14, %r9, -1;
setp.gt.s32	%p5, %r14, 0;
mov.u32 %r34, %r14;
mov.u32 %r38, %r13;
mov.u32 %r39, %r13;
mov.u32 %r42, %r43;
@%p5 bra BB127_5;

BB127_6:
ld.local.u32 %r30, [%rd1+108];
mad.lo.s32 %r31, %r30, %r38, %r42;
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd17, %rd16;
mul.wide.u32 %rd18, %r31, 4;
add.s64 %rd19, %rd17, %rd18;
mul.lo.s32 %r32, %r8, %r18;
mul.wide.u32 %rd20, %r32, 4;
add.s64 %rd21, %rd4, %rd20;
ld.global.f32 %f3, [%rd21];
setp.neu.f32	%p6, %f3, %f2;
selp.u16	%rs9, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs9;
st.global.f32 [%rd19], %f4;
add.s32 %r40, %r6, %r8;
setp.lt.u32	%p7, %r40, %r19;
@%p7 bra BB127_4;

BB127_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[40],
.param .u32 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot128[216];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<8>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<69>;
.reg .b64 %rd<24>;


mov.u64 %rd23, __local_depot128;
cvta.local.u64 %SP, %rd23;
ld.param.v2.u32 {%r31, %r32}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+32];
ld.param.v2.u32 {%r33, %r34}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+24];
ld.param.v2.u32 {%r35, %r36}, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+16];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd2, _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELi2EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
add.u64 %rd11, %SP, 0;
cvta.to.local.u64 %rd1, %rd11;
mov.u32 %r58, 0;
mov.pred %p1, 0;
@%p1 bra BB128_2;

BB128_1:
mul.wide.s32 %rd12, %r58, 8;
add.s64 %rd13, %rd2, %rd12;
ld.param.u64 %rd14, [%rd13];
add.s64 %rd15, %rd1, %rd12;
st.local.u64 [%rd15], %rd14;
add.s32 %r58, %r58, 1;
setp.lt.u32	%p2, %r58, 27;
@%p2 bra BB128_1;

BB128_2:
mov.u32 %r39, %ntid.x;
mov.u32 %r40, %ctaid.x;
mov.u32 %r41, %tid.x;
mad.lo.s32 %r65, %r39, %r40, %r41;
setp.ge.u32	%p3, %r65, %r29;
@%p3 bra BB128_7;

ld.local.u32 %r42, [%rd1+208];
add.s32 %r9, %r42, -1;
ld.local.u32 %r10, [%rd1+108];
ld.local.u64 %rd16, [%rd1];
cvta.to.global.u64 %rd4, %rd16;
cvta.to.global.u64 %rd5, %rd10;
mul.wide.s32 %rd17, %r42, 4;
add.s64 %rd6, %rd1, %rd17;

BB128_4:
mov.u32 %r60, %r65;
mov.u32 %r11, %r60;
mov.u64 %rd22, %rd6;
mov.u32 %r67, 0;
mov.u32 %r68, %r67;
setp.lt.s32	%p4, %r9, 1;
mov.u32 %r59, %r9;
mov.u32 %r63, %r11;
mov.u32 %r64, %r11;
@%p4 bra BB128_6;

BB128_5:
mov.u32 %r13, %r64;
mov.u32 %r12, %r59;
ld.local.u32 %r45, [%rd22+4];
rem.u32 %r46, %r13, %r45;
ld.local.u32 %r47, [%rd22+104];
mad.lo.s32 %r68, %r47, %r46, %r68;
div.u32 %r16, %r13, %r45;
add.s64 %rd22, %rd22, -4;
add.s32 %r17, %r12, -1;
setp.gt.s32	%p5, %r17, 0;
mov.u32 %r59, %r17;
mov.u32 %r63, %r16;
mov.u32 %r64, %r16;
mov.u32 %r67, %r68;
@%p5 bra BB128_5;

BB128_6:
mad.lo.s32 %r48, %r10, %r63, %r67;
mul.wide.u32 %rd18, %r48, 4;
add.s64 %rd19, %rd4, %rd18;
mul.hi.u32 %r49, %r11, %r33;
add.s32 %r50, %r49, %r11;
shr.u32 %r51, %r50, %r34;
mul.lo.s32 %r52, %r51, %r36;
sub.s32 %r53, %r11, %r52;
mul.lo.s32 %r54, %r53, %r32;
mad.lo.s32 %r55, %r31, %r51, %r54;
mul.wide.u32 %rd20, %r55, 4;
add.s64 %rd21, %rd5, %rd20;
ld.global.f32 %f3, [%rd21];
setp.neu.f32	%p6, %f3, %f2;
selp.u16	%rs1, 1, 0, %p6;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd19], %f4;
mov.u32 %r57, %nctaid.x;
mad.lo.s32 %r65, %r57, %r39, %r11;
setp.lt.u32	%p7, %r65, %r29;
@%p7 bra BB128_4;

BB128_7:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[216],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[216],
.param .u32 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot129[432];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<12>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<72>;
.reg .b64 %rd<39>;


mov.u64 %rd38, __local_depot129;
cvta.local.u64 %SP, %rd38;
ld.param.u32 %r29, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffjLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd18, %SP, 216;
cvta.to.local.u64 %rd2, %rd18;
add.u64 %rd19, %SP, 0;
cvta.to.local.u64 %rd3, %rd19;
mov.u32 %r50, 0;
mov.pred %p1, 0;
@%p1 bra BB129_2;

BB129_1:
mul.wide.s32 %rd20, %r50, 8;
add.s64 %rd21, %rd4, %rd20;
ld.param.u64 %rd22, [%rd21];
add.s64 %rd23, %rd2, %rd20;
st.local.u64 [%rd23], %rd22;
add.s32 %r50, %r50, 1;
setp.lt.u32	%p2, %r50, 27;
@%p2 bra BB129_1;

BB129_2:
mov.u32 %r51, 0;
@%p1 bra BB129_4;

BB129_3:
mul.wide.s32 %rd24, %r51, 8;
add.s64 %rd25, %rd1, %rd24;
ld.param.u64 %rd26, [%rd25];
add.s64 %rd27, %rd3, %rd24;
st.local.u64 [%rd27], %rd26;
add.s32 %r51, %r51, 1;
setp.lt.u32	%p4, %r51, 27;
@%p4 bra BB129_3;

BB129_4:
mov.u32 %r32, %ntid.x;
mov.u32 %r33, %ctaid.x;
mov.u32 %r34, %tid.x;
mad.lo.s32 %r64, %r32, %r33, %r34;
setp.ge.u32	%p5, %r64, %r29;
@%p5 bra BB129_11;

ld.local.u32 %r35, [%rd2+208];
add.s32 %r6, %r35, -1;
ld.local.u32 %r7, [%rd2+108];
ld.local.u64 %rd28, [%rd2];
cvta.to.global.u64 %rd8, %rd28;
ld.local.u32 %r36, [%rd3+208];
add.s32 %r8, %r36, -1;
ld.local.u32 %r9, [%rd3+108];
ld.local.u64 %rd29, [%rd3];
cvta.to.global.u64 %rd9, %rd29;
mul.wide.s32 %rd30, %r35, 4;
add.s64 %rd10, %rd2, %rd30;
mul.wide.s32 %rd31, %r36, 4;
add.s64 %rd11, %rd3, %rd31;

BB129_6:
mov.u32 %r54, %r64;
mov.u32 %r10, %r54;
mov.u64 %rd36, %rd10;
mov.u32 %r38, 0;
mov.u32 %r71, %r38;
setp.lt.s32	%p6, %r6, 1;
mov.u32 %r52, %r6;
mov.u32 %r62, %r10;
mov.u32 %r63, %r10;
mov.u32 %r70, %r38;
@%p6 bra BB129_8;

BB129_7:
mov.u32 %r12, %r63;
mov.u32 %r11, %r52;
ld.local.u32 %r39, [%rd36+4];
rem.u32 %r40, %r12, %r39;
ld.local.u32 %r41, [%rd36+104];
mad.lo.s32 %r71, %r41, %r40, %r71;
div.u32 %r15, %r12, %r39;
add.s64 %rd36, %rd36, -4;
add.s32 %r16, %r11, -1;
setp.gt.s32	%p7, %r16, 0;
mov.u32 %r52, %r16;
mov.u32 %r62, %r15;
mov.u32 %r63, %r15;
mov.u32 %r65, %r71;
mov.u32 %r70, %r65;
@%p7 bra BB129_7;

BB129_8:
mov.u32 %r18, %r70;
mov.u64 %rd37, %rd11;
mad.lo.s32 %r19, %r7, %r62, %r18;
mov.u32 %r69, %r38;
setp.lt.s32	%p8, %r8, 1;
mov.u32 %r53, %r8;
mov.u32 %r61, %r10;
mov.u32 %r60, %r10;
mov.u32 %r68, %r38;
@%p8 bra BB129_10;

BB129_9:
mov.u32 %r20, %r53;
ld.local.u32 %r44, [%rd37+4];
rem.u32 %r45, %r61, %r44;
ld.local.u32 %r46, [%rd37+104];
mad.lo.s32 %r69, %r46, %r45, %r69;
div.u32 %r61, %r61, %r44;
add.s64 %rd37, %rd37, -4;
add.s32 %r25, %r20, -1;
setp.gt.s32	%p9, %r25, 0;
mov.u32 %r53, %r25;
mov.u32 %r60, %r61;
mov.u32 %r68, %r69;
@%p9 bra BB129_9;

BB129_10:
mul.wide.u32 %rd32, %r19, 4;
add.s64 %rd33, %rd8, %rd32;
mad.lo.s32 %r47, %r9, %r60, %r68;
mul.wide.u32 %rd34, %r47, 4;
add.s64 %rd35, %rd9, %rd34;
ld.global.f32 %f3, [%rd35];
setp.neu.f32	%p10, %f3, %f2;
selp.u16	%rs1, 1, 0, %p10;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd33], %f4;
mov.u32 %r49, %nctaid.x;
mad.lo.s32 %r64, %r49, %r32, %r10;
setp.lt.u32	%p11, %r64, %r29;
@%p11 bra BB129_6;

BB129_11:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[16],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[16],
.param .u64 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.reg .pred %p<4>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<5>;
.reg .b64 %rd<25>;


ld.param.u64 %rd11, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0+8];
ld.param.u64 %rd10, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0];
ld.param.u64 %rd13, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1+8];
ld.param.u64 %rd12, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1];
ld.param.u64 %rd14, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffmLi1ELi1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %ntid.x;
cvt.u64.u32	%rd1, %r2;
mul.wide.u32 %rd15, %r2, %r1;
mov.u32 %r3, %tid.x;
cvt.u64.u32	%rd16, %r3;
add.s64 %rd24, %rd15, %rd16;
setp.ge.u64	%p1, %rd24, %rd14;
@%p1 bra BB130_3;

cvta.to.global.u64 %rd3, %rd10;
cvta.to.global.u64 %rd5, %rd12;
mov.u32 %r4, %nctaid.x;
cvt.u64.u32	%rd17, %r4;
mul.lo.s64 %rd7, %rd17, %rd1;

BB130_2:
mul.lo.s64 %rd18, %rd24, %rd11;
shl.b64 %rd19, %rd18, 2;
add.s64 %rd20, %rd3, %rd19;
mul.lo.s64 %rd21, %rd24, %rd13;
shl.b64 %rd22, %rd21, 2;
add.s64 %rd23, %rd5, %rd22;
ld.global.f32 %f3, [%rd23];
setp.neu.f32	%p2, %f3, %f2;
selp.u16	%rs1, 1, 0, %p2;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd20], %f4;
add.s64 %rd24, %rd7, %rd24;
setp.lt.u64	%p3, %rd24, %rd14;
@%p3 bra BB130_2;

BB130_3:
ret;
}


.visible .entry _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T_(
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0[416],
.param .align 8 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1[416],
.param .u64 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2,
.param .align 4 .b8 _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3[4]
)
{
.local .align 8 .b8 __local_depot131[832];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<14>;
.reg .b16 %rs<2>;
.reg .f32 %f<5>;
.reg .b32 %r<32>;
.reg .b64 %rd<113>;


mov.u64 %rd112, __local_depot131;
cvta.local.u64 %SP, %rd112;
ld.param.u64 %rd49, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_2];
ld.param.f32 %f2, [_Z21kernelPointwiseApply2I15TensorNEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_3];
mov.u64 %rd4, _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_0;
mov.u64 %rd1, _Z21kernelPointwiseApply2I15TensorNEValueOpIffEffmLin1ELin1EEv10OffsetInfoIT0_T2_XT3_EES2_IT1_S4_XT4_EES4_T__param_1;
add.u64 %rd50, %SP, 416;
cvta.to.local.u64 %rd2, %rd50;
add.u64 %rd51, %SP, 0;
cvta.to.local.u64 %rd3, %rd51;
mov.u32 %r28, 0;
mov.pred %p1, 0;
@%p1 bra BB131_2;

BB131_1:
mul.wide.s32 %rd52, %r28, 8;
add.s64 %rd53, %rd4, %rd52;
ld.param.u64 %rd54, [%rd53];
add.s64 %rd55, %rd2, %rd52;
st.local.u64 [%rd55], %rd54;
add.s32 %r28, %r28, 1;
setp.lt.u32	%p2, %r28, 52;
@%p2 bra BB131_1;

BB131_2:
mov.u32 %r29, 0;
@%p1 bra BB131_4;

BB131_3:
mul.wide.s32 %rd56, %r29, 8;
add.s64 %rd57, %rd1, %rd56;
ld.param.u64 %rd58, [%rd57];
add.s64 %rd59, %rd3, %rd56;
st.local.u64 [%rd59], %rd58;
add.s32 %r29, %r29, 1;
setp.lt.u32	%p4, %r29, 52;
@%p4 bra BB131_3;

BB131_4:
mov.u32 %r13, %ctaid.x;
mov.u32 %r14, %ntid.x;
mul.wide.u32 %rd60, %r14, %r13;
mov.u32 %r15, %tid.x;
cvt.u64.u32	%rd61, %r15;
add.s64 %rd104, %rd60, %rd61;
setp.ge.u64	%p5, %rd104, %rd49;
@%p5 bra BB131_17;

ld.local.u32 %r16, [%rd2+408];
add.s32 %r5, %r16, -1;
ld.local.u64 %rd9, [%rd2+208];
ld.local.u64 %rd62, [%rd2];
cvta.to.global.u64 %rd10, %rd62;
ld.local.u32 %r17, [%rd3+408];
add.s32 %r6, %r17, -1;
ld.local.u64 %rd11, [%rd3+208];
ld.local.u64 %rd63, [%rd3];
cvta.to.global.u64 %rd12, %rd63;
mul.wide.s32 %rd64, %r16, 8;
add.s64 %rd13, %rd2, %rd64;
mul.wide.s32 %rd65, %r17, 8;
add.s64 %rd14, %rd3, %rd65;

BB131_6:
mov.u64 %rd90, %rd104;
mov.u64 %rd15, %rd90;
mov.u64 %rd86, %rd13;
mov.u64 %rd67, 0;
mov.u64 %rd111, %rd67;
setp.lt.s32	%p6, %r5, 1;
mov.u32 %r30, %r5;
mov.u64 %rd101, %rd15;
mov.u64 %rd102, %rd15;
mov.u64 %rd110, %rd67;
@%p6 bra BB131_11;

BB131_7:
mov.u64 %rd18, %rd102;
mov.u32 %r7, %r30;
ld.local.u64 %rd21, [%rd86];
or.b64 %rd68, %rd18, %rd21;
and.b64 %rd69, %rd68, -4294967296;
setp.eq.s64	%p7, %rd69, 0;
@%p7 bra BB131_9;
bra.uni BB131_8;

BB131_9:
cvt.u32.u64	%r18, %rd21;
cvt.u32.u64	%r19, %rd18;
div.u32 %r20, %r19, %r18;
rem.u32 %r21, %r19, %r18;
cvt.u64.u32	%rd103, %r20;
cvt.u64.u32	%rd87, %r21;
bra.uni BB131_10;

BB131_8:
div.u64 %rd103, %rd18, %rd21;
rem.u64 %rd87, %rd18, %rd21;

BB131_10:
mov.u64 %rd26, %rd103;
ld.local.u64 %rd70, [%rd86+200];
mul.lo.s64 %rd71, %rd70, %rd87;
add.s64 %rd111, %rd71, %rd111;
add.s64 %rd86, %rd86, -8;
add.s32 %r8, %r7, -1;
setp.gt.s32	%p8, %r8, 0;
mov.u32 %r30, %r8;
mov.u64 %rd101, %rd26;
mov.u64 %rd102, %rd26;
mov.u64 %rd105, %rd111;
mov.u64 %rd110, %rd105;
@%p8 bra BB131_7;

BB131_11:
mov.u64 %rd31, %rd110;
mov.u64 %rd88, %rd14;
mul.lo.s64 %rd74, %rd9, %rd101;
add.s64 %rd33, %rd74, %rd31;
mov.u64 %rd109, %rd67;
setp.lt.s32	%p9, %r6, 1;
mov.u32 %r31, %r6;
mov.u64 %rd99, %rd15;
mov.u64 %rd98, %rd15;
mov.u64 %rd108, %rd67;
@%p9 bra BB131_16;

BB131_12:
mov.u32 %r9, %r31;
ld.local.u64 %rd37, [%rd88];
or.b64 %rd75, %rd99, %rd37;
and.b64 %rd76, %rd75, -4294967296;
setp.eq.s64	%p10, %rd76, 0;
@%p10 bra BB131_14;
bra.uni BB131_13;

BB131_14:
cvt.u32.u64	%r22, %rd37;
cvt.u32.u64	%r23, %rd99;
div.u32 %r24, %r23, %r22;
rem.u32 %r25, %r23, %r22;
cvt.u64.u32	%rd100, %r24;
cvt.u64.u32	%rd89, %r25;
bra.uni BB131_15;

BB131_13:
div.u64 %rd100, %rd99, %rd37;
rem.u64 %rd89, %rd99, %rd37;

BB131_15:
mov.u64 %rd99, %rd100;
ld.local.u64 %rd77, [%rd88+200];
mul.lo.s64 %rd78, %rd77, %rd89;
add.s64 %rd109, %rd78, %rd109;
add.s64 %rd88, %rd88, -8;
add.s32 %r10, %r9, -1;
setp.gt.s32	%p11, %r10, 0;
mov.u32 %r31, %r10;
mov.u64 %rd98, %rd99;
mov.u64 %rd108, %rd109;
@%p11 bra BB131_12;

BB131_16:
shl.b64 %rd79, %rd33, 2;
add.s64 %rd80, %rd10, %rd79;
mul.lo.s64 %rd81, %rd11, %rd98;
add.s64 %rd82, %rd81, %rd108;
shl.b64 %rd83, %rd82, 2;
add.s64 %rd84, %rd12, %rd83;
ld.global.f32 %f3, [%rd84];
setp.neu.f32	%p12, %f3, %f2;
selp.u16	%rs1, 1, 0, %p12;
cvt.rn.f32.s16	%f4, %rs1;
st.global.f32 [%rd80], %f4;
mov.u32 %r26, %nctaid.x;
mul.wide.u32 %rd85, %r26, %r14;
add.s64 %rd104, %rd85, %rd15;
setp.lt.u64	%p13, %rd104, %rd49;
@%p13 bra BB131_6;

BB131_17:
ret;
}


