







.version 5.0
.target sm_50
.address_size 64


.extern .shared .align 8 .b8 smem[];

.visible .entry _Z16getrf_kernelWarpIddLb0EEv14cublasLuParamsPPT_(
.param .align 8 .b8 _Z16getrf_kernelWarpIddLb0EEv14cublasLuParamsPPT__param_0[32],
.param .u64 _Z16getrf_kernelWarpIddLb0EEv14cublasLuParamsPPT__param_1
)
{
.reg .pred %p<14>;
.reg .b16 %rs<9>;
.reg .b32 %r<50>;
.reg .f64 %fd<11>;
.reg .b64 %rd<48>;


ld.param.v2.u32 {%r23, %r24}, [_Z16getrf_kernelWarpIddLb0EEv14cublasLuParamsPPT__param_0+16];
ld.param.u64 %rd7, [_Z16getrf_kernelWarpIddLb0EEv14cublasLuParamsPPT__param_0+8];
ld.param.u32 %r22, [_Z16getrf_kernelWarpIddLb0EEv14cublasLuParamsPPT__param_0+24];
ld.param.u64 %rd8, [_Z16getrf_kernelWarpIddLb0EEv14cublasLuParamsPPT__param_1];
mov.u32 %r1, %ntid.y;
mov.u32 %r25, %ctaid.x;
mov.u32 %r2, %tid.y;
mad.lo.s32 %r3, %r1, %r25, %r2;
setp.ge.u32	%p2, %r3, %r22;
@%p2 bra BB0_13;

cvta.to.global.u64 %rd9, %rd8;
shl.b32 %r27, %r1, 5;
cvt.u64.u32	%rd10, %r27;
add.s64 %rd11, %rd10, %rd10;
shl.b64 %rd12, %rd11, 2;
mov.u64 %rd13, smem;
add.s64 %rd1, %rd13, %rd12;
add.s32 %r6, %r23, 1;
mul.lo.s32 %r28, %r6, %r23;
mul.lo.s32 %r29, %r28, %r2;
cvt.u64.u32	%rd14, %r29;
add.s64 %rd2, %rd14, %rd10;
cvt.u64.u32	%rd3, %r3;
mul.wide.u32 %rd15, %r3, 8;
add.s64 %rd16, %rd9, %rd15;
ld.global.u64 %rd17, [%rd16];
cvta.to.global.u64 %rd4, %rd17;
mov.u32 %r7, %tid.x;
setp.lt.s32	%p3, %r7, %r23;
setp.gt.s32	%p4, %r23, 0;
and.pred %p1, %p3, %p4;
mov.u32 %r43, 0;
@!%p1 bra BB0_3;
bra.uni BB0_2;

BB0_2:
mad.lo.s32 %r30, %r43, %r24, %r7;
mul.wide.s32 %rd18, %r30, 8;
add.s64 %rd19, %rd4, %rd18;
ld.global.f64 %fd3, [%rd19];
mad.lo.s32 %r31, %r43, %r6, %r7;
cvt.s64.s32	%rd20, %r31;
add.s64 %rd21, %rd20, %rd2;
shl.b64 %rd22, %rd21, 3;
add.s64 %rd23, %rd1, %rd22;
st.shared.f64 [%rd23], %fd3;
add.s32 %r43, %r43, 1;
setp.lt.s32	%p5, %r43, %r23;
@%p5 bra BB0_2;

BB0_3:
mov.u32 %r48, 0;
mov.u32 %r44, %r48;
setp.lt.s32	%p6, %r23, 1;
mov.u32 %r49, %r48;
@%p6 bra BB0_11;

BB0_4:
mul.lo.s32 %r11, %r44, %r6;
add.s32 %r34, %r11, %r44;
cvt.s64.s32	%rd24, %r34;
add.s64 %rd25, %rd24, %rd2;
shl.b64 %rd26, %rd25, 3;
add.s64 %rd27, %rd1, %rd26;
ld.shared.f64 %fd1, [%rd27];
setp.eq.f64	%p7, %fd1, 0d0000000000000000;
@%p7 bra BB0_10;

setp.ge.s32	%p8, %r7, %r23;
@%p8 bra BB0_9;

add.s32 %r35, %r11, %r7;
cvt.s64.s32	%rd28, %r35;
add.s64 %rd29, %rd28, %rd2;
shl.b64 %rd30, %rd29, 3;
add.s64 %rd5, %rd1, %rd30;
ld.shared.f64 %fd4, [%rd5];
rcp.rn.f64 %fd5, %fd1;
mul.f64 %fd2, %fd5, %fd4;
setp.le.s32	%p9, %r7, %r44;
@%p9 bra BB0_9;

st.shared.f64 [%rd5], %fd2;
add.s32 %r45, %r44, 1;
setp.ge.s32	%p10, %r45, %r23;
@%p10 bra BB0_9;

BB0_8:
mul.lo.s32 %r36, %r45, %r6;
add.s32 %r37, %r36, %r44;
cvt.s64.s32	%rd31, %r37;
add.s64 %rd32, %rd31, %rd2;
shl.b64 %rd33, %rd32, 3;
add.s64 %rd34, %rd1, %rd33;
ld.shared.f64 %fd6, [%rd34];
mul.f64 %fd7, %fd2, %fd6;
add.s32 %r38, %r36, %r7;
cvt.s64.s32	%rd35, %r38;
add.s64 %rd36, %rd35, %rd2;
shl.b64 %rd37, %rd36, 3;
add.s64 %rd38, %rd1, %rd37;
ld.shared.f64 %fd8, [%rd38];
sub.f64 %fd9, %fd8, %fd7;
st.shared.f64 [%rd38], %fd9;
add.s32 %r45, %r45, 1;
setp.lt.s32	%p11, %r45, %r23;
@%p11 bra BB0_8;

BB0_9:
add.s32 %r44, %r44, 1;
setp.lt.s32	%p12, %r44, %r23;
mov.u32 %r49, %r48;
@%p12 bra BB0_4;
bra.uni BB0_11;

BB0_10:
add.s32 %r49, %r44, 1;

BB0_11:
cvta.to.global.u64 %rd39, %rd7;
shl.b64 %rd40, %rd3, 2;
add.s64 %rd41, %rd39, %rd40;
st.global.u32 [%rd41], %r49;
@!%p1 bra BB0_13;
bra.uni BB0_12;

BB0_12:
mad.lo.s32 %r41, %r48, %r6, %r7;
cvt.s64.s32	%rd42, %r41;
add.s64 %rd43, %rd42, %rd2;
shl.b64 %rd44, %rd43, 3;
add.s64 %rd45, %rd1, %rd44;
ld.shared.f64 %fd10, [%rd45];
mad.lo.s32 %r42, %r48, %r24, %r7;
mul.wide.s32 %rd46, %r42, 8;
add.s64 %rd47, %rd4, %rd46;
st.global.f64 [%rd47], %fd10;
add.s32 %r48, %r48, 1;
setp.lt.s32	%p13, %r48, %r23;
@%p13 bra BB0_12;

BB0_13:
ret;
}


.visible .entry _Z16getrf_kernelWarpIddLb1EEv14cublasLuParamsPPT_(
.param .align 8 .b8 _Z16getrf_kernelWarpIddLb1EEv14cublasLuParamsPPT__param_0[32],
.param .u64 _Z16getrf_kernelWarpIddLb1EEv14cublasLuParamsPPT__param_1
)
{
.reg .pred %p<48>;
.reg .b16 %rs<9>;
.reg .b32 %r<78>;
.reg .f64 %fd<29>;
.reg .b64 %rd<84>;


ld.param.v2.u32 {%r34, %r35}, [_Z16getrf_kernelWarpIddLb1EEv14cublasLuParamsPPT__param_0+16];
ld.param.u64 %rd15, [_Z16getrf_kernelWarpIddLb1EEv14cublasLuParamsPPT__param_0+8];
ld.param.u64 %rd14, [_Z16getrf_kernelWarpIddLb1EEv14cublasLuParamsPPT__param_0];
ld.param.u32 %r33, [_Z16getrf_kernelWarpIddLb1EEv14cublasLuParamsPPT__param_0+24];
ld.param.u64 %rd16, [_Z16getrf_kernelWarpIddLb1EEv14cublasLuParamsPPT__param_1];
mov.u32 %r1, %ntid.y;
mov.u32 %r36, %ctaid.x;
mov.u32 %r2, %tid.y;
mad.lo.s32 %r3, %r1, %r36, %r2;
setp.ge.u32	%p1, %r3, %r33;
@%p1 bra BB1_34;

cvta.to.global.u64 %rd17, %rd16;
shl.b32 %r38, %r1, 5;
cvt.u64.u32	%rd18, %r38;
add.s64 %rd19, %rd18, %rd18;
shl.b64 %rd20, %rd19, 2;
mov.u64 %rd21, smem;
add.s64 %rd1, %rd21, %rd20;
shl.b32 %r39, %r2, 5;
cvt.u64.u32	%rd2, %r39;
mul.wide.u32 %rd22, %r39, 4;
add.s64 %rd3, %rd21, %rd22;
add.s64 %rd4, %rd2, %rd18;
add.s32 %r6, %r34, 1;
mul.lo.s32 %r40, %r6, %r34;
mul.lo.s32 %r41, %r40, %r2;
cvt.u64.u32	%rd23, %r41;
add.s64 %rd5, %rd23, %rd18;
cvt.u64.u32	%rd6, %r3;
mul.wide.u32 %rd24, %r3, 8;
add.s64 %rd25, %rd17, %rd24;
ld.global.u64 %rd26, [%rd25];
cvta.to.global.u64 %rd7, %rd26;
mov.u32 %r7, %tid.x;
cvt.s64.s32	%rd8, %r7;
add.s64 %rd27, %rd8, %rd4;
shl.b64 %rd28, %rd27, 2;
add.s64 %rd9, %rd21, %rd28;
st.shared.u32 [%rd9], %r7;
setp.lt.s32	%p2, %r7, %r34;
setp.gt.s32	%p3, %r34, 0;
and.pred %p4, %p2, %p3;
mov.u32 %r62, 0;
@!%p4 bra BB1_3;
bra.uni BB1_2;

BB1_2:
mad.lo.s32 %r42, %r62, %r35, %r7;
mul.wide.s32 %rd29, %r42, 8;
add.s64 %rd30, %rd7, %rd29;
ld.global.f64 %fd9, [%rd30];
mad.lo.s32 %r43, %r62, %r6, %r7;
cvt.s64.s32	%rd31, %r43;
add.s64 %rd32, %rd31, %rd5;
shl.b64 %rd33, %rd32, 3;
add.s64 %rd34, %rd1, %rd33;
st.shared.f64 [%rd34], %fd9;
add.s32 %r62, %r62, 1;
setp.lt.s32	%p5, %r62, %r34;
@%p5 bra BB1_2;

BB1_3:
mov.u32 %r76, 0;
setp.lt.s32	%p6, %r34, 1;
@%p6 bra BB1_31;

shl.b64 %rd35, %rd2, 3;
add.s64 %rd10, %rd1, %rd35;
add.s64 %rd36, %rd8, %rd2;
shl.b64 %rd37, %rd36, 3;
add.s64 %rd11, %rd1, %rd37;
shl.b64 %rd38, %rd36, 2;
add.s64 %rd12, %rd21, %rd38;
mul.lo.s32 %r10, %r7, %r6;
mov.u32 %r63, 0;

BB1_5:
add.s32 %r12, %r63, %r7;
mov.f64 %fd28, 0d0000000000000000;
setp.ge.s32	%p7, %r12, %r34;
@%p7 bra BB1_7;

mad.lo.s32 %r46, %r63, %r6, %r12;
cvt.s64.s32	%rd40, %r46;
add.s64 %rd41, %rd40, %rd5;
shl.b64 %rd42, %rd41, 3;
add.s64 %rd43, %rd1, %rd42;
ld.shared.f64 %fd11, [%rd43];
abs.f64 %fd28, %fd11;

BB1_7:
st.shared.f64 [%rd11], %fd28;
st.shared.u32 [%rd12], %r12;
setp.gt.s32	%p8, %r7, 15;
mov.u32 %r74, %r12;
@%p8 bra BB1_10;

ld.shared.f64 %fd12, [%rd11];
ld.shared.f64 %fd3, [%rd11+128];
setp.geu.f64	%p9, %fd12, %fd3;
ld.shared.u32 %r13, [%rd12+64];
setp.le.s32	%p10, %r12, %r13;
setp.neu.f64	%p11, %fd12, %fd3;
or.pred %p12, %p11, %p10;
and.pred %p13, %p9, %p12;
mov.u32 %r64, %r12;
mov.u32 %r74, %r64;
@%p13 bra BB1_10;

st.shared.f64 [%rd11], %fd3;
st.shared.u32 [%rd12], %r13;
mov.u32 %r74, %r13;

BB1_10:
mov.u32 %r14, %r74;
setp.gt.s32	%p14, %r7, 7;
mov.u32 %r73, %r14;
@%p14 bra BB1_13;

ld.shared.f64 %fd13, [%rd11];
ld.shared.f64 %fd4, [%rd11+64];
setp.geu.f64	%p15, %fd13, %fd4;
ld.shared.u32 %r15, [%rd12+32];
setp.le.s32	%p16, %r14, %r15;
setp.neu.f64	%p17, %fd13, %fd4;
or.pred %p18, %p17, %p16;
and.pred %p19, %p15, %p18;
mov.u32 %r66, %r14;
mov.u32 %r73, %r66;
@%p19 bra BB1_13;

st.shared.f64 [%rd11], %fd4;
st.shared.u32 [%rd12], %r15;
mov.u32 %r73, %r15;

BB1_13:
mov.u32 %r16, %r73;
setp.gt.s32	%p20, %r7, 3;
mov.u32 %r72, %r16;
@%p20 bra BB1_16;

ld.shared.f64 %fd14, [%rd11];
ld.shared.f64 %fd5, [%rd11+32];
setp.geu.f64	%p21, %fd14, %fd5;
ld.shared.u32 %r17, [%rd12+16];
setp.le.s32	%p22, %r16, %r17;
setp.neu.f64	%p23, %fd14, %fd5;
or.pred %p24, %p23, %p22;
and.pred %p25, %p21, %p24;
mov.u32 %r68, %r16;
mov.u32 %r72, %r68;
@%p25 bra BB1_16;

st.shared.f64 [%rd11], %fd5;
st.shared.u32 [%rd12], %r17;
mov.u32 %r72, %r17;

BB1_16:
mov.u32 %r18, %r72;
setp.gt.s32	%p26, %r7, 1;
mov.u32 %r71, %r18;
@%p26 bra BB1_19;

ld.shared.f64 %fd15, [%rd11];
ld.shared.f64 %fd6, [%rd11+16];
setp.geu.f64	%p27, %fd15, %fd6;
ld.shared.u32 %r19, [%rd12+8];
setp.le.s32	%p28, %r18, %r19;
setp.neu.f64	%p29, %fd15, %fd6;
or.pred %p30, %p29, %p28;
and.pred %p31, %p27, %p30;
mov.u32 %r70, %r18;
mov.u32 %r71, %r70;
@%p31 bra BB1_19;

st.shared.f64 [%rd11], %fd6;
st.shared.u32 [%rd12], %r19;
mov.u32 %r71, %r19;

BB1_19:
setp.gt.s32	%p32, %r7, 0;
@%p32 bra BB1_22;

ld.shared.f64 %fd16, [%rd11];
ld.shared.f64 %fd7, [%rd11+8];
setp.geu.f64	%p33, %fd16, %fd7;
ld.shared.u32 %r21, [%rd12+4];
setp.le.s32	%p34, %r71, %r21;
setp.neu.f64	%p35, %fd16, %fd7;
or.pred %p36, %p35, %p34;
and.pred %p37, %p33, %p36;
@%p37 bra BB1_22;

st.shared.f64 [%rd11], %fd7;
st.shared.u32 [%rd12], %r21;

BB1_22:
ld.shared.u32 %r22, [%rd3];
setp.ge.s32	%p38, %r7, %r34;
@%p38 bra BB1_24;

add.s32 %r47, %r22, %r10;
cvt.s64.s32	%rd44, %r47;
add.s64 %rd45, %rd44, %rd5;
shl.b64 %rd46, %rd45, 3;
add.s64 %rd47, %rd1, %rd46;
ld.shared.f64 %fd17, [%rd47];
add.s32 %r48, %r63, %r10;
cvt.s64.s32	%rd48, %r48;
add.s64 %rd49, %rd48, %rd5;
shl.b64 %rd50, %rd49, 3;
add.s64 %rd51, %rd1, %rd50;
ld.shared.f64 %fd18, [%rd51];
st.shared.f64 [%rd47], %fd18;
st.shared.f64 [%rd51], %fd17;

BB1_24:
cvt.s64.s32	%rd52, %r63;
add.s64 %rd53, %rd52, %rd4;
shl.b64 %rd54, %rd53, 2;
add.s64 %rd56, %rd21, %rd54;
st.shared.u32 [%rd56], %r22;
ld.shared.f64 %fd19, [%rd10];
setp.eq.f64	%p39, %fd19, 0d0000000000000000;
@%p39 bra BB1_30;

@%p38 bra BB1_29;

mul.lo.s32 %r49, %r63, %r6;
add.s32 %r50, %r49, %r63;
cvt.s64.s32	%rd57, %r50;
add.s64 %rd58, %rd57, %rd5;
shl.b64 %rd59, %rd58, 3;
add.s64 %rd60, %rd1, %rd59;
ld.shared.f64 %fd20, [%rd60];
rcp.rn.f64 %fd21, %fd20;
add.s32 %r51, %r49, %r7;
cvt.s64.s32	%rd61, %r51;
add.s64 %rd62, %rd61, %rd5;
shl.b64 %rd63, %rd62, 3;
add.s64 %rd13, %rd1, %rd63;
ld.shared.f64 %fd22, [%rd13];
mul.f64 %fd8, %fd21, %fd22;
setp.le.s32	%p41, %r7, %r63;
@%p41 bra BB1_29;

st.shared.f64 [%rd13], %fd8;
add.s32 %r75, %r63, 1;
setp.ge.s32	%p42, %r75, %r34;
@%p42 bra BB1_29;

BB1_28:
mul.lo.s32 %r52, %r75, %r6;
add.s32 %r53, %r52, %r63;
cvt.s64.s32	%rd64, %r53;
add.s64 %rd65, %rd64, %rd5;
shl.b64 %rd66, %rd65, 3;
add.s64 %rd67, %rd1, %rd66;
ld.shared.f64 %fd23, [%rd67];
mul.f64 %fd24, %fd8, %fd23;
add.s32 %r54, %r52, %r7;
cvt.s64.s32	%rd68, %r54;
add.s64 %rd69, %rd68, %rd5;
shl.b64 %rd70, %rd69, 3;
add.s64 %rd71, %rd1, %rd70;
ld.shared.f64 %fd25, [%rd71];
sub.f64 %fd26, %fd25, %fd24;
st.shared.f64 [%rd71], %fd26;
add.s32 %r75, %r75, 1;
setp.lt.s32	%p43, %r75, %r34;
@%p43 bra BB1_28;

BB1_29:
add.s32 %r63, %r63, 1;
setp.lt.s32	%p44, %r63, %r34;
mov.u32 %r76, 0;
@%p44 bra BB1_5;
bra.uni BB1_31;

BB1_30:
add.s32 %r76, %r63, 1;

BB1_31:
cvta.to.global.u64 %rd72, %rd15;
shl.b64 %rd73, %rd6, 2;
add.s64 %rd74, %rd72, %rd73;
st.global.u32 [%rd74], %r76;
setp.ge.s32	%p45, %r7, %r34;
@%p45 bra BB1_34;

cvta.to.global.u64 %rd75, %rd14;
ld.shared.u32 %r57, [%rd9];
add.s32 %r58, %r57, 1;
mad.lo.s32 %r59, %r3, %r34, %r7;
mul.wide.u32 %rd76, %r59, 4;
add.s64 %rd77, %rd75, %rd76;
st.global.u32 [%rd77], %r58;
mov.u32 %r77, 0;
@%p6 bra BB1_34;

BB1_33:
mad.lo.s32 %r60, %r77, %r6, %r7;
cvt.s64.s32	%rd78, %r60;
add.s64 %rd79, %rd78, %rd5;
shl.b64 %rd80, %rd79, 3;
add.s64 %rd81, %rd1, %rd80;
ld.shared.f64 %fd27, [%rd81];
mad.lo.s32 %r61, %r77, %r35, %r7;
mul.wide.s32 %rd82, %r61, 8;
add.s64 %rd83, %rd7, %rd82;
st.global.f64 [%rd83], %fd27;
add.s32 %r77, %r77, 1;
setp.lt.s32	%p47, %r77, %r34;
@%p47 bra BB1_33;

BB1_34:
ret;
}


.visible .entry _Z16getrf_kernelWarpI7double2dLb0EEv14cublasLuParamsPPT_(
.param .align 8 .b8 _Z16getrf_kernelWarpI7double2dLb0EEv14cublasLuParamsPPT__param_0[32],
.param .u64 _Z16getrf_kernelWarpI7double2dLb0EEv14cublasLuParamsPPT__param_1
)
{
.reg .pred %p<16>;
.reg .b16 %rs<9>;
.reg .b32 %r<50>;
.reg .f64 %fd<54>;
.reg .b64 %rd<49>;


ld.param.v2.u32 {%r23, %r24}, [_Z16getrf_kernelWarpI7double2dLb0EEv14cublasLuParamsPPT__param_0+16];
ld.param.u64 %rd7, [_Z16getrf_kernelWarpI7double2dLb0EEv14cublasLuParamsPPT__param_0+8];
ld.param.u32 %r22, [_Z16getrf_kernelWarpI7double2dLb0EEv14cublasLuParamsPPT__param_0+24];
ld.param.u64 %rd8, [_Z16getrf_kernelWarpI7double2dLb0EEv14cublasLuParamsPPT__param_1];
mov.u32 %r1, %ntid.y;
mov.u32 %r25, %ctaid.x;
mov.u32 %r2, %tid.y;
mad.lo.s32 %r3, %r1, %r25, %r2;
setp.ge.u32	%p2, %r3, %r22;
@%p2 bra BB2_14;

cvta.to.global.u64 %rd9, %rd8;
shl.b32 %r27, %r1, 5;
cvt.u64.u32	%rd10, %r27;
add.s64 %rd11, %rd10, %rd10;
shl.b64 %rd12, %rd11, 2;
mov.u64 %rd13, smem;
add.s64 %rd14, %rd13, %rd12;
mul.wide.u32 %rd15, %r27, 8;
add.s64 %rd1, %rd14, %rd15;
add.s32 %r6, %r23, 1;
mul.lo.s32 %r28, %r6, %r23;
mul.lo.s32 %r29, %r28, %r2;
cvt.u64.u32	%rd2, %r29;
cvt.u64.u32	%rd3, %r3;
mul.wide.u32 %rd16, %r3, 8;
add.s64 %rd17, %rd9, %rd16;
ld.global.u64 %rd18, [%rd17];
cvta.to.global.u64 %rd4, %rd18;
mov.u32 %r7, %tid.x;
setp.lt.s32	%p3, %r7, %r23;
setp.gt.s32	%p4, %r23, 0;
and.pred %p1, %p3, %p4;
mov.u32 %r43, 0;
@!%p1 bra BB2_3;
bra.uni BB2_2;

BB2_2:
mad.lo.s32 %r30, %r43, %r6, %r7;
cvt.s64.s32	%rd19, %r30;
add.s64 %rd20, %rd19, %rd2;
shl.b64 %rd21, %rd20, 4;
add.s64 %rd22, %rd1, %rd21;
mad.lo.s32 %r31, %r43, %r24, %r7;
mul.wide.s32 %rd23, %r31, 16;
add.s64 %rd24, %rd4, %rd23;
ld.global.v2.f64 {%fd9, %fd10}, [%rd24];
st.shared.v2.f64 [%rd22], {%fd9, %fd10};
add.s32 %r43, %r43, 1;
setp.lt.s32	%p5, %r43, %r23;
@%p5 bra BB2_2;

BB2_3:
mov.u32 %r48, 0;
mov.u32 %r44, %r48;
setp.lt.s32	%p6, %r23, 1;
mov.u32 %r49, %r48;
@%p6 bra BB2_12;

BB2_4:
mul.lo.s32 %r11, %r44, %r6;
add.s32 %r34, %r11, %r44;
cvt.s64.s32	%rd25, %r34;
add.s64 %rd26, %rd25, %rd2;
shl.b64 %rd27, %rd26, 4;
add.s64 %rd28, %rd1, %rd27;
ld.shared.v2.f64 {%fd13, %fd14}, [%rd28];
setp.eq.f64	%p7, %fd13, 0d0000000000000000;
setp.eq.f64	%p8, %fd14, 0d0000000000000000;
and.pred %p9, %p7, %p8;
@%p9 bra BB2_11;

abs.f64 %fd15, %fd14;
abs.f64 %fd16, %fd13;
add.f64 %fd17, %fd16, %fd15;
rcp.rn.f64 %fd18, %fd17;
mul.f64 %fd19, %fd18, 0d0000000000000000;
mul.f64 %fd20, %fd13, %fd18;
mul.f64 %fd21, %fd14, %fd18;
mul.f64 %fd22, %fd21, %fd21;
fma.rn.f64 %fd23, %fd20, %fd20, %fd22;
rcp.rn.f64 %fd24, %fd23;
mul.f64 %fd25, %fd19, %fd21;
fma.rn.f64 %fd26, %fd18, %fd20, %fd25;
mul.f64 %fd3, %fd24, %fd26;
mul.f64 %fd27, %fd19, %fd20;
mul.f64 %fd28, %fd18, %fd21;
sub.f64 %fd29, %fd27, %fd28;
mul.f64 %fd4, %fd24, %fd29;
setp.ge.s32	%p10, %r7, %r23;
@%p10 bra BB2_10;

add.s32 %r35, %r11, %r7;
cvt.s64.s32	%rd29, %r35;
add.s64 %rd30, %rd29, %rd2;
shl.b64 %rd31, %rd30, 4;
add.s64 %rd5, %rd1, %rd31;
ld.shared.v2.f64 {%fd30, %fd31}, [%rd5];
mul.f64 %fd34, %fd3, %fd30;
mul.f64 %fd35, %fd4, %fd31;
sub.f64 %fd5, %fd34, %fd35;
mul.f64 %fd36, %fd3, %fd31;
fma.rn.f64 %fd6, %fd4, %fd30, %fd36;
setp.le.s32	%p11, %r7, %r44;
@%p11 bra BB2_10;

st.shared.v2.f64 [%rd5], {%fd5, %fd6};
add.s32 %r45, %r44, 1;
setp.ge.s32	%p12, %r45, %r23;
@%p12 bra BB2_10;

neg.f64 %fd7, %fd5;
neg.f64 %fd8, %fd6;

BB2_9:
mul.lo.s32 %r36, %r45, %r6;
add.s32 %r37, %r36, %r7;
cvt.s64.s32	%rd32, %r37;
add.s64 %rd33, %rd32, %rd2;
shl.b64 %rd34, %rd33, 4;
add.s64 %rd35, %rd1, %rd34;
add.s32 %r38, %r36, %r44;
cvt.s64.s32	%rd36, %r38;
add.s64 %rd37, %rd36, %rd2;
shl.b64 %rd38, %rd37, 4;
add.s64 %rd39, %rd1, %rd38;
ld.shared.v2.f64 {%fd37, %fd38}, [%rd39];
ld.shared.v2.f64 {%fd41, %fd42}, [%rd35];
fma.rn.f64 %fd45, %fd37, %fd7, %fd41;
fma.rn.f64 %fd46, %fd38, %fd7, %fd42;
mul.f64 %fd47, %fd38, %fd8;
fma.rn.f64 %fd48, %fd37, %fd8, %fd46;
sub.f64 %fd49, %fd45, %fd47;
st.shared.v2.f64 [%rd35], {%fd49, %fd48};
add.s32 %r45, %r45, 1;
setp.lt.s32	%p13, %r45, %r23;
@%p13 bra BB2_9;

BB2_10:
add.s32 %r44, %r44, 1;
setp.lt.s32	%p14, %r44, %r23;
mov.u32 %r49, %r48;
@%p14 bra BB2_4;
bra.uni BB2_12;

BB2_11:
add.s32 %r49, %r44, 1;

BB2_12:
cvta.to.global.u64 %rd40, %rd7;
shl.b64 %rd41, %rd3, 2;
add.s64 %rd42, %rd40, %rd41;
st.global.u32 [%rd42], %r49;
@!%p1 bra BB2_14;
bra.uni BB2_13;

BB2_13:
mad.lo.s32 %r41, %r48, %r24, %r7;
mul.wide.s32 %rd43, %r41, 16;
add.s64 %rd44, %rd4, %rd43;
mad.lo.s32 %r42, %r48, %r6, %r7;
cvt.s64.s32	%rd45, %r42;
add.s64 %rd46, %rd45, %rd2;
shl.b64 %rd47, %rd46, 4;
add.s64 %rd48, %rd1, %rd47;
ld.shared.v2.f64 {%fd50, %fd51}, [%rd48];
st.global.v2.f64 [%rd44], {%fd50, %fd51};
add.s32 %r48, %r48, 1;
setp.lt.s32	%p15, %r48, %r23;
@%p15 bra BB2_13;

BB2_14:
ret;
}


.visible .entry _Z16getrf_kernelWarpI7double2dLb1EEv14cublasLuParamsPPT_(
.param .align 8 .b8 _Z16getrf_kernelWarpI7double2dLb1EEv14cublasLuParamsPPT__param_0[32],
.param .u64 _Z16getrf_kernelWarpI7double2dLb1EEv14cublasLuParamsPPT__param_1
)
{
.reg .pred %p<48>;
.reg .b16 %rs<9>;
.reg .b32 %r<78>;
.reg .f64 %fd<82>;
.reg .b64 %rd<86>;


ld.param.v2.u32 {%r35, %r36}, [_Z16getrf_kernelWarpI7double2dLb1EEv14cublasLuParamsPPT__param_0+16];
ld.param.u64 %rd17, [_Z16getrf_kernelWarpI7double2dLb1EEv14cublasLuParamsPPT__param_0+8];
ld.param.u64 %rd16, [_Z16getrf_kernelWarpI7double2dLb1EEv14cublasLuParamsPPT__param_0];
ld.param.u32 %r34, [_Z16getrf_kernelWarpI7double2dLb1EEv14cublasLuParamsPPT__param_0+24];
ld.param.u64 %rd18, [_Z16getrf_kernelWarpI7double2dLb1EEv14cublasLuParamsPPT__param_1];
mov.u32 %r1, %ntid.y;
mov.u32 %r37, %ctaid.x;
mov.u32 %r2, %tid.y;
mad.lo.s32 %r3, %r1, %r37, %r2;
setp.ge.u32	%p1, %r3, %r34;
@%p1 bra BB3_35;

cvta.to.global.u64 %rd19, %rd18;
shl.b32 %r39, %r1, 5;
cvt.u64.u32	%rd20, %r39;
add.s64 %rd21, %rd20, %rd20;
shl.b64 %rd22, %rd21, 2;
mov.u64 %rd23, smem;
add.s64 %rd2, %rd23, %rd22;
mul.wide.u32 %rd24, %r39, 8;
add.s64 %rd3, %rd2, %rd24;
shl.b32 %r40, %r2, 5;
cvt.u64.u32	%rd4, %r40;
mul.wide.u32 %rd25, %r40, 4;
add.s64 %rd5, %rd23, %rd25;
add.s64 %rd6, %rd4, %rd20;
add.s32 %r6, %r35, 1;
mul.lo.s32 %r41, %r6, %r35;
mul.lo.s32 %r42, %r41, %r2;
cvt.u64.u32	%rd7, %r42;
cvt.u64.u32	%rd8, %r3;
mul.wide.u32 %rd26, %r3, 8;
add.s64 %rd27, %rd19, %rd26;
ld.global.u64 %rd28, [%rd27];
cvta.to.global.u64 %rd9, %rd28;
mov.u32 %r7, %tid.x;
cvt.s64.s32	%rd10, %r7;
add.s64 %rd29, %rd10, %rd6;
shl.b64 %rd30, %rd29, 2;
add.s64 %rd11, %rd23, %rd30;
st.shared.u32 [%rd11], %r7;
setp.lt.s32	%p2, %r7, %r35;
setp.gt.s32	%p3, %r35, 0;
and.pred %p4, %p2, %p3;
mov.u32 %r62, 0;
@!%p4 bra BB3_3;
bra.uni BB3_2;

BB3_2:
mad.lo.s32 %r43, %r62, %r6, %r7;
cvt.s64.s32	%rd31, %r43;
add.s64 %rd32, %rd31, %rd7;
shl.b64 %rd33, %rd32, 4;
add.s64 %rd34, %rd3, %rd33;
mad.lo.s32 %r44, %r62, %r36, %r7;
mul.wide.s32 %rd35, %r44, 16;
add.s64 %rd36, %rd9, %rd35;
ld.global.v2.f64 {%fd14, %fd15}, [%rd36];
st.shared.v2.f64 [%rd34], {%fd14, %fd15};
add.s32 %r62, %r62, 1;
setp.lt.s32	%p5, %r62, %r35;
@%p5 bra BB3_2;

BB3_3:
mov.u32 %r76, 0;
setp.lt.s32	%p6, %r35, 1;
@%p6 bra BB3_32;

shl.b64 %rd37, %rd4, 3;
add.s64 %rd12, %rd2, %rd37;
add.s64 %rd38, %rd10, %rd4;
shl.b64 %rd39, %rd38, 3;
add.s64 %rd13, %rd2, %rd39;
shl.b64 %rd40, %rd38, 2;
add.s64 %rd14, %rd23, %rd40;
mul.lo.s32 %r10, %r7, %r6;
mov.u32 %r63, 0;

BB3_5:
add.s32 %r12, %r63, %r7;
mov.f64 %fd81, 0d0000000000000000;
setp.ge.s32	%p7, %r12, %r35;
@%p7 bra BB3_7;

mad.lo.s32 %r47, %r63, %r6, %r12;
cvt.s64.s32	%rd42, %r47;
add.s64 %rd43, %rd42, %rd7;
shl.b64 %rd44, %rd43, 4;
add.s64 %rd45, %rd3, %rd44;
ld.shared.v2.f64 {%fd19, %fd20}, [%rd45];
mul.f64 %fd23, %fd20, %fd20;
fma.rn.f64 %fd81, %fd19, %fd19, %fd23;

BB3_7:
st.shared.f64 [%rd13], %fd81;
st.shared.u32 [%rd14], %r12;
setp.gt.s32	%p8, %r7, 15;
mov.u32 %r74, %r12;
@%p8 bra BB3_10;

ld.shared.f64 %fd24, [%rd13];
ld.shared.f64 %fd3, [%rd13+128];
setp.geu.f64	%p9, %fd24, %fd3;
ld.shared.u32 %r13, [%rd14+64];
setp.le.s32	%p10, %r12, %r13;
setp.neu.f64	%p11, %fd24, %fd3;
or.pred %p12, %p11, %p10;
and.pred %p13, %p9, %p12;
mov.u32 %r64, %r12;
mov.u32 %r74, %r64;
@%p13 bra BB3_10;

st.shared.f64 [%rd13], %fd3;
st.shared.u32 [%rd14], %r13;
mov.u32 %r74, %r13;

BB3_10:
mov.u32 %r14, %r74;
setp.gt.s32	%p14, %r7, 7;
mov.u32 %r73, %r14;
@%p14 bra BB3_13;

ld.shared.f64 %fd25, [%rd13];
ld.shared.f64 %fd4, [%rd13+64];
setp.geu.f64	%p15, %fd25, %fd4;
ld.shared.u32 %r15, [%rd14+32];
setp.le.s32	%p16, %r14, %r15;
setp.neu.f64	%p17, %fd25, %fd4;
or.pred %p18, %p17, %p16;
and.pred %p19, %p15, %p18;
mov.u32 %r66, %r14;
mov.u32 %r73, %r66;
@%p19 bra BB3_13;

st.shared.f64 [%rd13], %fd4;
st.shared.u32 [%rd14], %r15;
mov.u32 %r73, %r15;

BB3_13:
mov.u32 %r16, %r73;
setp.gt.s32	%p20, %r7, 3;
mov.u32 %r72, %r16;
@%p20 bra BB3_16;

ld.shared.f64 %fd26, [%rd13];
ld.shared.f64 %fd5, [%rd13+32];
setp.geu.f64	%p21, %fd26, %fd5;
ld.shared.u32 %r17, [%rd14+16];
setp.le.s32	%p22, %r16, %r17;
setp.neu.f64	%p23, %fd26, %fd5;
or.pred %p24, %p23, %p22;
and.pred %p25, %p21, %p24;
mov.u32 %r68, %r16;
mov.u32 %r72, %r68;
@%p25 bra BB3_16;

st.shared.f64 [%rd13], %fd5;
st.shared.u32 [%rd14], %r17;
mov.u32 %r72, %r17;

BB3_16:
mov.u32 %r18, %r72;
setp.gt.s32	%p26, %r7, 1;
mov.u32 %r71, %r18;
@%p26 bra BB3_19;

ld.shared.f64 %fd27, [%rd13];
ld.shared.f64 %fd6, [%rd13+16];
setp.geu.f64	%p27, %fd27, %fd6;
ld.shared.u32 %r19, [%rd14+8];
setp.le.s32	%p28, %r18, %r19;
setp.neu.f64	%p29, %fd27, %fd6;
or.pred %p30, %p29, %p28;
and.pred %p31, %p27, %p30;
mov.u32 %r70, %r18;
mov.u32 %r71, %r70;
@%p31 bra BB3_19;

st.shared.f64 [%rd13], %fd6;
st.shared.u32 [%rd14], %r19;
mov.u32 %r71, %r19;

BB3_19:
setp.gt.s32	%p32, %r7, 0;
@%p32 bra BB3_22;

ld.shared.f64 %fd28, [%rd13];
ld.shared.f64 %fd7, [%rd13+8];
setp.geu.f64	%p33, %fd28, %fd7;
ld.shared.u32 %r21, [%rd14+4];
setp.le.s32	%p34, %r71, %r21;
setp.neu.f64	%p35, %fd28, %fd7;
or.pred %p36, %p35, %p34;
and.pred %p37, %p33, %p36;
@%p37 bra BB3_22;

st.shared.f64 [%rd13], %fd7;
st.shared.u32 [%rd14], %r21;

BB3_22:
ld.shared.u32 %r22, [%rd5];
setp.ge.s32	%p38, %r7, %r35;
@%p38 bra BB3_24;

add.s32 %r48, %r22, %r10;
cvt.s64.s32	%rd46, %r48;
add.s64 %rd47, %rd46, %rd7;
shl.b64 %rd48, %rd47, 4;
add.s64 %rd49, %rd3, %rd48;
ld.shared.v2.f64 {%fd29, %fd30}, [%rd49];
add.s32 %r49, %r63, %r10;
cvt.s64.s32	%rd50, %r49;
add.s64 %rd51, %rd50, %rd7;
shl.b64 %rd52, %rd51, 4;
add.s64 %rd53, %rd3, %rd52;
ld.shared.v2.f64 {%fd31, %fd32}, [%rd53];
st.shared.v2.f64 [%rd49], {%fd31, %fd32};
st.shared.v2.f64 [%rd53], {%fd29, %fd30};

BB3_24:
cvt.s64.s32	%rd54, %r63;
add.s64 %rd55, %rd54, %rd6;
shl.b64 %rd56, %rd55, 2;
add.s64 %rd58, %rd23, %rd56;
st.shared.u32 [%rd58], %r22;
ld.shared.f64 %fd37, [%rd12];
setp.eq.f64	%p39, %fd37, 0d0000000000000000;
@%p39 bra BB3_31;

mul.lo.s32 %r23, %r63, %r6;
add.s32 %r50, %r23, %r63;
cvt.s64.s32	%rd59, %r50;
add.s64 %rd60, %rd59, %rd7;
shl.b64 %rd61, %rd60, 4;
add.s64 %rd62, %rd3, %rd61;
ld.shared.v2.f64 {%fd38, %fd39}, [%rd62];
abs.f64 %fd42, %fd38;
abs.f64 %fd43, %fd39;
add.f64 %fd44, %fd42, %fd43;
rcp.rn.f64 %fd45, %fd44;
mul.f64 %fd46, %fd45, 0d0000000000000000;
mul.f64 %fd47, %fd38, %fd45;
mul.f64 %fd48, %fd39, %fd45;
mul.f64 %fd49, %fd48, %fd48;
fma.rn.f64 %fd50, %fd47, %fd47, %fd49;
rcp.rn.f64 %fd51, %fd50;
mul.f64 %fd52, %fd46, %fd48;
fma.rn.f64 %fd53, %fd45, %fd47, %fd52;
mul.f64 %fd8, %fd51, %fd53;
mul.f64 %fd54, %fd46, %fd47;
mul.f64 %fd55, %fd45, %fd48;
sub.f64 %fd56, %fd54, %fd55;
mul.f64 %fd9, %fd51, %fd56;
@%p38 bra BB3_30;

add.s32 %r51, %r23, %r7;
cvt.s64.s32	%rd63, %r51;
add.s64 %rd64, %rd63, %rd7;
shl.b64 %rd65, %rd64, 4;
add.s64 %rd15, %rd3, %rd65;
ld.shared.v2.f64 {%fd57, %fd58}, [%rd15];
mul.f64 %fd61, %fd8, %fd57;
mul.f64 %fd62, %fd9, %fd58;
sub.f64 %fd10, %fd61, %fd62;
mul.f64 %fd63, %fd8, %fd58;
fma.rn.f64 %fd11, %fd9, %fd57, %fd63;
setp.le.s32	%p41, %r7, %r63;
@%p41 bra BB3_30;

st.shared.v2.f64 [%rd15], {%fd10, %fd11};
add.s32 %r75, %r63, 1;
setp.ge.s32	%p42, %r75, %r35;
@%p42 bra BB3_30;

neg.f64 %fd12, %fd10;
neg.f64 %fd13, %fd11;

BB3_29:
mul.lo.s32 %r52, %r75, %r6;
add.s32 %r53, %r52, %r7;
cvt.s64.s32	%rd66, %r53;
add.s64 %rd67, %rd66, %rd7;
shl.b64 %rd68, %rd67, 4;
add.s64 %rd69, %rd3, %rd68;
add.s32 %r54, %r52, %r63;
cvt.s64.s32	%rd70, %r54;
add.s64 %rd71, %rd70, %rd7;
shl.b64 %rd72, %rd71, 4;
add.s64 %rd73, %rd3, %rd72;
ld.shared.v2.f64 {%fd64, %fd65}, [%rd73];
ld.shared.v2.f64 {%fd68, %fd69}, [%rd69];
fma.rn.f64 %fd72, %fd64, %fd12, %fd68;
fma.rn.f64 %fd73, %fd65, %fd12, %fd69;
mul.f64 %fd74, %fd65, %fd13;
fma.rn.f64 %fd75, %fd64, %fd13, %fd73;
sub.f64 %fd76, %fd72, %fd74;
st.shared.v2.f64 [%rd69], {%fd76, %fd75};
add.s32 %r75, %r75, 1;
setp.lt.s32	%p43, %r75, %r35;
@%p43 bra BB3_29;

BB3_30:
add.s32 %r63, %r63, 1;
setp.lt.s32	%p44, %r63, %r35;
mov.u32 %r76, 0;
@%p44 bra BB3_5;
bra.uni BB3_32;

BB3_31:
add.s32 %r76, %r63, 1;

BB3_32:
cvta.to.global.u64 %rd74, %rd17;
shl.b64 %rd75, %rd8, 2;
add.s64 %rd76, %rd74, %rd75;
st.global.u32 [%rd76], %r76;
setp.ge.s32	%p45, %r7, %r35;
@%p45 bra BB3_35;

cvta.to.global.u64 %rd77, %rd16;
ld.shared.u32 %r57, [%rd11];
add.s32 %r58, %r57, 1;
mad.lo.s32 %r59, %r3, %r35, %r7;
mul.wide.u32 %rd78, %r59, 4;
add.s64 %rd79, %rd77, %rd78;
st.global.u32 [%rd79], %r58;
mov.u32 %r77, 0;
@%p6 bra BB3_35;

BB3_34:
mad.lo.s32 %r60, %r77, %r36, %r7;
mul.wide.s32 %rd80, %r60, 16;
add.s64 %rd81, %rd9, %rd80;
mad.lo.s32 %r61, %r77, %r6, %r7;
cvt.s64.s32	%rd82, %r61;
add.s64 %rd83, %rd82, %rd7;
shl.b64 %rd84, %rd83, 4;
add.s64 %rd85, %rd3, %rd84;
ld.shared.v2.f64 {%fd77, %fd78}, [%rd85];
st.global.v2.f64 [%rd81], {%fd77, %fd78};
add.s32 %r77, %r77, 1;
setp.lt.s32	%p47, %r77, %r35;
@%p47 bra BB3_34;

BB3_35:
ret;
}


